{"id": "2506.19952", "pdf": "https://arxiv.org/pdf/2506.19952", "abs": "https://arxiv.org/abs/2506.19952", "authors": ["Deepon Halder", "Thanmay Jayakumar", "Raj Dabre"], "title": "CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs), despite their ability to perform few-shot\nmachine translation (MT), often lag behind dedicated MT systems trained on\nparallel corpora, which are crucial for high quality machine translation (MT).\nHowever, parallel corpora are often scarce or non-existent for low-resource\nlanguages. In this paper, we propose CycleDistill, a bootstrapping approach\nleveraging LLMs and few-shot translation to obtain high-quality MT systems.\nCycleDistill involves iteratively generating synthetic parallel corpora from\nmonolingual corpora via zero- or few-shot MT, which is then used to fine-tune\nthe model that was used for generating said data for MT. CycleDistill does not\nneed parallel corpora beyond 1 to 4 few-shot examples, and in our experiments\nfocusing on three Indian languages, by relying solely on monolingual corpora,\nit can achieve high-quality machine translation, improving upon a few-shot\nbaseline model by over 20-30 chrF points on average in the first iteration. We\nalso study the effect of leveraging softmax activations during the distillation\nprocess and observe mild improvements in translation quality.", "AI": {"tldr": "CycleDistill\u5229\u7528LLMs\u548c\u5c11\u6837\u672c\u7ffb\u8bd1\uff0c\u901a\u8fc7\u8fed\u4ee3\u751f\u6210\u5408\u6210\u5e73\u884c\u8bed\u6599\u5e93\u6765\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\uff0c\u65e0\u9700\u5927\u91cf\u5e73\u884c\u8bed\u6599\u3002", "motivation": "\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u56e0\u5e73\u884c\u8bed\u6599\u7a00\u7f3a\u800c\u96be\u4ee5\u5b9e\u73b0\u9ad8\u8d28\u91cf\u673a\u5668\u7ffb\u8bd1\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faCycleDistill\u65b9\u6cd5\uff0c\u901a\u8fc7\u96f6\u6837\u672c\u6216\u5c11\u6837\u672c\u7ffb\u8bd1\u4ece\u5355\u8bed\u8bed\u6599\u751f\u6210\u5408\u6210\u5e73\u884c\u8bed\u6599\u5e93\uff0c\u5e76\u7528\u4e8e\u5fae\u8c03\u6a21\u578b\u3002", "result": "\u5728\u4e09\u79cd\u5370\u5ea6\u8bed\u8a00\u4e0a\uff0c\u9996\u8f6e\u8fed\u4ee3\u5373\u53ef\u63d0\u534720-30 chrF\u70b9\uff0c\u4e14\u5229\u7528softmax\u6fc0\u6d3b\u80fd\u8f7b\u5fae\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\u3002", "conclusion": "CycleDistill\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u673a\u5668\u7ffb\u8bd1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.19967", "pdf": "https://arxiv.org/pdf/2506.19967", "abs": "https://arxiv.org/abs/2506.19967", "authors": ["Travis Thompson", "Seung-Hwan Lim", "Paul Liu", "Ruoying He", "Dongkuan Xu"], "title": "Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved impressive capabilities in\nlanguage understanding and generation, yet they continue to underperform on\nknowledge-intensive reasoning tasks due to limited access to structured context\nand multi-hop information. Retrieval-Augmented Generation (RAG) partially\nmitigates this by grounding generation in retrieved context, but conventional\nRAG and GraphRAG methods often fail to capture relational structure across\nnodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel\nframework that enhances LLM-based graph reasoning by applying inference-time\ncompute scaling. Our method combines sequential scaling with deep\nchain-of-thought graph traversal, and parallel scaling with majority voting\nover sampled trajectories within an interleaved reasoning-execution loop.\nExperiments on the GRBench benchmark demonstrate that our approach\nsignificantly improves multi-hop question answering performance, achieving\nsubstantial gains over both traditional GraphRAG and prior graph traversal\nbaselines. These findings suggest that inference-time scaling is a practical\nand architecture-agnostic solution for structured knowledge reasoning with LLMs", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aInference-Scaled GraphRAG\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u8ba1\u7b97\u6269\u5c55\u63d0\u5347LLM\u5728\u56fe\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u663e\u8457\u6539\u8fdb\u4e86\u591a\u8df3\u95ee\u7b54\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u56e0\u4e3a\u7f3a\u4e4f\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u548c\u591a\u8df3\u4fe1\u606f\u7684\u8bbf\u95ee\u3002", "method": "\u7ed3\u5408\u987a\u5e8f\u6269\u5c55\u548c\u6df1\u5ea6\u94fe\u5f0f\u56fe\u904d\u5386\uff0c\u4ee5\u53ca\u5e76\u884c\u6269\u5c55\u548c\u591a\u6570\u6295\u7968\u91c7\u6837\u8f68\u8ff9\uff0c\u5f62\u6210\u4ea4\u66ff\u63a8\u7406-\u6267\u884c\u5faa\u73af\u3002", "result": "\u5728GRBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edfGraphRAG\u548c\u56fe\u904d\u5386\u57fa\u7ebf\u3002", "conclusion": "\u63a8\u7406\u65f6\u6269\u5c55\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u67b6\u6784\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8eLLM\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u63a8\u7406\u3002"}}
{"id": "2506.19998", "pdf": "https://arxiv.org/pdf/2506.19998", "abs": "https://arxiv.org/abs/2506.19998", "authors": ["Xinyi Ni", "Haonan Jian", "Qiuyang Wang", "Vedanshi Chetan Shah", "Pengyu Hong"], "title": "Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation", "categories": ["cs.CL"], "comment": null, "summary": "REST APIs play important roles in enriching the action space of web agents,\nyet most API-based agents rely on curated and uniform toolsets that do not\nreflect the complexity of real-world APIs. Building tool-using agents for\narbitrary domains remains a major challenge, as it requires reading\nunstructured API documentation, testing APIs and inferring correct parameters.\nWe propose Doc2Agent, a scalable pipeline to build agents that can call\nPython-based tools generated from API documentation. Doc2Agent generates\nexecutable tools from API documentations and iteratively refines them using a\ncode agent. We evaluate our approach on real-world APIs, WebArena APIs, and\nresearch APIs, producing validated tools. We achieved a 55\\% relative\nperformance improvement with 90\\% lower cost compared to direct API calling on\nWebArena benchmark. A domain-specific agent built for glycomaterial science\nfurther demonstrates the pipeline's adaptability to complex, knowledge-rich\ntasks. Doc2Agent offers a generalizable solution for building tool agents from\nunstructured API documentation at scale.", "AI": {"tldr": "Doc2Agent\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u6d41\u7a0b\uff0c\u7528\u4e8e\u4eceAPI\u6587\u6863\u6784\u5efa\u53ef\u8c03\u7528Python\u5de5\u5177\u7684\u4ee3\u7406\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709API\u4ee3\u7406\u5de5\u5177\u96c6\u5355\u4e00\u4e14\u65e0\u6cd5\u5e94\u5bf9\u73b0\u5b9e\u590d\u6742API\u7684\u95ee\u9898\u3002", "method": "\u4eceAPI\u6587\u6863\u751f\u6210\u53ef\u6267\u884c\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u4ee3\u7801\u4ee3\u7406\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728WebArena\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u63d0\u534755%\uff0c\u6210\u672c\u964d\u4f4e90%\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u590d\u6742\u9886\u57df\u3002", "conclusion": "Doc2Agent\u4e3a\u4ece\u975e\u7ed3\u6784\u5316API\u6587\u6863\u5927\u89c4\u6a21\u6784\u5efa\u5de5\u5177\u4ee3\u7406\u63d0\u4f9b\u4e86\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.19999", "pdf": "https://arxiv.org/pdf/2506.19999", "abs": "https://arxiv.org/abs/2506.19999", "authors": ["Francesco Ignazio Re", "Andreas Opedal", "Glib Manaiev", "Mario Giulianelli", "Ryan Cotterell"], "title": "A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior", "categories": ["cs.LG", "cs.CL", "q-bio.NC"], "comment": "ACL 2025", "summary": "Reading is a process that unfolds across space and time, alternating between\nfixations where a reader focuses on a specific point in space, and saccades\nwhere a reader rapidly shifts their focus to a new point. An ansatz of\npsycholinguistics is that modeling a reader's fixations and saccades yields\ninsight into their online sentence processing. However, standard approaches to\nsuch modeling rely on aggregated eye-tracking measurements and models that\nimpose strong assumptions, ignoring much of the spatio-temporal dynamics that\noccur during reading. In this paper, we propose a more general probabilistic\nmodel of reading behavior, based on a marked spatio-temporal point process,\nthat captures not only how long fixations last, but also where they land in\nspace and when they take place in time. The saccades are modeled using a Hawkes\nprocess, which captures how each fixation excites the probability of a new\nfixation occurring near it in time and space. The duration time of fixation\nevents is modeled as a function of fixation-specific predictors convolved\nacross time, thus capturing spillover effects. Empirically, our Hawkes process\nmodel exhibits a better fit to human saccades than baselines. With respect to\nfixation durations, we observe that incorporating contextual surprisal as a\npredictor results in only a marginal improvement in the model's predictive\naccuracy. This finding suggests that surprisal theory struggles to explain\nfine-grained eye movements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u7a7a\u70b9\u8fc7\u7a0b\u7684\u9605\u8bfb\u884c\u4e3a\u6982\u7387\u6a21\u578b\uff0c\u6355\u6349\u6ce8\u89c6\u70b9\u548c\u626b\u89c6\u7684\u65f6\u7a7a\u52a8\u6001\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u805a\u5408\u7684\u773c\u52a8\u6570\u636e\uff0c\u5ffd\u7565\u4e86\u9605\u8bfb\u4e2d\u7684\u65f6\u7a7a\u52a8\u6001\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u6807\u8bb0\u7684\u65f6\u7a7a\u70b9\u8fc7\u7a0b\u548cHawkes\u8fc7\u7a0b\u5efa\u6a21\u6ce8\u89c6\u70b9\u548c\u626b\u89c6\uff0c\u8003\u8651\u65f6\u7a7a\u90bb\u8fd1\u6027\u548c\u6ea2\u51fa\u6548\u5e94\u3002", "result": "Hawkes\u8fc7\u7a0b\u6a21\u578b\u5bf9\u626b\u89c6\u7684\u62df\u5408\u4f18\u4e8e\u57fa\u7ebf\uff1b\u6ce8\u89c6\u65f6\u95f4\u6a21\u578b\u4e2d\uff0c\u4e0a\u4e0b\u6587\u60ca\u8bb6\u5ea6\u4ec5\u5e26\u6765\u8fb9\u9645\u6539\u8fdb\u3002", "conclusion": "\u60ca\u8bb6\u5ea6\u7406\u8bba\u96be\u4ee5\u89e3\u91ca\u7cbe\u7ec6\u773c\u52a8\u884c\u4e3a\uff0c\u65b0\u6a21\u578b\u66f4\u5168\u9762\u5730\u6355\u6349\u9605\u8bfb\u52a8\u6001\u3002"}}
{"id": "2506.19923", "pdf": "https://arxiv.org/pdf/2506.19923", "abs": "https://arxiv.org/abs/2506.19923", "authors": ["Kaito Baba", "Chaoran Liu", "Shuhei Kurita", "Akiyoshi Sannai"], "title": "Prover Agent: An Agent-based Framework for Formal Mathematical Proofs", "categories": ["cs.AI", "cs.LG"], "comment": "22 pages, 2 figures", "summary": "We present Prover Agent, a novel AI agent for automated theorem proving that\nintegrates large language models (LLMs) with a formal proof assistant, Lean.\nProver Agent coordinates an informal reasoning LLM, a formal prover model, and\nfeedback from Lean while also generating auxiliary lemmas to assist in\ndiscovering the overall proof strategy. It achieves an 86.1% success rate on\nthe MiniF2F benchmark, establishing a new state-of-the-art among methods using\nsmall language models (SLMs) with a much lower sample budget than previous\napproaches. We also present case studies illustrating how these generated\nlemmas contribute to solving challenging problems.", "AI": {"tldr": "Prover Agent\u662f\u4e00\u79cd\u65b0\u578bAI\u4ee3\u7406\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u5f62\u5f0f\u5316\u8bc1\u660e\u52a9\u624bLean\uff0c\u5b9e\u73b0\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\uff0c\u6210\u529f\u7387\u8fbe86.1%\u3002", "motivation": "\u5c06LLMs\u4e0e\u5f62\u5f0f\u5316\u8bc1\u660e\u5de5\u5177\u7ed3\u5408\uff0c\u63d0\u5347\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u7684\u6548\u7387\u548c\u6210\u529f\u7387\u3002", "method": "\u6574\u5408\u975e\u6b63\u5f0f\u63a8\u7406LLM\u3001\u5f62\u5f0f\u5316\u8bc1\u660e\u6a21\u578b\u548cLean\u53cd\u9988\uff0c\u751f\u6210\u8f85\u52a9\u5f15\u7406\u4ee5\u8f85\u52a9\u8bc1\u660e\u7b56\u7565\u3002", "result": "\u5728MiniF2F\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523086.1%\u7684\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6\u4f7f\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "conclusion": "Prover Agent\u5c55\u793a\u4e86\u7ed3\u5408LLMs\u548c\u5f62\u5f0f\u5316\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u4e3a\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.19993", "pdf": "https://arxiv.org/pdf/2506.19993", "abs": "https://arxiv.org/abs/2506.19993", "authors": ["Haochen Zhang", "Tianyi Zhang", "Junze Yin", "Oren Gal", "Anshumali Shrivastava", "Vladimir Braverman"], "title": "CoVE: Compressed Vocabulary Expansion Makes Better LLM-based Recommender Systems", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted by ACL 2025 Findings", "summary": "Recommender systems play a pivotal role in providing relevant content to\nusers. With the rapid development of large language models (LLMs), researchers\nhave begun utilizing LLMs to build more powerful recommender systems. However,\nexisting approaches that focus on aligning LLMs with recommendation tasks do\nnot fully leverage their sequential information processing capabilities,\nleading to suboptimal performance.\n  In this paper, we propose a novel system called compressed vocabulary\nexpansion (CoVE). In CoVE, each item is assigned a unique ID within the\nexpanded vocabulary. Our framework effectively capitalizes on sequence\nunderstanding abilities of LLMs, significantly enhancing their performance on\nrecommendation tasks. Additionally, we compress the embedding layer, making\nCoVE practical for large-scale industrial applications. The effectiveness and\nperformance of CoVE are demonstrated through comprehensive experiments on\nmultiple recommendation datasets and comparisons with prior works. Our code can\nbe found at https://github.com/HaochenZhang717/CoVE-official-Repo.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCoVE\u7684\u65b0\u7cfb\u7edf\uff0c\u901a\u8fc7\u538b\u7f29\u8bcd\u6c47\u6269\u5c55\u548c\u5229\u7528LLM\u7684\u5e8f\u5217\u7406\u89e3\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528LLM\u7684\u5e8f\u5217\u4fe1\u606f\u5904\u7406\u80fd\u529b\uff0c\u5bfc\u81f4\u63a8\u8350\u4efb\u52a1\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u4e3a\u6bcf\u4e2a\u9879\u76ee\u5206\u914d\u552f\u4e00ID\uff0c\u6269\u5c55\u8bcd\u6c47\u8868\uff0c\u5e76\u538b\u7f29\u5d4c\u5165\u5c42\u4ee5\u9002\u914d\u5927\u89c4\u6a21\u5e94\u7528\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u8350\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86CoVE\u7684\u6709\u6548\u6027\u548c\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "CoVE\u901a\u8fc7\u4f18\u5316LLM\u7684\u5e8f\u5217\u5904\u7406\u80fd\u529b\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.19882", "pdf": "https://arxiv.org/pdf/2506.19882", "abs": "https://arxiv.org/abs/2506.19882", "authors": ["Rylan Schaeffer", "Joshua Kazdan", "Yegor Denisov-Blanch", "Brando Miranda", "Matthias Gerstgrasser", "Susan Zhang", "Andreas Haupt", "Isha Gupta", "Elyas Obbad", "Jesse Dodge", "Jessica Zosa Forde", "Koustuv Sinha", "Francesco Orabona", "Sanmi Koyejo", "David Donoho"], "title": "Position: Machine Learning Conferences Should Establish a \"Refutations and Critiques\" Track", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Science progresses by iteratively advancing and correcting humanity's\nunderstanding of the world. In machine learning (ML) research, rapid\nadvancements have led to an explosion of publications, but have also led to\nmisleading, incorrect, flawed or perhaps even fraudulent studies being accepted\nand sometimes highlighted at ML conferences due to the fallibility of peer\nreview. While such mistakes are understandable, ML conferences do not offer\nrobust processes to help the field systematically correct when such errors are\nmade.This position paper argues that ML conferences should establish a\ndedicated \"Refutations and Critiques\" (R & C) Track. This R & C Track would\nprovide a high-profile, reputable platform to support vital research that\ncritically challenges prior research, thereby fostering a dynamic\nself-correcting research ecosystem. We discuss key considerations including\ntrack design, review principles, potential pitfalls, and provide an\nillustrative example submission concerning a recent ICLR 2025 Oral. We conclude\nthat ML conferences should create official, reputable mechanisms to help ML\nresearch self-correct.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u673a\u5668\u5b66\u4e60\u4f1a\u8bae\u5e94\u8bbe\u7acb\u4e13\u95e8\u7684\u201c\u53cd\u9a73\u4e0e\u6279\u8bc4\u201d\u8f68\u9053\uff0c\u4ee5\u7cfb\u7edf\u6027\u7ea0\u6b63\u7814\u7a76\u4e2d\u7684\u9519\u8bef\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7814\u7a76\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u5b58\u5728\u8bef\u5bfc\u6027\u3001\u9519\u8bef\u6216\u6b3a\u8bc8\u6027\u7814\u7a76\u88ab\u63a5\u53d7\u7684\u95ee\u9898\uff0c\u7f3a\u4e4f\u7ea0\u6b63\u673a\u5236\u3002", "method": "\u63d0\u51fa\u5728\u4f1a\u8bae\u4e2d\u8bbe\u7acb\u201c\u53cd\u9a73\u4e0e\u6279\u8bc4\u201d\u8f68\u9053\uff0c\u8ba8\u8bba\u5176\u8bbe\u8ba1\u3001\u8bc4\u5ba1\u539f\u5219\u53ca\u6f5c\u5728\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u9ad8\u58f0\u8a89\u5e73\u53f0\u652f\u6301\u6279\u5224\u6027\u7814\u7a76\uff0c\u4fc3\u8fdb\u7814\u7a76\u751f\u6001\u7684\u81ea\u6211\u4fee\u6b63\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u4f1a\u8bae\u5e94\u5efa\u7acb\u5b98\u65b9\u673a\u5236\uff0c\u5e2e\u52a9\u7814\u7a76\u81ea\u6211\u7ea0\u6b63\u3002"}}
{"id": "2506.20073", "pdf": "https://arxiv.org/pdf/2506.20073", "abs": "https://arxiv.org/abs/2506.20073", "authors": ["Kethmi Hirushini Hettige", "Jiahao Ji", "Cheng Long", "Shili Xiang", "Gao Cong", "Jingyuan Wang"], "title": "A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Spatio-temporal data mining plays a pivotal role in informed decision making\nacross diverse domains. However, existing models are often restricted to narrow\ntasks, lacking the capacity for multi-task inference and complex long-form\nreasoning that require generation of in-depth, explanatory outputs. These\nlimitations restrict their applicability to real-world, multi-faceted decision\nscenarios. In this work, we introduce STReason, a novel framework that\nintegrates the reasoning strengths of large language models (LLMs) with the\nanalytical capabilities of spatio-temporal models for multi-task inference and\nexecution. Without requiring task-specific finetuning, STReason leverages\nin-context learning to decompose complex natural language queries into modular,\ninterpretable programs, which are then systematically executed to generate both\nsolutions and detailed rationales. To facilitate rigorous evaluation, we\nconstruct a new benchmark dataset and propose a unified evaluation framework\nwith metrics specifically designed for long-form spatio-temporal reasoning.\nExperimental results show that STReason significantly outperforms advanced LLM\nbaselines across all metrics, particularly excelling in complex,\nreasoning-intensive spatio-temporal scenarios. Human evaluations further\nvalidate STReason's credibility and practical utility, demonstrating its\npotential to reduce expert workload and broaden the applicability to real-world\nspatio-temporal tasks. We believe STReason provides a promising direction for\ndeveloping more capable and generalizable spatio-temporal reasoning systems.", "AI": {"tldr": "STReason\u662f\u4e00\u4e2a\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u65f6\u7a7a\u6a21\u578b\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u4efb\u52a1\u63a8\u7406\u548c\u590d\u6742\u65f6\u7a7a\u6570\u636e\u5206\u6790\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u5373\u53ef\u751f\u6210\u8be6\u7ec6\u89e3\u91ca\u548c\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u65f6\u7a7a\u6570\u636e\u6316\u6398\u6a21\u578b\u5c40\u9650\u4e8e\u5355\u4e00\u4efb\u52a1\uff0c\u7f3a\u4e4f\u591a\u4efb\u52a1\u63a8\u7406\u548c\u590d\u6742\u957f\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u51b3\u7b56\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "method": "STReason\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u5c06\u590d\u6742\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5206\u89e3\u4e3a\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u7684\u7a0b\u5e8f\uff0c\u5e76\u7cfb\u7edf\u6267\u884c\u4ee5\u751f\u6210\u89e3\u51b3\u65b9\u6848\u548c\u8be6\u7ec6\u7406\u7531\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSTReason\u5728\u590d\u6742\u65f6\u7a7a\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u57fa\u7ebf\uff0c\u5e76\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u5176\u53ef\u4fe1\u5ea6\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "STReason\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u66f4\u901a\u7528\u7684\u65f6\u7a7a\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2506.19977", "pdf": "https://arxiv.org/pdf/2506.19977", "abs": "https://arxiv.org/abs/2506.19977", "authors": ["Deng Pan", "Keerthiram Murugesan", "Nuno Moniz", "Nitesh Chawla"], "title": "Context Attribution with Multi-Armed Bandit Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Understanding which parts of the retrieved context contribute to a large\nlanguage model's generated answer is essential for building interpretable and\ntrustworthy generative QA systems. We propose a novel framework that formulates\ncontext attribution as a combinatorial multi-armed bandit (CMAB) problem. Each\ncontext segment is treated as a bandit arm, and we employ Combinatorial\nThompson Sampling (CTS) to efficiently explore the exponentially large space of\ncontext subsets under a limited query budget. Our method defines a reward\nfunction based on normalized token likelihoods, capturing how well a subset of\nsegments supports the original model response. Unlike traditional\nperturbation-based attribution methods such as SHAP, which sample subsets\nuniformly and incur high computational costs, our approach adaptively balances\nexploration and exploitation by leveraging posterior estimates of segment\nrelevance. This leads to substantially improved query efficiency while\nmaintaining high attribution fidelity. Extensive experiments on diverse\ndatasets and LLMs demonstrate that our method achieves competitive attribution\nquality with fewer model queries.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\uff08CMAB\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u63a2\u7d22\u4e0a\u4e0b\u6587\u5b50\u96c6\uff0c\u4ee5\u7406\u89e3\u751f\u6210\u5f0fQA\u7cfb\u7edf\u4e2d\u4e0a\u4e0b\u6587\u5bf9\u6a21\u578b\u56de\u7b54\u7684\u8d21\u732e\u3002", "motivation": "\u63d0\u9ad8\u751f\u6210\u5f0fQA\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u901a\u8fc7\u7406\u89e3\u4e0a\u4e0b\u6587\u5bf9\u6a21\u578b\u56de\u7b54\u7684\u5177\u4f53\u8d21\u732e\u3002", "method": "\u5c06\u4e0a\u4e0b\u6587\u6bb5\u89c6\u4e3a\u8001\u864e\u673a\u81c2\uff0c\u4f7f\u7528\u7ec4\u5408\u6c64\u666e\u68ee\u91c7\u6837\uff08CTS\uff09\u5728\u6709\u9650\u67e5\u8be2\u9884\u7b97\u4e0b\u9ad8\u6548\u63a2\u7d22\u4e0a\u4e0b\u6587\u5b50\u96c6\uff0c\u5b9a\u4e49\u57fa\u4e8e\u5f52\u4e00\u5316\u6807\u8bb0\u4f3c\u7136\u7684\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u6a21\u578b\u67e5\u8be2\u6b21\u6570\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u9ad8\u5f52\u56e0\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u9ad8\u6548\u6027\u548c\u5f52\u56e0\u8d28\u91cf\u4e0a\u4f18\u4e8e\u4f20\u7edf\u6270\u52a8\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6570\u636e\u96c6\u548cLLM\u3002"}}
{"id": "2506.20051", "pdf": "https://arxiv.org/pdf/2506.20051", "abs": "https://arxiv.org/abs/2506.20051", "authors": ["Jia-Huei Ju", "Suzan Verberne", "Maarten de Rijke", "Andrew Yates"], "title": "Controlled Retrieval-augmented Context Evaluation for Long-form RAG", "categories": ["cs.IR"], "comment": null, "summary": "Retrieval-augmented generation (RAG) enhances large language models by\nincorporating context retrieved from external knowledge sources. While the\neffectiveness of the retrieval module is typically evaluated with\nrelevance-based ranking metrics, such metrics may be insufficient to reflect\nthe retrieval's impact on the final RAG result, especially in long-form\ngeneration scenarios. We argue that providing a comprehensive\nretrieval-augmented context is important for long-form RAG tasks like report\ngeneration and propose metrics for assessing the context independent of\ngeneration. We introduce CRUX, a \\textbf{C}ontrolled\n\\textbf{R}etrieval-a\\textbf{U}gmented conte\\textbf{X}t evaluation framework\ndesigned to directly assess retrieval-augmented contexts. This framework uses\nhuman-written summaries to control the information scope of knowledge, enabling\nus to measure how well the context covers information essential for long-form\ngeneration. CRUX uses question-based evaluation to assess RAG's retrieval in a\nfine-grained manner. Empirical results show that CRUX offers more reflective\nand diagnostic evaluation. Our findings also reveal substantial room for\nimprovement in current retrieval methods, pointing to promising directions for\nadvancing RAG's retrieval. Our data and code are publicly available to support\nand advance future research on retrieval.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86CRUX\u6846\u67b6\uff0c\u7528\u4e8e\u76f4\u63a5\u8bc4\u4f30\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e2d\u7684\u68c0\u7d22\u4e0a\u4e0b\u6587\uff0c\u7279\u522b\u9488\u5bf9\u957f\u6587\u672c\u751f\u6210\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u68c0\u7d22\u8bc4\u4f30\u6307\u6807\u4e0d\u8db3\u4ee5\u53cd\u6620\u68c0\u7d22\u5bf9\u6700\u7ec8RAG\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u5728\u957f\u6587\u672c\u751f\u6210\u573a\u666f\u4e2d\u3002", "method": "\u5f15\u5165CRUX\u6846\u67b6\uff0c\u5229\u7528\u4eba\u5de5\u7f16\u5199\u7684\u6458\u8981\u63a7\u5236\u4fe1\u606f\u8303\u56f4\uff0c\u901a\u8fc7\u95ee\u9898\u8bc4\u4f30\u7ec6\u7c92\u5ea6\u8861\u91cf\u68c0\u7d22\u4e0a\u4e0b\u6587\u7684\u8d28\u91cf\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660eCRUX\u63d0\u4f9b\u4e86\u66f4\u5177\u53cd\u601d\u6027\u548c\u8bca\u65ad\u6027\u7684\u8bc4\u4f30\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524d\u68c0\u7d22\u65b9\u6cd5\u7684\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "CRUX\u4e3aRAG\u7684\u68c0\u7d22\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u6570\u636e\u548c\u4ee3\u7801\u516c\u5f00\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2506.19883", "pdf": "https://arxiv.org/pdf/2506.19883", "abs": "https://arxiv.org/abs/2506.19883", "authors": ["Zhuqing Liu", "Chaosheng Dong", "Michinari Momma", "Simone Shao", "Shaoyuan Xu", "Yan Gao", "Haibo Yang", "Jia Liu"], "title": "STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, multi-objective optimization (MOO) has gained attention for its\nbroad applications in ML, operations research, and engineering. However, MOO\nalgorithm design remains in its infancy and many existing MOO methods suffer\nfrom unsatisfactory convergence rate and sample complexity performance. To\naddress this challenge, in this paper, we propose an algorithm called STIMULUS(\nstochastic path-integrated multi-gradient recursive e\\ulstimator), a new and\nrobust approach for solving MOO problems. Different from the traditional\nmethods, STIMULUS introduces a simple yet powerful recursive framework for\nupdating stochastic gradient estimates to improve convergence performance with\nlow sample complexity. In addition, we introduce an enhanced version of\nSTIMULUS, termed STIMULUS-M, which incorporates a momentum term to further\nexpedite convergence. We establish $O(1/T)$ convergence rates of the proposed\nmethods for non-convex settings and $O (\\exp{-\\mu T})$ for strongly convex\nsettings, where $T$ is the total number of iteration rounds. Additionally, we\nachieve the state-of-the-art $O \\left(n+\\sqrt{n}\\epsilon^{-1}\\right)$ sample\ncomplexities for non-convex settings and $O\\left(n+ \\sqrt{n} \\ln\n({\\mu/\\epsilon})\\right)$ for strongly convex settings, where $\\epsilon>0$ is a\ndesired stationarity error. Moreover, to alleviate the periodic full gradient\nevaluation requirement in STIMULUS and STIMULUS-M, we further propose enhanced\nversions with adaptive batching called STIMULUS+/ STIMULUS-M+ and provide their\ntheoretical analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSTIMULUS\u7684\u65b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u9012\u5f52\u6846\u67b6\u66f4\u65b0\u68af\u5ea6\u4f30\u8ba1\uff0c\u63d0\u9ad8\u4e86\u6536\u655b\u6027\u80fd\u548c\u6837\u672c\u6548\u7387\u3002\u8fd8\u63d0\u51fa\u4e86\u589e\u5f3a\u7248\u672cSTIMULUS-M\u548c\u81ea\u9002\u5e94\u6279\u5904\u7406\u7248\u672cSTIMULUS+/STIMULUS-M+\u3002", "motivation": "\u591a\u76ee\u6807\u4f18\u5316\u5728\u591a\u4e2a\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6536\u655b\u901f\u5ea6\u548c\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "STIMULUS\u91c7\u7528\u9012\u5f52\u6846\u67b6\u66f4\u65b0\u68af\u5ea6\u4f30\u8ba1\uff0cSTIMULUS-M\u52a0\u5165\u52a8\u91cf\u9879\uff0cSTIMULUS+/STIMULUS-M+\u5f15\u5165\u81ea\u9002\u5e94\u6279\u5904\u7406\u3002", "result": "\u5728\u975e\u51f8\u548c\u5f3a\u51f8\u8bbe\u7f6e\u4e0b\u5206\u522b\u8fbe\u5230O(1/T)\u548cO(exp{-\u03bcT})\u7684\u6536\u655b\u901f\u5ea6\uff0c\u6837\u672c\u590d\u6742\u5ea6\u8fbe\u5230\u5f53\u524d\u6700\u4f18\u6c34\u5e73\u3002", "conclusion": "STIMULUS\u7cfb\u5217\u7b97\u6cd5\u5728\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6536\u655b\u6027\u80fd\u548c\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2506.20081", "pdf": "https://arxiv.org/pdf/2506.20081", "abs": "https://arxiv.org/abs/2506.20081", "authors": ["Dhruv Gupta", "Gayathri Ganesh Lakshmy", "Yiqing Xie"], "title": "SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Code Generation (RACG) is a critical technique for\nenhancing code generation by retrieving relevant information. In this work, we\nconduct an in-depth analysis of code retrieval by systematically masking\nspecific features while preserving code functionality. Our discoveries include:\n(1) although trained on code, current retrievers heavily rely on surface-level\ntextual features (e.g., docstrings, identifier names), and (2) they exhibit a\nstrong bias towards well-documented code, even if the documentation is\nirrelevant.Based on our discoveries, we propose SACL, a framework that enriches\ntextual information and reduces bias by augmenting code or structural knowledge\nwith semantic information. Extensive experiments show that SACL substantially\nimproves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval /\nMBPP / SWE-Bench-Lite), which also leads to better code generation performance\n(e.g., by 4.88% Pass@1 on HumanEval).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSACL\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u4ee3\u7801\u6216\u7ed3\u6784\u77e5\u8bc6\u4e2d\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u51cf\u5c11\u68c0\u7d22\u504f\u5dee\u5e76\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSACL\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u68c0\u7d22\u548c\u751f\u6210\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u68c0\u7d22\u5668\u8fc7\u4e8e\u4f9d\u8d56\u8868\u9762\u6587\u672c\u7279\u5f81\uff08\u5982\u6587\u6863\u5b57\u7b26\u4e32\u3001\u6807\u8bc6\u7b26\u540d\u79f0\uff09\uff0c\u5e76\u5bf9\u6587\u6863\u4e30\u5bcc\u7684\u4ee3\u7801\u5b58\u5728\u5f3a\u70c8\u504f\u89c1\uff0c\u5373\u4f7f\u6587\u6863\u65e0\u5173\u3002\u8fd9\u9650\u5236\u4e86\u4ee3\u7801\u751f\u6210\u7684\u6548\u679c\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u5c4f\u853d\u7279\u5b9a\u7279\u5f81\u4f46\u4fdd\u7559\u4ee3\u7801\u529f\u80fd\uff0c\u5206\u6790\u4ee3\u7801\u68c0\u7d22\u884c\u4e3a\uff0c\u5e76\u63d0\u51fa\u4e86SACL\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u589e\u5f3a\u8bed\u4e49\u4fe1\u606f\u6765\u51cf\u5c11\u504f\u5dee\u3002", "result": "SACL\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u68c0\u7d22\u6027\u80fd\uff08\u5982HumanEval / MBPP / SWE-Bench-Lite\u4e0a\u7684Recall@1\u5206\u522b\u63d0\u9ad8\u4e8612.8% / 9.4% / 7.0%\uff09\uff0c\u5e76\u8fdb\u4e00\u6b65\u6539\u5584\u4e86\u4ee3\u7801\u751f\u6210\u6027\u80fd\uff08\u5982HumanEval\u4e0a\u7684Pass@1\u63d0\u9ad8\u4e864.88%\uff09\u3002", "conclusion": "SACL\u901a\u8fc7\u589e\u5f3a\u8bed\u4e49\u4fe1\u606f\u6709\u6548\u51cf\u5c11\u4e86\u4ee3\u7801\u68c0\u7d22\u4e2d\u7684\u504f\u5dee\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u548c\u751f\u6210\u6027\u80fd\uff0c\u4e3a\u4ee3\u7801\u751f\u6210\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2506.20008", "pdf": "https://arxiv.org/pdf/2506.20008", "abs": "https://arxiv.org/abs/2506.20008", "authors": ["Abdul Basit", "Minghao Shao", "Haider Asif", "Nouhaila Innan", "Muhammad Kashif", "Alberto Marchisio", "Muhammad Shafique"], "title": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "categories": ["cs.AI", "cs.PL", "cs.SE", "68T50, 81P68, 68T07, 68T20", "I.2.7; I.2.2"], "comment": "8 pages, 6 figures, 3 tables, submitted to QAI 2025", "summary": "Recent advances in Large Language Models (LLMs) have demonstrated strong\npotential in code generation, yet their effectiveness in quantum computing\nremains underexplored. This paper benchmarks LLMs for PennyLane-based quantum\ncode generation using real-world challenges from the Quantum Hackathon (QHack).\nWe introduce QHackBench, a novel benchmark dataset derived from QHack\ncompetitions, and evaluate model performance under vanilla prompting and\nRetrieval-Augmented Generation (RAG). Our structured evaluation framework\nassesses functional correctness, syntactic validity, and execution success\nacross varying challenge difficulties. Results indicate that RAG-enhanced\nmodels, supplemented with an augmented PennyLane dataset, approximately\ngenerate similar results as the standard prompting, particularly in complex\nquantum algorithms. Additionally, we introduce a multi-agent evaluation\npipeline that iteratively refines incorrect solutions, further enhancing\nexecution success rates. To foster further research, we commit to publicly\nreleasing QHackBench, along with our evaluation framework and experimental\nresults, enabling continued advancements in AI-assisted quantum programming.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728PennyLane\u91cf\u5b50\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u5f15\u5165QHackBench\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u6bd4\u8f83\u4e86\u6807\u51c6\u63d0\u793a\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u6548\u679c\u3002\u7ed3\u679c\u8868\u660eRAG\u5728\u590d\u6742\u91cf\u5b50\u7b97\u6cd5\u4e2d\u8868\u73b0\u63a5\u8fd1\u6807\u51c6\u63d0\u793a\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53\u8bc4\u4f30\u7ba1\u9053\u4ee5\u63d0\u9ad8\u6210\u529f\u7387\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u91cf\u5b50\u8ba1\u7b97\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u6f5c\u529b\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u4f7f\u7528QHack\u7ade\u8d5b\u7684\u771f\u5b9e\u6311\u6218\u6784\u5efaQHackBench\u6570\u636e\u96c6\uff0c\u8bc4\u4f30LLMs\u5728\u6807\u51c6\u63d0\u793a\u548cRAG\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u5f15\u5165\u591a\u667a\u80fd\u4f53\u8bc4\u4f30\u7ba1\u9053\u3002", "result": "RAG\u589e\u5f3a\u6a21\u578b\u5728\u590d\u6742\u91cf\u5b50\u7b97\u6cd5\u4e2d\u8868\u73b0\u63a5\u8fd1\u6807\u51c6\u63d0\u793a\uff0c\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6267\u884c\u6210\u529f\u7387\u3002", "conclusion": "QHackBench\u548c\u8bc4\u4f30\u6846\u67b6\u7684\u516c\u5f00\u5c06\u4fc3\u8fdbAI\u8f85\u52a9\u91cf\u5b50\u7f16\u7a0b\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2506.20070", "pdf": "https://arxiv.org/pdf/2506.20070", "abs": "https://arxiv.org/abs/2506.20070", "authors": ["KMA Solaiman", "Bharat Bhargava"], "title": "Multimodal Information Retrieval for Open World with Edit Distance Weak Supervision", "categories": ["cs.IR", "cs.LG", "cs.MM"], "comment": "Submitted to ICDE'24. An earlier version of this paper appeared on\n  TechRxiv: https://www.techrxiv.org/doi/full/10.36227/techrxiv.21990284.v1,\n  uploaded on February 05, 2023", "summary": "Existing multi-media retrieval models either rely on creating a common\nsubspace with modality-specific representation models or require schema mapping\namong modalities to measure similarities among multi-media data. Our goal is to\navoid the annotation overhead incurred from considering retrieval as a\nsupervised classification task and re-use the pretrained encoders in large\nlanguage models and vision tasks. We propose \"FemmIR\", a framework to retrieve\nmultimodal results relevant to information needs expressed with multimodal\nqueries by example without any similarity label. Such identification is\nnecessary for real-world applications where data annotations are scarce and\nsatisfactory performance is required without fine-tuning with a common\nframework across applications. We curate a new dataset called MuQNOL for\nbenchmarking progress on this task. Our technique is based on weak supervision\nintroduced through edit distance between samples: graph edit distance can be\nmodified to consider the cost of replacing a data sample in terms of its\nproperties, and relevance can be measured through the implicit signal from the\namount of edit cost among the objects. Unlike metric learning or encoding\nnetworks, FemmIR re-uses the high-level properties and maintains the property\nvalue and relationship constraints with a multi-level interaction score between\ndata samples and the query example provided by the user. We empirically\nevaluate FemmIR on a missing person use case with MuQNOL. FemmIR performs\ncomparably to similar retrieval systems in delivering on-demand retrieval\nresults with exact and approximate similarities while using the existing\nproperty identifiers in the system.", "AI": {"tldr": "FemmIR\u662f\u4e00\u4e2a\u65e0\u9700\u6807\u6ce8\u76f8\u4f3c\u6027\u6807\u7b7e\u7684\u591a\u5a92\u4f53\u68c0\u7d22\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u548c\u5f31\u76d1\u7763\u65b9\u6cd5\u5b9e\u73b0\u8de8\u6a21\u6001\u68c0\u7d22\u3002", "motivation": "\u907f\u514d\u4f20\u7edf\u591a\u5a92\u4f53\u68c0\u7d22\u6a21\u578b\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u5229\u7528\u73b0\u6709\u9884\u8bad\u7ec3\u6a21\u578b\u51cf\u5c11\u6807\u6ce8\u5f00\u9500\u3002", "method": "\u57fa\u4e8e\u7f16\u8f91\u8ddd\u79bb\u7684\u5f31\u76d1\u7763\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u7ea7\u4ea4\u4e92\u8bc4\u5206\u8861\u91cf\u6837\u672c\u4e0e\u67e5\u8be2\u793a\u4f8b\u7684\u76f8\u5173\u6027\u3002", "result": "\u5728MuQNOL\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4e0e\u73b0\u6709\u68c0\u7d22\u7cfb\u7edf\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "FemmIR\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u6807\u6ce8\u7684\u9ad8\u6548\u8de8\u6a21\u6001\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.19885", "pdf": "https://arxiv.org/pdf/2506.19885", "abs": "https://arxiv.org/abs/2506.19885", "authors": ["Jing Lu", "Xuan Wu", "Yizhun Tian", "Songhan Fan", "Yali Fang"], "title": "FlightKooba: A Fast Interpretable FTP Model", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "7 figures", "summary": "The Koopman theory is a powerful and effective modeling tool for converting\nnonlinear systems into linear representations, and flight trajectory prediction\n(FTP) is a complex nonlinear system. However, current models applying the\nKoopman theory to FTP tasks are not very effective, model interpretability is\nindeed an issue, and the Koopman operators are computationally intensive,\nresulting in long training times. To address this issue, this paper proposes a\nnew modeling and control framework based on the HIPPO method, the Koopman\ntheory, and state space equations from cybernetics: FlightKooba. Inspired by\nthe idea of structural state space equations, FlightKooba directly constructs\nthe Koopman operators from data. This makes the framework highly interpretable\nand significantly reduces the number of trainable parameters in the module,\nthereby greatly reducing training time. Experiments have demonstrated the\nsuperiority of the FlightKooba modeling method in terms of time and memory\nconsumption (training time comparable to the Mamba module without using\nCUDA-level acceleration; memory reduced by more than 50% on most datasets, with\na tenfold reduction in the number of parameters), essentially completing the\nFTP task. It provides a new method for the fast computation of the Koopman\noperators, opening up new possibilities for the combination of time series\nforecasting and control.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFlightKooba\u6846\u67b6\uff0c\u7ed3\u5408HIPPO\u65b9\u6cd5\u3001Koopman\u7406\u8bba\u548c\u72b6\u6001\u7a7a\u95f4\u65b9\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u98de\u884c\u8f68\u8ff9\u9884\u6d4b\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eKoopman\u7406\u8bba\u7684\u98de\u884c\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u6548\u7387\u4f4e\u3001\u53ef\u89e3\u91ca\u6027\u5dee\uff0c\u8ba1\u7b97\u91cf\u5927\u3002", "method": "\u7ed3\u5408HIPPO\u65b9\u6cd5\u3001Koopman\u7406\u8bba\u548c\u72b6\u6001\u7a7a\u95f4\u65b9\u7a0b\uff0c\u76f4\u63a5\u4ece\u6570\u636e\u6784\u5efaKoopman\u7b97\u5b50\uff0c\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "result": "\u8bad\u7ec3\u65f6\u95f4\u63a5\u8fd1Mamba\u6a21\u5757\uff08\u65e0CUDA\u52a0\u901f\uff09\uff0c\u5185\u5b58\u51cf\u5c1150%\u4ee5\u4e0a\uff0c\u53c2\u6570\u51cf\u5c1110\u500d\u3002", "conclusion": "FlightKooba\u4e3aKoopman\u7b97\u5b50\u5feb\u901f\u8ba1\u7b97\u63d0\u4f9b\u65b0\u65b9\u6cd5\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e0e\u63a7\u5236\u7ed3\u5408\u5f00\u8f9f\u65b0\u53ef\u80fd\u3002"}}
{"id": "2506.20083", "pdf": "https://arxiv.org/pdf/2506.20083", "abs": "https://arxiv.org/abs/2506.20083", "authors": ["Yingji Zhang", "Danilo S. Carvalho", "Andr\u00e9 Freitas"], "title": "Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder", "categories": ["cs.CL"], "comment": "In progress", "summary": "Integrating compositional and symbolic properties into current distributional\nsemantic spaces can enhance the interpretability, controllability,\ncompositionality, and generalisation capabilities of Transformer-based\nauto-regressive language models (LMs). In this survey, we offer a novel\nperspective on latent space geometry through the lens of compositional\nsemantics, a direction we refer to as \\textit{semantic representation\nlearning}. This direction enables a bridge between symbolic and distributional\nsemantics, helping to mitigate the gap between them. We review and compare\nthree mainstream autoencoder architectures-Variational AutoEncoder (VAE),\nVector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the\ndistinctive latent geometries they induce in relation to semantic structure and\ninterpretability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u7ed3\u5408\u7ec4\u5408\u548c\u7b26\u53f7\u7279\u6027\u6765\u63d0\u5347\u57fa\u4e8eTransformer\u7684\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u91ca\u6027\u3001\u53ef\u63a7\u6027\u3001\u7ec4\u5408\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f25\u5408\u7b26\u53f7\u8bed\u4e49\u548c\u5206\u5e03\u8bed\u4e49\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u8868\u793a\u80fd\u529b\u3002", "method": "\u7efc\u8ff0\u4e86\u4e09\u79cd\u4e3b\u6d41\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff08VAE\u3001VQVAE\u3001SAE\uff09\uff0c\u5e76\u5206\u6790\u4e86\u5b83\u4eec\u5728\u8bed\u4e49\u7ed3\u6784\u548c\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6f5c\u5728\u51e0\u4f55\u7279\u6027\u3002", "result": "\u901a\u8fc7\u8bed\u4e49\u8868\u793a\u5b66\u4e60\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\u51e0\u4f55\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002", "conclusion": "\u7ed3\u5408\u7ec4\u5408\u548c\u7b26\u53f7\u7279\u6027\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u8868\u793a\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.20009", "pdf": "https://arxiv.org/pdf/2506.20009", "abs": "https://arxiv.org/abs/2506.20009", "authors": ["Konstantinos Vrettos", "Michail E. Klontzas"], "title": "Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks", "categories": ["cs.AI", "cs.CL", "I.2.7"], "comment": "18 pages, 3 Figures", "summary": "Background The increasing adoption of Artificial Intelligence (AI) in\nhealthcare has sparked growing concerns about its environmental and ethical\nimplications. Commercial Large Language Models (LLMs), such as ChatGPT and\nDeepSeek, require substantial resources, while the utilization of these systems\nfor medical purposes raises critical issues regarding patient privacy and\nsafety. Methods We developed a customizable Retrieval-Augmented Generation\n(RAG) framework for medical tasks, which monitors its energy usage and CO2\nemissions. This system was then used to create RAGs based on various\nopen-source LLMs. The tested models included both general purpose models like\nllama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs\nperformance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs\no4-mini model. A dataset of medical questions was used for the evaluation.\nResults Custom RAG models outperformed commercial models in accuracy and energy\nconsumption. The RAG model built on llama3.1:8B achieved the highest accuracy\n(58.5%) and was significantly better than other models, including o4-mini and\nDeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption\nand CO2 footprint among all models, with a Performance per kWh of 0.52 and a\ntotal CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x\ntimes more accuracy points per kWh and 172% less electricity usage while\nmaintaining higher accuracy. Conclusion Our study demonstrates that local LLMs\ncan be leveraged to develop RAGs that outperform commercial, online LLMs in\nmedical tasks, while having a smaller environmental impact. Our modular\nframework promotes sustainable AI development, reducing electricity usage and\naligning with the UNs Sustainable Development Goals.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u53ef\u5b9a\u5236\u7684RAG\u6846\u67b6\uff0c\u7528\u4e8e\u533b\u7597\u4efb\u52a1\uff0c\u5176\u6027\u80fd\u548c\u80fd\u8017\u4f18\u4e8e\u5546\u4e1aLLM\uff0c\u540c\u65f6\u51cf\u5c11\u73af\u5883\u5f71\u54cd\u3002", "motivation": "\u63a2\u8ba8AI\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u5e26\u6765\u7684\u73af\u5883\u548c\u4f26\u7406\u95ee\u9898\uff0c\u63d0\u51fa\u53ef\u6301\u7eed\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u76d1\u63a7\u80fd\u8017\u548cCO2\u6392\u653e\u7684RAG\u6846\u67b6\uff0c\u5e76\u57fa\u4e8e\u5f00\u6e90LLM\u6784\u5efa\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u6d4b\u8bd5\u3002", "result": "\u81ea\u5b9a\u4e49RAG\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u80fd\u8017\u4e0a\u4f18\u4e8e\u5546\u4e1a\u6a21\u578b\uff0c\u5176\u4e2dllama3.1:8B\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u672c\u5730LLM\u5f00\u53d1\u7684RAG\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5546\u4e1a\u6a21\u578b\uff0c\u4e14\u66f4\u73af\u4fdd\uff0c\u652f\u6301\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u3002"}}
{"id": "2506.20330", "pdf": "https://arxiv.org/pdf/2506.20330", "abs": "https://arxiv.org/abs/2506.20330", "authors": ["Zhigong Zhou", "Ning Ding", "Xiaochuan Fan", "Yue Shang", "Yiming Qiu", "Jingwei Zhuo", "Zhiwei Ge", "Songlin Wang", "Lin Liu", "Sulong Xu", "Han Zhang"], "title": "Semantic-enhanced Modality-asymmetric Retrieval for Online E-commerce Search", "categories": ["cs.IR"], "comment": "published in sigir2023", "summary": "Semantic retrieval, which retrieves semantically matched items given a\ntextual query, has been an essential component to enhance system effectiveness\nin e-commerce search. In this paper, we study the multimodal retrieval problem,\nwhere the visual information (e.g, image) of item is leveraged as supplementary\nof textual information to enrich item representation and further improve\nretrieval performance. Though learning from cross-modality data has been\nstudied extensively in tasks such as visual question answering or media\nsummarization, multimodal retrieval remains a non-trivial and unsolved problem\nespecially in the asymmetric scenario where the query is unimodal while the\nitem is multimodal. In this paper, we propose a novel model named SMAR, which\nstands for Semantic-enhanced Modality-Asymmetric Retrieval, to tackle the\nproblem of modality fusion and alignment in this kind of asymmetric scenario.\nExtensive experimental results on an industrial dataset show that the proposed\nmodel outperforms baseline models significantly in retrieval accuracy. We have\nopen sourced our industrial dataset for the sake of reproducibility and future\nresearch works.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSMAR\u7684\u65b0\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u6a21\u6001\u68c0\u7d22\u4e2d\u7684\u6a21\u6001\u878d\u5408\u548c\u5bf9\u9f50\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u67e5\u8be2\u662f\u5355\u6a21\u6001\u800c\u9879\u76ee\u662f\u591a\u6a21\u6001\u7684\u4e0d\u5bf9\u79f0\u573a\u666f\u4e0b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u68c0\u7d22\u51c6\u786e\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5728\u7535\u5b50\u5546\u52a1\u641c\u7d22\u4e2d\uff0c\u8bed\u4e49\u68c0\u7d22\u901a\u8fc7\u5229\u7528\u89c6\u89c9\u4fe1\u606f\uff08\u5982\u56fe\u50cf\uff09\u4f5c\u4e3a\u6587\u672c\u4fe1\u606f\u7684\u8865\u5145\uff0c\u53ef\u4ee5\u4e30\u5bcc\u9879\u76ee\u8868\u793a\u5e76\u63d0\u9ad8\u68c0\u7d22\u6027\u80fd\u3002\u7136\u800c\uff0c\u591a\u6a21\u6001\u68c0\u7d22\u5728\u67e5\u8be2\u4e3a\u5355\u6a21\u6001\u800c\u9879\u76ee\u4e3a\u591a\u6a21\u6001\u7684\u4e0d\u5bf9\u79f0\u573a\u666f\u4e2d\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u96be\u9898\u3002", "method": "\u63d0\u51faSMAR\u6a21\u578b\uff08\u8bed\u4e49\u589e\u5f3a\u7684\u6a21\u6001\u4e0d\u5bf9\u79f0\u68c0\u7d22\uff09\uff0c\u4e13\u6ce8\u4e8e\u89e3\u51b3\u4e0d\u5bf9\u79f0\u573a\u666f\u4e0b\u7684\u6a21\u6001\u878d\u5408\u548c\u5bf9\u9f50\u95ee\u9898\u3002", "result": "\u5728\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSMAR\u6a21\u578b\u5728\u68c0\u7d22\u51c6\u786e\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "SMAR\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u68c0\u7d22\u4e2d\u7684\u6a21\u6001\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u5e76\u5f00\u6e90\u4e86\u5de5\u4e1a\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2506.19890", "pdf": "https://arxiv.org/pdf/2506.19890", "abs": "https://arxiv.org/abs/2506.19890", "authors": ["Ziru Zhang", "Jiadong Yu", "Danny H. K. Tsang"], "title": "Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The optimization of quality of experience (QoE) in multi-user virtual reality\n(VR) interactions demands a delicate balance between ultra-low latency,\nhigh-fidelity motion synchronization, and equitable resource allocation. While\nadaptive keyframe extraction mitigates transmission overhead, existing\napproaches often overlook the causal relationships among allocated bandwidth,\nCPU frequency, and user perception, limiting QoE gains. This paper proposes an\nintelligent framework to maximize QoE by integrating adaptive keyframe\nextraction with causal-aware reinforcement learning (RL). First, a novel QoE\nmetric is formulated using the Weber-Fechner Law, combining perceptual\nsensitivity, attention-driven priorities, and motion reconstruction accuracy.\nThe QoE optimization problem is then modeled as a mixed integer programming\n(MIP) task, jointly optimizing keyframe ratios, bandwidth, and computational\nresources under horizon-fairness constraints. We propose Partial State Causal\nDeep Deterministic Policy Gradient (PS-CDDPG), which integrates the Deep\nDeterministic Policy Gradient (DDPG) method with causal influence detection. By\nleveraging causal information regarding how QoE is influenced and determined by\nvarious actions, we explore actions guided by weights calculated from causal\ninference (CI), which in turn improves training efficiency. Experiments\nconducted with the CMU Motion Capture Database demonstrate that our framework\nsignificantly reduces interactive latency, enhances QoE, and maintains\nfairness, achieving superior performance compared to benchmark methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u9002\u5e94\u5173\u952e\u5e27\u63d0\u53d6\u548c\u56e0\u679c\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u6846\u67b6\uff0c\u4ee5\u6700\u5927\u5316\u591a\u7528\u6237VR\u4ea4\u4e92\u4e2d\u7684QoE\u3002\u901a\u8fc7Weber-Fechner\u5b9a\u5f8b\u5236\u5b9aQoE\u6307\u6807\uff0c\u5e76\u91c7\u7528PS-CDDPG\u65b9\u6cd5\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u4e86QoE\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e86\u5e26\u5bbd\u3001CPU\u9891\u7387\u4e0e\u7528\u6237\u611f\u77e5\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u9650\u5236\u4e86QoE\u7684\u63d0\u5347\u3002", "method": "\u7ed3\u5408\u81ea\u9002\u5e94\u5173\u952e\u5e27\u63d0\u53d6\u4e0e\u56e0\u679c\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff08PS-CDDPG\uff09\uff0c\u5229\u7528Weber-Fechner\u5b9a\u5f8b\u5236\u5b9aQoE\u6307\u6807\uff0c\u5e76\u901a\u8fc7MIP\u4efb\u52a1\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u964d\u4f4e\u4e86\u4ea4\u4e92\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u4e86QoE\uff0c\u5e76\u4fdd\u6301\u4e86\u516c\u5e73\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u667a\u80fd\u6846\u67b6\u5728\u591a\u7528\u6237VR\u4ea4\u4e92\u4e2d\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684QoE\u4f18\u5316\u6548\u679c\u3002"}}
{"id": "2506.20093", "pdf": "https://arxiv.org/pdf/2506.20093", "abs": "https://arxiv.org/abs/2506.20093", "authors": ["Yilin Wang", "Peixuan Lei", "Jie Song", "Yuzhe Hao", "Tao Chen", "Yuxuan Zhang", "Lei Jia", "Yuanxiang Li", "Zhongyu Wei"], "title": "ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset", "categories": ["cs.CL"], "comment": null, "summary": "Time-series data are critical in diverse applications, such as industrial\nmonitoring, medical diagnostics, and climate research. However, effectively\nintegrating these high-dimensional temporal signals with natural language for\ndynamic, interactive tasks remains a significant challenge. To address this, we\nintroduce the Time-Series Question Answering (Time-Series QA) task and release\nEngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset\ndesigned to capture complex interactions between time-series signals and\nnatural language. Building on this resource, we propose the Instruct Time\nTransformer (ITFormer), a novel framework that bridges time-series encoders\nwith frozen large language models (LLMs). ITFormer effectively extracts,\naligns, and fuses temporal and textual features, achieving a strong improvement\nin QA accuracy over strong baselines with fewer than 1\\% additional trainable\nparameters. By combining computational efficiency with robust cross-modal\nmodeling, our work establishes a adaptable paradigm for integrating temporal\ndata with natural language, paving the way for new research and applications in\nmulti-modal AI. More details about the project, including datasets and code,\nare available at: https://pandalin98.github.io/itformer_site/", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Time-Series QA\u4efb\u52a1\u548cEngineMT-QA\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u4e86ITFormer\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u878d\u5408\u65f6\u95f4\u5e8f\u5217\u4e0e\u81ea\u7136\u8bed\u8a00\uff0c\u663e\u8457\u63d0\u5347QA\u51c6\u786e\u6027\u3002", "motivation": "\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u4e0e\u81ea\u7136\u8bed\u8a00\u7684\u6709\u6548\u878d\u5408\u5728\u52a8\u6001\u4ea4\u4e92\u4efb\u52a1\u4e2d\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faITFormer\u6846\u67b6\uff0c\u7ed3\u5408\u65f6\u95f4\u5e8f\u5217\u7f16\u7801\u5668\u4e0e\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u53d6\u3001\u5bf9\u9f50\u548c\u878d\u5408\u65f6\u5e8f\u4e0e\u6587\u672c\u7279\u5f81\u3002", "result": "ITFormer\u5728QA\u51c6\u786e\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4e14\u4ec5\u9700\u4e0d\u52301%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u65f6\u95f4\u5e8f\u5217\u4e0e\u81ea\u7136\u8bed\u8a00\u7684\u878d\u5408\u63d0\u4f9b\u4e86\u9ad8\u6548\u8303\u5f0f\uff0c\u63a8\u52a8\u4e86\u591a\u6a21\u6001AI\u7684\u7814\u7a76\u4e0e\u5e94\u7528\u3002"}}
{"id": "2506.20018", "pdf": "https://arxiv.org/pdf/2506.20018", "abs": "https://arxiv.org/abs/2506.20018", "authors": ["Zechun Deng", "Ziwei Liu", "Ziqian Bi", "Junhao Song", "Chia Xin Liang", "Joe Yeong", "Junfeng Hao"], "title": "Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models", "categories": ["cs.AI", "cs.AR"], "comment": null, "summary": "This paper investigates real-time decision support systems that leverage\nlow-latency AI models, bringing together recent progress in holistic AI-driven\ndecision tools, integration with Edge-IoT technologies, and approaches for\neffective human-AI teamwork. It looks into how large language models can assist\ndecision-making, especially when resources are limited. The research also\nexamines the effects of technical developments such as DeLLMa, methods for\ncompressing models, and improvements for analytics on edge devices, while also\naddressing issues like limited resources and the need for adaptable frameworks.\nThrough a detailed review, the paper offers practical perspectives on\ndevelopment strategies and areas of application, adding to the field by\npointing out opportunities for more efficient and flexible AI-supported\nsystems. The conclusions set the stage for future breakthroughs in this\nfast-changing area, highlighting how AI can reshape real-time decision support.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u4f4e\u5ef6\u8fdfAI\u6a21\u578b\u7684\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86AI\u9a71\u52a8\u51b3\u7b56\u5de5\u5177\u3001Edge-IoT\u6280\u672f\u548c\u4eba\u673a\u534f\u4f5c\u65b9\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u6709\u9650\u65f6\u7684\u51b3\u7b56\u8f85\u52a9\u4f5c\u7528\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u6574\u5408AI\u6280\u672f\u3001\u8fb9\u7f18\u8ba1\u7b97\u548c\u4eba\u673a\u534f\u4f5c\uff0c\u4ee5\u63d0\u5347\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u7684\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "method": "\u901a\u8fc7\u8be6\u7ec6\u7efc\u8ff0\uff0c\u5206\u6790\u4e86DeLLMa\u3001\u6a21\u578b\u538b\u7f29\u6280\u672f\u548c\u8fb9\u7f18\u8bbe\u5907\u5206\u6790\u6539\u8fdb\u7b49\u6280\u672f\u53d1\u5c55\uff0c\u5e76\u63a2\u8ba8\u4e86\u8d44\u6e90\u9650\u5236\u548c\u9002\u5e94\u6027\u6846\u67b6\u7684\u9700\u6c42\u3002", "result": "\u63d0\u4f9b\u4e86\u5f00\u53d1\u7b56\u7565\u548c\u5e94\u7528\u9886\u57df\u7684\u5b9e\u7528\u89c6\u89d2\uff0c\u6307\u51fa\u4e86\u9ad8\u6548\u7075\u6d3bAI\u652f\u6301\u7cfb\u7edf\u7684\u673a\u4f1a\u3002", "conclusion": "\u4e3a\u8fd9\u4e00\u5feb\u901f\u53d8\u5316\u9886\u57df\u7684\u672a\u6765\u7a81\u7834\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86AI\u5982\u4f55\u91cd\u5851\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2506.20501", "pdf": "https://arxiv.org/pdf/2506.20501", "abs": "https://arxiv.org/abs/2506.20501", "authors": ["Philipp Hager", "Onno Zoeter", "Maarten de Rijke"], "title": "Unidentified and Confounded? Understanding Two-Tower Models for Unbiased Learning to Rank", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Additive two-tower models are popular learning-to-rank methods for handling\nbiased user feedback in industry settings. Recent studies, however, report a\nconcerning phenomenon: training two-tower models on clicks collected by\nwell-performing production systems leads to decreased ranking performance. This\npaper investigates two recent explanations for this observation: confounding\neffects from logging policies and model identifiability issues. We\ntheoretically analyze the identifiability conditions of two-tower models,\nshowing that either document swaps across positions or overlapping feature\ndistributions are required to recover model parameters from clicks. We also\ninvestigate the effect of logging policies on two-tower models, finding that\nthey introduce no bias when models perfectly capture user behavior. However,\nlogging policies can amplify biases when models imperfectly capture user\nbehavior, particularly when prediction errors correlate with document placement\nacross positions. We propose a sample weighting technique to mitigate these\neffects and provide actionable insights for researchers and practitioners using\ntwo-tower models.", "AI": {"tldr": "\u4e24\u5854\u6a21\u578b\u5728\u70b9\u51fb\u6570\u636e\u8bad\u7ec3\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u7814\u7a76\u63a2\u8ba8\u4e86\u65e5\u5fd7\u7b56\u7565\u6df7\u6dc6\u548c\u6a21\u578b\u53ef\u8bc6\u522b\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u6837\u672c\u52a0\u6743\u6280\u672f\u7f13\u89e3\u504f\u5dee\u3002", "motivation": "\u7814\u7a76\u4e24\u5854\u6a21\u578b\u5728\u70b9\u51fb\u6570\u636e\u8bad\u7ec3\u4e2d\u6027\u80fd\u4e0b\u964d\u7684\u539f\u56e0\uff0c\u91cd\u70b9\u5173\u6ce8\u65e5\u5fd7\u7b56\u7565\u548c\u6a21\u578b\u53ef\u8bc6\u522b\u6027\u7684\u5f71\u54cd\u3002", "method": "\u7406\u8bba\u5206\u6790\u4e24\u5854\u6a21\u578b\u7684\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\uff0c\u7814\u7a76\u65e5\u5fd7\u7b56\u7565\u5bf9\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u6837\u672c\u52a0\u6743\u6280\u672f\u3002", "result": "\u53d1\u73b0\u65e5\u5fd7\u7b56\u7565\u5728\u6a21\u578b\u5b8c\u7f8e\u6355\u6349\u7528\u6237\u884c\u4e3a\u65f6\u4e0d\u5f15\u5165\u504f\u5dee\uff0c\u4f46\u5728\u4e0d\u5b8c\u7f8e\u65f6\u4f1a\u653e\u5927\u504f\u5dee\uff1b\u63d0\u51fa\u6837\u672c\u52a0\u6743\u6280\u672f\u6709\u6548\u3002", "conclusion": "\u4e24\u5854\u6a21\u578b\u9700\u6ce8\u610f\u65e5\u5fd7\u7b56\u7565\u548c\u53ef\u8bc6\u522b\u6027\u95ee\u9898\uff0c\u6837\u672c\u52a0\u6743\u6280\u672f\u53ef\u7f13\u89e3\u504f\u5dee\uff0c\u4e3a\u5b9e\u8df5\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2506.19891", "pdf": "https://arxiv.org/pdf/2506.19891", "abs": "https://arxiv.org/abs/2506.19891", "authors": ["Qinghui Gong", "Xue Yang", "Xiaohu Tang"], "title": "Orthogonal Soft Pruning for Efficient Class Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages,3 figures", "summary": "Machine unlearning aims to selectively remove class-specific knowledge from\npretrained neural networks to satisfy privacy regulations such as the GDPR.\nExisting methods typically face a trade-off between unlearning speed and\npreservation of predictive accuracy, often incurring either high computational\noverhead or significant performance degradation on retained classes. In this\npaper, we propose a novel class-aware soft pruning framework leveraging\northogonal convolutional kernel regularization to achieve rapid and precise\nforgetting with millisecond-level response times. By enforcing orthogonality\nconstraints during training, our method decorrelates convolutional filters and\ndisentangles feature representations, while efficiently identifying\nclass-specific channels through activation difference analysis. Extensive\nevaluations across multiple architectures and datasets demonstrate stable\npruning with near-instant execution, complete forgetting of targeted classes,\nand minimal accuracy loss on retained data. Experiments on CIFAR-10, CIFAR-100,\nand TinyImageNet confirm that our approach substantially reduces membership\ninference attack risks and accelerates unlearning by orders of magnitude\ncompared to state-of-the-art baselines. This framework provides an efficient,\npractical solution for real-time machine unlearning in Machine Learning as a\nService (MLaaS) scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u4ea4\u5377\u79ef\u6838\u6b63\u5219\u5316\u7684\u7c7b\u611f\u77e5\u8f6f\u526a\u679d\u6846\u67b6\uff0c\u5b9e\u73b0\u5feb\u901f\u7cbe\u786e\u7684\u673a\u5668\u9057\u5fd8\uff0c\u54cd\u5e94\u65f6\u95f4\u8fbe\u6beb\u79d2\u7ea7\u3002", "motivation": "\u6ee1\u8db3GDPR\u7b49\u9690\u79c1\u6cd5\u89c4\u8981\u6c42\uff0c\u9009\u62e9\u6027\u79fb\u9664\u9884\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u7279\u5b9a\u7c7b\u522b\u77e5\u8bc6\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u9057\u5fd8\u901f\u5ea6\u548c\u9884\u6d4b\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u5229\u7528\u6b63\u4ea4\u5377\u79ef\u6838\u6b63\u5219\u5316\uff0c\u901a\u8fc7\u6fc0\u6d3b\u5dee\u5f02\u5206\u6790\u9ad8\u6548\u8bc6\u522b\u7279\u5b9a\u7c7b\u522b\u901a\u9053\uff0c\u5b9e\u73b0\u7279\u5f81\u8868\u793a\u7684\u89e3\u8026\u548c\u5377\u79ef\u6ee4\u6ce2\u5668\u7684\u53bb\u76f8\u5173\u3002", "result": "\u5728CIFAR-10\u3001CIFAR-100\u548cTinyImageNet\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u76ee\u6807\u7c7b\u522b\u7684\u5b8c\u5168\u9057\u5fd8\u3001\u4fdd\u7559\u6570\u636e\u7684\u51c6\u786e\u6027\u635f\u5931\u6781\u5c0f\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u6210\u5458\u63a8\u7406\u653b\u51fb\u98ce\u9669\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aMLaaS\u573a\u666f\u4e2d\u7684\u5b9e\u65f6\u673a\u5668\u9057\u5fd8\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.20100", "pdf": "https://arxiv.org/pdf/2506.20100", "abs": "https://arxiv.org/abs/2506.20100", "authors": ["Vardhan Dongre", "Chi Gui", "Shubham Garg", "Hooshang Nayyeri", "Gokhan Tur", "Dilek Hakkani-T\u00fcr", "Vikram S. Adve"], "title": "MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "66 pages, 32 figures, 23 tables", "summary": "We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning\nand decision-making in consultative interaction settings. Designed for the\nagriculture domain, MIRAGE captures the full complexity of expert consultations\nby combining natural user queries, expert-authored responses, and image-based\ncontext, offering a high-fidelity benchmark for evaluating models on grounded\nreasoning, clarification strategies, and long-form generation in a real-world,\nknowledge-intensive domain. Grounded in over 35,000 real user-expert\ninteractions and curated through a carefully designed multi-step pipeline,\nMIRAGE spans diverse crop health, pest diagnosis, and crop management\nscenarios. The benchmark includes more than 7,000 unique biological entities,\ncovering plant species, pests, and diseases, making it one of the most\ntaxonomically diverse benchmarks available for vision-language models, grounded\nin the real world. Unlike existing benchmarks that rely on well-specified user\ninputs and closed-set taxonomies, MIRAGE features underspecified, context-rich\nscenarios with open-world settings, requiring models to infer latent knowledge\ngaps, handle rare entities, and either proactively guide the interaction or\nrespond. Project Page: https://mirage-benchmark.github.io", "AI": {"tldr": "MIRAGE\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001\u4e13\u5bb6\u7ea7\u63a8\u7406\u548c\u51b3\u7b56\u7684\u65b0\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u519c\u4e1a\u9886\u57df\u7684\u54a8\u8be2\u4ea4\u4e92\u573a\u666f\uff0c\u7ed3\u5408\u81ea\u7136\u7528\u6237\u67e5\u8be2\u3001\u4e13\u5bb6\u56de\u7b54\u548c\u56fe\u50cf\u4e0a\u4e0b\u6587\uff0c\u8bc4\u4f30\u6a21\u578b\u7684\u63a8\u7406\u3001\u6f84\u6e05\u7b56\u7565\u548c\u957f\u6587\u672c\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u901a\u5e38\u4f9d\u8d56\u660e\u786e\u8f93\u5165\u548c\u5c01\u95ed\u5206\u7c7b\u6cd5\uff0c\u800cMIRAGE\u65e8\u5728\u89e3\u51b3\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e0b\u7684\u6a21\u7cca\u3001\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u4ea4\u4e92\u9700\u6c42\uff0c\u586b\u8865\u4e86\u771f\u5b9e\u4e16\u754c\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u7684\u8bc4\u4f30\u7a7a\u767d\u3002", "method": "\u57fa\u4e8e35,000+\u771f\u5b9e\u7528\u6237-\u4e13\u5bb6\u4ea4\u4e92\u6570\u636e\uff0c\u901a\u8fc7\u591a\u6b65\u9aa4\u6d41\u7a0b\u6784\u5efa\uff0c\u6db5\u76d6\u4f5c\u7269\u5065\u5eb7\u3001\u5bb3\u866b\u8bca\u65ad\u548c\u7ba1\u7406\u573a\u666f\uff0c\u5305\u542b7,000+\u751f\u7269\u5b9e\u4f53\u3002", "result": "MIRAGE\u6210\u4e3a\u76ee\u524d\u6700\u5168\u9762\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u4e4b\u4e00\uff0c\u652f\u6301\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\uff0c\u8981\u6c42\u6a21\u578b\u63a8\u65ad\u6f5c\u5728\u77e5\u8bc6\u5dee\u8ddd\u5e76\u5904\u7406\u7f55\u89c1\u5b9e\u4f53\u3002", "conclusion": "MIRAGE\u4e3a\u591a\u6a21\u6001\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u590d\u6742\u573a\u666f\u4e2d\u7684\u80fd\u529b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u9ad8\u4fdd\u771f\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u5f00\u653e\u4e16\u754c\u63a8\u7406\u548c\u4ea4\u4e92\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.20020", "pdf": "https://arxiv.org/pdf/2506.20020", "abs": "https://arxiv.org/abs/2506.20020", "authors": ["Saloni Dash", "Am\u00e9lie Reymond", "Emma S. Spiro", "Aylin Caliskan"], "title": "Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reasoning in humans is prone to biases due to underlying motivations like\nidentity protection, that undermine rational decision-making and judgment. This\nmotivated reasoning at a collective level can be detrimental to society when\ndebating critical issues such as human-driven climate change or vaccine safety,\nand can further aggravate political polarization. Prior studies have reported\nthat large language models (LLMs) are also susceptible to human-like cognitive\nbiases, however, the extent to which LLMs selectively reason toward\nidentity-congruent conclusions remains largely unexplored. Here, we investigate\nwhether assigning 8 personas across 4 political and socio-demographic\nattributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and\nproprietary) across two reasoning tasks from human-subject studies -- veracity\ndiscernment of misinformation headlines and evaluation of numeric scientific\nevidence -- we find that persona-assigned LLMs have up to 9% reduced veracity\ndiscernment relative to models without personas. Political personas\nspecifically, are up to 90% more likely to correctly evaluate scientific\nevidence on gun control when the ground truth is congruent with their induced\npolitical identity. Prompt-based debiasing methods are largely ineffective at\nmitigating these effects. Taken together, our empirical findings are the first\nto suggest that persona-assigned LLMs exhibit human-like motivated reasoning\nthat is hard to mitigate through conventional debiasing prompts -- raising\nconcerns of exacerbating identity-congruent reasoning in both LLMs and humans.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8d4b\u4e88\u7279\u5b9a\u653f\u6cbb\u548c\u793e\u4f1a\u8eab\u4efd\u540e\uff0c\u4f1a\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u52a8\u673a\u6027\u63a8\u7406\uff0c\u5bfc\u81f4\u5224\u65ad\u504f\u5dee\uff0c\u4e14\u5e38\u89c4\u53bb\u504f\u65b9\u6cd5\u6548\u679c\u6709\u9650\u3002", "motivation": "\u63a2\u8ba8LLMs\u662f\u5426\u4f1a\u5728\u8eab\u4efd\u8ba4\u540c\u9a71\u52a8\u4e0b\u8fdb\u884c\u9009\u62e9\u6027\u63a8\u7406\uff0c\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8ba4\u77e5\u504f\u5dee\uff0c\u5c24\u5176\u662f\u5728\u5173\u952e\u793e\u4f1a\u8bae\u9898\u4e0a\u3002", "method": "\u901a\u8fc7\u4e3a8\u79cdLLMs\u8d4b\u4e884\u7c7b\u653f\u6cbb\u548c\u793e\u4f1a\u8eab\u4efd\uff0c\u6d4b\u8bd5\u5176\u5728\u4fe1\u606f\u771f\u5b9e\u6027\u8fa8\u522b\u548c\u79d1\u5b66\u8bc1\u636e\u8bc4\u4f30\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u8eab\u4efd\u8d4b\u4e88\u7684LLMs\u5728\u771f\u5b9e\u6027\u8fa8\u522b\u4e0a\u964d\u4f4e9%\uff0c\u653f\u6cbb\u8eab\u4efd\u6a21\u578b\u5728\u67aa\u63a7\u8bc1\u636e\u8bc4\u4f30\u4e2d\u6b63\u786e\u7387\u63d0\u9ad890%\uff08\u5f53\u8bc1\u636e\u4e0e\u8eab\u4efd\u4e00\u81f4\u65f6\uff09\u3002", "conclusion": "LLMs\u8868\u73b0\u51fa\u96be\u4ee5\u901a\u8fc7\u5e38\u89c4\u65b9\u6cd5\u6d88\u9664\u7684\u52a8\u673a\u6027\u63a8\u7406\uff0c\u53ef\u80fd\u52a0\u5267\u8eab\u4efd\u8ba4\u540c\u9a71\u52a8\u7684\u5224\u65ad\u504f\u5dee\u3002"}}
{"id": "2506.20041", "pdf": "https://arxiv.org/pdf/2506.20041", "abs": "https://arxiv.org/abs/2506.20041", "authors": ["Soheil Abadifard", "Fazli Can"], "title": "LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for Evolving Multi-Class Imbalanced Classification", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "The classification of imbalanced data streams, which have unequal class\ndistributions, is a key difficulty in machine learning, especially when dealing\nwith multiple classes. While binary imbalanced data stream classification tasks\nhave received considerable attention, only a few studies have focused on\nmulti-class imbalanced data streams. Effectively managing the dynamic imbalance\nratio is a key challenge in this domain. This study introduces a novel, robust,\nand resilient approach to address these challenges by integrating Locality\nSensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic\nEnsemble Diversification (DynED) framework. To the best of our knowledge, we\npresent the first application of LSH-RHP for undersampling in the context of\nimbalanced non-stationary data streams. The proposed method undersamples the\nmajority classes by utilizing LSH-RHP, provides a balanced training set, and\nimproves the ensemble's prediction performance. We conduct comprehensive\nexperiments on 23 real-world and ten semi-synthetic datasets and compare\nLSH-DynED with 15 state-of-the-art methods. The results reveal that LSH-DynED\noutperforms other approaches in terms of both Kappa and mG-Mean effectiveness\nmeasures, demonstrating its capability in dealing with multi-class imbalanced\nnon-stationary data streams. Notably, LSH-DynED performs well in large-scale,\nhigh-dimensional datasets with considerable class imbalances and demonstrates\nadaptation and robustness in real-world circumstances. To motivate our design,\nwe review existing methods for imbalanced data streams, outline key challenges,\nand offer guidance for future work. For the reproducibility of our results, we\nhave made our implementation available on GitHub.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLSH-RHP\u548cDynED\u6846\u67b6\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u591a\u7c7b\u4e0d\u5e73\u8861\u6570\u636e\u6d41\u5206\u7c7b\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u591a\u7c7b\u4e0d\u5e73\u8861\u6570\u636e\u6d41\u5206\u7c7b\u4e2d\u52a8\u6001\u4e0d\u5e73\u8861\u6bd4\u7387\u7684\u6311\u6218\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u7ed3\u5408LSH-RHP\u8fdb\u884c\u591a\u6570\u7c7b\u6b20\u91c7\u6837\uff0c\u751f\u6210\u5e73\u8861\u8bad\u7ec3\u96c6\uff0c\u5e76\u96c6\u6210\u5230DynED\u6846\u67b6\u4e2d\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u572823\u4e2a\u771f\u5b9e\u548c10\u4e2a\u534a\u5408\u6210\u6570\u636e\u96c6\u4e0a\uff0cLSH-DynED\u5728Kappa\u548cmG-Mean\u6307\u6807\u4e0a\u4f18\u4e8e15\u79cd\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "LSH-DynED\u5728\u5904\u7406\u5927\u89c4\u6a21\u3001\u9ad8\u7ef4\u548c\u591a\u7c7b\u4e0d\u5e73\u8861\u6570\u636e\u6d41\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.19893", "pdf": "https://arxiv.org/pdf/2506.19893", "abs": "https://arxiv.org/abs/2506.19893", "authors": ["Jingzhi Hu", "Geoffrey Ye Li"], "title": "Distillation-Enabled Knowledge Alignment for Generative Semantic Communications in AIGC Provisioning Tasks", "categories": ["cs.LG", "cs.AI", "cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "Due to the surging amount of AI-generated content (AIGC), its provisioning to\nedges and mobile users from the cloud incurs substantial traffic on networks.\nGenerative semantic communication (GSC) offers a promising solution by\ntransmitting highly compact information, i.e., prompt text and latent\nrepresentations, instead of high-dimensional AIGC data. However, GSC relies on\nthe alignment between the knowledge in the cloud generative AI (GAI) and that\npossessed by the edges and users, and between the knowledge for wireless\ntransmission and that of actual channels, which remains challenging. In this\npaper, we propose DeKA-g, a distillation-enabled knowledge alignment algorithm\nfor GSC systems. The core idea is to distill the generation knowledge from the\ncloud-GAI into low-rank matrices, which can be incorporated by the edge and\nused to adapt the transmission knowledge to diverse wireless channel\nconditions. DeKA-g comprises two novel methods: metaword-aided knowledge\ndistillation (MAKD) and variable-rate grouped SNR adaptation (VGSA). For MAKD,\nan optimized metaword is employed to enhance the efficiency of knowledge\ndistillation, while VGSA enables efficient adaptation to diverse compression\nrates and SNR ranges. From simulation results, DeKA-g improves the alignment\nbetween the edge-generated images and the cloud-generated ones by 44%.\nMoreover, it adapts to compression rates with 116% higher efficiency than the\nbaseline and enhances the performance in low-SNR conditions by 28%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDeKA-g\u7b97\u6cd5\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548c\u81ea\u9002\u5e94\u4f20\u8f93\u4f18\u5316\u751f\u6210\u8bed\u4e49\u901a\u4fe1\uff08GSC\uff09\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u8fb9\u7f18\u751f\u6210\u5185\u5bb9\u4e0e\u4e91\u7aef\u751f\u6210\u5185\u5bb9\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3\u751f\u6210\u8bed\u4e49\u901a\u4fe1\uff08GSC\uff09\u4e2d\u4e91\u7aef\u4e0e\u8fb9\u7f18\u77e5\u8bc6\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u4ee5\u53ca\u65e0\u7ebf\u4f20\u8f93\u77e5\u8bc6\u4e0e\u5b9e\u9645\u4fe1\u9053\u6761\u4ef6\u7684\u5339\u914d\u95ee\u9898\u3002", "method": "\u63d0\u51faDeKA-g\u7b97\u6cd5\uff0c\u5305\u542b\u5143\u8bcd\u8f85\u52a9\u77e5\u8bc6\u84b8\u998f\uff08MAKD\uff09\u548c\u53ef\u53d8\u7387\u5206\u7ec4SNR\u81ea\u9002\u5e94\uff08VGSA\uff09\u4e24\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f4e\u79e9\u77e9\u9635\u84b8\u998f\u4e91\u7aef\u751f\u6210\u77e5\u8bc6\u5e76\u9002\u5e94\u4e0d\u540c\u4fe1\u9053\u6761\u4ef6\u3002", "result": "DeKA-g\u5c06\u8fb9\u7f18\u751f\u6210\u56fe\u50cf\u4e0e\u4e91\u7aef\u751f\u6210\u56fe\u50cf\u7684\u5bf9\u9f50\u5ea6\u63d0\u534744%\uff0c\u538b\u7f29\u7387\u9002\u5e94\u6548\u7387\u63d0\u9ad8116%\uff0c\u4f4eSNR\u6761\u4ef6\u4e0b\u6027\u80fd\u63d0\u534728%\u3002", "conclusion": "DeKA-g\u6709\u6548\u89e3\u51b3\u4e86GSC\u7cfb\u7edf\u4e2d\u7684\u77e5\u8bc6\u5bf9\u9f50\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u548c\u4f20\u8f93\u6548\u7387\u3002"}}
{"id": "2506.20112", "pdf": "https://arxiv.org/pdf/2506.20112", "abs": "https://arxiv.org/abs/2506.20112", "authors": ["Songsoo Kim", "Seungtae Lee", "See Young Lee", "Joonho Kim", "Keechan Kan", "Dukyong Yoon"], "title": "A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection", "categories": ["cs.CL", "I.2.7"], "comment": "29 pages, 5 figures, 4 tables. Code available at\n  https://github.com/radssk/mp-rred", "summary": "Background: The positive predictive value (PPV) of large language model\n(LLM)-based proofreading for radiology reports is limited due to the low error\nprevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV\nand reduces operational costs compared with baseline approaches. Materials and\nMethods: A retrospective analysis was performed on 1,000 consecutive radiology\nreports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III\ndatabase. Two external datasets (CheXpert and Open-i) were validation sets.\nThree LLM frameworks were tested: (1) single-prompt detector; (2) extractor\nplus detector; and (3) extractor, detector, and false-positive verifier.\nPrecision was measured by PPV and absolute true positive rate (aTPR).\nEfficiency was calculated from model inference charges and reviewer\nremuneration. Statistical significance was tested using cluster bootstrap,\nexact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV\nincreased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118,\nFramework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs.\nbaselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per\n1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and\nUSD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively.\nHuman-reviewed reports decreased from 192 to 88. External validation supported\nFramework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR\n(0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and\nreduced operational costs, maintaining detection performance, providing an\neffective strategy for AI-assisted radiology report quality assurance.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u9636\u6bb5LLM\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653e\u5c04\u5b66\u62a5\u544a\u7684\u9633\u6027\u9884\u6d4b\u503c\uff08PPV\uff09\u5e76\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u653e\u5c04\u5b66\u62a5\u544a\u6821\u5bf9\u4e2d\u7684\u9633\u6027\u9884\u6d4b\u503c\uff08PPV\uff09\u8f83\u4f4e\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4e09\u9636\u6bb5\u6846\u67b6\u63d0\u5347PPV\u5e76\u51cf\u5c11\u6210\u672c\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e861000\u4efd\u653e\u5c04\u5b66\u62a5\u544a\uff0c\u6d4b\u8bd5\u4e86\u4e09\u79cdLLM\u6846\u67b6\uff1a\u5355\u63d0\u793a\u68c0\u6d4b\u5668\u3001\u63d0\u53d6\u5668\u52a0\u68c0\u6d4b\u5668\u3001\u4ee5\u53ca\u63d0\u53d6\u5668\u3001\u68c0\u6d4b\u5668\u548c\u5047\u9633\u6027\u9a8c\u8bc1\u5668\u7684\u7ec4\u5408\u3002\u901a\u8fc7PPV\u548c\u7edd\u5bf9\u771f\u9633\u6027\u7387\uff08aTPR\uff09\u8bc4\u4f30\u6027\u80fd\uff0c\u5e76\u8ba1\u7b97\u8fd0\u8425\u6210\u672c\u3002", "result": "\u4e09\u9636\u6bb5\u6846\u67b6\uff08\u6846\u67b63\uff09\u663e\u8457\u63d0\u9ad8\u4e86PPV\uff080.159\uff09\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\uff08\u6bcf1000\u4efd\u62a5\u544a5.58\u7f8e\u5143\uff09\u3002\u5916\u90e8\u9a8c\u8bc1\u4e5f\u652f\u6301\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "\u4e09\u9636\u6bb5LLM\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86PPV\u548c\u6210\u672c\u6548\u76ca\uff0c\u4e3aAI\u8f85\u52a9\u653e\u5c04\u5b66\u62a5\u544a\u8d28\u91cf\u4fdd\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u7b56\u7565\u3002"}}
{"id": "2506.20059", "pdf": "https://arxiv.org/pdf/2506.20059", "abs": "https://arxiv.org/abs/2506.20059", "authors": ["Weijieying Ren", "Tianxiang Zhao", "Lei Wang", "Tianchun Wang", "Vasant Honavar"], "title": "DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have led to remarkable\nprogresses in medical consultation. However, existing medical LLMs overlook the\nessential role of Electronic Health Records (EHR) and focus primarily on\ndiagnosis recommendation, limiting their clinical applicability. We propose\nDiaLLM, the first medical LLM that integrates heterogeneous EHR data into\nclinically grounded dialogues, enabling clinical test recommendation, result\ninterpretation, and diagnosis prediction to better align with real-world\nmedical practice. To construct clinically grounded dialogues from EHR, we\ndesign a Clinical Test Reference (CTR) strategy that maps each clinical code to\nits corresponding description and classifies test results as \"normal\" or\n\"abnormal\". Additionally, DiaLLM employs a reinforcement learning framework for\nevidence acquisition and automated diagnosis. To handle the large action space,\nwe introduce a reject sampling strategy to reduce redundancy and improve\nexploration efficiency. Furthermore, a confirmation reward and a\nclass-sensitive diagnosis reward are designed to guide accurate diagnosis\nprediction. Extensive experimental results demonstrate that DiaLLM outperforms\nbaselines in clinical test recommendation and diagnosis prediction.", "AI": {"tldr": "DiaLLM\u662f\u4e00\u79cd\u65b0\u578b\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6574\u5408\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u6570\u636e\uff0c\u652f\u6301\u4e34\u5e8a\u6d4b\u8bd5\u63a8\u8350\u3001\u7ed3\u679c\u89e3\u91ca\u548c\u8bca\u65ad\u9884\u6d4b\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u5ffd\u89c6\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u7684\u4f5c\u7528\uff0c\u4ec5\u5173\u6ce8\u8bca\u65ad\u63a8\u8350\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u5e94\u7528\u3002DiaLLM\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e34\u5e8a\u6d4b\u8bd5\u53c2\u8003\uff08CTR\uff09\u7b56\u7565\uff0c\u5c06\u4e34\u5e8a\u4ee3\u7801\u6620\u5c04\u5230\u63cf\u8ff0\u5e76\u5206\u7c7b\u6d4b\u8bd5\u7ed3\u679c\uff1b\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u8bc1\u636e\u83b7\u53d6\u548c\u81ea\u52a8\u8bca\u65ad\uff0c\u5f15\u5165\u62d2\u7edd\u91c7\u6837\u7b56\u7565\u548c\u5956\u52b1\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDiaLLM\u5728\u4e34\u5e8a\u6d4b\u8bd5\u63a8\u8350\u548c\u8bca\u65ad\u9884\u6d4b\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DiaLLM\u901a\u8fc7\u6574\u5408EHR\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u7597\u5bf9\u8bdd\u6a21\u578b\u7684\u4e34\u5e8a\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.20156", "pdf": "https://arxiv.org/pdf/2506.20156", "abs": "https://arxiv.org/abs/2506.20156", "authors": ["Xuefei Hou", "Xizhao Tan"], "title": "Irec: A Metacognitive Scaffolding for Self-Regulated Learning through Just-in-Time Insight Recall: A Conceptual Framework and System Prototype", "categories": ["cs.HC", "cs.AI", "cs.IR", "H.5.2; I.2.7; H.3.3"], "comment": "Version 1 of a work in progress. Finalized system flowcharts, a\n  public GitHub repository with the source code, and a full reproducibility\n  package detailing the prompts, models, and testing guidelines will be\n  provided in v2", "summary": "The core challenge in learning has shifted from knowledge acquisition to\neffective Self-Regulated Learning (SRL): planning, monitoring, and reflecting\non one's learning. Existing digital tools, however, inadequately support\nmetacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized\nreview, overlooking the role of context, while Personal Knowledge Management\n(PKM) tools require high manual maintenance.\n  To address these challenges, this paper introduces \"Insight Recall,\" a novel\nparadigm that conceptualizes the context-triggered retrieval of personal past\ninsights as a metacognitive scaffold to promote SRL. We formalize this paradigm\nusing the Just-in-Time Adaptive Intervention (JITAI) framework and implement a\nprototype system, Irec, to demonstrate its feasibility. At its core, Irec uses\na dynamic knowledge graph of the user's learning history. When a user faces a\nnew problem, a hybrid retrieval engine recalls relevant personal \"insights.\"\nSubsequently, a large language model (LLM) performs a deep similarity\nassessment to filter and present the most relevant scaffold in a just-in-time\nmanner. To reduce cognitive load, Irec features a human-in-the-loop pipeline\nfor LLM-based knowledge graph construction. We also propose an optional \"Guided\nInquiry\" module, where users can engage in a Socratic dialogue with an expert\nLLM, using the current problem and recalled insights as context. The\ncontribution of this paper is a solid theoretical framework and a usable system\nplatform for designing next-generation intelligent learning systems that\nenhance metacognition and self-regulation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a'Insight Recall'\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u89e6\u53d1\u7684\u4e2a\u4eba\u8fc7\u53bb\u89c1\u89e3\u68c0\u7d22\u6765\u652f\u6301\u81ea\u6211\u8c03\u8282\u5b66\u4e60\uff08SRL\uff09\uff0c\u5e76\u5f00\u53d1\u4e86\u539f\u578b\u7cfb\u7edfIrec\u3002", "motivation": "\u73b0\u6709\u6570\u5b57\u5de5\u5177\u5728\u652f\u6301\u5143\u8ba4\u77e5\u53cd\u601d\u65b9\u9762\u4e0d\u8db3\uff0c\u5982Spaced Repetition Systems\uff08SRS\uff09\u7f3a\u4e4f\u4e0a\u4e0b\u6587\uff0cPersonal Knowledge Management\uff08PKM\uff09\u5de5\u5177\u7ef4\u62a4\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528Just-in-Time Adaptive Intervention\uff08JITAI\uff09\u6846\u67b6\uff0c\u6784\u5efa\u52a8\u6001\u77e5\u8bc6\u56fe\u8c31\u548c\u6df7\u5408\u68c0\u7d22\u5f15\u64ce\uff0c\u7ed3\u5408LLM\u8fdb\u884c\u6df1\u5ea6\u76f8\u4f3c\u6027\u8bc4\u4f30\uff0c\u5e76\u8bbe\u8ba1'Guided Inquiry'\u6a21\u5757\u3002", "result": "\u5f00\u53d1\u4e86Irec\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u5176\u53ef\u884c\u6027\uff0c\u63d0\u4f9b\u4e86\u589e\u5f3a\u5143\u8ba4\u77e5\u548c\u81ea\u6211\u8c03\u8282\u7684\u667a\u80fd\u5b66\u4e60\u7cfb\u7edf\u8bbe\u8ba1\u6846\u67b6\u3002", "conclusion": "\u8bba\u6587\u8d21\u732e\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u7cfb\u7edf\u5e73\u53f0\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u5b66\u4e60\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.19894", "pdf": "https://arxiv.org/pdf/2506.19894", "abs": "https://arxiv.org/abs/2506.19894", "authors": ["Antoine Pesenti", "Aidan OSullivan"], "title": "Explaining deep neural network models for electricity price forecasting with XAI", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Electricity markets are highly complex, involving lots of interactions and\ncomplex dependencies that make it hard to understand the inner workings of the\nmarket and what is driving prices. Econometric methods have been developed for\nthis, white-box models, however, they are not as powerful as deep neural\nnetwork models (DNN). In this paper, we use a DNN to forecast the price and\nthen use XAI methods to understand the factors driving the price dynamics in\nthe market. The objective is to increase our understanding of how different\nelectricity markets work. To do that, we apply explainable methods such as SHAP\nand Gradient, combined with visual techniques like heatmaps (saliency maps) to\nanalyse the behaviour and contributions of various features across five\nelectricity markets. We introduce the novel concepts of SSHAP values and SSHAP\nlines to enhance the complex representation of high-dimensional tabular models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u548c\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u7535\u4ef7\u5e76\u5206\u6790\u5e02\u573a\u52a8\u6001\u3002", "motivation": "\u7535\u529b\u5e02\u573a\u590d\u6742\u4e14\u96be\u4ee5\u7406\u89e3\uff0c\u4f20\u7edf\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u65b9\u6cd5\uff08\u767d\u76d2\u6a21\u578b\uff09\u80fd\u529b\u6709\u9650\uff0c\u800cDNN\u867d\u5f3a\u5927\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528DNN\u9884\u6d4b\u7535\u4ef7\uff0c\u5e76\u5e94\u7528SHAP\u3001Gradient\u7b49XAI\u65b9\u6cd5\u53ca\u70ed\u56fe\u6280\u672f\u5206\u6790\u5e02\u573a\u7279\u5f81\u3002", "result": "\u901a\u8fc7SSHAP\u503c\u548cSSHAP\u7ebf\u7b49\u65b0\u6982\u5ff5\uff0c\u589e\u5f3a\u4e86\u5bf9\u9ad8\u7ef4\u8868\u683c\u6a21\u578b\u590d\u6742\u8868\u793a\u7684\u7406\u89e3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5bf9\u7535\u529b\u5e02\u573a\u8fd0\u4f5c\u673a\u5236\u7684\u7406\u89e3\uff0c\u4e3a\u5e02\u573a\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.20119", "pdf": "https://arxiv.org/pdf/2506.20119", "abs": "https://arxiv.org/abs/2506.20119", "authors": ["Masaki Uto", "Yuma Ito"], "title": "Leveraging AI Graders for Missing Score Imputation to Achieve Accurate Ability Estimation in Constructed-Response Tests", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to EvalLAC'25: 2nd Workshop on Automatic Evaluation of\n  Learning and Assessment Content, held at AIED 2025, Palermo, Italy. This is\n  the camera-ready version submitted to CEUR Workshop Proceedings", "summary": "Evaluating the abilities of learners is a fundamental objective in the field\nof education. In particular, there is an increasing need to assess higher-order\nabilities such as expressive skills and logical thinking. Constructed-response\ntests such as short-answer and essay-based questions have become widely used as\na method to meet this demand. Although these tests are effective, they require\nsubstantial manual grading, making them both labor-intensive and costly. Item\nresponse theory (IRT) provides a promising solution by enabling the estimation\nof ability from incomplete score data, where human raters grade only a subset\nof answers provided by learners across multiple test items. However, the\naccuracy of ability estimation declines as the proportion of missing scores\nincreases. Although data augmentation techniques for imputing missing scores\nhave been explored in order to address this limitation, they often struggle\nwith inaccuracy for sparse or heterogeneous data. To overcome these challenges,\nthis study proposes a novel method for imputing missing scores by leveraging\nautomated scoring technologies for accurate IRT-based ability estimation. The\nproposed method achieves high accuracy in ability estimation while markedly\nreducing manual grading workload.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u81ea\u52a8\u8bc4\u5206\u6280\u672f\u586b\u8865\u7f3a\u5931\u5206\u6570\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8IRT\u80fd\u529b\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u5e76\u51cf\u5c11\u4eba\u5de5\u8bc4\u5206\u8d1f\u62c5\u3002", "motivation": "\u8bc4\u4f30\u5b66\u4e60\u8005\u7684\u80fd\u529b\u662f\u6559\u80b2\u9886\u57df\u7684\u6838\u5fc3\u76ee\u6807\uff0c\u5c24\u5176\u662f\u9ad8\u9636\u80fd\u529b\u5982\u8868\u8fbe\u6280\u80fd\u548c\u903b\u8f91\u601d\u7ef4\u3002\u867d\u7136\u6784\u5efa\u6027\u53cd\u5e94\u6d4b\u8bd5\uff08\u5982\u7b80\u7b54\u548c\u8bba\u8ff0\u9898\uff09\u6709\u6548\uff0c\u4f46\u4eba\u5de5\u8bc4\u5206\u6210\u672c\u9ad8\u4e14\u8017\u65f6\u3002IRT\u867d\u80fd\u4ece\u4e0d\u5b8c\u6574\u6570\u636e\u4f30\u8ba1\u80fd\u529b\uff0c\u4f46\u968f\u7740\u7f3a\u5931\u5206\u6570\u6bd4\u4f8b\u589e\u52a0\uff0c\u51c6\u786e\u6027\u4e0b\u964d\u3002\u73b0\u6709\u6570\u636e\u589e\u5f3a\u6280\u672f\u5bf9\u7a00\u758f\u6216\u5f02\u6784\u6570\u636e\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u81ea\u52a8\u8bc4\u5206\u6280\u672f\u586b\u8865\u7f3a\u5931\u5206\u6570\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8IRT\u80fd\u529b\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u80fd\u529b\u4f30\u8ba1\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u8bc4\u5206\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9ad8\u6548\u3001\u51c6\u786e\u5730\u8bc4\u4f30\u5b66\u4e60\u8005\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u65b9\u6848\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6d4b\u8bd5\u573a\u666f\u3002"}}
{"id": "2506.20130", "pdf": "https://arxiv.org/pdf/2506.20130", "abs": "https://arxiv.org/abs/2506.20130", "authors": ["Adrien Bibal", "Steven N. Minton", "Deborah Khider", "Yolanda Gil"], "title": "AI Copilots for Reproducibility in Science: A Case Study", "categories": ["cs.AI"], "comment": null, "summary": "Open science initiatives seek to make research outputs more transparent,\naccessible, and reusable, but ensuring that published findings can be\nindependently reproduced remains a persistent challenge. This paper introduces\nOpenPub, an AI-powered platform that supports researchers, reviewers, and\nreaders through a suite of modular copilots focused on key open science tasks.\nIn this work, we present the Reproducibility Copilot, which analyzes\nmanuscripts, code, and supplementary materials to generate structured Jupyter\nNotebooks and recommendations aimed at facilitating computational, or \"rote\",\nreproducibility. We conducted feasibility tests using previously studied\nresearch papers with known reproducibility benchmarks. Results indicate that\nOpenPub can substantially reduce reproduction time - from over 30 hours to\nabout 1 hour - while achieving high coverage of figures, tables, and results\nsuitable for computational reproduction. The system systematically detects\nbarriers to reproducibility, including missing hyperparameters, undocumented\npreprocessing steps, and incomplete or inaccessible datasets. These findings\nsuggest that AI-driven tools can meaningfully reduce the burden of\nreproducibility efforts and contribute to more transparent and verifiable\nscientific communication. The modular copilot architecture also provides a\nfoundation for extending AI assistance to additional open science objectives\nbeyond reproducibility.", "AI": {"tldr": "OpenPub\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u5e73\u53f0\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u52a9\u624b\u652f\u6301\u5f00\u653e\u79d1\u5b66\u4efb\u52a1\uff0c\u7279\u522b\u662f\u53ef\u91cd\u590d\u6027\u52a9\u624b\uff0c\u80fd\u663e\u8457\u51cf\u5c11\u91cd\u590d\u5b9e\u9a8c\u65f6\u95f4\u3002", "motivation": "\u5f00\u653e\u79d1\u5b66\u5021\u8bae\u65e8\u5728\u63d0\u9ad8\u7814\u7a76\u7684\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\uff0c\u4f46\u72ec\u7acb\u91cd\u590d\u7814\u7a76\u7ed3\u679c\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "OpenPub\u7684\u53ef\u91cd\u590d\u6027\u52a9\u624b\u5206\u6790\u8bba\u6587\u3001\u4ee3\u7801\u548c\u8865\u5145\u6750\u6599\uff0c\u751f\u6210\u7ed3\u6784\u5316Jupyter Notebook\u548c\u5efa\u8bae\u3002", "result": "\u6d4b\u8bd5\u663e\u793a\uff0cOpenPub\u5c06\u91cd\u590d\u65f6\u95f4\u4ece30\u591a\u5c0f\u65f6\u7f29\u77ed\u81f3\u7ea61\u5c0f\u65f6\uff0c\u5e76\u9ad8\u8986\u76d6\u7387\u5730\u91cd\u73b0\u56fe\u8868\u548c\u7ed3\u679c\u3002", "conclusion": "AI\u5de5\u5177\u80fd\u6709\u6548\u51cf\u8f7b\u53ef\u91cd\u590d\u6027\u8d1f\u62c5\uff0c\u4fc3\u8fdb\u66f4\u900f\u660e\u7684\u79d1\u5b66\u4ea4\u6d41\uff0c\u5176\u6a21\u5757\u5316\u67b6\u6784\u8fd8\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u5f00\u653e\u79d1\u5b66\u76ee\u6807\u3002"}}
{"id": "2506.20291", "pdf": "https://arxiv.org/pdf/2506.20291", "abs": "https://arxiv.org/abs/2506.20291", "authors": ["Haoran Zhang", "Xin Zhao", "Jinze Chen", "Junpeng Guo"], "title": "A Literature Review on Simulation in Conversational Recommender Systems", "categories": ["cs.HC", "cs.IR"], "comment": "6 pages, 1 figures, accepted as a poster for CSWIM 2025", "summary": "Conversational Recommender Systems (CRSs) have garnered attention as a novel\napproach to delivering personalized recommendations through multi-turn\ndialogues. This review developed a taxonomy framework to systematically\ncategorize relevant publications into four groups: dataset construction,\nalgorithm design, system evaluation, and empirical studies, providing a\ncomprehensive analysis of simulation methods in CRSs research. Our analysis\nreveals that simulation methods play a key role in tackling CRSs' main\nchallenges. For example, LLM-based simulation methods have been used to create\nconversational recommendation data, enhance CRSs algorithms, and evaluate CRSs.\nDespite several challenges, such as dataset bias, the limited output\nflexibility of LLM-based simulations, and the gap between text semantic space\nand behavioral semantics, persist due to the complexity in Human-Computer\nInteraction (HCI) of CRSs, simulation methods hold significant potential for\nadvancing CRS research. This review offers a thorough summary of the current\nresearch landscape in this domain and identifies promising directions for\nfuture inquiry.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff08CRSs\uff09\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7c7b\u6846\u67b6\uff0c\u603b\u7ed3\u4e86\u6a21\u62df\u65b9\u6cd5\u5728\u89e3\u51b3CRSs\u6311\u6218\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff08CRSs\uff09\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u5b9e\u73b0\u4e2a\u6027\u5316\u63a8\u8350\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u5206\u6790\u6a21\u62df\u65b9\u6cd5\u5728\u89e3\u51b3\u5176\u6838\u5fc3\u6311\u6218\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u7c7b\u6846\u67b6\uff0c\u5c06\u76f8\u5173\u7814\u7a76\u5206\u4e3a\u6570\u636e\u96c6\u6784\u5efa\u3001\u7b97\u6cd5\u8bbe\u8ba1\u3001\u7cfb\u7edf\u8bc4\u4f30\u548c\u5b9e\u8bc1\u7814\u7a76\u56db\u7c7b\uff0c\u5e76\u5bf9\u6a21\u62df\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\u3002", "result": "\u6a21\u62df\u65b9\u6cd5\uff08\u5982\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff09\u5728\u751f\u6210\u6570\u636e\u3001\u4f18\u5316\u7b97\u6cd5\u548c\u8bc4\u4f30\u7cfb\u7edf\u4e2d\u53d1\u6325\u4e86\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u4ecd\u5b58\u5728\u6570\u636e\u96c6\u504f\u5dee\u548c\u8bed\u4e49\u5dee\u8ddd\u7b49\u6311\u6218\u3002", "conclusion": "\u6a21\u62df\u65b9\u6cd5\u5bf9\u63a8\u52a8CRSs\u7814\u7a76\u5177\u6709\u6f5c\u529b\uff0c\u672a\u6765\u9700\u89e3\u51b3\u73b0\u6709\u6311\u6218\u5e76\u63a2\u7d22\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.19895", "pdf": "https://arxiv.org/pdf/2506.19895", "abs": "https://arxiv.org/abs/2506.19895", "authors": ["Miguel N. Font", "Jos\u00e9 L. Jorro-Aragoneses", "Carlos M. Ala\u00edz"], "title": "A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted for presentation at ICANN 2025\n  (International Conference on Artificial Neural Networks) and will appear in\n  the conference proceedings published by Springer Nature in the Lecture Notes\n  in Computer Science (LNCS) series. The final authenticated version will be\n  available on the publisher website", "summary": "Neural Networks have high accuracy in solving problems where it is difficult\nto detect patterns or create a logical model. However, these algorithms\nsometimes return wrong solutions, which become problematic in high-risk domains\nlike medical diagnosis or autonomous driving. One strategy to detect and\nmitigate these errors is the measurement of the uncertainty over neural network\ndecisions. In this paper, we present a novel post-hoc framework for measuring\nthe uncertainty of a decision based on retrieved training cases that have a\nsimilar activation vector to the query for each layer. Based on these retrieved\ncases, we propose two new metrics: Decision Change and Layer Uncertainty, which\ncapture changes in nearest-neighbor class distributions across layers. We\nevaluated our approach in a classification model for two datasets: CIFAR-10 and\nMNIST. The results show that these metrics enhance uncertainty estimation,\nespecially in challenging classification tasks, outperforming softmax-based\nconfidence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bad\u7ec3\u6848\u4f8b\u68c0\u7d22\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u6d4b\u91cf\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u6307\u6807\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u57fa\u4e8esoftmax\u7684\u7f6e\u4fe1\u5ea6\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u533b\u7597\u8bca\u65ad\u6216\u81ea\u52a8\u9a7e\u9a76\uff09\u4e2d\u53ef\u80fd\u8fd4\u56de\u9519\u8bef\u51b3\u7b56\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u7f13\u89e3\u8fd9\u4e9b\u9519\u8bef\u3002", "method": "\u901a\u8fc7\u68c0\u7d22\u4e0e\u67e5\u8be2\u5177\u6709\u76f8\u4f3c\u6fc0\u6d3b\u5411\u91cf\u7684\u8bad\u7ec3\u6848\u4f8b\uff0c\u63d0\u51fa\u4e24\u79cd\u65b0\u6307\u6807\uff1a\u51b3\u7b56\u53d8\u5316\u548c\u5c42\u4e0d\u786e\u5b9a\u6027\uff0c\u7528\u4e8e\u6355\u6349\u8de8\u5c42\u6700\u8fd1\u90bb\u7c7b\u5206\u5e03\u7684\u53d8\u5316\u3002", "result": "\u5728CIFAR-10\u548cMNIST\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u6307\u6807\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u548c\u6307\u6807\u80fd\u6709\u6548\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2506.20128", "pdf": "https://arxiv.org/pdf/2506.20128", "abs": "https://arxiv.org/abs/2506.20128", "authors": ["Aashiq Muhamed"], "title": "CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at LLM4Eval @ SIGIR 2025", "summary": "RAG systems enhance LLMs by incorporating external knowledge, which is\ncrucial for domains that demand factual accuracy and up-to-date information.\nHowever, evaluating the multifaceted quality of RAG outputs, spanning aspects\nsuch as contextual coherence, query relevance, factual correctness, and\ninformational completeness, poses significant challenges. Existing evaluation\nmethods often rely on simple lexical overlap metrics, which are inadequate for\ncapturing these nuances, or involve complex multi-stage pipelines with\nintermediate steps like claim extraction or require finetuning specialized\njudge models, hindering practical efficiency. To address these limitations, we\npropose CCRS (Contextual Coherence and Relevance Score), a novel suite of five\nmetrics that utilizes a single, powerful, pretrained LLM as a zero-shot,\nend-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance\n(QR), Information Density (ID), Answer Correctness (AC), and Information Recall\n(IR). We apply CCRS to evaluate six diverse RAG system configurations on the\nchallenging BioASQ dataset. Our analysis demonstrates that CCRS effectively\ndiscriminates between system performances, confirming, for instance, that the\nMistral-7B reader outperforms Llama variants. We provide a detailed analysis of\nCCRS metric properties, including score distributions, convergent/discriminant\nvalidity, tie rates, population statistics, and discriminative power. Compared\nto the complex RAGChecker framework, CCRS offers comparable or superior\ndiscriminative power for key aspects like recall and faithfulness, while being\nsignificantly more computationally efficient. CCRS thus provides a practical,\ncomprehensive, and efficient framework for evaluating and iteratively improving\nRAG systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCCRS\uff0c\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3LLM\u7684\u96f6\u6837\u672c\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30RAG\u7cfb\u7edf\u7684\u591a\u7ef4\u5ea6\u8d28\u91cf\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u8fde\u8d2f\u6027\u3001\u95ee\u9898\u76f8\u5173\u6027\u7b49\u4e94\u4e2a\u6307\u6807\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u5982\u7b80\u5355\u8bcd\u6c47\u91cd\u53e0\u6307\u6807\u65e0\u6cd5\u6355\u6349\u8d28\u91cf\u7ec6\u8282\uff0c\u6216\u590d\u6742\u591a\u9636\u6bb5\u6d41\u7a0b\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faCCRS\uff0c\u5229\u7528\u5355\u4e00\u9884\u8bad\u7ec3LLM\u4f5c\u4e3a\u96f6\u6837\u672c\u7aef\u5230\u7aef\u8bc4\u4f30\u5668\uff0c\u5305\u542b\u4e94\u4e2a\u6307\u6807\uff08CC\u3001QR\u3001ID\u3001AC\u3001IR\uff09\u3002", "result": "\u5728BioASQ\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1CCRS\u80fd\u6709\u6548\u533a\u5206\u7cfb\u7edf\u6027\u80fd\uff0c\u5982Mistral-7B\u4f18\u4e8eLlama\u53d8\u4f53\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u4f18\u4e8eRAGChecker\u3002", "conclusion": "CCRS\u4e3aRAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u3001\u5168\u9762\u4e14\u9ad8\u6548\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2506.20249", "pdf": "https://arxiv.org/pdf/2506.20249", "abs": "https://arxiv.org/abs/2506.20249", "authors": ["Junyan Cheng", "Peter Clark", "Kyle Richardson"], "title": "Language Modeling by Language Models", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "Can we leverage LLMs to model the process of discovering novel language model\n(LM) architectures? Inspired by real research, we propose a multi-agent LLM\napproach that simulates the conventional stages of research, from ideation and\nliterature search (proposal stage) to design implementation (code generation),\ngenerative pre-training, and downstream evaluation (verification). Using ideas\nfrom scaling laws, our system, Genesys, employs a Ladder of Scales approach;\nnew designs are proposed, adversarially reviewed, implemented, and selectively\nverified at increasingly larger model scales (14M$\\sim$350M parameters) with a\nnarrowing budget (the number of models we can train at each scale). To help\nmake discovery efficient and factorizable, Genesys uses a novel genetic\nprogramming backbone, which we show has empirical advantages over commonly used\ndirect prompt generation workflows (e.g., $\\sim$86\\% percentage point\nimprovement in successful design generation, a key bottleneck). We report\nexperiments involving 1,162 newly discovered designs (1,062 fully verified\nthrough pre-training) and find the best designs to be highly competitive with\nknown architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common\nbenchmarks). We couple these results with comprehensive system-level ablations\nand formal results, which give broader insights into the design of effective\nautonomous discovery systems.", "AI": {"tldr": "\u5229\u7528\u591a\u4ee3\u7406LLM\u6a21\u62df\u7814\u7a76\u8fc7\u7a0b\uff0c\u63d0\u51faGenesys\u7cfb\u7edf\uff0c\u901a\u8fc7\u9057\u4f20\u7f16\u7a0b\u751f\u6210\u65b0\u67b6\u6784\u8bbe\u8ba1\uff0c\u9a8c\u8bc1\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22LLM\u80fd\u5426\u7528\u4e8e\u53d1\u73b0\u65b0\u8bed\u8a00\u6a21\u578b\u67b6\u6784\uff0c\u6a21\u62df\u771f\u5b9e\u7814\u7a76\u6d41\u7a0b\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u91c7\u7528\u591a\u4ee3\u7406LLM\u65b9\u6cd5\uff0c\u7ed3\u5408\u9057\u4f20\u7f16\u7a0b\u548c\u89c4\u6a21\u9636\u68af\u7b56\u7565\uff0c\u5206\u9636\u6bb5\u751f\u6210\u3001\u9a8c\u8bc1\u8bbe\u8ba1\u3002", "result": "\u751f\u62101,162\u4e2a\u65b0\u8bbe\u8ba1\uff0c\u5176\u4e2d1,062\u4e2a\u901a\u8fc7\u9a8c\u8bc1\uff0c\u90e8\u5206\u8bbe\u8ba1\u6027\u80fd\u4f18\u4e8eGPT2\u548cMamba2\u3002", "conclusion": "Genesys\u7cfb\u7edf\u5728\u81ea\u4e3b\u53d1\u73b0\u9ad8\u6548\u67b6\u6784\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4e3a\u81ea\u52a8\u5316\u7814\u7a76\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2506.20476", "pdf": "https://arxiv.org/pdf/2506.20476", "abs": "https://arxiv.org/abs/2506.20476", "authors": ["Tong Zhou"], "title": "Knowledge-Aware Diverse Reranking for Cross-Source Question Answering", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "This paper presents Team Marikarp's solution for the SIGIR 2025 LiveRAG\ncompetition. The competition's evaluation set, automatically generated by\nDataMorgana from internet corpora, encompassed a wide range of target topics,\nquestion types, question formulations, audience types, and knowledge\norganization methods. It offered a fair evaluation of retrieving\nquestion-relevant supporting documents from a 15M documents subset of the\nFineWeb corpus. Our proposed knowledge-aware diverse reranking RAG pipeline\nachieved first place in the competition.", "AI": {"tldr": "Team Marikarp\u7684\u89e3\u51b3\u65b9\u6848\u5728SIGIR 2025 LiveRAG\u7ade\u8d5b\u4e2d\u593a\u51a0\uff0c\u5176\u77e5\u8bc6\u611f\u77e5\u591a\u6837\u6027\u91cd\u6392\u5e8fRAG\u7ba1\u9053\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7ade\u8d5b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u516c\u5e73\u7684\u8bc4\u4f30\u73af\u5883\uff0c\u6d4b\u8bd5\u4ece15M\u6587\u6863\u5b50\u96c6\u4e2d\u68c0\u7d22\u95ee\u9898\u76f8\u5173\u652f\u6301\u6587\u6863\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u77e5\u8bc6\u611f\u77e5\u591a\u6837\u6027\u91cd\u6392\u5e8fRAG\u7ba1\u9053\u3002", "result": "\u5728\u7ade\u8d5b\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u5316\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.19929", "pdf": "https://arxiv.org/pdf/2506.19929", "abs": "https://arxiv.org/abs/2506.19929", "authors": ["Efe \u00c7ak\u0131r", "Patrick Dumond"], "title": "A Comparative Analysis of Reinforcement Learning and Conventional Deep Learning Approaches for Bearing Fault Diagnosis", "categories": ["cs.LG", "I.2.6"], "comment": "5 pages, 5 figures. To appear in the Proceedings of the Canadian\n  Society for Mechanical Engineering (CSME) Congress 2025", "summary": "Bearing faults in rotating machinery can lead to significant operational\ndisruptions and maintenance costs. Modern methods for bearing fault diagnosis\nrely heavily on vibration analysis and machine learning techniques, which often\nrequire extensive labeled data and may not adapt well to dynamic environments.\nThis study explores the feasibility of reinforcement learning (RL),\nspecifically Deep Q-Networks (DQNs), for bearing fault classification tasks in\nmachine condition monitoring to enhance the accuracy and adaptability of\nbearing fault diagnosis. The results demonstrate that while RL models developed\nin this study can match the performance of traditional supervised learning\nmodels under controlled conditions, they excel in adaptability when equipped\nwith optimized reward structures. However, their computational demands\nhighlight areas for further improvement. These findings demonstrate RL's\npotential to complement traditional methods, paving the way for adaptive\ndiagnostic frameworks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5728\u8f74\u627f\u6545\u969c\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\uff0c\u7ed3\u679c\u8868\u660eRL\u5728\u9002\u5e94\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u8ba1\u7b97\u9700\u6c42\u8f83\u9ad8\u3002", "motivation": "\u8f74\u627f\u6545\u969c\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u8fd0\u8425\u4e2d\u65ad\u548c\u7ef4\u62a4\u6210\u672c\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u8bb0\u6570\u636e\u4e14\u9002\u5e94\u6027\u4e0d\u8db3\uff0c\u56e0\u6b64\u63a2\u7d22RL\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6Q\u7f51\u7edc\uff08DQN\uff09\u8fdb\u884c\u8f74\u627f\u6545\u969c\u5206\u7c7b\uff0c\u7814\u7a76\u5176\u5728\u673a\u5668\u72b6\u6001\u76d1\u6d4b\u4e2d\u7684\u8868\u73b0\u3002", "result": "RL\u6a21\u578b\u5728\u63a7\u5236\u6761\u4ef6\u4e0b\u4e0e\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u76f8\u5f53\uff0c\u4f46\u5728\u9002\u5e94\u6027\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u8ba1\u7b97\u9700\u6c42\u8f83\u9ad8\u3002", "conclusion": "RL\u6709\u6f5c\u529b\u8865\u5145\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e3a\u81ea\u9002\u5e94\u8bca\u65ad\u6846\u67b6\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2506.20160", "pdf": "https://arxiv.org/pdf/2506.20160", "abs": "https://arxiv.org/abs/2506.20160", "authors": ["Ruosen Li", "Ziming Luo", "Quan Zhang", "Ruochen Li", "Ben Zhou", "Ali Payani", "Xinya Du"], "title": "AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control", "categories": ["cs.CL"], "comment": null, "summary": "Large reasoning models (LRMs) achieve impressive reasoning capabilities by\ngenerating lengthy chain-of-thoughts, but this \"overthinking\" incurs high\nlatency and cost without commensurate accuracy gains. In this work, we\nintroduce AALC, a lightweight, accuracy-aware length reward integrated into\nreinforcement learning that dynamically balances correctness and brevity during\ntraining. By incorporating validation accuracy into the reward and employing a\nsmooth, dynamically scheduled length penalty, AALC delays length penalty until\ntarget performance is met. Through extensive experiments across standard and\nout-of-distribution math benchmarks, we show that our approach reduces response\nlength by over 50% while maintaining or even improving the original accuracy.\nFurthermore, qualitative analysis reveals that our method curbs redundant\nreasoning patterns such as excessive subgoal setting and verification, leading\nto structurally refined outputs rather than naive truncation. We also identify\nthat efficiency gains are accompanied by reduced interpretability: models\ntrained with AALC omit some narrative framing and explanatory context. These\nfindings highlight the potential of reward-based strategies to guide LRMs\ntoward more efficient, generalizable reasoning paths.", "AI": {"tldr": "AALC\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u3001\u57fa\u4e8e\u51c6\u786e\u6027\u7684\u957f\u5ea6\u5956\u52b1\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u5e73\u8861\u6b63\u786e\u6027\u548c\u7b80\u6d01\u6027\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u6a21\u578b\u7684\u54cd\u5e94\u957f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u901a\u8fc7\u751f\u6210\u5197\u957f\u7684\u601d\u7ef4\u94fe\u5b9e\u73b0\u5f3a\u5927\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u548c\u6210\u672c\uff0c\u4e14\u51c6\u786e\u6027\u63d0\u5347\u6709\u9650\u3002", "method": "AALC\u5c06\u9a8c\u8bc1\u51c6\u786e\u6027\u7eb3\u5165\u5956\u52b1\u673a\u5236\uff0c\u5e76\u91c7\u7528\u52a8\u6001\u8c03\u5ea6\u7684\u957f\u5ea6\u60e9\u7f5a\uff0c\u5ef6\u8fdf\u957f\u5ea6\u60e9\u7f5a\u76f4\u81f3\u8fbe\u5230\u76ee\u6807\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAALC\u5c06\u54cd\u5e94\u957f\u5ea6\u51cf\u5c1150%\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u5197\u4f59\u63a8\u7406\u6a21\u5f0f\u3002", "conclusion": "AALC\u5c55\u793a\u4e86\u57fa\u4e8e\u5956\u52b1\u7684\u7b56\u7565\u5728\u5f15\u5bfcLRMs\u5b9e\u73b0\u9ad8\u6548\u3001\u901a\u7528\u63a8\u7406\u8def\u5f84\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4f46\u4e5f\u53ef\u80fd\u727a\u7272\u90e8\u5206\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.20274", "pdf": "https://arxiv.org/pdf/2506.20274", "abs": "https://arxiv.org/abs/2506.20274", "authors": ["Liya Wang", "David Yi", "Damien Jose", "John Passarelli", "James Gao", "Jordan Leventis", "Kang Li"], "title": "Enterprise Large Language Model Evaluation Benchmark", "categories": ["cs.AI"], "comment": "Submitted to MLNLP 2025 at https://csity2025.org/mlnlp/index", "summary": "Large Language Models (LLMs) ) have demonstrated promise in boosting\nproductivity across AI-powered tools, yet existing benchmarks like Massive\nMultitask Language Understanding (MMLU) inadequately assess enterprise-specific\ntask complexities. We propose a 14-task framework grounded in Bloom's Taxonomy\nto holistically evaluate LLM capabilities in enterprise contexts. To address\nchallenges of noisy data and costly annotation, we develop a scalable pipeline\ncombining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented\ngeneration (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six\nleading models shows open-source contenders like DeepSeek R1 rival proprietary\nmodels in reasoning tasks but lag in judgment-based scenarios, likely due to\noverthinking. Our benchmark reveals critical enterprise performance gaps and\noffers actionable insights for model optimization. This work provides\nenterprises a blueprint for tailored evaluations and advances practical LLM\ndeployment.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eBloom\u5206\u7c7b\u6cd5\u768414\u4efb\u52a1\u6846\u67b6\uff0c\u8bc4\u4f30\u4f01\u4e1a\u73af\u5883\u4e2dLLM\u80fd\u529b\uff0c\u5f00\u53d1\u53ef\u6269\u5c55\u6807\u6ce8\u6d41\u7a0b\uff0c\u6784\u5efa9700\u6837\u672c\u57fa\u51c6\uff0c\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u63a5\u8fd1\u4e13\u6709\u6a21\u578b\uff0c\u4f46\u5728\u5224\u65ad\u4efb\u52a1\u4e2d\u843d\u540e\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\uff08\u5982MMLU\uff09\u672a\u80fd\u5145\u5206\u8bc4\u4f30\u4f01\u4e1a\u7279\u5b9a\u4efb\u52a1\u7684\u590d\u6742\u6027\uff0c\u9700\u5f00\u53d1\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa14\u4efb\u52a1\u6846\u67b6\uff0c\u7ed3\u5408LLM-as-a-Labeler\u3001LLM-as-a-Judge\u548cCRAG\u6280\u672f\uff0c\u6784\u5efa9700\u6837\u672c\u57fa\u51c6\u3002", "result": "\u5f00\u6e90\u6a21\u578b\uff08\u5982DeepSeek R1\uff09\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u63a5\u8fd1\u4e13\u6709\u6a21\u578b\uff0c\u4f46\u5728\u5224\u65ad\u4efb\u52a1\u4e2d\u56e0\u8fc7\u5ea6\u601d\u8003\u800c\u843d\u540e\u3002", "conclusion": "\u4e3a\u4f01\u4e1a\u63d0\u4f9b\u5b9a\u5236\u5316\u8bc4\u4f30\u84dd\u56fe\uff0c\u63a8\u52a8LLM\u5b9e\u9645\u90e8\u7f72\uff0c\u63ed\u793a\u6027\u80fd\u5dee\u8ddd\u5e76\u63d0\u51fa\u4f18\u5316\u5efa\u8bae\u3002"}}
{"id": "2506.20495", "pdf": "https://arxiv.org/pdf/2506.20495", "abs": "https://arxiv.org/abs/2506.20495", "authors": ["Haoze Wu", "Yunzhi Yao", "Wenhao Yu", "Huajun Chen", "Ningyu Zhang"], "title": "ReCode: Updating Code API Knowledge with Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.SE"], "comment": "Work in progress", "summary": "Large Language Models (LLMs) exhibit remarkable code generation capabilities\nbut falter when adapting to frequent updates in external library APIs. This\ncritical limitation, stemming from reliance on outdated API knowledge from\ntheir training data, even with access to current documentation, impedes\nreliable code generation in dynamic environments. To tackle this issue, we\npropose ReCode (rule-based Reinforcement learning for Code Update), a novel\nframework that mimics human programmer adaptation to API changes. Specifically,\nwe construct a dataset of approximately 2,000 data entries to train the LLMs to\nperform version migration based on updated information. Then, we introduce a\nmodified string similarity metric for code evaluation as the reward for\nreinforcement learning. Our experiments demonstrate that ReCode substantially\nboosts LLMs' code generation performance in dynamic API scenarios, especially\non the unseen CodeUpdateArena task. Crucially, compared to supervised\nfine-tuning, ReCode has less impact on LLMs' general code generation abilities.\nWe apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and\nDAPO), all achieving consistent improvements. Notably, after training,\nQwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned\nmodel and the reasoning model with the same architecture. Code is available at\nhttps://github.com/zjunlp/ReCode.", "AI": {"tldr": "ReCode\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5e2e\u52a9LLMs\u9002\u5e94\u52a8\u6001API\u66f4\u65b0\uff0c\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u5bf9\u901a\u7528\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7684\u5f71\u54cd\u3002", "motivation": "LLMs\u5728\u52a8\u6001API\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u5176\u4f9d\u8d56\u8fc7\u65f6\u7684API\u77e5\u8bc6\uff0c\u5373\u4f7f\u6709\u6700\u65b0\u6587\u6863\u4e5f\u96be\u4ee5\u53ef\u9760\u751f\u6210\u4ee3\u7801\u3002", "method": "\u6784\u5efa2000\u6761\u6570\u636e\u8bad\u7ec3LLMs\u8fdb\u884c\u7248\u672c\u8fc1\u79fb\uff0c\u5f15\u5165\u6539\u8fdb\u7684\u5b57\u7b26\u4e32\u76f8\u4f3c\u5ea6\u6307\u6807\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u3002", "result": "ReCode\u663e\u8457\u63d0\u5347LLMs\u5728\u52a8\u6001API\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u672a\u89c1\u4efb\u52a1CodeUpdateArena\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "ReCode\u5728\u591a\u79cdLLMs\u548c\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e2d\u5747\u6709\u6548\uff0cQwen2.5-Coder-7B\u751a\u81f3\u8d85\u8d8a\u66f4\u5927\u53c2\u6570\u6a21\u578b\u3002"}}
{"id": "2506.19935", "pdf": "https://arxiv.org/pdf/2506.19935", "abs": "https://arxiv.org/abs/2506.19935", "authors": ["Shuchen Xue", "Tianyu Xie", "Tianyang Hu", "Zijin Feng", "Jiacheng Sun", "Kenji Kawaguchi", "Zhenguo Li", "Zhi-Ming Ma"], "title": "Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Large language models (LLMs) predominantly use autoregressive (AR)\napproaches, but masked diffusion models (MDMs) are emerging as viable\nalternatives. A key challenge in comparing AR and MDM paradigms is their\ntypical architectural difference: AR models are often decoder-only, while MDMs\nhave largely been encoder-only. This practice of changing both the modeling\nparadigm and architecture simultaneously makes direct comparisons unfair, as\nit's hard to distinguish whether observed differences stem from the paradigm\nitself or the architectural shift. This research evaluates MDMs within a\ndecoder-only framework to: (1) equitably compare MDM (as Any-Order AR, or\nAO-AR) and standard AR paradigms. Our investigation suggests that the standard\nAO-AR objective, which averages over all token permutations, may benefit from\nrefinement, as many permutations appear less informative compared to the\nlanguage's inherent left-to-right structure. (2) Investigate architectural\ninfluences (decoder-only vs. encoder-only) within MDMs. We demonstrate that\nwhile encoder-only MDMs model a simpler conditional probability space,\ndecoder-only MDMs can achieve dramatic generation speedups ($\\sim25\\times$) and\ncomparable perplexity with temperature annealing despite modeling a vastly\nlarger space, highlighting key trade-offs. This work thus decouples core\nparadigm differences from architectural influences, offering insights for\nfuture model design. Code is available at https://github.com/scxue/AO-GPT-MDM.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u81ea\u56de\u5f52\uff08AR\uff09\u548c\u63a9\u7801\u6269\u6563\u6a21\u578b\uff08MDM\uff09\u5728\u89e3\u7801\u5668\u6846\u67b6\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0MDM\uff08\u4f5c\u4e3a\u4efb\u610f\u987a\u5e8fAR\uff09\u5728\u751f\u6210\u901f\u5ea6\u548c\u56f0\u60d1\u5ea6\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u540c\u65f6\u63a2\u8ba8\u4e86\u67b6\u6784\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u516c\u5e73\u6bd4\u8f83AR\u548cMDM\u8303\u5f0f\uff0c\u907f\u514d\u56e0\u67b6\u6784\u5dee\u5f02\u5bfc\u81f4\u7684\u4e0d\u516c\u5e73\u5bf9\u6bd4\uff0c\u5e76\u63a2\u7d22MDM\u5728\u89e3\u7801\u5668\u6846\u67b6\u4e0b\u7684\u6f5c\u529b\u3002", "method": "\u65b9\u6cd5\u662f\u5c06MDM\u7f6e\u4e8e\u89e3\u7801\u5668\u6846\u67b6\u4e0b\uff0c\u4f5c\u4e3a\u4efb\u610f\u987a\u5e8fAR\uff08AO-AR\uff09\u4e0e\u6807\u51c6AR\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e76\u7814\u7a76\u67b6\u6784\uff08\u89e3\u7801\u5668\u4e0e\u7f16\u7801\u5668\uff09\u5bf9MDM\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u89e3\u7801\u5668MDM\u5728\u751f\u6210\u901f\u5ea6\u4e0a\u663e\u8457\u63d0\u5347\uff08\u7ea625\u500d\uff09\uff0c\u4e14\u56f0\u60d1\u5ea6\u4e0e\u6807\u51c6AR\u76f8\u5f53\uff0c\u4f46\u9700\u8981\u6e29\u5ea6\u9000\u706b\u3002\u7f16\u7801\u5668MDM\u5efa\u6a21\u66f4\u7b80\u5355\uff0c\u4f46\u6027\u80fd\u53d7\u9650\u3002", "conclusion": "\u7ed3\u8bba\u662f\u89e3\u7801\u5668MDM\u5728\u901f\u5ea6\u548c\u6027\u80fd\u4e0a\u6709\u4f18\u52bf\uff0c\u67b6\u6784\u9009\u62e9\u5bf9\u6a21\u578b\u8868\u73b0\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.20167", "pdf": "https://arxiv.org/pdf/2506.20167", "abs": "https://arxiv.org/abs/2506.20167", "authors": ["Fengze Li", "Yue Wang", "Yangle Liu", "Ming Huang", "Dou Hong", "Jieming Ma"], "title": "SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multivariate time series forecasting requires models to simultaneously\ncapture variable-wise structural dependencies and generalize across diverse\ntasks. While structural encoders are effective in modeling feature\ninteractions, they lack the capacity to support semantic-level reasoning or\ntask adaptation. Conversely, large language models (LLMs) possess strong\ngeneralization capabilities but remain incompatible with raw time series\ninputs. This gap limits the development of unified, transferable prediction\nsystems. Therefore, we introduce SEED, a structural encoder for\nembedding-driven decoding, which integrates four stages: a token-aware encoder\nfor patch extraction, a projection module that aligns patches with language\nmodel embeddings, a semantic reprogramming mechanism that maps patches to\ntask-aware prototypes, and a frozen language model for prediction. This modular\narchitecture decouples representation learning from inference, enabling\nefficient alignment between numerical patterns and semantic reasoning.\nEmpirical results demonstrate that the proposed method achieves consistent\nimprovements over strong baselines, and comparative studies on various datasets\nconfirm SEED's role in addressing the structural-semantic modeling gap.", "AI": {"tldr": "SEED\u662f\u4e00\u79cd\u7ed3\u6784\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u56db\u9636\u6bb5\u8bbe\u8ba1\uff08\u8865\u4e01\u63d0\u53d6\u3001\u5d4c\u5165\u5bf9\u9f50\u3001\u8bed\u4e49\u91cd\u7f16\u7a0b\u548c\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\uff09\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7ed3\u6784\u4f9d\u8d56\u4e0e\u8bed\u4e49\u63a8\u7406\u7684\u9e3f\u6c9f\u3002", "motivation": "\u73b0\u6709\u7ed3\u6784\u7f16\u7801\u5668\u7f3a\u4e4f\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u76f4\u63a5\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u9650\u5236\u4e86\u7edf\u4e00\u9884\u6d4b\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "method": "SEED\u5305\u542b\u56db\u4e2a\u6a21\u5757\uff1a\u8865\u4e01\u63d0\u53d6\u7684\u7f16\u7801\u5668\u3001\u5d4c\u5165\u5bf9\u9f50\u7684\u6295\u5f71\u6a21\u5757\u3001\u4efb\u52a1\u611f\u77e5\u539f\u578b\u7684\u8bed\u4e49\u91cd\u7f16\u7a0b\u673a\u5236\uff0c\u4ee5\u53ca\u51bb\u7ed3\u7684\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSEED\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6709\u6548\u586b\u8865\u4e86\u7ed3\u6784-\u8bed\u4e49\u5efa\u6a21\u7684\u9e3f\u6c9f\u3002", "conclusion": "SEED\u901a\u8fc7\u89e3\u8026\u8868\u793a\u5b66\u4e60\u4e0e\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u6570\u503c\u6a21\u5f0f\u4e0e\u8bed\u4e49\u63a8\u7406\u7684\u9ad8\u6548\u5bf9\u9f50\uff0c\u4e3a\u7edf\u4e00\u9884\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.20332", "pdf": "https://arxiv.org/pdf/2506.20332", "abs": "https://arxiv.org/abs/2506.20332", "authors": ["Jihao Gu", "Qihang Ai", "Yingyao Wang", "Pi Bu", "Jingxuan Xing", "Zekun Zhu", "Wei Jiang", "Ziming Wang", "Yingxiu Zhao", "Ming-Liang Zhang", "Jun Song", "Yuning Jiang", "Bo Zheng"], "title": "Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards", "categories": ["cs.AI"], "comment": "14 pages, 12 figures", "summary": "Vision-language model-based mobile agents have gained the ability to not only\nunderstand complex instructions and mobile screenshots, but also optimize their\naction outputs via thinking and reasoning, benefiting from reinforcement\nlearning, such as Group Relative Policy Optimization (GRPO). However, existing\nresearch centers on offline reinforcement learning training or online\noptimization using action-level rewards, which limits the agent's dynamic\ninteraction with the environment. This often results in agents settling into\nlocal optima, thereby weakening their ability for exploration and error action\ncorrection. To address these challenges, we introduce an approach called\nMobile-R1, which employs interactive multi-turn reinforcement learning with\ntask-level rewards for mobile agents. Our training framework consists of three\nstages: initial format finetuning, single-step online training via action-level\nreward, followed by online training via task-level reward based on multi-turn\ntrajectories. This strategy is designed to enhance the exploration and error\ncorrection capabilities of Mobile-R1, leading to significant performance\nimprovements. Moreover, we have collected a dataset covering 28 Chinese\napplications with 24,521 high-quality manual annotations and established a new\nbenchmark with 500 trajectories. We will open source all resources, including\nthe dataset, benchmark, model weight, and codes:\nhttps://mobile-r1.github.io/Mobile-R1/.", "AI": {"tldr": "Mobile-R1\u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u8f6e\u4ea4\u4e92\u5f3a\u5316\u5b66\u4e60\u7684\u79fb\u52a8\u4ee3\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u4efb\u52a1\u7ea7\u5956\u52b1\u63d0\u5347\u63a2\u7d22\u548c\u7ea0\u9519\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c40\u9650\u4e8e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6216\u52a8\u4f5c\u7ea7\u5956\u52b1\u7684\u5728\u7ebf\u4f18\u5316\uff0c\u5bfc\u81f4\u4ee3\u7406\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a\u521d\u59cb\u5fae\u8c03\u3001\u52a8\u4f5c\u7ea7\u5956\u52b1\u5355\u6b65\u8bad\u7ec3\u3001\u4efb\u52a1\u7ea7\u5956\u52b1\u591a\u8f6e\u8f68\u8ff9\u8bad\u7ec3\u3002", "result": "\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u7684\u63a2\u7d22\u548c\u7ea0\u9519\u80fd\u529b\uff0c\u5e76\u5efa\u7acb\u4e86\u5305\u542b28\u4e2a\u5e94\u7528\u7684\u6570\u636e\u96c6\u548c500\u8f68\u8ff9\u7684\u57fa\u51c6\u3002", "conclusion": "Mobile-R1\u901a\u8fc7\u4efb\u52a1\u7ea7\u5956\u52b1\u548c\u591a\u8f6e\u4ea4\u4e92\u5f3a\u5316\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2506.19937", "pdf": "https://arxiv.org/pdf/2506.19937", "abs": "https://arxiv.org/abs/2506.19937", "authors": ["Tomas M. Bosschieter", "Luis Franca", "Jessica Wolk", "Yiyuan Wu", "Bella Mehta", "Joseph Dehoney", "Orsolya Kiss", "Fiona C. Baker", "Qingyu Zhao", "Rich Caruana", "Kilian M. Pohl"], "title": "The Most Important Features in Generalized Additive Models Might Be Groups of Features", "categories": ["cs.LG"], "comment": null, "summary": "While analyzing the importance of features has become ubiquitous in\ninterpretable machine learning, the joint signal from a group of related\nfeatures is sometimes overlooked or inadvertently excluded. Neglecting the\njoint signal could bypass a critical insight: in many instances, the most\nsignificant predictors are not isolated features, but rather the combined\neffect of groups of features. This can be especially problematic for datasets\nthat contain natural groupings of features, including multimodal datasets. This\npaper introduces a novel approach to determine the importance of a group of\nfeatures for Generalized Additive Models (GAMs) that is efficient, requires no\nmodel retraining, allows defining groups posthoc, permits overlapping groups,\nand remains meaningful in high-dimensional settings. Moreover, this definition\noffers a parallel with explained variation in statistics. We showcase\nproperties of our method on three synthetic experiments that illustrate the\nbehavior of group importance across various data regimes. We then demonstrate\nthe importance of groups of features in identifying depressive symptoms from a\nmultimodal neuroscience dataset, and study the importance of social\ndeterminants of health after total hip arthroplasty. These two case studies\nreveal that analyzing group importance offers a more accurate, holistic view of\nthe medical issues compared to a single-feature analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5e7f\u4e49\u52a0\u6027\u6a21\u578b\uff08GAMs\uff09\u4e2d\u7279\u5f81\u7ec4\u7684\u91cd\u8981\u6027\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\uff0c\u652f\u6301\u4e8b\u540e\u5b9a\u4e49\u7ec4\u548c\u91cd\u53e0\u7ec4\uff0c\u5e76\u5728\u9ad8\u7ef4\u6570\u636e\u4e2d\u4fdd\u6301\u6709\u6548\u6027\u3002", "motivation": "\u5728\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u7279\u5f81\u7ec4\u7684\u91cd\u8981\u6027\u5e38\u88ab\u5ffd\u89c6\uff0c\u800c\u8054\u5408\u4fe1\u53f7\u53ef\u80fd\u63d0\u4f9b\u5173\u952e\u89c1\u89e3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u786e\u5b9aGAMs\u4e2d\u7279\u5f81\u7ec4\u7684\u91cd\u8981\u6027\uff0c\u5177\u6709\u9ad8\u6548\u6027\u3001\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3001\u652f\u6301\u4e8b\u540e\u5b9a\u4e49\u548c\u91cd\u53e0\u7ec4\u7684\u7279\u70b9\u3002", "result": "\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u548c\u4e24\u4e2a\u771f\u5b9e\u6848\u4f8b\uff08\u6291\u90c1\u75c7\u75c7\u72b6\u8bc6\u522b\u548c\u9acb\u5173\u8282\u7f6e\u6362\u540e\u7684\u5065\u5eb7\u793e\u4f1a\u51b3\u5b9a\u56e0\u7d20\uff09\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5206\u6790\u7279\u5f81\u7ec4\u7684\u91cd\u8981\u6027\u6bd4\u5355\u7279\u5f81\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u3001\u5168\u9762\u7684\u89c6\u89d2\uff0c\u5c24\u5176\u5728\u533b\u5b66\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.20178", "pdf": "https://arxiv.org/pdf/2506.20178", "abs": "https://arxiv.org/abs/2506.20178", "authors": ["Zhiyuan Wang", "Jinhao Duan", "Qingni Wang", "Xiaofeng Zhu", "Tianlong Chen", "Xiaoshuang Shi", "Kaidi Xu"], "title": "COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Uncertainty quantification (UQ) for foundation models is essential to\nidentify and mitigate potential hallucinations in automatically generated text.\nHowever, heuristic UQ approaches lack formal guarantees for key metrics such as\nthe false discovery rate (FDR) in selective prediction. Previous work adopts\nthe split conformal prediction (SCP) framework to ensure desired coverage of\nadmissible answers by constructing prediction sets, but these sets often\ncontain incorrect candidates, limiting their practical utility. To address\nthis, we propose COIN, an uncertainty-guarding selection framework that\ncalibrates statistically valid thresholds to filter a single generated answer\nper question under user-specified FDR constraints. COIN estimates the empirical\nerror rate on a calibration set and applies confidence interval methods such as\nClopper-Pearson to establish a high-probability upper bound on the true error\nrate (i.e., FDR). This enables the selection of the largest uncertainty\nthreshold that ensures FDR control on test data while significantly increasing\nsample retention. We demonstrate COIN's robustness in risk control, strong\ntest-time power in retaining admissible answers, and predictive efficiency\nunder limited calibration data across both general and multimodal text\ngeneration tasks. Furthermore, we show that employing alternative upper bound\nconstructions and UQ strategies can further boost COIN's power performance,\nwhich underscores its extensibility and adaptability to diverse application\nscenarios.", "AI": {"tldr": "COIN\u662f\u4e00\u4e2a\u4e0d\u786e\u5b9a\u6027\u4fdd\u62a4\u9009\u62e9\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u8ba1\u6821\u51c6\u9608\u503c\u5728\u7528\u6237\u6307\u5b9a\u7684FDR\u7ea6\u675f\u4e0b\u7b5b\u9009\u5355\u4e2a\u751f\u6210\u7b54\u6848\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u4fdd\u7559\u7387\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u5bf9\u8bc6\u522b\u548c\u51cf\u5c11\u81ea\u52a8\u751f\u6210\u6587\u672c\u4e2d\u7684\u5e7b\u89c9\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u5173\u952e\u6307\u6807\uff08\u5982FDR\uff09\u7684\u5f62\u5f0f\u5316\u4fdd\u8bc1\u3002", "method": "\u63d0\u51faCOIN\u6846\u67b6\uff0c\u5229\u7528\u6821\u51c6\u96c6\u4f30\u8ba1\u7ecf\u9a8c\u9519\u8bef\u7387\uff0c\u5e76\u5e94\u7528Clopper-Pearson\u7b49\u65b9\u6cd5\u5efa\u7acb\u771f\u5b9e\u9519\u8bef\u7387\u7684\u9ad8\u6982\u7387\u4e0a\u9650\uff0c\u4ee5\u9009\u62e9\u6700\u5927\u4e0d\u786e\u5b9a\u6027\u9608\u503c\u3002", "result": "COIN\u5728\u98ce\u9669\u63a7\u5236\u3001\u6d4b\u8bd5\u65f6\u4fdd\u7559\u5408\u683c\u7b54\u6848\u7684\u80fd\u529b\u4ee5\u53ca\u6709\u9650\u6821\u51c6\u6570\u636e\u4e0b\u7684\u9884\u6d4b\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u53ef\u901a\u8fc7\u66ff\u4ee3\u4e0a\u9650\u6784\u9020\u548cUQ\u7b56\u7565\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "COIN\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u5b9e\u7528\u6027\u548c\u6548\u679c\u3002"}}
{"id": "2506.20357", "pdf": "https://arxiv.org/pdf/2506.20357", "abs": "https://arxiv.org/abs/2506.20357", "authors": ["Sungwon Han", "Sungkyu Park", "Seungeon Lee"], "title": "Tabular Feature Discovery With Reasoning Type Exploration", "categories": ["cs.AI"], "comment": null, "summary": "Feature engineering for tabular data remains a critical yet challenging step\nin machine learning. Recently, large language models (LLMs) have been used to\nautomatically generate new features by leveraging their vast knowledge.\nHowever, existing LLM-based approaches often produce overly simple or\nrepetitive features, partly due to inherent biases in the transformations the\nLLM chooses and the lack of structured reasoning guidance during generation. In\nthis paper, we propose a novel method REFeat, which guides an LLM to discover\ndiverse and informative features by leveraging multiple types of reasoning to\nsteer the feature generation process. Experiments on 59 benchmark datasets\ndemonstrate that our approach not only achieves higher predictive accuracy on\naverage, but also discovers more diverse and meaningful features. These results\nhighlight the promise of incorporating rich reasoning paradigms and adaptive\nstrategy selection into LLM-driven feature discovery for tabular data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aREFeat\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u79cd\u63a8\u7406\u7c7b\u578b\u6307\u5bfcLLM\u751f\u6210\u591a\u6837\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u7279\u5f81\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u65b9\u6cd5\u751f\u6210\u7279\u5f81\u8fc7\u4e8e\u7b80\u5355\u6216\u91cd\u590d\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u7279\u5f81\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u751f\u6210\u7279\u5f81\u8fc7\u4e8e\u7b80\u5355\u6216\u91cd\u590d\u7684\u95ee\u9898\uff0c\u90e8\u5206\u539f\u56e0\u662fLLM\u9009\u62e9\u7684\u8f6c\u6362\u5b58\u5728\u56fa\u6709\u504f\u89c1\uff0c\u4e14\u7f3a\u4e4f\u7ed3\u6784\u5316\u63a8\u7406\u6307\u5bfc\u3002", "method": "\u63d0\u51faREFeat\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u79cd\u63a8\u7406\u7c7b\u578b\u5f15\u5bfcLLM\u751f\u6210\u7279\u5f81\uff0c\u4ee5\u589e\u5f3a\u7279\u5f81\u7684\u591a\u6837\u6027\u548c\u4fe1\u606f\u91cf\u3002", "result": "\u572859\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cREFeat\u4e0d\u4ec5\u5e73\u5747\u9884\u6d4b\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u8fd8\u80fd\u53d1\u73b0\u66f4\u591a\u6837\u4e14\u6709\u610f\u4e49\u7684\u7279\u5f81\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u4e30\u5bcc\u7684\u63a8\u7406\u8303\u5f0f\u548c\u81ea\u9002\u5e94\u7b56\u7565\u9009\u62e9\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347LLM\u9a71\u52a8\u7684\u8868\u683c\u6570\u636e\u7279\u5f81\u53d1\u73b0\u6548\u679c\u3002"}}
{"id": "2506.19992", "pdf": "https://arxiv.org/pdf/2506.19992", "abs": "https://arxiv.org/abs/2506.19992", "authors": ["Gabor Petnehazi", "Bernadett Aradi"], "title": "HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The explosive growth of complex datasets across various modalities\nnecessitates advanced analytical tools that not only group data effectively but\nalso provide human-understandable insights into the discovered structures. We\nintroduce HERCULES (Hierarchical Embedding-based Recursive Clustering Using\nLLMs for Efficient Summarization), a novel algorithm and Python package\ndesigned for hierarchical k-means clustering of diverse data types, including\ntext, images, and numeric data (processed one modality per run). HERCULES\nconstructs a cluster hierarchy by recursively applying k-means clustering,\nstarting from individual data points at level 0. A key innovation is its deep\nintegration of Large Language Models (LLMs) to generate semantically rich\ntitles and descriptions for clusters at each level of the hierarchy,\nsignificantly enhancing interpretability. The algorithm supports two main\nrepresentation modes: `direct' mode, which clusters based on original data\nembeddings or scaled numeric features, and `description' mode, which clusters\nbased on embeddings derived from LLM-generated summaries. Users can provide a\n`topic\\_seed' to guide LLM-generated summaries towards specific themes. An\ninteractive visualization tool facilitates thorough analysis and understanding\nof the clustering results. We demonstrate HERCULES's capabilities and discuss\nits potential for extracting meaningful, hierarchical knowledge from complex\ndatasets.", "AI": {"tldr": "HERCULES\u662f\u4e00\u79cd\u65b0\u578b\u5206\u5c42k-means\u805a\u7c7b\u7b97\u6cd5\uff0c\u652f\u6301\u591a\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u5229\u7528LLM\u751f\u6210\u8bed\u4e49\u4e30\u5bcc\u7684\u805a\u7c7b\u6807\u9898\u548c\u63cf\u8ff0\uff0c\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u590d\u6742\u6570\u636e\u96c6\u7684\u5feb\u901f\u589e\u957f\u9700\u8981\u65e2\u80fd\u6709\u6548\u5206\u7ec4\u6570\u636e\u53c8\u80fd\u63d0\u4f9b\u4eba\u7c7b\u53ef\u7406\u89e3\u6d1e\u5bdf\u7684\u5de5\u5177\u3002", "method": "HERCULES\u901a\u8fc7\u9012\u5f52\u5e94\u7528k-means\u805a\u7c7b\u6784\u5efa\u5c42\u6b21\u7ed3\u6784\uff0c\u5e76\u96c6\u6210LLM\u751f\u6210\u805a\u7c7b\u6807\u9898\u548c\u63cf\u8ff0\uff0c\u652f\u6301\u4e24\u79cd\u8868\u793a\u6a21\u5f0f\u3002", "result": "\u7b97\u6cd5\u80fd\u591f\u4ece\u590d\u6742\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u5206\u5c42\u77e5\u8bc6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u5de5\u5177\u3002", "conclusion": "HERCULES\u5728\u589e\u5f3a\u805a\u7c7b\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u6027\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.20199", "pdf": "https://arxiv.org/pdf/2506.20199", "abs": "https://arxiv.org/abs/2506.20199", "authors": ["Mengqi Wang", "Tiantian Feng", "Shrikanth Narayanan"], "title": "How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have enabled a wide variety of real-world\napplications in various domains. However, creating a high-performing\napplication with high accuracy remains challenging, particularly for subjective\ntasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this\nstudy investigates approaches to improving conversational emotion recognition\n(CER) by LLMs. Specifically, we explore how to retrieve high-quality examples\nin in-context learning (ICL) to enhance CER. We propose various strategies\nbased on random and augmented example retrieval and also analyze the impact of\nconversational context on CER accuracy. Experiments were conducted on the three\ndatasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented\nexample retrieval consistently outperforms other techniques under investigation\nacross all datasets, highlighting the importance of retrieving coherent\ntargeted examples and enhancing them through paraphrasing.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u68c0\u7d22\u9ad8\u8d28\u91cf\u793a\u4f8b\u63d0\u5347\u5bf9\u8bdd\u60c5\u611f\u8bc6\u522b\uff08CER\uff09\u6027\u80fd\uff0c\u63d0\u51fa\u968f\u673a\u548c\u589e\u5f3a\u793a\u4f8b\u68c0\u7d22\u7b56\u7565\uff0c\u5e76\u5206\u6790\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u5bf9CER\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u8868\u660e\u589e\u5f3a\u793a\u4f8b\u68c0\u7d22\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u591a\u4e2a\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u4e3b\u89c2\u4efb\u52a1\uff08\u5982\u60c5\u611f\u8bc6\u522b\uff09\u4e2d\u5b9e\u73b0\u9ad8\u51c6\u786e\u6027\u4ecd\u5177\u6311\u6218\u6027\u3002\u7814\u7a76\u65e8\u5728\u63d0\u5347\u5bf9\u8bdd\u60c5\u611f\u8bc6\u522b\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u968f\u673a\u548c\u589e\u5f3a\u793a\u4f8b\u68c0\u7d22\u7684\u7b56\u7565\uff0c\u5206\u6790\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u5bf9CER\u7684\u5f71\u54cd\uff0c\u5e76\u5728IEMOCAP\u3001MELD\u548cEmoryNLP\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u589e\u5f3a\u793a\u4f8b\u68c0\u7d22\u5728\u6240\u6709\u6570\u636e\u96c6\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u8868\u660e\u68c0\u7d22\u8fde\u8d2f\u76ee\u6807\u793a\u4f8b\u5e76\u901a\u8fc7\u6539\u5199\u589e\u5f3a\u5176\u8d28\u91cf\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u589e\u5f3a\u793a\u4f8b\u68c0\u7d22\u662f\u63d0\u5347\u5bf9\u8bdd\u60c5\u611f\u8bc6\u522b\u6027\u80fd\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u9ad8\u8d28\u91cf\u793a\u4f8b\u548c\u4e0a\u4e0b\u6587\u4f18\u5316\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.20384", "pdf": "https://arxiv.org/pdf/2506.20384", "abs": "https://arxiv.org/abs/2506.20384", "authors": ["Dror Ivry", "Oran Nahum"], "title": "Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios", "categories": ["cs.AI"], "comment": "6 pages, 2 figures", "summary": "This paper introduces two significant contributions to address the issue of\ngrounding claims in a given context. Grounding means that given a context\n(document) and a claim, there's at least one supportive evidence for the claim\nin the document. We will introduce Paladin-mini, a compact (3.8B parameters)\nopen-source classifier model (used for labeling data as grounded or ungrounded)\nengineered for robust performance in real-world scenarios, and the\ngrounding-benchmark, a new evaluation dataset designed to assess performance on\ncritical reasoning tasks. We'll also demonstrate the results of Paladin-mini\nwith benchmarks against the current State-of-the-art and share clear and\nreproducible results.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Paladin-mini\uff083.8B\u53c2\u6570\u7684\u5206\u7c7b\u6a21\u578b\uff09\u548cgrounding-benchmark\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u89e3\u51b3\u4e0a\u4e0b\u6587\u4e2d\u7684\u58f0\u660e\u652f\u6301\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u7ed9\u5b9a\u4e0a\u4e0b\u6587\u4e2d\u4e3a\u58f0\u660e\u63d0\u4f9b\u652f\u6301\u8bc1\u636e\u7684\u95ee\u9898\uff08\u5373\u58f0\u660e\u662f\u5426\u88ab\u4e0a\u4e0b\u6587\u652f\u6301\uff09\u3002", "method": "\u63d0\u51fa\u4e86Paladin-mini\uff08\u5c0f\u578b\u5f00\u6e90\u5206\u7c7b\u6a21\u578b\uff09\u548cgrounding-benchmark\uff08\u8bc4\u4f30\u6570\u636e\u96c6\uff09\uff0c\u7528\u4e8e\u6807\u8bb0\u6570\u636e\u662f\u5426\u88ab\u652f\u6301\u3002", "result": "\u5c55\u793a\u4e86Paladin-mini\u5728\u5f53\u524d\u6700\u5148\u8fdb\u6280\u672f\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\uff0c\u7ed3\u679c\u6e05\u6670\u4e14\u53ef\u590d\u73b0\u3002", "conclusion": "Paladin-mini\u548cgrounding-benchmark\u4e3a\u58f0\u660e\u652f\u6301\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.19997", "pdf": "https://arxiv.org/pdf/2506.19997", "abs": "https://arxiv.org/abs/2506.19997", "authors": ["Geonwoo Cho", "Jaegyun Im", "Jihwan Lee", "Hojun Yi", "Sejin Kim", "Sundong Kim"], "title": "TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generalizing deep reinforcement learning agents to unseen environments\nremains a significant challenge. One promising solution is Unsupervised\nEnvironment Design (UED), a co-evolutionary framework in which a teacher\nadaptively generates tasks with high learning potential, while a student learns\na robust policy from this evolving curriculum. Existing UED methods typically\nmeasure learning potential via regret, the gap between optimal and current\nperformance, approximated solely by value-function loss. Building on these\napproaches, we introduce the transition prediction error as an additional term\nin our regret approximation. To capture how training on one task affects\nperformance on others, we further propose a lightweight metric called\nco-learnability. By combining these two measures, we present Transition-aware\nRegret Approximation with Co-learnability for Environment Design (TRACED).\nEmpirical evaluations show that TRACED yields curricula that improve zero-shot\ngeneralization across multiple benchmarks while requiring up to 2x fewer\nenvironment interactions than strong baselines. Ablation studies confirm that\nthe transition prediction error drives rapid complexity ramp-up and that\nco-learnability delivers additional gains when paired with the transition\nprediction error. These results demonstrate how refined regret approximation\nand explicit modeling of task relationships can be leveraged for\nsample-efficient curriculum design in UED.", "AI": {"tldr": "TRACED\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u8f6c\u79fb\u9884\u6d4b\u8bef\u5dee\u548c\u5171\u5b66\u4e60\u6027\uff0c\u6539\u8fdb\u4e86UED\u6846\u67b6\u4e2d\u7684\u4efb\u52a1\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u73af\u5883\u4ea4\u4e92\u9700\u6c42\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u672a\u77e5\u73af\u5883\u4e2d\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6539\u8fdbUED\u6846\u67b6\u4e2d\u7684\u4efb\u52a1\u751f\u6210\u548c\u5b66\u4e60\u6f5c\u529b\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faTRACED\u65b9\u6cd5\uff0c\u7ed3\u5408\u8f6c\u79fb\u9884\u6d4b\u8bef\u5dee\u548c\u5171\u5b66\u4e60\u6027\u4f5c\u4e3a\u5b66\u4e60\u6f5c\u529b\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u4f18\u5316\u4efb\u52a1\u751f\u6210\u3002", "result": "TRACED\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u4e86\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u4e14\u73af\u5883\u4ea4\u4e92\u9700\u6c42\u51cf\u5c11\u81f3\u57fa\u7ebf\u7684\u4e00\u534a\u3002", "conclusion": "\u901a\u8fc7\u7cbe\u7ec6\u5316\u5b66\u4e60\u6f5c\u529b\u8bc4\u4f30\u548c\u4efb\u52a1\u5173\u7cfb\u5efa\u6a21\uff0cTRACED\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u8bfe\u7a0b\u8bbe\u8ba1\u3002"}}
