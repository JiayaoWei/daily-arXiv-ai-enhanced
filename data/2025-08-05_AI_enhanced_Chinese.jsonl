{"id": "2508.00864", "pdf": "https://arxiv.org/pdf/2508.00864", "abs": "https://arxiv.org/abs/2508.00864", "authors": ["Margarita Bugue\u00f1o", "Gerard de Melo"], "title": "Rethinking Graph-Based Document Classification: Learning Data-Driven Structures Beyond Heuristic Approaches", "categories": ["cs.CL"], "comment": "7 pages, 3 figures, 3 tables. Appendix starts on page 10", "summary": "In document classification, graph-based models effectively capture document\nstructure, overcoming sequence length limitations and enhancing contextual\nunderstanding. However, most existing graph document representations rely on\nheuristics, domain-specific rules, or expert knowledge. Unlike previous\napproaches, we propose a method to learn data-driven graph structures,\neliminating the need for manual design and reducing domain dependence. Our\napproach constructs homogeneous weighted graphs with sentences as nodes, while\nedges are learned via a self-attention model that identifies dependencies\nbetween sentence pairs. A statistical filtering strategy aims to retain only\nstrongly correlated sentences, improving graph quality while reducing the graph\nsize. Experiments on three document classification datasets demonstrate that\nlearned graphs consistently outperform heuristic-based graphs, achieving higher\naccuracy and $F_1$ score. Furthermore, our study demonstrates the effectiveness\nof the statistical filtering in improving classification robustness. These\nresults highlight the potential of automatic graph generation over traditional\nheuristic approaches and open new directions for broader applications in NLP.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u56fe\u7ed3\u6784\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u6587\u6863\u5206\u7c7b\uff0c\u4f18\u4e8e\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u56fe\u6587\u6863\u8868\u793a\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u9886\u57df\u77e5\u8bc6\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u7684\u56fe\u7ed3\u6784\u5b66\u4e60\u3002", "method": "\u6784\u5efa\u540c\u8d28\u52a0\u6743\u56fe\uff0c\u8282\u70b9\u4e3a\u53e5\u5b50\uff0c\u8fb9\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u6a21\u578b\u5b66\u4e60\uff0c\u5e76\u4f7f\u7528\u7edf\u8ba1\u8fc7\u6ee4\u4fdd\u7559\u5f3a\u76f8\u5173\u53e5\u5b50\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u548cF1\u5206\u6570\u66f4\u9ad8\uff0c\u7edf\u8ba1\u8fc7\u6ee4\u63d0\u5347\u4e86\u5206\u7c7b\u9c81\u68d2\u6027\u3002", "conclusion": "\u81ea\u52a8\u56fe\u751f\u6210\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u542f\u53d1\u5f0f\uff0c\u4e3aNLP\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.01036", "pdf": "https://arxiv.org/pdf/2508.01036", "abs": "https://arxiv.org/abs/2508.01036", "authors": ["Omar Elgohary", "Nathan Jorgenson", "Trenton Marple"], "title": "Addressing Cold Start For next-article Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "This replication study modifies ALMM, the Adaptive Linear Mapping Model\nconstructed for the next song recommendation, to the news recommendation\nproblem on the MIND dataset. The original version of ALMM computes latent\nrepresentations for users, last-time items, and current items in a tensor\nfactorization structure and learns a linear mapping from content features to\nlatent item vectors. Our replication aims to improve recommendation performance\nin cold-start scenarios by restructuring this model to sequential news click\nbehavior, viewing consecutively read articles as (last news, next news) tuples.\nInstead of the original audio features, we apply BERT and a TF-IDF (Term\nFrequency-Inverse Document Frequency) to news titles and abstracts to extract\ntoken contextualized representations and align them with triplet-based user\nreading patterns. We also propose a reproducibly thorough pre-processing\npipeline combining news filtering and feature integrity validation. Our\nimplementation of ALMM with TF-IDF shows relatively improved recommendation\naccuracy and robustness over Forbes and Oord baseline models in the cold-start\nscenario. We demonstrate that ALMM in a minimally modified state is not\nsuitable for next news recommendation.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06ALMM\u6a21\u578b\u4ece\u6b4c\u66f2\u63a8\u8350\u8c03\u6574\u5230\u65b0\u95fb\u63a8\u8350\uff0c\u6539\u8fdb\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u7684\u63a8\u8350\u6027\u80fd\uff0c\u4f7f\u7528BERT\u548cTF-IDF\u63d0\u53d6\u65b0\u95fb\u7279\u5f81\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6539\u8fdb\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u65b0\u95fb\u63a8\u8350\u6027\u80fd\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u8c03\u6574ALMM\u6a21\u578b\u4ee5\u9002\u5e94\u65b0\u95fb\u63a8\u8350\u4efb\u52a1\u3002", "method": "\u4fee\u6539ALMM\u6a21\u578b\uff0c\u4f7f\u7528BERT\u548cTF-IDF\u63d0\u53d6\u65b0\u95fb\u6807\u9898\u548c\u6458\u8981\u7684\u7279\u5f81\uff0c\u5e76\u7ed3\u5408\u7528\u6237\u9605\u8bfb\u884c\u4e3a\u6784\u5efa\u4e09\u5143\u7ec4\u3002", "result": "\u6539\u8fdb\u540e\u7684ALMM\u6a21\u578b\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u4e8eForbes\u548cOord\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "ALMM\u6a21\u578b\u5728\u672a\u5927\u5e45\u4fee\u6539\u7684\u60c5\u51b5\u4e0b\u4e0d\u9002\u7528\u4e8e\u65b0\u95fb\u63a8\u8350\u4efb\u52a1\u3002"}}
{"id": "2508.00889", "pdf": "https://arxiv.org/pdf/2508.00889", "abs": "https://arxiv.org/abs/2508.00889", "authors": ["Hagyeong Shin", "Binoy Robin Dalal", "Iwona Bialynicka-Birula", "Navjot Matharu", "Ryan Muir", "Xingwei Yang", "Samuel W. K. Wong"], "title": "FECT: Factuality Evaluation of Interpretive AI-Generated Claims in Contact Center Conversation Transcripts", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted for an oral presentation at Agentic & GenAI Evaluation KDD\n  2025: KDD workshop on Evaluation and Trustworthiness of Agentic and\n  Generative AI Models", "summary": "Large language models (LLMs) are known to hallucinate, producing natural\nlanguage outputs that are not grounded in the input, reference materials, or\nreal-world knowledge. In enterprise applications where AI features support\nbusiness decisions, such hallucinations can be particularly detrimental. LLMs\nthat analyze and summarize contact center conversations introduce a unique set\nof challenges for factuality evaluation, because ground-truth labels often do\nnot exist for analytical interpretations about sentiments captured in the\nconversation and root causes of the business problems. To remedy this, we first\nintroduce a \\textbf{3D} -- \\textbf{Decompose, Decouple, Detach} -- paradigm in\nthe human annotation guideline and the LLM-judges' prompt to ground the\nfactuality labels in linguistically-informed evaluation criteria. We then\nintroduce \\textbf{FECT}, a novel benchmark dataset for \\textbf{F}actuality\n\\textbf{E}valuation of Interpretive AI-Generated \\textbf{C}laims in Contact\nCenter Conversation \\textbf{T}ranscripts, labeled under our 3D paradigm.\nLastly, we report our findings from aligning LLM-judges on the 3D paradigm.\nOverall, our findings contribute a new approach for automatically evaluating\nthe factuality of outputs generated by an AI system for analyzing contact\ncenter conversations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a3D\uff08\u5206\u89e3\u3001\u89e3\u8026\u3001\u8131\u79bb\uff09\u7684\u65b0\u8303\u5f0f\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8054\u7cfb\u4e2d\u5fc3\u5bf9\u8bdd\u5206\u6790\u4e2d\u7684\u4e8b\u5b9e\u6027\uff0c\u5e76\u5f15\u5165\u4e86FECT\u57fa\u51c6\u6570\u636e\u96c6\u3002", "motivation": "\u4f01\u4e1a\u5e94\u7528\u4e2d\uff0cLLM\u7684\u5e7b\u89c9\u95ee\u9898\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u7684\u4e1a\u52a1\u51b3\u7b56\uff0c\u5c24\u5176\u662f\u5728\u8054\u7cfb\u4e2d\u5fc3\u5bf9\u8bdd\u5206\u6790\u4e2d\uff0c\u7f3a\u4e4f\u4e8b\u5b9e\u6027\u8bc4\u4f30\u7684\u6807\u51c6\u3002", "method": "\u63d0\u51fa3D\u8303\u5f0f\uff08\u5206\u89e3\u3001\u89e3\u8026\u3001\u8131\u79bb\uff09\u4f5c\u4e3a\u4eba\u7c7b\u6807\u6ce8\u6307\u5357\u548cLLM\u8bc4\u4f30\u63d0\u793a\uff0c\u5e76\u521b\u5efaFECT\u6570\u636e\u96c6\u3002", "result": "\u901a\u8fc73D\u8303\u5f0f\u5bf9\u9f50LLM\u8bc4\u4f30\uff0c\u5b9e\u73b0\u4e86\u5bf9\u8054\u7cfb\u4e2d\u5fc3\u5bf9\u8bdd\u5206\u6790\u4e2dAI\u751f\u6210\u5185\u5bb9\u7684\u4e8b\u5b9e\u6027\u81ea\u52a8\u8bc4\u4f30\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8bc4\u4f30\u8054\u7cfb\u4e2d\u5fc3\u5bf9\u8bdd\u5206\u6790\u4e2dAI\u751f\u6210\u5185\u5bb9\u7684\u4e8b\u5b9e\u6027\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2508.01128", "pdf": "https://arxiv.org/pdf/2508.01128", "abs": "https://arxiv.org/abs/2508.01128", "authors": ["Leyao Wang", "Xutao Mao", "Xuhui Zhan", "Yuying Zhao", "Bo Ni", "Ryan A. Rossi", "Nesreen K. Ahmed", "Tyler Derr"], "title": "Towards Bridging Review Sparsity in Recommendation with Textual Edge Graph Representation", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "13 pages", "summary": "Textual reviews enrich recommender systems with fine-grained preference\nsignals and enhanced explainability. However, in real-world scenarios, users\nrarely leave reviews, resulting in severe sparsity that undermines the\neffectiveness of existing models. A natural solution is to impute or generate\nmissing reviews to enrich the data. However, conventional imputation techniques\n-- such as matrix completion and LLM-based augmentation -- either lose\ncontextualized semantics by embedding texts into vectors, or overlook\nstructural dependencies among user-item interactions. To address these\nshortcomings, we propose TWISTER (ToWards Imputation on Sparsity with Textual\nEdge Graph Representation), a unified framework that imputes missing reviews by\njointly modeling semantic and structural signals. Specifically, we represent\nuser-item interactions as a Textual-Edge Graph (TEG), treating reviews as edge\nattributes. To capture relational context, we construct line-graph views and\nemploy a large language model as a graph-aware aggregator. For each interaction\nlacking a textual review, our model aggregates the neighborhood's\nnatural-language representations to generate a coherent and personalized\nreview. Experiments on the Amazon and Goodreads datasets show that TWISTER\nconsistently outperforms traditional numeric, graph-based, and LLM baselines,\ndelivering higher-quality imputed reviews and, more importantly, enhanced\nrecommendation performance. In summary, TWISTER generates reviews that are more\nhelpful, authentic, and specific, while smoothing structural signals for\nimproved recommendations.", "AI": {"tldr": "TWISTER\u662f\u4e00\u4e2a\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u8bed\u4e49\u548c\u7ed3\u6784\u4fe1\u53f7\u6765\u586b\u8865\u7f3a\u5931\u8bc4\u8bba\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u7528\u6237\u5f88\u5c11\u7559\u4e0b\u8bc4\u8bba\uff0c\u5bfc\u81f4\u6570\u636e\u7a00\u758f\u6027\u4e25\u91cd\uff0c\u73b0\u6709\u6a21\u578b\u6548\u679c\u53d7\u9650\u3002\u4f20\u7edf\u586b\u8865\u65b9\u6cd5\u8981\u4e48\u4e22\u5931\u8bed\u4e49\uff0c\u8981\u4e48\u5ffd\u7565\u7ed3\u6784\u4f9d\u8d56\u3002", "method": "\u63d0\u51faTWISTER\u6846\u67b6\uff0c\u5c06\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u8868\u793a\u4e3a\u6587\u672c\u8fb9\u56fe\uff08TEG\uff09\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u56fe\u611f\u77e5\u805a\u5408\u5668\u751f\u6210\u7f3a\u5931\u8bc4\u8bba\u3002", "result": "\u5728Amazon\u548cGoodreads\u6570\u636e\u96c6\u4e0a\uff0cTWISTER\u4f18\u4e8e\u4f20\u7edf\u6570\u503c\u3001\u57fa\u4e8e\u56fe\u548cLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u8bc4\u8bba\u5e76\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "conclusion": "TWISTER\u751f\u6210\u7684\u8bc4\u8bba\u66f4\u6709\u5e2e\u52a9\u3001\u771f\u5b9e\u4e14\u5177\u4f53\uff0c\u540c\u65f6\u4f18\u5316\u7ed3\u6784\u4fe1\u53f7\u4ee5\u6539\u8fdb\u63a8\u8350\u6548\u679c\u3002"}}
{"id": "2508.00924", "pdf": "https://arxiv.org/pdf/2508.00924", "abs": "https://arxiv.org/abs/2508.00924", "authors": ["Ernesto L. Estevanell-Valladares", "Suilan Estevez-Velarde", "Yoan Guti\u00e9rrez", "Andr\u00e9s Montoyo", "Ruslan Mitkov"], "title": "XAutoLM: Efficient Fine-Tuning of Language Models via Meta-Learning and AutoML", "categories": ["cs.CL", "68T05, 68T50", "I.2.6; I.2.7; I.2.8"], "comment": "17 pages, 10 figures, 7 tables. Preprint. Under review at EMNLP 2025.\n  This is not the final version", "summary": "Experts in machine learning leverage domain knowledge to navigate decisions\nin model selection, hyperparameter optimisation, and resource allocation. This\nis particularly critical for fine-tuning language models (LMs), where repeated\ntrials incur substantial computational overhead and environmental impact.\nHowever, no existing automated framework simultaneously tackles the entire\nmodel selection and HPO task for resource-efficient LM fine-tuning. We\nintroduce XAutoLM, a meta-learning-augmented AutoML framework that reuses past\nexperiences to optimise discriminative and generative LM fine-tuning pipelines\nefficiently. XAutoLM learns from stored successes and failures by extracting\ntask- and system-level meta-features to bias its sampling toward fruitful\nconfigurations and away from costly dead ends. On four text classification and\ntwo question-answering benchmarks, XAutoLM surpasses zero-shot optimiser's peak\nF1 on five of six tasks, cuts mean evaluation time by up to 4.5x, reduces error\nratios by up to sevenfold, and uncovers up to 50% more pipelines above the\nzero-shot Pareto front. In contrast, simpler memory-based baselines suffer\nnegative transfer. We release XAutoLM and our experience store to catalyse\nresource-efficient, Green AI fine-tuning in the NLP community.", "AI": {"tldr": "XAutoLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5143\u5b66\u4e60\u7684AutoML\u6846\u67b6\uff0c\u65e8\u5728\u9ad8\u6548\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u6d41\u7a0b\uff0c\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u6846\u67b6\u672a\u80fd\u540c\u65f6\u89e3\u51b3\u6a21\u578b\u9009\u62e9\u548c\u8d85\u53c2\u6570\u4f18\u5316\u95ee\u9898\uff0c\u5bfc\u81f4\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u7684\u8ba1\u7b97\u6210\u672c\u548c\u73af\u5883\u5f71\u54cd\u8f83\u9ad8\u3002", "method": "XAutoLM\u901a\u8fc7\u63d0\u53d6\u4efb\u52a1\u548c\u7cfb\u7edf\u7ea7\u5143\u7279\u5f81\uff0c\u590d\u7528\u5386\u53f2\u7ecf\u9a8c\uff0c\u4f18\u5316\u91c7\u6837\u7b56\u7565\uff0c\u907f\u514d\u65e0\u6548\u914d\u7f6e\u3002", "result": "\u5728\u591a\u4e2a\u6587\u672c\u5206\u7c7b\u548c\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0cXAutoLM\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u51cf\u5c11\u4e86\u8bc4\u4f30\u65f6\u95f4\u548c\u9519\u8bef\u7387\u3002", "conclusion": "XAutoLM\u4e3a\u8d44\u6e90\u9ad8\u6548\u7684\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u7eff\u8272AI\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.01226", "pdf": "https://arxiv.org/pdf/2508.01226", "abs": "https://arxiv.org/abs/2508.01226", "authors": ["Xin Zhou", "Yongjie Wang", "Zhiqi Shen"], "title": "CM$^3$: Calibrating Multimodal Recommendation", "categories": ["cs.IR", "cs.MM"], "comment": "Working Paper: https://github.com/enoche/CM3", "summary": "Alignment and uniformity are fundamental principles within the domain of\ncontrastive learning. In recommender systems, prior work has established that\noptimizing the Bayesian Personalized Ranking (BPR) loss contributes to the\nobjectives of alignment and uniformity. Specifically, alignment aims to draw\ntogether the representations of interacting users and items, while uniformity\nmandates a uniform distribution of user and item embeddings across a unit\nhypersphere. This study revisits the alignment and uniformity properties within\nthe context of multimodal recommender systems, revealing a proclivity among\nextant models to prioritize uniformity to the detriment of alignment. Our\nhypothesis challenges the conventional assumption of equitable item treatment\nthrough a uniformity loss, proposing a more nuanced approach wherein items with\nsimilar multimodal attributes converge toward proximal representations within\nthe hyperspheric manifold. Specifically, we leverage the inherent similarity\nbetween items' multimodal data to calibrate their uniformity distribution,\nthereby inducing a more pronounced repulsive force between dissimilar entities\nwithin the embedding space. A theoretical analysis elucidates the relationship\nbetween this calibrated uniformity loss and the conventional uniformity\nfunction. Moreover, to enhance the fusion of multimodal features, we introduce\na Spherical B\\'ezier method designed to integrate an arbitrary number of\nmodalities while ensuring that the resulting fused features are constrained to\nthe same hyperspherical manifold. Empirical evaluations conducted on five\nreal-world datasets substantiate the superiority of our approach over competing\nbaselines. We also shown that the proposed methods can achieve up to a 5.4%\nincrease in NDCG@20 performance via the integration of MLLM-extracted features.\nSource code is available at: https://github.com/enoche/CM3.", "AI": {"tldr": "\u8be5\u7814\u7a76\u91cd\u65b0\u5ba1\u89c6\u4e86\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5bf9\u9f50\u548c\u5747\u5300\u6027\u5c5e\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u76f8\u4f3c\u6027\u7684\u6821\u51c6\u5747\u5300\u6027\u635f\u5931\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7403\u5f62B\u00e9zier\u65b9\u6cd5\u878d\u5408\u591a\u6a21\u6001\u7279\u5f81\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e2d\u503e\u5411\u4e8e\u8fc7\u5ea6\u5f3a\u8c03\u5747\u5300\u6027\u800c\u5ffd\u89c6\u5bf9\u9f50\u6027\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6821\u51c6\u5747\u5300\u6027\u635f\u5931\u548c\u66f4\u597d\u7684\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u65b9\u6cd5\u6539\u8fdb\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u7684\u76f8\u4f3c\u6027\u6821\u51c6\u5747\u5300\u6027\u5206\u5e03\uff0c\u5f15\u5165\u7403\u5f62B\u00e9zier\u65b9\u6cd5\u878d\u5408\u591a\u6a21\u6001\u7279\u5f81\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\uff0cNDCG@20\u6027\u80fd\u63d0\u5347\u8fbe5.4%\u3002", "conclusion": "\u6821\u51c6\u5747\u5300\u6027\u635f\u5931\u548c\u6539\u8fdb\u7684\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2508.01005", "pdf": "https://arxiv.org/pdf/2508.01005", "abs": "https://arxiv.org/abs/2508.01005", "authors": ["Yiqun Chen", "Erhan Zhang", "Lingyong Yan", "Shuaiqiang Wang", "Jizhou Huang", "Dawei Yin", "Jiaxin Mao"], "title": "MAO-ARAG: Multi-Agent Orchestration for Adaptive Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "In question-answering (QA) systems, Retrieval-Augmented Generation (RAG) has\nbecome pivotal in enhancing response accuracy and reducing hallucination\nissues. The architecture of RAG systems varies significantly, encompassing\nsingle-round RAG, iterative RAG, and reasoning RAG, each tailored to address\ndifferent types of queries. Due to the varying complexity of real-world\nqueries, a fixed RAG pipeline often struggles to balance performance and cost\nefficiency across different queries. To address this challenge, we propose an\nadaptive RAG framework called MAO-ARAG, which leverages multi-agent\norchestration. Our adaptive RAG is conceived as a multi-turn framework.\nSpecifically, we define multiple executor agents, representing typical RAG\nmodules such as query reformulation agents, document selection agent, and\ngeneration agents. A planner agent intelligently selects and integrates the\nappropriate agents from these executors into a suitable workflow tailored for\neach query, striving for high-quality answers while maintaining reasonable\ncosts. During each turn, the planner agent is trained using reinforcement\nlearning, guided by an outcome-based reward (F1 score) and a cost-based\npenalty, continuously improving answer quality while keeping costs within a\nreasonable range. Experiments conducted on multiple QA datasets demonstrate\nthat our approach, which dynamically plans workflows for each query, not only\nachieves high answer quality but also maintains both cost and latency within\nacceptable limits.The code of MAO-ARAG is on\nhttps://github.com/chenyiqun/Agentic-RAG.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94RAG\u6846\u67b6MAO-ARAG\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u8c03\u52a8\u6001\u89c4\u5212\u5de5\u4f5c\u6d41\uff0c\u4ee5\u63d0\u9ad8\u95ee\u7b54\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u6210\u672c\u6548\u7387\u3002", "motivation": "\u56fa\u5b9aRAG\u7ba1\u9053\u96be\u4ee5\u5e73\u8861\u4e0d\u540c\u67e5\u8be2\u7684\u6027\u80fd\u548c\u6210\u672c\u6548\u7387\uff0c\u9700\u81ea\u9002\u5e94\u89e3\u51b3\u65b9\u6848\u3002", "method": "MAO-ARAG\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u8c03\uff0c\u5305\u62ec\u6267\u884c\u5668\u667a\u80fd\u4f53\uff08\u5982\u67e5\u8be2\u91cd\u6784\u3001\u6587\u6863\u9009\u62e9\u548c\u751f\u6210\uff09\u548c\u89c4\u5212\u667a\u80fd\u4f53\uff0c\u540e\u8005\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u9009\u62e9\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u591a\u4e2aQA\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cMAO-ARAG\u80fd\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7b54\u6848\uff0c\u540c\u65f6\u63a7\u5236\u6210\u672c\u548c\u5ef6\u8fdf\u3002", "conclusion": "MAO-ARAG\u901a\u8fc7\u52a8\u6001\u89c4\u5212\u5de5\u4f5c\u6d41\uff0c\u663e\u8457\u63d0\u5347\u4e86\u95ee\u7b54\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2508.01265", "pdf": "https://arxiv.org/pdf/2508.01265", "abs": "https://arxiv.org/abs/2508.01265", "authors": ["Ali Fallahi", "Azam Bastanfard", "Amineh Amini", "Hadi Saboohi"], "title": "A Study on Enhancing User Engagement by Employing Gamified Recommender Systems", "categories": ["cs.IR"], "comment": "June 2023, 21 pages, 6 figures", "summary": "Providing customized products and services in the modern business world is\none of the most efficient solutions to improve users' experience and their\nengagements with the industries. To aim, recommender systems, by producing\npersonalized recommendations, have a crucial role in the digital age. As a\nconsequence of modern improvements in the internet and online-based\ntechnologies, using gamification rules also increased in various fields. Recent\nstudies showed that considering gamification concepts in implementing\nrecommendation systems not only can become helpful to overcome the cold start\nand lack of sufficient data, moreover, can effectively improve user engagement.\nGamification can motivate individuals to have more activities on the system;\nthese interactions are valuable resources of data for recommender engines.\nUnlike the past related works about using gamified recommendation systems in\ndifferent environments or studies that particularly surveyed gamification\nstrategies or recommenders separately, this work provides a comprehensive\nreview of how gamified recommender systems can enhance user engagement in\nvarious domain applications. Furthermore, comparing different approaches for\nbuilding recommender systems is followed by in-depth surveying about\ninvestigating the gamified recommender systems, including their approaches,\nlimitations, evaluation metrics, proposed achievements, datasets, domain areas,\nand their recommendation techniques. This exhaustive analysis provides a\ndetailed picture of the topic's popularity, gaps, and unexplored regions. It is\nenvisaged that the proposed research and introduced possible future directions\nwould serve as a stepping stone for researchers interested in using gamified\nrecommender systems for user satisfaction and engagement.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6e38\u620f\u5316\u63a8\u8350\u7cfb\u7edf\u5982\u4f55\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540c\u6784\u5efa\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u5176\u5c40\u9650\u6027\u3001\u8bc4\u4f30\u6307\u6807\u53ca\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u73b0\u4ee3\u5546\u4e1a\u4e2d\uff0c\u4e2a\u6027\u5316\u63a8\u8350\u7cfb\u7edf\u5bf9\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u81f3\u5173\u91cd\u8981\u3002\u6e38\u620f\u5316\u89c4\u5219\u7684\u5e94\u7528\u80fd\u89e3\u51b3\u51b7\u542f\u52a8\u548c\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u9ad8\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "method": "\u901a\u8fc7\u5168\u9762\u7efc\u8ff0\u6e38\u620f\u5316\u63a8\u8350\u7cfb\u7edf\uff0c\u6bd4\u8f83\u4e0d\u540c\u6784\u5efa\u65b9\u6cd5\uff0c\u5e76\u6df1\u5165\u5206\u6790\u5176\u65b9\u6cd5\u3001\u5c40\u9650\u6027\u3001\u8bc4\u4f30\u6307\u6807\u3001\u6570\u636e\u96c6\u53ca\u63a8\u8350\u6280\u672f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6e38\u620f\u5316\u63a8\u8350\u7cfb\u7edf\u80fd\u6709\u6548\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u5e76\u63ed\u793a\u4e86\u8be5\u9886\u57df\u7684\u6d41\u884c\u8d8b\u52bf\u3001\u7814\u7a76\u7a7a\u767d\u548c\u672a\u63a2\u7d22\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u6e38\u620f\u5316\u63a8\u8350\u7cfb\u7edf\u7684\u8be6\u7ec6\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u4fc3\u8fdb\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u53c2\u4e0e\u5ea6\u7684\u63d0\u5347\u3002"}}
{"id": "2508.00844", "pdf": "https://arxiv.org/pdf/2508.00844", "abs": "https://arxiv.org/abs/2508.00844", "authors": ["Christopher Wissuchek", "Patrick Zschech"], "title": "Exploring Agentic Artificial Intelligence Systems: Towards a Typological Framework", "categories": ["cs.AI", "cs.ET", "cs.MA", "econ.GN", "q-fin.EC"], "comment": "Preprint accepted for archival and presentation at the Pacific-Asia\n  Conference on Information Systems (PACIS) 2025, Kuala Lumpur, Malaysia", "summary": "Artificial intelligence (AI) systems are evolving beyond passive tools into\nautonomous agents capable of reasoning, adapting, and acting with minimal human\nintervention. Despite their growing presence, a structured framework is lacking\nto classify and compare these systems. This paper develops a typology of\nagentic AI systems, introducing eight dimensions that define their cognitive\nand environmental agency in an ordinal structure. Using a multi-phase\nmethodological approach, we construct and refine this typology, which is then\nevaluated through a human-AI hybrid approach and further distilled into\nconstructed types. The framework enables researchers and practitioners to\nanalyze varying levels of agency in AI systems. By offering a structured\nperspective on the progression of AI capabilities, the typology provides a\nfoundation for assessing current systems and anticipating future developments\nin agentic AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7c7b\u81ea\u4e3bAI\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u5b9a\u4e49\u4e86\u516b\u4e2a\u7ef4\u5ea6\u4ee5\u8bc4\u4f30\u5176\u8ba4\u77e5\u548c\u73af\u5883\u4ee3\u7406\u80fd\u529b\u3002", "motivation": "AI\u7cfb\u7edf\u6b63\u4ece\u88ab\u52a8\u5de5\u5177\u53d1\u5c55\u4e3a\u81ea\u4e3b\u4ee3\u7406\uff0c\u4f46\u7f3a\u4e4f\u5206\u7c7b\u548c\u6bd4\u8f83\u8fd9\u4e9b\u7cfb\u7edf\u7684\u7ed3\u6784\u5316\u6846\u67b6\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u65b9\u6cd5\u8bba\u6784\u5efa\u5e76\u7cbe\u70bc\u4e86\u4e00\u4e2a\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u4eba\u673a\u6df7\u5408\u65b9\u6cd5\u8bc4\u4f30\uff0c\u5e76\u8fdb\u4e00\u6b65\u63d0\u70bc\u4e3a\u6784\u9020\u7c7b\u578b\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5206\u6790AI\u7cfb\u7edf\u4e0d\u540c\u4ee3\u7406\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u4e3a\u8bc4\u4f30\u5f53\u524dAI\u7cfb\u7edf\u548c\u9884\u6d4b\u672a\u6765\u81ea\u4e3bAI\u53d1\u5c55\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.00835", "pdf": "https://arxiv.org/pdf/2508.00835", "abs": "https://arxiv.org/abs/2508.00835", "authors": ["Zachary T. Rewolinski", "Bin Yu"], "title": "PCS Workflow for Veridical Data Science in the Age of AI", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "Data science is a pillar of artificial intelligence (AI), which is\ntransforming nearly every domain of human activity, from the social and\nphysical sciences to engineering and medicine. While data-driven findings in AI\noffer unprecedented power to extract insights and guide decision-making, many\nare difficult or impossible to replicate. A key reason for this challenge is\nthe uncertainty introduced by the many choices made throughout the data science\nlife cycle (DSLC). Traditional statistical frameworks often fail to account for\nthis uncertainty. The Predictability-Computability-Stability (PCS) framework\nfor veridical (truthful) data science offers a principled approach to\naddressing this challenge throughout the DSLC. This paper presents an updated\nand streamlined PCS workflow, tailored for practitioners and enhanced with\nguided use of generative AI. We include a running example to display the PCS\nframework in action, and conduct a related case study which showcases the\nuncertainty in downstream predictions caused by judgment calls in the data\ncleaning stage.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86PCS\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u6570\u636e\u79d1\u5b66\u751f\u547d\u5468\u671f\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u6570\u636e\u6e05\u7406\u9636\u6bb5\u7684\u51b3\u7b56\u5bf9\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "motivation": "\u6570\u636e\u79d1\u5b66\u5728AI\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u7ed3\u679c\u96be\u4ee5\u590d\u73b0\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u6570\u636e\u79d1\u5b66\u751f\u547d\u5468\u671f\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u66f4\u65b0\u7684PCS\u6846\u67b6\uff0c\u7ed3\u5408\u751f\u6210\u5f0fAI\uff0c\u63d0\u4f9b\u539f\u5219\u6027\u65b9\u6cd5\u4ee5\u5e94\u5bf9\u6570\u636e\u79d1\u5b66\u751f\u547d\u5468\u671f\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u6570\u636e\u6e05\u7406\u9636\u6bb5\u7684\u51b3\u7b56\u5982\u4f55\u5f71\u54cd\u4e0b\u6e38\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "PCS\u6846\u67b6\u4e3a\u6570\u636e\u79d1\u5b66\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9a8c\u8bc1\u7684\u65b9\u6cd5\uff0c\u5e2e\u52a9\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u5e76\u63d0\u9ad8\u7ed3\u679c\u7684\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2508.01006", "pdf": "https://arxiv.org/pdf/2508.01006", "abs": "https://arxiv.org/abs/2508.01006", "authors": ["Farah Adeeba", "Brian Dillon", "Hassan Sajjad", "Rajesh Bhatt"], "title": "UrBLiMP: A Benchmark for Evaluating the Linguistic Competence of Large Language Models in Urdu", "categories": ["cs.CL"], "comment": null, "summary": "Multilingual Large Language Models (LLMs) have shown remarkable performance\nacross various languages; however, they often include significantly less data\nfor low-resource languages such as Urdu compared to high-resource languages\nlike English. To assess the linguistic knowledge of LLMs in Urdu, we present\nthe Urdu Benchmark of Linguistic Minimal Pairs (UrBLiMP) i.e. pairs of\nminimally different sentences that contrast in grammatical acceptability.\nUrBLiMP comprises 5,696 minimal pairs targeting ten core syntactic phenomena,\ncarefully curated using the Urdu Treebank and diverse Urdu text corpora. A\nhuman evaluation of UrBLiMP annotations yielded a 96.10% inter-annotator\nagreement, confirming the reliability of the dataset. We evaluate twenty\nmultilingual LLMs on UrBLiMP, revealing significant variation in performance\nacross linguistic phenomena. While LLaMA-3-70B achieves the highest average\naccuracy (94.73%), its performance is statistically comparable to other top\nmodels such as Gemma-3-27B-PT. These findings highlight both the potential and\nthe limitations of current multilingual LLMs in capturing fine-grained\nsyntactic knowledge in low-resource languages.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86UrBLiMP\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e4c\u5c14\u90fd\u8bed\u4e2d\u7684\u8bed\u6cd5\u77e5\u8bc6\uff0c\u53d1\u73b0\u6a21\u578b\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002", "motivation": "\u8bc4\u4f30\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e4c\u5c14\u90fd\u8bed\u4e2d\u7684\u8bed\u6cd5\u77e5\u8bc6\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efaUrBLiMP\u6570\u636e\u96c6\uff0c\u5305\u542b5,696\u5bf9\u6700\u5c0f\u5dee\u5f02\u53e5\u5b50\uff0c\u9488\u5bf9\u5341\u79cd\u6838\u5fc3\u8bed\u6cd5\u73b0\u8c61\uff0c\u5e76\u8fdb\u884c\u4eba\u5de5\u8bc4\u4f30\u3002", "result": "LLaMA-3-70B\u8868\u73b0\u6700\u4f73\uff0894.73%\uff09\uff0c\u4f46\u4e0e\u5176\u4ed6\u9876\u7ea7\u6a21\u578b\uff08\u5982Gemma-3-27B-PT\uff09\u65e0\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u5f53\u524d\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u6355\u6349\u7ec6\u7c92\u5ea6\u8bed\u6cd5\u77e5\u8bc6\u7684\u80fd\u529b\u5b58\u5728\u6f5c\u529b\u4e0e\u5c40\u9650\u6027\u3002"}}
{"id": "2508.01375", "pdf": "https://arxiv.org/pdf/2508.01375", "abs": "https://arxiv.org/abs/2508.01375", "authors": ["Yining Yao", "Ziwei Li", "Shuwen Xiao", "Boya Du", "Jialin Zhu", "Junjun Zheng", "Xiangheng Kong", "Yuning Jiang"], "title": "SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation", "categories": ["cs.IR"], "comment": null, "summary": "In recommendation systems, predicting Click-Through Rate (CTR) is crucial for\naccurately matching users with items. To improve recommendation performance for\ncold-start and long-tail items, recent studies focus on leveraging item\nmultimodal features to model users' interests. However, obtaining multimodal\nrepresentations for items relies on complex pre-trained encoders, which incurs\nunacceptable computation cost to train jointly with downstream ranking models.\nTherefore, it is important to maintain alignment between semantic and behavior\nspace in a lightweight way.\n  To address these challenges, we propose a Semantic-Behavior Alignment for\nCold-start Recommendation framework, which mainly focuses on utilizing\nmultimodal representations that align with the user behavior space to predict\nCTR. First, we leverage domain-specific knowledge to train a multimodal encoder\nto generate behavior-aware semantic representations. Second, we use residual\nquantized semantic ID to dynamically bridge the gap between multimodal\nrepresentations and the ranking model, facilitating the continuous\nsemantic-behavior alignment. We conduct our offline and online experiments on\nthe Taobao, one of the world's largest e-commerce platforms, and have achieved\nan increase of 0.83% in offline AUC, 13.21% clicks increase and 13.44% orders\nincrease in the online A/B test, emphasizing the efficacy of our method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u8bed\u4e49-\u884c\u4e3a\u5bf9\u9f50\u6846\u67b6\uff0c\u7528\u4e8e\u51b7\u542f\u52a8\u63a8\u8350\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u8868\u793a\u548c\u884c\u4e3a\u7a7a\u95f4\u5bf9\u9f50\u63d0\u5347CTR\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u51b7\u542f\u52a8\u548c\u957f\u5c3e\u7269\u54c1\u63a8\u8350\u4e2d\u591a\u6a21\u6001\u7279\u5f81\u4e0e\u884c\u4e3a\u7a7a\u95f4\u5bf9\u9f50\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002", "method": "\u5229\u7528\u9886\u57df\u77e5\u8bc6\u8bad\u7ec3\u591a\u6a21\u6001\u7f16\u7801\u5668\u751f\u6210\u884c\u4e3a\u611f\u77e5\u8bed\u4e49\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u6b8b\u5dee\u91cf\u5316\u8bed\u4e49ID\u52a8\u6001\u5bf9\u9f50\u591a\u6a21\u6001\u8868\u793a\u4e0e\u6392\u5e8f\u6a21\u578b\u3002", "result": "\u5728\u6dd8\u5b9d\u5e73\u53f0\u4e0a\uff0c\u79bb\u7ebfAUC\u63d0\u53470.83%\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u70b9\u51fb\u91cf\u589e\u52a013.21%\uff0c\u8ba2\u5355\u91cf\u589e\u52a013.44%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u51b7\u542f\u52a8\u63a8\u8350\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u8bed\u4e49-\u884c\u4e3a\u5bf9\u9f50\u7684\u8f7b\u91cf\u7ea7\u5b9e\u73b0\u53ef\u884c\u6027\u3002"}}
{"id": "2508.00853", "pdf": "https://arxiv.org/pdf/2508.00853", "abs": "https://arxiv.org/abs/2508.00853", "authors": ["Kei Itoh"], "title": "A Formal Framework for the Definition of 'State': Hierarchical Representation and Meta-Universe Interpretation", "categories": ["cs.AI", "cs.LO"], "comment": "43 pages, 8 figures, 8 Tables, in English, in Japanese", "summary": "This study aims to reinforce the theoretical foundation for diverse\nsystems--including the axiomatic definition of intelligence--by introducing a\nmathematically rigorous and unified formal structure for the concept of\n'state,' which has long been used without consensus or formal clarity. First, a\n'hierarchical state grid' composed of two axes--state depth and mapping\nhierarchy--is proposed to provide a unified notational system applicable across\nmathematical, physical, and linguistic domains. Next, the 'Intermediate\nMeta-Universe (IMU)' is introduced to enable explicit descriptions of definers\n(ourselves) and the languages we use, thereby allowing conscious meta-level\noperations while avoiding self-reference and logical inconsistency. Building on\nthis meta-theoretical foundation, this study expands inter-universal theory\nbeyond mathematics to include linguistic translation and agent integration,\nintroducing the conceptual division between macrocosm-inter-universal and\nmicrocosm-inter-universal operations for broader expressivity. Through these\ncontributions, this paper presents a meta-formal logical framework--grounded in\nthe principle of definition = state--that spans time, language, agents, and\noperations, providing a mathematically robust foundation applicable to the\ndefinition of intelligence, formal logic, and scientific theory at large.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u6570\u5b66\u4e0a\u4e25\u8c28\u7684'\u72b6\u6001'\u6982\u5ff5\u7edf\u4e00\u5f62\u5f0f\u7ed3\u6784\uff0c\u5f3a\u5316\u4e86\u5305\u62ec\u667a\u80fd\u516c\u7406\u5316\u5b9a\u4e49\u5728\u5185\u7684\u591a\u6837\u5316\u7cfb\u7edf\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u89e3\u51b3'\u72b6\u6001'\u6982\u5ff5\u957f\u671f\u7f3a\u4e4f\u5171\u8bc6\u548c\u5f62\u5f0f\u5316\u6e05\u6670\u5b9a\u4e49\u7684\u95ee\u9898\uff0c\u4e3a\u8de8\u9886\u57df\u7684\u7406\u8bba\u7814\u7a76\u63d0\u4f9b\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51fa'\u5206\u5c42\u72b6\u6001\u7f51\u683c'\u548c'\u4e2d\u95f4\u5143\u5b87\u5b99\uff08IMU\uff09'\uff0c\u6784\u5efa\u5143\u7406\u8bba\u57fa\u7840\uff0c\u6269\u5c55\u8de8\u5b87\u5b99\u7406\u8bba\u81f3\u8bed\u8a00\u7ffb\u8bd1\u548c\u667a\u80fd\u4f53\u96c6\u6210\u3002", "result": "\u5efa\u7acb\u4e86\u57fa\u4e8e'\u5b9a\u4e49=\u72b6\u6001'\u539f\u5219\u7684\u5143\u5f62\u5f0f\u903b\u8f91\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u667a\u80fd\u5b9a\u4e49\u3001\u5f62\u5f0f\u903b\u8f91\u548c\u79d1\u5b66\u7406\u8bba\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u667a\u80fd\u5b9a\u4e49\u548c\u8de8\u9886\u57df\u7406\u8bba\u63d0\u4f9b\u4e86\u6570\u5b66\u4e0a\u4e25\u8c28\u7684\u57fa\u7840\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.00855", "pdf": "https://arxiv.org/pdf/2508.00855", "abs": "https://arxiv.org/abs/2508.00855", "authors": ["Ziyang Zhang", "Feifan Zhang", "Weidong Tang", "Lei Shi", "Tailai Chen"], "title": "A Residual Guided strategy with Generative Adversarial Networks in training Physics-Informed Transformer Networks", "categories": ["cs.LG", "cs.CE", "physics.flu-dyn"], "comment": null, "summary": "Nonlinear partial differential equations (PDEs) are pivotal in modeling\ncomplex physical systems, yet traditional Physics-Informed Neural Networks\n(PINNs) often struggle with unresolved residuals in critical spatiotemporal\nregions and violations of temporal causality. To address these limitations, we\npropose a novel Residual Guided Training strategy for Physics-Informed\nTransformer via Generative Adversarial Networks (GAN). Our framework integrates\na decoder-only Transformer to inherently capture temporal correlations through\nautoregressive processing, coupled with a residual-aware GAN that dynamically\nidentifies and prioritizes high-residual regions. By introducing a causal\npenalty term and an adaptive sampling mechanism, the method enforces temporal\ncausality while refining accuracy in problematic domains. Extensive numerical\nexperiments on the Allen-Cahn, Klein-Gordon, and Navier-Stokes equations\ndemonstrate significant improvements, achieving relative MSE reductions of up\nto three orders of magnitude compared to baseline methods. This work bridges\nthe gap between deep learning and physics-driven modeling, offering a robust\nsolution for multiscale and time-dependent PDE systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGAN\u7684\u6b8b\u5dee\u5f15\u5bfc\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7Transformer\u548cGAN\u7ed3\u5408\u89e3\u51b3PINNs\u5728\u65f6\u7a7a\u533a\u57df\u6b8b\u5dee\u672a\u89e3\u6790\u548c\u65f6\u5e8f\u56e0\u679c\u6027\u8fdd\u53cd\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfPINNs\u5728\u590d\u6742\u7269\u7406\u7cfb\u7edf\u5efa\u6a21\u4e2d\u5b58\u5728\u6b8b\u5dee\u672a\u89e3\u6790\u548c\u65f6\u5e8f\u56e0\u679c\u6027\u8fdd\u53cd\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u89e3\u7801\u5668Transformer\u6355\u6349\u65f6\u5e8f\u76f8\u5173\u6027\uff0c\u7ed3\u5408\u6b8b\u5dee\u611f\u77e5GAN\u52a8\u6001\u8bc6\u522b\u9ad8\u6b8b\u5dee\u533a\u57df\uff0c\u5e76\u5f15\u5165\u56e0\u679c\u60e9\u7f5a\u9879\u548c\u81ea\u9002\u5e94\u91c7\u6837\u673a\u5236\u3002", "result": "\u5728Allen-Cahn\u3001Klein-Gordon\u548cNavier-Stokes\u65b9\u7a0b\u4e0a\u5b9e\u9a8c\uff0c\u76f8\u5bf9MSE\u964d\u4f4e\u8fbe\u4e09\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u586b\u8865\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e0e\u7269\u7406\u9a71\u52a8\u5efa\u6a21\u7684\u9e3f\u6c9f\uff0c\u4e3a\u591a\u5c3a\u5ea6\u548c\u65f6\u95f4\u4f9d\u8d56PDE\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.01096", "pdf": "https://arxiv.org/pdf/2508.01096", "abs": "https://arxiv.org/abs/2508.01096", "authors": ["Michael Farag", "Patrick Halina", "Andrey Zaytsev", "Alekhya Munagala", "Imtihan Ahmed", "Junhao Wang"], "title": "Cross-Domain Web Information Extraction at Pinterest", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "The internet offers a massive repository of unstructured information, but\nit's a significant challenge to convert this into a structured format. At\nPinterest, the ability to accurately extract structured product data from\ne-commerce websites is essential to enhance user experiences and improve\ncontent distribution. In this paper, we present Pinterest's system for\nattribute extraction, which achieves remarkable accuracy and scalability at a\nmanageable cost. Our approach leverages a novel webpage representation that\ncombines structural, visual, and text modalities into a compact form,\noptimizing it for small model learning. This representation captures each\nvisible HTML node with its text, style and layout information. We show how this\nallows simple models such as eXtreme Gradient Boosting (XGBoost) to extract\nattributes more accurately than much more complex Large Language Models (LLMs)\nsuch as Generative Pre-trained Transformer (GPT). Our results demonstrate a\nsystem that is highly scalable, processing over 1,000 URLs per second, while\nbeing 1000 times more cost-effective than the cheapest GPT alternatives.", "AI": {"tldr": "Pinterest\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u7ed3\u6784\u5316\u6570\u636e\u63d0\u53d6\u7cfb\u7edf\uff0c\u7ed3\u5408\u7f51\u9875\u7684\u7ed3\u6784\u3001\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\uff0c\u4f7f\u7528\u7b80\u5355\u6a21\u578b\uff08\u5982XGBoost\uff09\u5b9e\u73b0\u6bd4\u590d\u6742\u6a21\u578b\uff08\u5982GPT\uff09\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4e92\u8054\u7f51\u4e0a\u5b58\u5728\u5927\u91cf\u975e\u7ed3\u6784\u5316\u4fe1\u606f\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u683c\u5f0f\u5bf9\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u5185\u5bb9\u5206\u53d1\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u65b0\u9896\u7684\u7f51\u9875\u8868\u793a\u65b9\u6cd5\uff0c\u7ed3\u5408\u7ed3\u6784\u3001\u89c6\u89c9\u548c\u6587\u672c\u6a21\u6001\uff0c\u4f18\u5316\u4e3a\u5c0f\u578b\u6a21\u578b\u5b66\u4e60\uff0c\u6355\u83b7HTML\u8282\u70b9\u7684\u6587\u672c\u3001\u6837\u5f0f\u548c\u5e03\u5c40\u4fe1\u606f\u3002", "result": "\u7cfb\u7edf\u5904\u7406\u901f\u5ea6\u8d85\u8fc7\u6bcf\u79d21000\u4e2aURL\uff0c\u6210\u672c\u6bd4\u6700\u4fbf\u5b9c\u7684GPT\u66ff\u4ee3\u65b9\u6848\u4f4e1000\u500d\uff0c\u4e14\u51c6\u786e\u6027\u66f4\u9ad8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5728\u7ed3\u6784\u5316\u6570\u636e\u63d0\u53d6\u4efb\u52a1\u4e2d\uff0c\u7b80\u5355\u6a21\u578b\u53ef\u4ee5\u8d85\u8d8a\u590d\u6742\u6a21\u578b\uff0c\u540c\u65f6\u5177\u5907\u9ad8\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2508.01502", "pdf": "https://arxiv.org/pdf/2508.01502", "abs": "https://arxiv.org/abs/2508.01502", "authors": ["Ali Fallahi", "Amineh Amini", "Azam Bastanfard", "Hadi Saboohi"], "title": "Req-Rec: Enhancing Requirements Elicitation for Increasing Stakeholder's Satisfaction Using a Collaborative Filtering Based Recommender System", "categories": ["cs.IR"], "comment": "March 2023, 28 pages, 7 figures", "summary": "The success or failure of a project is highly related to recognizing the\nright stakeholders and accurately finding and discovering their requirements.\nHowever, choosing the proper elicitation technique was always a considerable\nchallenge for efficient requirement engineering. As a consequence of the swift\nimprovement of digital technologies since the past decade, recommender systems\nhave become an efficient channel for making a deeply personalized interactive\ncommunication with stakeholders. In this research, a new method, called the\nReq-Rec (Requirements Recommender), is proposed. It is a hybrid recommender\nsystem based on the collaborative filtering approach and the repertory grid\ntechnique as the core component. The primary goal of Req-Rec is to increase\nstakeholder satisfaction by assisting them in the requirement elicitation\nphase. Based on the results, the method efficiently could overcome weaknesses\nof common requirement elicitation techniques, such as time limitation,\nlocation-based restrictions, and bias in requirements' elicitation process.\nTherefore, recommending related requirements assists stakeholders in becoming\nmore aware of different aspects of the project.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReq-Rec\u7684\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\uff0c\u7ed3\u5408\u534f\u540c\u8fc7\u6ee4\u548crepertory grid\u6280\u672f\uff0c\u7528\u4e8e\u9700\u6c42\u83b7\u53d6\u9636\u6bb5\uff0c\u4ee5\u63d0\u9ad8\u5229\u76ca\u76f8\u5173\u8005\u6ee1\u610f\u5ea6\u5e76\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u9879\u76ee\u6210\u529f\u4e0e\u5426\u4e0e\u8bc6\u522b\u6b63\u786e\u7684\u5229\u76ca\u76f8\u5173\u8005\u53ca\u5176\u9700\u6c42\u5bc6\u5207\u76f8\u5173\uff0c\u4f46\u4f20\u7edf\u9700\u6c42\u83b7\u53d6\u6280\u672f\u5b58\u5728\u6548\u7387\u4f4e\u3001\u65f6\u95f4\u9650\u5236\u548c\u5730\u57df\u9650\u5236\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faReq-Rec\u65b9\u6cd5\uff0c\u7ed3\u5408\u534f\u540c\u8fc7\u6ee4\u548crepertory grid\u6280\u672f\uff0c\u6784\u5efa\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\u3002", "result": "Req-Rec\u6709\u6548\u514b\u670d\u4e86\u4f20\u7edf\u9700\u6c42\u83b7\u53d6\u6280\u672f\u7684\u5f31\u70b9\uff0c\u5982\u65f6\u95f4\u9650\u5236\u3001\u5730\u57df\u9650\u5236\u548c\u9700\u6c42\u83b7\u53d6\u8fc7\u7a0b\u4e2d\u7684\u504f\u89c1\u3002", "conclusion": "Req-Rec\u901a\u8fc7\u63a8\u8350\u76f8\u5173\u9700\u6c42\uff0c\u5e2e\u52a9\u5229\u76ca\u76f8\u5173\u8005\u66f4\u5168\u9762\u5730\u4e86\u89e3\u9879\u76ee\uff0c\u63d0\u9ad8\u4e86\u9700\u6c42\u83b7\u53d6\u7684\u6548\u7387\u548c\u6ee1\u610f\u5ea6\u3002"}}
{"id": "2508.00890", "pdf": "https://arxiv.org/pdf/2508.00890", "abs": "https://arxiv.org/abs/2508.00890", "authors": ["Fali Wang", "Hui Liu", "Zhenwei Dai", "Jingying Zeng", "Zhiwei Zhang", "Zongyu Wu", "Chen Luo", "Zhen Li", "Xianfeng Tang", "Qi He", "Suhang Wang"], "title": "AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7"], "comment": "Under review", "summary": "Test-time scaling (TTS) enhances the performance of large language models\n(LLMs) by allocating additional compute resources during inference. However,\nexisting research primarily investigates TTS in single-stage tasks; while many\nreal-world problems are multi-stage complex tasks, composed of a sequence of\nheterogeneous subtasks with each subtask requires LLM of specific capability.\nTherefore, we study a novel problem: the test-time compute-optimal scaling in\nmulti-stage complex tasks, aiming to select suitable models and allocate\nbudgets per subtask to maximize overall performance. TTS in multi-stage tasks\nintroduces two fundamental challenges: (i) The combinatorial search space of\nmodel and budget allocations, combined with the high cost of inference, makes\nbrute-force search impractical. (ii) The optimal model and budget allocations\nacross subtasks are interdependent, increasing the complexity of the\ncompute-optimal search. To address this gap, we conduct extensive pilot\nexperiments on four tasks across six datasets, deriving three empirical\ninsights characterizing the behavior of LLMs in multi-stage complex tasks.\nInformed by these insights, we propose AgentTTS, an LLM-agent-based framework\nthat autonomously searches for compute-optimal allocations through iterative\nfeedback-driven interactions with the execution environment. Experimental\nresults demonstrate that AgentTTS significantly outperforms traditional and\nother LLM-based baselines in search efficiency, and shows improved robustness\nto varying training set sizes and enhanced interpretability.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u591a\u9636\u6bb5\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6700\u4f18\u6269\u5c55\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eLLM\u7684AgentTTS\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u9636\u6bb5\u4efb\u52a1\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\uff0c\u800c\u73b0\u5b9e\u4e2d\u7684\u591a\u9636\u6bb5\u590d\u6742\u4efb\u52a1\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u5b50\u4efb\u52a1\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u56e0\u6b64\u7814\u7a76\u591a\u9636\u6bb5\u4efb\u52a1\u7684\u4f18\u5316\u5206\u914d\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u5f97\u51fa\u4e09\u4e2a\u7ecf\u9a8c\u6027\u89c1\u89e3\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51faAgentTTS\u6846\u67b6\uff0c\u5229\u7528LLM\u4ee3\u7406\u901a\u8fc7\u8fed\u4ee3\u53cd\u9988\u81ea\u4e3b\u641c\u7d22\u6700\u4f18\u5206\u914d\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAgentTTS\u5728\u641c\u7d22\u6548\u7387\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u5176\u4ed6\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\uff0c\u4e14\u5bf9\u8bad\u7ec3\u96c6\u89c4\u6a21\u53d8\u5316\u66f4\u5177\u9c81\u68d2\u6027\u3002", "conclusion": "AgentTTS\u4e3a\u89e3\u51b3\u591a\u9636\u6bb5\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00858", "pdf": "https://arxiv.org/pdf/2508.00858", "abs": "https://arxiv.org/abs/2508.00858", "authors": ["Christina Butsko", "Kristof Van Tricht", "Gabriel Tseng", "Giorgia Milli", "David Rolnick", "Ruben Cartuyvels", "Inbal Becker Reshef", "Zoltan Szantoi", "Hannah Kerner"], "title": "Deploying Geospatial Foundation Models in the Real World: Lessons from WorldCereal", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "The increasing availability of geospatial foundation models has the potential\nto transform remote sensing applications such as land cover classification,\nenvironmental monitoring, and change detection. Despite promising benchmark\nresults, the deployment of these models in operational settings is challenging\nand rare. Standardized evaluation tasks often fail to capture real-world\ncomplexities relevant for end-user adoption such as data heterogeneity,\nresource constraints, and application-specific requirements. This paper\npresents a structured approach to integrate geospatial foundation models into\noperational mapping systems. Our protocol has three key steps: defining\napplication requirements, adapting the model to domain-specific data and\nconducting rigorous empirical testing. Using the Presto model in a case study\nfor crop mapping, we demonstrate that fine-tuning a pre-trained model\nsignificantly improves performance over conventional supervised methods. Our\nresults highlight the model's strong spatial and temporal generalization\ncapabilities. Our protocol provides a replicable blueprint for practitioners\nand lays the groundwork for future research to operationalize foundation models\nin diverse remote sensing applications. Application of the protocol to the\nWorldCereal global crop-mapping system showcases the framework's scalability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u5c06\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u6574\u5408\u5230\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u6027\u80fd\u63d0\u5347\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u5728\u9065\u611f\u5e94\u7528\u4e2d\u6709\u6f5c\u529b\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9762\u4e34\u6311\u6218\uff0c\u6807\u51c6\u5316\u8bc4\u4f30\u672a\u80fd\u6355\u6349\u771f\u5b9e\u4e16\u754c\u7684\u590d\u6742\u6027\u3002", "method": "\u63d0\u51fa\u4e09\u6b65\u534f\u8bae\uff1a\u5b9a\u4e49\u5e94\u7528\u9700\u6c42\u3001\u9002\u5e94\u9886\u57df\u6570\u636e\u3001\u4e25\u683c\u5b9e\u8bc1\u6d4b\u8bd5\uff0c\u5e76\u4ee5Presto\u6a21\u578b\u5728\u4f5c\u7269\u5236\u56fe\u4e2d\u7684\u6848\u4f8b\u4e3a\u4f8b\u3002", "result": "\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u76d1\u7763\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u65f6\u7a7a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u534f\u8bae\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684\u84dd\u56fe\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.01159", "pdf": "https://arxiv.org/pdf/2508.01159", "abs": "https://arxiv.org/abs/2508.01159", "authors": ["Liam G. McCoy", "Fateme Nateghi Haredasht", "Kanav Chopra", "David Wu", "David JH Wu", "Abass Conteh", "Sarita Khemani", "Saloni Kumar Maharaj", "Vishnu Ravi", "Arth Pahwa", "Yingjie Weng", "Leah Rosengaus", "Lena Giang", "Kelvin Zhenghao Li", "Olivia Jee", "Daniel Shirvani", "Ethan Goh", "Jonathan H. Chen"], "title": "Asking the Right Questions: Benchmarking Large Language Models in the Development of Clinical Consultation Templates", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This study evaluates the capacity of large language models (LLMs) to generate\nstructured clinical consultation templates for electronic consultation. Using\n145 expert-crafted templates developed and routinely used by Stanford's\neConsult team, we assess frontier models -- including o3, GPT-4o, Kimi K2,\nClaude 4 Sonnet, Llama 3 70B, and Gemini 2.5 Pro -- for their ability to\nproduce clinically coherent, concise, and prioritized clinical question\nschemas. Through a multi-agent pipeline combining prompt optimization, semantic\nautograding, and prioritization analysis, we show that while models like o3\nachieve high comprehensiveness (up to 92.2\\%), they consistently generate\nexcessively long templates and fail to correctly prioritize the most clinically\nimportant questions under length constraints. Performance varies across\nspecialties, with significant degradation in narrative-driven fields such as\npsychiatry and pain medicine. Our findings demonstrate that LLMs can enhance\nstructured clinical information exchange between physicians, while highlighting\nthe need for more robust evaluation methods that capture a model's ability to\nprioritize clinically salient information within the time constraints of\nreal-world physician communication.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u7ed3\u6784\u5316\u4e34\u5e8a\u54a8\u8be2\u6a21\u677f\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u5168\u9762\u6027\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u6a21\u677f\u8fc7\u957f\u4e14\u4f18\u5148\u7ea7\u6392\u5e8f\u4e0d\u4f73\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u7535\u5b50\u54a8\u8be2\u4e2d\u751f\u6210\u4e34\u5e8a\u6a21\u677f\u7684\u6f5c\u529b\uff0c\u4ee5\u63d0\u5347\u533b\u751f\u95f4\u4fe1\u606f\u4ea4\u6362\u6548\u7387\u3002", "method": "\u4f7f\u7528145\u4e2a\u4e13\u5bb6\u6a21\u677f\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u6d41\u7a0b\uff08\u63d0\u793a\u4f18\u5316\u3001\u8bed\u4e49\u81ea\u52a8\u8bc4\u5206\u548c\u4f18\u5148\u7ea7\u5206\u6790\uff09\u8bc4\u4f30\u591a\u4e2a\u524d\u6cbf\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5982o3\u5168\u9762\u6027\u9ad8\u8fbe92.2%\uff0c\u4f46\u6a21\u677f\u8fc7\u957f\u4e14\u4f18\u5148\u7ea7\u6392\u5e8f\u4e0d\u51c6\u786e\uff0c\u6027\u80fd\u56e0\u4e13\u79d1\u800c\u5f02\u3002", "conclusion": "LLMs\u53ef\u63d0\u5347\u4e34\u5e8a\u4fe1\u606f\u4ea4\u6362\uff0c\u4f46\u9700\u66f4\u7a33\u5065\u7684\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u4f18\u5316\u4f18\u5148\u7ea7\u6392\u5e8f\u3002"}}
{"id": "2508.01514", "pdf": "https://arxiv.org/pdf/2508.01514", "abs": "https://arxiv.org/abs/2508.01514", "authors": ["Danial Ebrat", "Tina Aminian", "Sepideh Ahmadian", "Luis Rueda"], "title": "End-to-End Personalization: Unifying Recommender Systems with Large Language Models", "categories": ["cs.IR", "cs.LG"], "comment": "Second Workshop on Generative AI for Recommender Systems and\n  Personalization at the ACM Conference on Knowledge Discovery and Data Mining\n  (GenAIRecP@KDD 2025)", "summary": "Recommender systems are essential for guiding users through the vast and\ndiverse landscape of digital content by delivering personalized and relevant\nsuggestions. However, improving both personalization and interpretability\nremains a challenge, particularly in scenarios involving limited user feedback\nor heterogeneous item attributes. In this article, we propose a novel hybrid\nrecommendation framework that combines Graph Attention Networks (GATs) with\nLarge Language Models (LLMs) to address these limitations. LLMs are first used\nto enrich user and item representations by generating semantically meaningful\nprofiles based on metadata such as titles, genres, and overviews. These\nenriched embeddings serve as initial node features in a user and movie\nbipartite graph, which is processed using a GAT based collaborative filtering\nmodel. To enhance ranking accuracy, we introduce a hybrid loss function that\ncombines Bayesian Personalized Ranking (BPR), cosine similarity, and robust\nnegative sampling. Post-processing involves reranking the GAT-generated\nrecommendations using the LLM, which also generates natural-language\njustifications to improve transparency. We evaluated our model on benchmark\ndatasets, including MovieLens 100k and 1M, where it consistently outperforms\nstrong baselines. Ablation studies confirm that LLM-based embeddings and the\ncosine similarity term significantly contribute to performance gains. This work\ndemonstrates the potential of integrating LLMs to improve both the accuracy and\ninterpretability of recommender systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GAT\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6df7\u5408\u63a8\u8350\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u4e2a\u6027\u5316\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u6709\u9650\u7528\u6237\u53cd\u9988\u6216\u5f02\u6784\u9879\u76ee\u5c5e\u6027\u573a\u666f\u4e0b\uff0c\u63a8\u8350\u7cfb\u7edf\u7684\u4e2a\u6027\u5316\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528LLM\u751f\u6210\u7528\u6237\u548c\u9879\u76ee\u7684\u8bed\u4e49\u4e30\u5bcc\u8868\u793a\uff0c\u7ed3\u5408GAT\u8fdb\u884c\u534f\u540c\u8fc7\u6ee4\uff0c\u5e76\u5f15\u5165\u6df7\u5408\u635f\u5931\u51fd\u6570\u4f18\u5316\u6392\u540d\u3002", "result": "\u5728MovieLens\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0cLLM\u5d4c\u5165\u548c\u4f59\u5f26\u76f8\u4f3c\u5ea6\u9879\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "LLM\u7684\u96c6\u6210\u80fd\u663e\u8457\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.00899", "pdf": "https://arxiv.org/pdf/2508.00899", "abs": "https://arxiv.org/abs/2508.00899", "authors": ["Abeer Dyoub", "Ivan Letteri", "Francesca A. Lisi"], "title": "ff4ERA: A new Fuzzy Framework for Ethical Risk Assessment in AI", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.LG"], "comment": null, "summary": "The emergence of Symbiotic AI (SAI) introduces new challenges to ethical\ndecision-making as it deepens human-AI collaboration. As symbiosis grows, AI\nsystems pose greater ethical risks, including harm to human rights and trust.\nEthical Risk Assessment (ERA) thus becomes crucial for guiding decisions that\nminimize such risks. However, ERA is hindered by uncertainty, vagueness, and\nincomplete information, and morality itself is context-dependent and imprecise.\nThis motivates the need for a flexible, transparent, yet robust framework for\nERA. Our work supports ethical decision-making by quantitatively assessing and\nprioritizing multiple ethical risks so that artificial agents can select\nactions aligned with human values and acceptable risk levels. We introduce\nff4ERA, a fuzzy framework that integrates Fuzzy Logic, the Fuzzy Analytic\nHierarchy Process (FAHP), and Certainty Factors (CF) to quantify ethical risks\nvia an Ethical Risk Score (ERS) for each risk type. The final ERS combines the\nFAHP-derived weight, propagated CF, and risk level. The framework offers a\nrobust mathematical approach for collaborative ERA modeling and systematic,\nstep-by-step analysis. A case study confirms that ff4ERA yields\ncontext-sensitive, ethically meaningful risk scores reflecting both expert\ninput and sensor-based evidence. Risk scores vary consistently with relevant\nfactors while remaining robust to unrelated inputs. Local sensitivity analysis\nshows predictable, mostly monotonic behavior across perturbations, and global\nSobol analysis highlights the dominant influence of expert-defined weights and\ncertainty factors, validating the model design. Overall, the results\ndemonstrate ff4ERA ability to produce interpretable, traceable, and risk-aware\nethical assessments, enabling what-if analyses and guiding designers in\ncalibrating membership functions and expert judgments for reliable ethical\ndecision support.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u7cca\u6846\u67b6ff4ERA\uff0c\u7528\u4e8e\u91cf\u5316\u4f26\u7406\u98ce\u9669\uff0c\u652f\u6301AI\u7cfb\u7edf\u5728\u4eba\u7c7b\u4ef7\u503c\u89c2\u548c\u53ef\u63a5\u53d7\u98ce\u9669\u6c34\u5e73\u4e0b\u7684\u51b3\u7b56\u3002", "motivation": "\u968f\u7740\u5171\u751fAI\u7684\u53d1\u5c55\uff0c\u4f26\u7406\u98ce\u9669\u8bc4\u4f30\uff08ERA\uff09\u9762\u4e34\u4e0d\u786e\u5b9a\u6027\u3001\u6a21\u7cca\u6027\u548c\u4fe1\u606f\u4e0d\u5b8c\u6574\u7b49\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u7075\u6d3b\u3001\u900f\u660e\u4e14\u7a33\u5065\u7684\u6846\u67b6\u3002", "method": "\u7ed3\u5408\u6a21\u7cca\u903b\u8f91\u3001\u6a21\u7cca\u5c42\u6b21\u5206\u6790\u6cd5\uff08FAHP\uff09\u548c\u786e\u5b9a\u6027\u56e0\u5b50\uff08CF\uff09\uff0c\u901a\u8fc7\u4f26\u7406\u98ce\u9669\u8bc4\u5206\uff08ERS\uff09\u91cf\u5316\u98ce\u9669\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cff4ERA\u80fd\u751f\u6210\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u4f26\u7406\u98ce\u9669\u8bc4\u5206\uff0c\u4e14\u5bf9\u65e0\u5173\u8f93\u5165\u4fdd\u6301\u7a33\u5065\u3002", "conclusion": "ff4ERA\u6846\u67b6\u80fd\u591f\u63d0\u4f9b\u53ef\u89e3\u91ca\u3001\u53ef\u8ffd\u8e2a\u4e14\u98ce\u9669\u611f\u77e5\u7684\u4f26\u7406\u8bc4\u4f30\uff0c\u652f\u6301\u5047\u8bbe\u5206\u6790\u548c\u8bbe\u8ba1\u4f18\u5316\u3002"}}
{"id": "2508.00869", "pdf": "https://arxiv.org/pdf/2508.00869", "abs": "https://arxiv.org/abs/2508.00869", "authors": ["Dmitriy Kashitsyn", "Dmitriy Shabanov"], "title": "Discrete approach to machine learning", "categories": ["cs.LG", "cs.ET", "cs.IT", "math.IT"], "comment": "preprint, 52 pages, 37 figures", "summary": "The article explores an encoding and structural information processing\napproach using sparse bit vectors and fixed-length linear vectors. The\nfollowing are presented: a discrete method of speculative stochastic\ndimensionality reduction of multidimensional code and linear spaces with linear\nasymptotic complexity; a geometric method for obtaining discrete embeddings of\nan organised code space that reflect the internal structure of a given\nmodality. The structure and properties of a code space are investigated using\nthree modalities as examples: morphology of Russian and English languages, and\nimmunohistochemical markers. Parallels are drawn between the resulting map of\nthe code space layout and so-called pinwheels appearing on the mammalian\nneocortex. A cautious assumption is made about similarities between neocortex\norganisation and processes happening in our models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u4f4d\u5411\u91cf\u548c\u56fa\u5b9a\u957f\u5ea6\u7ebf\u6027\u5411\u91cf\u7684\u7f16\u7801\u4e0e\u7ed3\u6784\u4fe1\u606f\u5904\u7406\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u591a\u7ef4\u4ee3\u7801\u7684\u964d\u7ef4\u548c\u79bb\u6563\u5d4c\u5165\u7684\u51e0\u4f55\u65b9\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86\u4e09\u79cd\u6a21\u6001\u4e0b\u7684\u4ee3\u7801\u7a7a\u95f4\u7ed3\u6784\u4e0e\u6027\u8d28\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u591a\u7ef4\u4ee3\u7801\u7684\u964d\u7ef4\u548c\u79bb\u6563\u5d4c\u5165\u65b9\u6cd5\uff0c\u4ee5\u53cd\u6620\u4e0d\u540c\u6a21\u6001\u7684\u5185\u90e8\u7ed3\u6784\uff0c\u5e76\u5c1d\u8bd5\u4e0e\u54fa\u4e73\u52a8\u7269\u65b0\u76ae\u8d28\u7684\u7ec4\u7ec7\u7ed3\u6784\u8fdb\u884c\u7c7b\u6bd4\u3002", "method": "\u91c7\u7528\u7a00\u758f\u4f4d\u5411\u91cf\u548c\u56fa\u5b9a\u957f\u5ea6\u7ebf\u6027\u5411\u91cf\u8fdb\u884c\u7f16\u7801\uff0c\u63d0\u51fa\u79bb\u6563\u7684\u968f\u673a\u964d\u7ef4\u65b9\u6cd5\u548c\u51e0\u4f55\u79bb\u6563\u5d4c\u5165\u65b9\u6cd5\uff0c\u5e76\u4ee5\u8bed\u8a00\u5f62\u6001\u5b66\u548c\u514d\u75ab\u7ec4\u5316\u6807\u8bb0\u4e3a\u4f8b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4ee3\u7801\u7a7a\u95f4\u7684\u5e03\u5c40\u4e0e\u65b0\u76ae\u8d28\u7684\u201c\u98ce\u8f66\u201d\u7ed3\u6784\u5b58\u5728\u76f8\u4f3c\u6027\uff0c\u63a8\u6d4b\u6a21\u578b\u4e2d\u7684\u8fc7\u7a0b\u53ef\u80fd\u4e0e\u65b0\u76ae\u8d28\u7684\u7ec4\u7ec7\u65b9\u5f0f\u7c7b\u4f3c\u3002", "conclusion": "\u8bba\u6587\u5c55\u793a\u4e86\u4ee3\u7801\u7a7a\u95f4\u7ed3\u6784\u4e0e\u65b0\u76ae\u8d28\u7ec4\u7ec7\u7684\u6f5c\u5728\u76f8\u4f3c\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2508.01161", "pdf": "https://arxiv.org/pdf/2508.01161", "abs": "https://arxiv.org/abs/2508.01161", "authors": ["Jiyu Chen", "Necva B\u00f6l\u00fcc\u00fc", "Sarvnaz Karimi", "Diego Moll\u00e1", "C\u00e9cile L. Paris"], "title": "CSIRO-LT at SemEval-2025 Task 11: Adapting LLMs for Emotion Recognition for Multiple Languages", "categories": ["cs.CL"], "comment": "In Proceedings of the 19th International Workshop on Semantic\n  Evaluation (SemEval-2025), Vienna, Austria. Association for Computational\n  Linguistics", "summary": "Detecting emotions across different languages is challenging due to the\nvaried and culturally nuanced ways of emotional expressions. The\n\\textit{Semeval 2025 Task 11: Bridging the Gap in Text-Based emotion} shared\ntask was organised to investigate emotion recognition across different\nlanguages. The goal of the task is to implement an emotion recogniser that can\nidentify the basic emotional states that general third-party observers would\nattribute to an author based on their written text snippet, along with the\nintensity of those emotions. We report our investigation of various\ntask-adaptation strategies for LLMs in emotion recognition. We show that the\nmost effective method for this task is to fine-tune a pre-trained multilingual\nLLM with LoRA setting separately for each language.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8de8\u8bed\u8a00\u60c5\u611f\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u8bed\u8a00\u9884\u8bad\u7ec3LLM\u548cLoRA\u5fae\u8c03\u7684\u65b9\u6cd5\uff0c\u6548\u679c\u6700\u4f73\u3002", "motivation": "\u89e3\u51b3\u4e0d\u540c\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u4e0b\u60c5\u611f\u8868\u8fbe\u7684\u591a\u6837\u6027\u95ee\u9898\uff0c\u63d0\u5347\u8de8\u8bed\u8a00\u60c5\u611f\u8bc6\u522b\u7684\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u591a\u8bed\u8a00LLM\uff0c\u5e76\u9488\u5bf9\u6bcf\u79cd\u8bed\u8a00\u5355\u72ec\u8fdb\u884cLoRA\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "\u901a\u8fc7\u8bed\u8a00\u7279\u5b9a\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u8de8\u8bed\u8a00\u60c5\u611f\u8bc6\u522b\u7684\u6027\u80fd\u3002"}}
{"id": "2508.01643", "pdf": "https://arxiv.org/pdf/2508.01643", "abs": "https://arxiv.org/abs/2508.01643", "authors": ["Ali Shiraee Kasmaee", "Mohammad Khodadad", "Mehdi Astaraki", "Mohammad Arshi Saloot", "Nicholas Sherck", "Hamidreza Mahyar", "Soheila Samiee"], "title": "ChEmbed: Enhancing Chemical Literature Search Through Domain-Specific Text Embeddings", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems in chemistry heavily depend on\naccurate and relevant retrieval of chemical literature. However,\ngeneral-purpose text embedding models frequently fail to adequately represent\ncomplex chemical terminologies, resulting in suboptimal retrieval quality.\nSpecialized embedding models tailored to chemical literature retrieval have not\nyet been developed, leaving a substantial performance gap. To address this\nchallenge, we introduce ChEmbed, a domain-adapted family of text embedding\nmodels fine-tuned on a dataset comprising chemistry-specific text from the\nPubChem, Semantic Scholar, and ChemRxiv corpora. To create effective training\ndata, we employ large language models to synthetically generate queries,\nresulting in approximately 1.7 million high-quality query-passage pairs.\nAdditionally, we augment the tokenizer by adding 900 chemically specialized\ntokens to previously unused slots, which significantly reduces the\nfragmentation of chemical entities, such as IUPAC names. ChEmbed also maintains\na 8192-token context length, enabling the efficient retrieval of longer\npassages compared to many other open-source embedding models, which typically\nhave a context length of 512 or 2048 tokens. Evaluated on our newly introduced\nChemRxiv Retrieval benchmark, ChEmbed outperforms state-of-the-art general\nembedding models, raising nDCG@10 from 0.82 to 0.91 (+9 pp). ChEmbed represents\na practical, lightweight, and reproducible embedding solution that effectively\nimproves retrieval for chemical literature search.", "AI": {"tldr": "ChEmbed\u662f\u4e00\u79cd\u9488\u5bf9\u5316\u5b66\u6587\u732e\u68c0\u7d22\u4f18\u5316\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff0c\u901a\u8fc7\u9886\u57df\u9002\u914d\u548c\u5316\u5b66\u4e13\u7528\u4ee4\u724c\u6539\u8fdb\u68c0\u7d22\u8d28\u91cf\uff0c\u663e\u8457\u4f18\u4e8e\u901a\u7528\u5d4c\u5165\u6a21\u578b\u3002", "motivation": "\u901a\u7528\u6587\u672c\u5d4c\u5165\u6a21\u578b\u5728\u5316\u5b66\u672f\u8bed\u8868\u793a\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u68c0\u7d22\u8d28\u91cf\u4f4e\u4e0b\uff0c\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u5316\u5b66\u6587\u732e\u7684\u5d4c\u5165\u6a21\u578b\u3002", "method": "\u5f00\u53d1\u4e86ChEmbed\u6a21\u578b\uff0c\u57fa\u4e8e\u5316\u5b66\u7279\u5b9a\u6587\u672c\u6570\u636e\u96c6\uff08PubChem\u3001Semantic Scholar\u3001ChemRxiv\uff09\u8fdb\u884c\u5fae\u8c03\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5408\u6210\u67e5\u8be2\uff0c\u5e76\u6269\u5c55\u4e86900\u4e2a\u5316\u5b66\u4e13\u7528\u4ee4\u724c\u3002", "result": "\u5728ChemRxiv Retrieval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cChEmbed\u5c06nDCG@10\u4ece0.82\u63d0\u5347\u81f30.91\uff08+9\u4e2a\u767e\u5206\u70b9\uff09\u3002", "conclusion": "ChEmbed\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u53ef\u590d\u73b0\u7684\u5d4c\u5165\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5316\u5b66\u6587\u732e\u68c0\u7d22\u7684\u6548\u7387\u3002"}}
{"id": "2508.00902", "pdf": "https://arxiv.org/pdf/2508.00902", "abs": "https://arxiv.org/abs/2508.00902", "authors": ["Kenneth Payne"], "title": "An analysis of AI Decision under Risk: Prospect theory emerges in Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.CY"], "comment": "26 pages, 2 figures, 9 tables, 2 appendices", "summary": "Judgment of risk is key to decision-making under uncertainty. As Daniel\nKahneman and Amos Tversky famously discovered, humans do so in a distinctive\nway that departs from mathematical rationalism. Specifically, they demonstrated\nexperimentally that humans accept more risk when they feel themselves at risk\nof losing something than when they might gain. I report the first tests of\nKahneman and Tversky's landmark 'prospect theory' with Large Language Models,\nincluding today's state of the art chain-of-thought 'reasoners'.\n  In common with humans, I find that prospect theory often anticipates how\nthese models approach risky decisions across a range of scenarios. I also\ndemonstrate that context is key to explaining much of the variance in risk\nappetite. The 'frame' through which risk is apprehended appears to be embedded\nwithin the language of the scenarios tackled by the models. Specifically, I\nfind that military scenarios generate far larger 'framing effects' than do\ncivilian settings, ceteris paribus. My research suggests, therefore, that\nlanguage models the world, capturing our human heuristics and biases. But also\nthat these biases are uneven - the idea of a 'frame' is richer than simple\ngains and losses. Wittgenstein's notion of 'language games' explains the\ncontingent, localised biases activated by these scenarios. Finally, I use my\nfindings to reframe the ongoing debate about reasoning and memorisation in\nLLMs.", "AI": {"tldr": "\u8bba\u6587\u6d4b\u8bd5\u4e86Kahneman\u548cTversky\u7684'\u524d\u666f\u7406\u8bba'\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u6a21\u578b\u4e0e\u4eba\u7c7b\u5728\u98ce\u9669\u51b3\u7b56\u4e2d\u8868\u73b0\u76f8\u4f3c\uff0c\u4e14\u60c5\u5883\uff08\u5982\u519b\u4e8b\u4e0e\u6c11\u7528\uff09\u5bf9\u98ce\u9669\u504f\u597d\u7684\u5f71\u54cd\u663e\u8457\u3002", "motivation": "\u9a8c\u8bc1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u50cf\u4eba\u7c7b\u4e00\u6837\u5728\u98ce\u9669\u51b3\u7b56\u4e2d\u8868\u73b0\u51fa\u524d\u666f\u7406\u8bba\u63cf\u8ff0\u7684\u504f\u5dee\uff0c\u5e76\u63a2\u8ba8\u60c5\u5883\u5bf9\u98ce\u9669\u504f\u597d\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u60c5\u5883\uff08\u5982\u519b\u4e8b\u4e0e\u6c11\u7528\uff09\u4e0b\u7684\u98ce\u9669\u51b3\u7b56\u884c\u4e3a\uff0c\u5206\u6790\u5176\u4e0e\u524d\u666f\u7406\u8bba\u7684\u5951\u5408\u5ea6\u3002", "result": "\u6a21\u578b\u5728\u98ce\u9669\u51b3\u7b56\u4e2d\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u524d\u666f\u7406\u8bba\u504f\u5dee\uff0c\u4e14\u519b\u4e8b\u60c5\u5883\u4e0b\u7684'\u6846\u67b6\u6548\u5e94'\u66f4\u663e\u8457\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u6355\u6349\u4e86\u4eba\u7c7b\u7684\u542f\u53d1\u5f0f\u4e0e\u504f\u89c1\uff0c\u4f46\u8fd9\u4e9b\u504f\u89c1\u5177\u6709\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u652f\u6301Wittgenstein\u7684'\u8bed\u8a00\u6e38\u620f'\u6982\u5ff5\u3002"}}
{"id": "2508.00876", "pdf": "https://arxiv.org/pdf/2508.00876", "abs": "https://arxiv.org/abs/2508.00876", "authors": ["Bakhtiyar Mammadli", "Casim Yazici", "Muhammed G\u00fcrb\u00fcz", "\u0130rfan Kocaman", "F. Javier Dominguez-Gutierrez", "Fatih Mehmet \u00d6zkal"], "title": "A Data-Driven Machine Learning Approach for Predicting Axial Load Capacity in Steel Storage Rack Columns", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": null, "summary": "In this study, we present a machine learning (ML) framework to predict the\naxial load-bearing capacity, (kN), of cold-formed steel structural members. The\nmethodology emphasizes robust model selection and interpretability, addressing\nthe limitations of traditional analytical approaches in capturing the\nnonlinearities and geometrical complexities inherent to buckling behavior. The\ndataset, comprising key geometric and mechanical parameters of steel columns,\nwas curated with appropriate pre-processing steps including removal of\nnon-informative identifiers and imputation of missing values. A comprehensive\nsuite of regression algorithms, ranging from linear models to kernel-based\nregressors and ensemble tree methods was evaluated. Among these, Gradient\nBoosting Regression exhibited superior predictive performance across multiple\nmetrics, including the coefficient of determination (R2), root mean squared\nerror (RMSE), and mean absolute error (MAE), and was consequently selected as\nthe final model. Model interpretability was addressed using SHapley Additive\nexPlanations (SHAP), enabling insight into the relative importance and\ninteraction of input features influencing the predicted axial capacity. To\nfacilitate practical deployment, the model was integrated into an interactive,\nPython-based web interface via Streamlit. This tool allows end-users-such as\nstructural engineers and designers, to input design parameters manually or\nthrough CSV upload, and to obtain real-time predictions of axial load capacity\nwithout the need for programming expertise. Applied to the context of steel\nstorage rack columns, the framework demonstrates how data-driven tools can\nenhance design safety, streamline validation workflows, and inform\ndecision-making in structural applications where buckling is a critical failure\nmode", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u51b7\u5f2f\u578b\u94a2\u6784\u4ef6\u7684\u8f74\u5411\u627f\u8f7d\u80fd\u529b\uff0c\u901a\u8fc7\u68af\u5ea6\u63d0\u5347\u56de\u5f52\u548cSHAP\u89e3\u91ca\u6027\u5206\u6790\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u548c\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u51b7\u5f2f\u578b\u94a2\u6784\u4ef6\u5728\u5c48\u66f2\u884c\u4e3a\u4e2d\u7684\u975e\u7ebf\u6027\u548c\u51e0\u4f55\u590d\u6742\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u591a\u79cd\u56de\u5f52\u7b97\u6cd5\uff08\u4ece\u7ebf\u6027\u6a21\u578b\u5230\u6838\u56de\u5f52\u548c\u96c6\u6210\u6811\u65b9\u6cd5\uff09\u8fdb\u884c\u6a21\u578b\u9009\u62e9\uff0c\u6700\u7ec8\u9009\u62e9\u68af\u5ea6\u63d0\u5347\u56de\u5f52\uff0c\u5e76\u4f7f\u7528SHAP\u8fdb\u884c\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u3002", "result": "\u68af\u5ea6\u63d0\u5347\u56de\u5f52\u5728\u591a\u4e2a\u6307\u6807\uff08\u5982R2\u3001RMSE\u3001MAE\uff09\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u5f0fWeb\u5de5\u5177\u5b9e\u73b0\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7ed3\u6784\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u51c6\u786e\u7684\u9884\u6d4b\u5de5\u5177\uff0c\u63d0\u5347\u4e86\u8bbe\u8ba1\u5b89\u5168\u6027\u548c\u51b3\u7b56\u6548\u7387\u3002"}}
{"id": "2508.01198", "pdf": "https://arxiv.org/pdf/2508.01198", "abs": "https://arxiv.org/abs/2508.01198", "authors": ["Yige Li", "Peihai Jiang", "Jun Sun", "Peng Shu", "Tianming Liu", "Zhen Xiang"], "title": "Adaptive Content Restriction for Large Language Models via Suffix Optimization", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages", "summary": "Large Language Models (LLMs) have demonstrated significant success across\ndiverse applications. However, enforcing content restrictions remains a\nsignificant challenge due to their expansive output space. One aspect of\ncontent restriction is preventing LLMs from generating harmful content via\nmodel alignment approaches such as supervised fine-tuning (SFT). Yet, the need\nfor content restriction may vary significantly across user groups, change\nrapidly over time, and not always align with general definitions of\nharmfulness. Applying SFT to each of these specific use cases is impractical\ndue to the high computational, data, and storage demands. Motivated by this\nneed, we propose a new task called \\textit{Adaptive Content Restriction}\n(AdaCoRe), which focuses on lightweight strategies -- methods without model\nfine-tuning -- to prevent deployed LLMs from generating restricted terms for\nspecific use cases. We propose the first method for AdaCoRe, named\n\\textit{Suffix Optimization (SOP)}, which appends a short, optimized suffix to\nany prompt to a) prevent a target LLM from generating a set of restricted\nterms, while b) preserving the output quality. To evaluate AdaCoRe approaches,\nincluding our SOP, we create a new \\textit{Content Restriction Benchmark}\n(CoReBench), which contains 400 prompts for 80 restricted terms across 8\ncarefully selected categories. We demonstrate the effectiveness of SOP on\nCoReBench, which outperforms the system-level baselines such as system suffix\nby 15\\%, 17\\%, 10\\%, 9\\%, and 6\\% on average restriction rates for Gemma2-2B,\nMistral-7B, Vicuna-7B, Llama3-8B, and Llama3.1-8B, respectively. We also\ndemonstrate that SOP is effective on POE, an online platform hosting various\ncommercial LLMs, highlighting its practicality in real-world scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff08Suffix Optimization, SOP\uff09\u6765\u52a8\u6001\u9650\u5236\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7279\u5b9a\u53d7\u9650\u5185\u5bb9\uff0c\u65e0\u9700\u5fae\u8c03\u6a21\u578b\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5185\u5bb9\u7684\u5e7f\u6cdb\u6027\uff0c\u9488\u5bf9\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u548c\u5feb\u901f\u53d8\u5316\u7684\u9700\u6c42\u8fdb\u884c\u5185\u5bb9\u9650\u5236\u5177\u6709\u6311\u6218\u6027\uff0c\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u6210\u672c\u9ad8\u6602\u4e14\u4e0d\u7075\u6d3b\u3002", "method": "\u63d0\u51faAdaptive Content Restriction (AdaCoRe)\u4efb\u52a1\uff0c\u91c7\u7528Suffix Optimization (SOP)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u63d0\u793a\u540e\u6dfb\u52a0\u4f18\u5316\u540e\u7f00\u5b9e\u73b0\u5185\u5bb9\u9650\u5236\u3002", "result": "SOP\u5728CoReBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u9650\u5236\u7387\u63d0\u53476%-17%\uff0c\u5e76\u5728\u5b9e\u9645\u5e73\u53f0POE\u4e0a\u9a8c\u8bc1\u4e86\u5b9e\u7528\u6027\u3002", "conclusion": "SOP\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u7684\u5185\u5bb9\u9650\u5236\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u9700\u6c42\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.01867", "pdf": "https://arxiv.org/pdf/2508.01867", "abs": "https://arxiv.org/abs/2508.01867", "authors": ["Kazuki Kawamura", "Takuma Udagawa", "Kei Tateno"], "title": "Counterfactual Reciprocal Recommender Systems for User-to-User Matching", "categories": ["cs.IR", "cs.AI"], "comment": "9 pages, 2 figures. Accepted for publication at the Workshop on\n  Two-sided Marketplace Optimization (TSMO '25), held in conjunction with the\n  31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2025),\n  Toronto, Canada", "summary": "Reciprocal recommender systems (RRS) in dating, gaming, and talent platforms\nrequire mutual acceptance for a match. Logged data, however, over-represents\npopular profiles due to past exposure policies, creating feedback loops that\nskew learning and fairness. We introduce Counterfactual Reciprocal Recommender\nSystems (CFRR), a causal framework to mitigate this bias. CFRR uses inverse\npropensity scored, self-normalized objectives. Experiments show CFRR improves\nNDCG@10 by up to 3.5% (e.g., from 0.459 to 0.475 on DBLP, from 0.299 to 0.307\non Synthetic), increases long-tail user coverage by up to 51% (from 0.504 to\n0.763 on Synthetic), and reduces Gini exposure inequality by up to 24% (from\n0.708 to 0.535 on Synthetic). CFRR offers a promising approach for more\naccurate and fair user-to-user matching.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCFRR\u7684\u56e0\u679c\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u4e92\u60e0\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u504f\u89c1\u95ee\u9898\uff0c\u901a\u8fc7\u9006\u503e\u5411\u8bc4\u5206\u548c\u81ea\u5f52\u4e00\u5316\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6548\u679c\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u4e92\u60e0\u63a8\u8350\u7cfb\u7edf\uff08\u5982\u7ea6\u4f1a\u3001\u6e38\u620f\u548c\u4eba\u624d\u5e73\u53f0\uff09\u4e2d\u7684\u5386\u53f2\u6570\u636e\u504f\u5411\u70ed\u95e8\u7528\u6237\uff0c\u5bfc\u81f4\u53cd\u9988\u5faa\u73af\u52a0\u5267\u504f\u89c1\uff0c\u5f71\u54cd\u5b66\u4e60\u548c\u516c\u5e73\u6027\u3002", "method": "\u63d0\u51faCounterfactual Reciprocal Recommender Systems (CFRR)\uff0c\u91c7\u7528\u9006\u503e\u5411\u8bc4\u5206\u548c\u81ea\u5f52\u4e00\u5316\u76ee\u6807\u6765\u51cf\u5c11\u504f\u89c1\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cCFRR\u5728NDCG@10\u4e0a\u63d0\u53473.5%\uff0c\u957f\u5c3e\u7528\u6237\u8986\u76d6\u7387\u589e\u52a051%\uff0c\u57fa\u5c3c\u66dd\u5149\u4e0d\u5e73\u7b49\u6027\u964d\u4f4e24%\u3002", "conclusion": "CFRR\u4e3a\u66f4\u51c6\u786e\u548c\u516c\u5e73\u7684\u7528\u6237\u5339\u914d\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00914", "pdf": "https://arxiv.org/pdf/2508.00914", "abs": "https://arxiv.org/abs/2508.00914", "authors": ["Dominic Simon", "Rickard Ewetz"], "title": "Knowledge Editing for Multi-Hop Question Answering Using Semantic Analysis", "categories": ["cs.AI", "cs.LG"], "comment": "14 pages, 15 figures, pre-print of paper accepted to IJCAI 2025", "summary": "Large Language Models (LLMs) require lightweight avenues of updating stored\ninformation that has fallen out of date. Knowledge Editing (KE) approaches have\nbeen successful in updating model knowledge for simple factual queries but\nstruggle with handling tasks that require compositional reasoning such as\nmulti-hop question answering (MQA). We observe that existing knowledge editors\nleverage decompositional techniques that result in illogical reasoning\nprocesses. In this paper, we propose a knowledge editor for MQA based on\nsemantic analysis called CHECK. Our framework is based on insights from an\nanalogy between compilers and reasoning using LLMs. Similar to how source code\nis first compiled before being executed, we propose to semantically analyze\nreasoning chains before executing the chains to answer questions. Reasoning\nchains with semantic errors are revised to ensure consistency through logic\noptimization and re-prompting the LLM model at a higher temperature. We\nevaluate the effectiveness of CHECK against five state-of-the-art frameworks on\nfour datasets and achieve an average 22.8% improved MQA accuracy.", "AI": {"tldr": "CHECK\u662f\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u5206\u6790\u7684\u77e5\u8bc6\u7f16\u8f91\u6846\u67b6\uff0c\u7528\u4e8e\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u903b\u8f91\u4f18\u5316\u548c\u91cd\u65b0\u63d0\u793a\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u5728\u5904\u7406\u9700\u8981\u7ec4\u5408\u63a8\u7406\u7684\u4efb\u52a1\uff08\u5982\u591a\u8df3\u95ee\u7b54\uff09\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u4e0d\u903b\u8f91\u3002", "method": "CHECK\u901a\u8fc7\u7c7b\u6bd4\u7f16\u8bd1\u5668\u548cLLM\u63a8\u7406\uff0c\u5148\u5bf9\u63a8\u7406\u94fe\u8fdb\u884c\u8bed\u4e49\u5206\u6790\uff0c\u4fee\u6b63\u8bed\u4e49\u9519\u8bef\uff0c\u518d\u901a\u8fc7\u903b\u8f91\u4f18\u5316\u548c\u9ad8\u6e29\u91cd\u65b0\u63d0\u793a\u6267\u884c\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cCHECK\u6bd4\u4e94\u79cd\u6700\u5148\u8fdb\u6846\u67b6\u5e73\u5747\u63d0\u9ad8\u4e8622.8%\u7684\u591a\u8df3\u95ee\u7b54\u51c6\u786e\u7387\u3002", "conclusion": "CHECK\u901a\u8fc7\u8bed\u4e49\u5206\u6790\u548c\u903b\u8f91\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2508.00877", "pdf": "https://arxiv.org/pdf/2508.00877", "abs": "https://arxiv.org/abs/2508.00877", "authors": ["Chao Yan", "Babak Mafakheri"], "title": "Satellite Connectivity Prediction for Fast-Moving Platforms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Satellite connectivity is gaining increased attention as the demand for\nseamless internet access, especially in transportation and remote areas,\ncontinues to grow. For fast-moving objects such as aircraft, vehicles, or\ntrains, satellite connectivity is critical due to their mobility and frequent\npresence in areas without terrestrial coverage. Maintaining reliable\nconnectivity in these cases requires frequent switching between satellite\nbeams, constellations, or orbits. To enhance user experience and address\nchallenges like long switching times, Machine Learning (ML) algorithms can\nanalyze historical connectivity data and predict network quality at specific\nlocations. This allows for proactive measures, such as network switching before\nconnectivity issues arise. In this paper, we analyze a real dataset of\ncommunication between a Geostationary Orbit (GEO) satellite and aircraft over\nmultiple flights, using ML to predict signal quality. Our prediction model\nachieved an F1 score of 0.97 on the test data, demonstrating the accuracy of\nmachine learning in predicting signal quality during flight. By enabling\nseamless broadband service, including roaming between different satellite\nconstellations and providers, our model addresses the need for real-time\npredictions of signal quality. This approach can further be adapted to automate\nsatellite and beam-switching mechanisms to improve overall communication\nefficiency. The model can also be retrained and applied to any moving object\nwith satellite connectivity, using customized datasets, including connected\nvehicles and trains.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u536b\u661f\u4fe1\u53f7\u8d28\u91cf\uff0c\u4ee5\u63d0\u5347\u79fb\u52a8\u7269\u4f53\uff08\u5982\u98de\u673a\uff09\u7684\u536b\u661f\u8fde\u63a5\u53ef\u9760\u6027\uff0c\u6d4b\u8bd5F1\u5206\u6570\u8fbe0.97\u3002", "motivation": "\u968f\u7740\u5bf9\u65e0\u7f1d\u4e92\u8054\u7f51\u63a5\u5165\u9700\u6c42\u7684\u589e\u957f\uff0c\u536b\u661f\u8fde\u63a5\u5728\u79fb\u52a8\u7269\u4f53\uff08\u5982\u98de\u673a\uff09\u4e2d\u7684\u91cd\u8981\u6027\u65e5\u76ca\u51f8\u663e\uff0c\u4f46\u9891\u7e41\u5207\u6362\u536b\u661f\u4fe1\u53f7\u5e26\u6765\u6311\u6218\u3002", "method": "\u901a\u8fc7\u5206\u6790GEO\u536b\u661f\u4e0e\u98de\u673a\u901a\u4fe1\u7684\u771f\u5b9e\u6570\u636e\u96c6\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u4fe1\u53f7\u8d28\u91cf\uff0c\u5e76\u5b9e\u73b0\u4e3b\u52a8\u7f51\u7edc\u5207\u6362\u3002", "result": "\u9884\u6d4b\u6a21\u578b\u5728\u6d4b\u8bd5\u6570\u636e\u4e0aF1\u5206\u6570\u8fbe0.97\uff0c\u9a8c\u8bc1\u4e86\u673a\u5668\u5b66\u4e60\u5728\u4fe1\u53f7\u8d28\u91cf\u9884\u6d4b\u4e2d\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u6a21\u578b\u53ef\u63d0\u5347\u536b\u661f\u901a\u4fe1\u6548\u7387\uff0c\u5e76\u9002\u7528\u4e8e\u5176\u4ed6\u79fb\u52a8\u7269\u4f53\uff0c\u5982\u8f66\u8f86\u548c\u706b\u8f66\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2508.01213", "pdf": "https://arxiv.org/pdf/2508.01213", "abs": "https://arxiv.org/abs/2508.01213", "authors": ["Shengqi Zhu", "Jeffrey M. Rzeszotarski", "David Mimno"], "title": "Show or Tell? Modeling the evolution of request-making in Human-LLM conversations", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Chat logs provide a rich source of information about LLM users, but patterns\nof user behavior are often masked by the variability of queries. We present a\nnew task, segmenting chat queries into contents of requests, roles,\nquery-specific context, and additional expressions. We find that, despite the\nfamiliarity of chat-based interaction, request-making in LLM queries remains\nsignificantly different from comparable human-human interactions. With the data\nresource, we introduce an important perspective of diachronic analyses with\nuser expressions. We find that query patterns vary between early ones\nemphasizing requests, and individual users explore patterns but tend to\nconverge with experience. Finally, we show that model capabilities affect user\nbehavior, particularly with the introduction of new models, which are traceable\nat the community level.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u4efb\u52a1\uff0c\u5c06\u804a\u5929\u67e5\u8be2\u5206\u5272\u4e3a\u8bf7\u6c42\u5185\u5bb9\u3001\u89d2\u8272\u3001\u67e5\u8be2\u7279\u5b9a\u4e0a\u4e0b\u6587\u548c\u9644\u52a0\u8868\u8fbe\uff0c\u5e76\u5206\u6790\u4e86\u7528\u6237\u884c\u4e3a\u6a21\u5f0f\u4e0e\u6a21\u578b\u80fd\u529b\u7684\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u7528\u6237\u5728\u4e0eLLM\u4ea4\u4e92\u65f6\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u63ed\u793a\u5176\u4e0e\u4eba\u7c7b\u95f4\u4e92\u52a8\u7684\u5dee\u5f02\uff0c\u5e76\u63a2\u7d22\u6a21\u578b\u80fd\u529b\u5bf9\u7528\u6237\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u5206\u5272\u804a\u5929\u67e5\u8be2\u7684\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u8d44\u6e90\u8fdb\u884c\u5386\u65f6\u5206\u6790\uff0c\u6bd4\u8f83\u65e9\u671f\u4e0e\u540e\u671f\u67e5\u8be2\u6a21\u5f0f\u7684\u53d8\u5316\u3002", "result": "\u53d1\u73b0\u7528\u6237\u67e5\u8be2\u6a21\u5f0f\u4ece\u5f3a\u8c03\u8bf7\u6c42\u9010\u6e10\u6536\u655b\uff0c\u4e14\u6a21\u578b\u80fd\u529b\u7684\u5f15\u5165\u5728\u793e\u533a\u5c42\u9762\u53ef\u8ffd\u8e2a\u7528\u6237\u884c\u4e3a\u53d8\u5316\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7406\u89e3LLM\u7528\u6237\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u5c55\u793a\u4e86\u6a21\u578b\u80fd\u529b\u5bf9\u7528\u6237\u884c\u4e3a\u7684\u663e\u8457\u5f71\u54cd\u3002"}}
{"id": "2508.02020", "pdf": "https://arxiv.org/pdf/2508.02020", "abs": "https://arxiv.org/abs/2508.02020", "authors": ["Ethan Bito", "Yongli Ren", "Estrid He"], "title": "Evaluating Position Bias in Large Language Model Recommendations", "categories": ["cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) are being increasingly explored as\ngeneral-purpose tools for recommendation tasks, enabling zero-shot and\ninstruction-following capabilities without the need for task-specific training.\nWhile the research community is enthusiastically embracing LLMs, there are\nimportant caveats to directly adapting them for recommendation tasks. In this\npaper, we show that LLM-based recommendation models suffer from position bias,\nwhere the order of candidate items in a prompt can disproportionately influence\nthe recommendations produced by LLMs. First, we analyse the position bias of\nLLM-based recommendations on real-world datasets, where results uncover\nsystemic biases of LLMs with high sensitivity to input orders. Furthermore, we\nintroduce a new prompting strategy to mitigate the position bias of LLM\nrecommendation models called Ranking via Iterative SElection (RISE). We compare\nour proposed method against various baselines on key benchmark datasets.\nExperiment results show that our method reduces sensitivity to input ordering\nand improves stability without requiring model fine-tuning or post-processing.", "AI": {"tldr": "LLM-based recommendation models exhibit position bias, where input order affects recommendations. A new prompting strategy, RISE, is introduced to mitigate this bias, showing improved stability without fine-tuning.", "motivation": "To address the position bias in LLM-based recommendation models, which can disproportionately influence recommendations based on input order.", "method": "Analyze position bias in LLM-based recommendations on real-world datasets and introduce the RISE prompting strategy to mitigate bias.", "result": "RISE reduces sensitivity to input ordering and improves stability, outperforming baselines without requiring fine-tuning.", "conclusion": "The RISE method effectively mitigates position bias in LLM-based recommendations, enhancing their reliability for practical use."}}
{"id": "2508.00967", "pdf": "https://arxiv.org/pdf/2508.00967", "abs": "https://arxiv.org/abs/2508.00967", "authors": ["Massoud Pourmandi"], "title": "Cooperative Perception: A Resource-Efficient Framework for Multi-Drone 3D Scene Reconstruction Using Federated Diffusion and NeRF", "categories": ["cs.AI", "cs.RO", "68T07, 68T45, 93C85", "I.2.6; I.2.9; I.2.10; I.4.8"], "comment": "15 pages, 3 figures, 1 table, 1 algorithm. Preprint based on NeurIPS\n  2024 template", "summary": "The proposal introduces an innovative drone swarm perception system that aims\nto solve problems related to computational limitations and low-bandwidth\ncommunication, and real-time scene reconstruction. The framework enables\nefficient multi-agent 3D/4D scene synthesis through federated learning of\nshared diffusion model and YOLOv12 lightweight semantic extraction and local\nNeRF updates while maintaining privacy and scalability. The framework redesigns\ngenerative diffusion models for joint scene reconstruction, and improves\ncooperative scene understanding, while adding semantic-aware compression\nprotocols. The approach can be validated through simulations and potential\nreal-world deployment on drone testbeds, positioning it as a disruptive\nadvancement in multi-agent AI for autonomous systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65e0\u4eba\u673a\u7fa4\u611f\u77e5\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u3001\u8f7b\u91cf\u7ea7\u8bed\u4e49\u63d0\u53d6\u548c\u5c40\u90e8NeRF\u66f4\u65b0\uff0c\u89e3\u51b3\u8ba1\u7b97\u9650\u5236\u3001\u4f4e\u5e26\u5bbd\u901a\u4fe1\u548c\u5b9e\u65f6\u573a\u666f\u91cd\u5efa\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u7fa4\u5728\u8ba1\u7b97\u80fd\u529b\u6709\u9650\u3001\u901a\u4fe1\u5e26\u5bbd\u4f4e\u4ee5\u53ca\u5b9e\u65f6\u573a\u666f\u91cd\u5efa\u4e2d\u7684\u6311\u6218\u3002", "method": "\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u7684\u5171\u4eab\u6269\u6563\u6a21\u578b\u3001YOLOv12\u8f7b\u91cf\u7ea7\u8bed\u4e49\u63d0\u53d6\u548c\u5c40\u90e8NeRF\u66f4\u65b0\uff0c\u8bbe\u8ba1\u751f\u6210\u6269\u6563\u6a21\u578b\u7528\u4e8e\u8054\u5408\u573a\u666f\u91cd\u5efa\uff0c\u5e76\u5f15\u5165\u8bed\u4e49\u611f\u77e5\u538b\u7f29\u534f\u8bae\u3002", "result": "\u7cfb\u7edf\u5728\u6a21\u62df\u548c\u5b9e\u9645\u65e0\u4eba\u673a\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u667a\u80fd\u4f53AI\u5728\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u7a81\u7834\u6027\u8fdb\u5c55\u3002"}}
{"id": "2508.00879", "pdf": "https://arxiv.org/pdf/2508.00879", "abs": "https://arxiv.org/abs/2508.00879", "authors": ["Moutaz Bellah Bentrad", "Adel Ghoggal", "Tahar Bahi", "Abderaouf Bahi"], "title": "GNN-ASE: Graph-Based Anomaly Detection and Severity Estimation in Three-Phase Induction Machines", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The diagnosis of induction machines has traditionally relied on model-based\nmethods that require the development of complex dynamic models, making them\ndifficult to implement and computationally expensive. To overcome these\nlimitations, this paper proposes a model-free approach using Graph Neural\nNetworks (GNNs) for fault diagnosis in induction machines. The focus is on\ndetecting multiple fault types -- including eccentricity, bearing defects, and\nbroken rotor bars -- under varying severity levels and load conditions. Unlike\ntraditional approaches, raw current and vibration signals are used as direct\ninputs, eliminating the need for signal preprocessing or manual feature\nextraction. The proposed GNN-ASE model automatically learns and extracts\nrelevant features from raw inputs, leveraging the graph structure to capture\ncomplex relationships between signal types and fault patterns. It is evaluated\nfor both individual fault detection and multi-class classification of combined\nfault conditions. Experimental results demonstrate the effectiveness of the\nproposed model, achieving 92.5\\% accuracy for eccentricity defects, 91.2\\% for\nbearing faults, and 93.1\\% for broken rotor bar detection. These findings\nhighlight the model's robustness and generalization capability across different\noperational scenarios. The proposed GNN-based framework offers a lightweight\nyet powerful solution that simplifies implementation while maintaining high\ndiagnostic performance. It stands as a promising alternative to conventional\nmodel-based diagnostic techniques for real-world induction machine monitoring\nand predictive maintenance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u65e0\u6a21\u578b\u65b9\u6cd5\uff0c\u7528\u4e8e\u611f\u5e94\u7535\u673a\u7684\u6545\u969c\u8bca\u65ad\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u6a21\u578b\u65b9\u6cd5\u7684\u590d\u6742\u6027\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6a21\u578b\u7684\u8bca\u65ad\u65b9\u6cd5\u590d\u6742\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u5f00\u53d1\u52a8\u6001\u6a21\u578b\uff0c\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u4f7f\u7528GNN-ASE\u6a21\u578b\u76f4\u63a5\u4ece\u539f\u59cb\u7535\u6d41\u548c\u632f\u52a8\u4fe1\u53f7\u4e2d\u81ea\u52a8\u5b66\u4e60\u7279\u5f81\uff0c\u65e0\u9700\u9884\u5904\u7406\u6216\u624b\u52a8\u7279\u5f81\u63d0\u53d6\u3002", "result": "\u6a21\u578b\u5728\u504f\u5fc3\u7f3a\u9677\u3001\u8f74\u627f\u6545\u969c\u548c\u65ad\u6761\u68c0\u6d4b\u4e2d\u5206\u522b\u8fbe\u523092.5%\u300191.2%\u548c93.1%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "GNN\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u4e14\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7b80\u5316\u4e86\u5b9e\u73b0\u5e76\u4fdd\u6301\u4e86\u9ad8\u8bca\u65ad\u6027\u80fd\uff0c\u662f\u4f20\u7edf\u65b9\u6cd5\u7684\u66ff\u4ee3\u9009\u62e9\u3002"}}
{"id": "2508.01222", "pdf": "https://arxiv.org/pdf/2508.01222", "abs": "https://arxiv.org/abs/2508.01222", "authors": ["Ethan Hsu", "Hong Meng Yam", "Ines Bouissou", "Aaron Murali John", "Raj Thota", "Josh Koe", "Vivek Sarath Putta", "G K Dharesan", "Alexander Spangher", "Shikhar Murty", "Tenghao Huang", "Christopher D. Manning"], "title": "WebDS: An End-to-End Benchmark for Web-based Data Science", "categories": ["cs.CL", "cs.AI"], "comment": "14 pages", "summary": "A large portion of real-world data science tasks are complex and require\nmulti-hop web-based interactions: finding appropriate data available on the\ninternet, synthesizing real-time data of various modalities from different\nlocations, and producing summarized analyses. Existing web benchmarks often\nfocus on simplistic interactions, such as form submissions or e-commerce\ntransactions, and often do not require diverse tool-using capabilities required\nfor web based data science. Conversely, traditional data science benchmarks\ntypically concentrate on static, often textually bound datasets and do not\nassess end-to-end workflows that encompass data acquisition, cleaning,\nanalysis, and insight generation. In response, we introduce WebDS, the first\nend-to-end web-based data science benchmark. It comprises 870 web-based data\nscience tasks across 29 diverse websites from structured government data\nportals to unstructured news media, challenging agents to perform complex,\nmulti-step operations requiring the use of tools and heterogeneous data formats\nthat better reflect the realities of modern data analytics. Evaluations of\ncurrent SOTA LLM agents indicate significant performance gaps in accomplishing\nthese tasks. For instance, Browser Use, which accomplishes 80% of tasks on Web\nVoyager, successfully completes only 15% of tasks in WebDS, which our analysis\nsuggests is due to new failure modes like poor information grounding,\nrepetitive behavior and shortcut-taking that agents performing WebDS' tasks\ndisplay. By providing a more robust and realistic testing ground, WebDS sets\nthe stage for significant advances in the development of practically useful\nLLM-based data science.", "AI": {"tldr": "WebDS\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u57fa\u4e8e\u7f51\u7edc\u7684\u6570\u636e\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b870\u4e2a\u4efb\u52a1\uff0c\u8986\u76d629\u4e2a\u7f51\u7ad9\uff0c\u65e8\u5728\u8bc4\u4f30\u590d\u6742\u3001\u591a\u6b65\u9aa4\u7684\u6570\u636e\u79d1\u5b66\u5de5\u4f5c\u6d41\u3002\u73b0\u6709SOTA LLM\u4ee3\u7406\u5728WebDS\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u63ed\u793a\u4e86\u65b0\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7f51\u7edc\u57fa\u51c6\u6d4b\u8bd5\u548c\u6570\u636e\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5168\u9762\u8bc4\u4f30\u590d\u6742\u7684\u6570\u636e\u79d1\u5b66\u4efb\u52a1\uff0c\u5c24\u5176\u662f\u6d89\u53ca\u591a\u6b65\u9aa4\u64cd\u4f5c\u548c\u5f02\u6784\u6570\u636e\u683c\u5f0f\u7684\u60c5\u51b5\u3002WebDS\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "WebDS\u5305\u542b870\u4e2a\u4efb\u52a1\uff0c\u8986\u76d629\u4e2a\u591a\u6837\u5316\u7f51\u7ad9\uff0c\u8981\u6c42\u4ee3\u7406\u6267\u884c\u590d\u6742\u64cd\u4f5c\uff0c\u4f7f\u7528\u5de5\u5177\u5904\u7406\u5f02\u6784\u6570\u636e\u3002", "result": "\u5f53\u524dSOTA LLM\u4ee3\u7406\u5728WebDS\u4efb\u52a1\u4e2d\u8868\u73b0\u8f83\u5dee\uff0c\u4f8b\u5982Browser Use\u4ec5\u5b8c\u621015%\u7684\u4efb\u52a1\uff0c\u5931\u8d25\u539f\u56e0\u5305\u62ec\u4fe1\u606f\u57fa\u7840\u4e0d\u8db3\u3001\u91cd\u590d\u884c\u4e3a\u548c\u8d70\u6377\u5f84\u3002", "conclusion": "WebDS\u4e3a\u5f00\u53d1\u5b9e\u7528\u7684\u57fa\u4e8eLLM\u7684\u6570\u636e\u79d1\u5b66\u5de5\u5177\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u548c\u5f3a\u5927\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2508.02050", "pdf": "https://arxiv.org/pdf/2508.02050", "abs": "https://arxiv.org/abs/2508.02050", "authors": ["Yuli Liu", "Wenjun Kong", "Cheng Luo", "Weizhi Ma"], "title": "Why Generate When You Can Transform? Unleashing Generative Attention for Dynamic Recommendation", "categories": ["cs.IR"], "comment": "Accepted at ACMMM 2025", "summary": "Sequential Recommendation (SR) focuses on personalizing user experiences by\npredicting future preferences based on historical interactions. Transformer\nmodels, with their attention mechanisms, have become the dominant architecture\nin SR tasks due to their ability to capture dependencies in user behavior\nsequences. However, traditional attention mechanisms, where attention weights\nare computed through query-key transformations, are inherently linear and\ndeterministic. This fixed approach limits their ability to account for the\ndynamic and non-linear nature of user preferences, leading to challenges in\ncapturing evolving interests and subtle behavioral patterns. Given that\ngenerative models excel at capturing non-linearity and probabilistic\nvariability, we argue that generating attention distributions offers a more\nflexible and expressive alternative compared to traditional attention\nmechanisms. To support this claim, we present a theoretical proof demonstrating\nthat generative attention mechanisms offer greater expressiveness and\nstochasticity than traditional deterministic approaches. Building upon this\ntheoretical foundation, we introduce two generative attention models for SR,\neach grounded in the principles of Variational Autoencoders (VAE) and Diffusion\nModels (DMs), respectively. These models are designed specifically to generate\nadaptive attention distributions that better align with variable user\npreferences. Extensive experiments on real-world datasets show our models\nsignificantly outperform state-of-the-art in both accuracy and diversity.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u751f\u6210\u5f0f\u6ce8\u610f\u529b\u673a\u5236\u66ff\u4ee3\u4f20\u7edf\u786e\u5b9a\u6027\u6ce8\u610f\u529b\uff0c\u63d0\u5347\u5e8f\u5217\u63a8\u8350\u7684\u7075\u6d3b\u6027\u548c\u8868\u73b0\u529b\u3002", "motivation": "\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u56e0\u7ebf\u6027\u786e\u5b9a\u6027\u9650\u5236\uff0c\u96be\u4ee5\u6355\u6349\u7528\u6237\u504f\u597d\u7684\u52a8\u6001\u975e\u7ebf\u6027\u7279\u5f81\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u548c\u6269\u6563\u6a21\u578b\uff08DMs\uff09\u7684\u4e24\u79cd\u751f\u6210\u5f0f\u6ce8\u610f\u529b\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u591a\u6837\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u751f\u6210\u5f0f\u6ce8\u610f\u529b\u673a\u5236\u4e3a\u5e8f\u5217\u63a8\u8350\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u8868\u8fbe\u529b\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.01012", "pdf": "https://arxiv.org/pdf/2508.01012", "abs": "https://arxiv.org/abs/2508.01012", "authors": ["Yiyi Lu", "Hoi Ian Au", "Junyao Zhang", "Jingyu Pan", "Yiting Wang", "Ang Li", "Jianyi Zhang", "Yiran Chen"], "title": "AutoEDA: Enabling EDA Flow Automation through Microservice-Based LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "Modern Electronic Design Automation (EDA) workflows, especially the\nRTL-to-GDSII flow, require heavily manual scripting and demonstrate a multitude\nof tool-specific interactions which limits scalability and efficiency. While\nLLMs introduces strides for automation, existing LLM solutions require\nexpensive fine-tuning and do not contain standardized frameworks for\nintegration and evaluation. We introduce AutoEDA, a framework for EDA\nautomation that leverages paralleled learning through the Model Context\nProtocol (MCP) specific for standardized and scalable natural language\nexperience across the entire RTL-to-GDSII flow. AutoEDA limits fine-tuning\nthrough structured prompt engineering, implements intelligent parameter\nextraction and task decomposition, and provides an extended CodeBLEU metric to\nevaluate the quality of TCL scripts. Results from experiments over five\npreviously curated benchmarks show improvements in automation accuracy and\nefficiency, as well as script quality when compared to existing methods.\nAutoEDA is released open-sourced to support reproducibility and the EDA\ncommunity. Available at: https://github.com/AndyLu666/MCP-EDA-Server", "AI": {"tldr": "AutoEDA\u662f\u4e00\u4e2a\u57fa\u4e8eMCP\u534f\u8bae\u7684EDA\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u51cf\u5c11\u5fae\u8c03\u9700\u6c42\uff0c\u63d0\u5347RTL-to-GDSII\u6d41\u7a0b\u7684\u6548\u7387\u548c\u811a\u672c\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edfEDA\u5de5\u4f5c\u6d41\u4f9d\u8d56\u624b\u52a8\u811a\u672c\u548c\u5de5\u5177\u4ea4\u4e92\uff0c\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u73b0\u6709LLM\u89e3\u51b3\u65b9\u6848\u9700\u6602\u8d35\u5fae\u8c03\u4e14\u7f3a\u4e4f\u6807\u51c6\u5316\u6846\u67b6\u3002", "method": "\u5229\u7528MCP\u534f\u8bae\u5b9e\u73b0\u5e76\u884c\u5b66\u4e60\uff0c\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u51cf\u5c11\u5fae\u8c03\uff0c\u667a\u80fd\u53c2\u6570\u63d0\u53d6\u4e0e\u4efb\u52a1\u5206\u89e3\uff0c\u6269\u5c55CodeBLEU\u8bc4\u4f30\u811a\u672c\u8d28\u91cf\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAutoEDA\u5728\u81ea\u52a8\u5316\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u811a\u672c\u8d28\u91cf\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "AutoEDA\u5f00\u6e90\u53d1\u5e03\uff0c\u652f\u6301EDA\u793e\u533a\u7684\u53ef\u91cd\u590d\u6027\u548c\u6807\u51c6\u5316\u81ea\u52a8\u5316\u3002"}}
{"id": "2508.00880", "pdf": "https://arxiv.org/pdf/2508.00880", "abs": "https://arxiv.org/abs/2508.00880", "authors": ["Adil Mukhtar", "Michael Hadwiger", "Franz Wotawa", "Gerald Schweiger"], "title": "Reproducibility of Machine Learning-Based Fault Detection and Diagnosis for HVAC Systems in Buildings: An Empirical Study", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reproducibility is a cornerstone of scientific research, enabling independent\nverification and validation of empirical findings. The topic gained prominence\nin fields such as psychology and medicine, where concerns about non -\nreplicable results sparked ongoing discussions about research practices. In\nrecent years, the fast-growing field of Machine Learning (ML) has become part\nof this discourse, as it faces similar concerns about transparency and\nreliability. Some reproducibility issues in ML research are shared with other\nfields, such as limited access to data and missing methodological details. In\naddition, ML introduces specific challenges, including inherent nondeterminism\nand computational constraints. While reproducibility issues are increasingly\nrecognized by the ML community and its major conferences, less is known about\nhow these challenges manifest in applied disciplines. This paper contributes to\nclosing this gap by analyzing the transparency and reproducibility standards of\nML applications in building energy systems. The results indicate that nearly\nall articles are not reproducible due to insufficient disclosure across key\ndimensions of reproducibility. 72% of the articles do not specify whether the\ndataset used is public, proprietary, or commercially available. Only two papers\nshare a link to their code - one of which was broken. Two-thirds of the\npublications were authored exclusively by academic researchers, yet no\nsignificant differences in reproducibility were observed compared to\npublications with industry-affiliated authors. These findings highlight the\nneed for targeted interventions, including reproducibility guidelines, training\nfor researchers, and policies by journals and conferences that promote\ntransparency and reproducibility.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u673a\u5668\u5b66\u4e60\u5728\u5efa\u7b51\u80fd\u6e90\u7cfb\u7edf\u4e2d\u7684\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u6807\u51c6\uff0c\u53d1\u73b0\u51e0\u4e4e\u6240\u6709\u6587\u7ae0\u56e0\u5173\u952e\u4fe1\u606f\u4e0d\u8db3\u800c\u4e0d\u53ef\u91cd\u590d\uff0c\u547c\u5401\u91c7\u53d6\u9488\u5bf9\u6027\u63aa\u65bd\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u6e90\u4e8e\u673a\u5668\u5b66\u4e60\u9886\u57df\u5bf9\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u7684\u5173\u6ce8\uff0c\u5c24\u5176\u662f\u5728\u5e94\u7528\u5b66\u79d1\u4e2d\u53ef\u91cd\u590d\u6027\u95ee\u9898\u7684\u8868\u73b0\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5efa\u7b51\u80fd\u6e90\u7cfb\u7edf\u4e2d\u673a\u5668\u5b66\u4e60\u5e94\u7528\u7684\u900f\u660e\u5ea6\u4e0e\u53ef\u91cd\u590d\u6027\u6807\u51c6\uff0c\u8bc4\u4f30\u5173\u952e\u7ef4\u5ea6\u7684\u4fe1\u606f\u62ab\u9732\u60c5\u51b5\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u51e0\u4e4e\u6240\u6709\u6587\u7ae0\u56e0\u4fe1\u606f\u62ab\u9732\u4e0d\u8db3\u800c\u4e0d\u53ef\u91cd\u590d\uff0c72%\u672a\u660e\u786e\u6570\u636e\u96c6\u6765\u6e90\uff0c\u4ec5\u4e24\u7bc7\u63d0\u4f9b\u4ee3\u7801\u94fe\u63a5\uff08\u5176\u4e2d\u4e00\u6761\u5931\u6548\uff09\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u9700\u8981\u5236\u5b9a\u53ef\u91cd\u590d\u6027\u6307\u5357\u3001\u7814\u7a76\u4eba\u5458\u57f9\u8bad\u53ca\u671f\u520a\u4f1a\u8bae\u653f\u7b56\u4ee5\u63d0\u5347\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2508.01245", "pdf": "https://arxiv.org/pdf/2508.01245", "abs": "https://arxiv.org/abs/2508.01245", "authors": ["Yue Chen", "Minghua He", "Fangkai Yang", "Pu Zhao", "Lu Wang", "Yu Kang", "Yifei Dong", "Yuefeng Zhan", "Hao Sun", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "title": "WarriorMath: Enhancing the Mathematical Ability of Large Language Models with a Defect-aware Framework", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) excel in solving mathematical problems, yet\ntheir performance is often limited by the availability of high-quality, diverse\ntraining data. Existing methods focus on augmenting datasets through rephrasing\nor difficulty progression but overlook the specific failure modes of LLMs. This\nresults in synthetic questions that the model can already solve, providing\nminimal performance gains. To address this, we propose WarriorMath, a\ndefect-aware framework for mathematical problem solving that integrates both\ntargeted data synthesis and progressive training. In the synthesis stage, we\nemploy multiple expert LLMs in a collaborative process to generate, critique,\nand refine problems. Questions that base LLMs fail to solve are identified and\niteratively improved through expert-level feedback, producing high-quality,\ndefect-aware training data. In the training stage, we introduce a progressive\nlearning framework that iteratively fine-tunes the model using increasingly\nchallenging data tailored to its weaknesses. Experiments on six mathematical\nbenchmarks show that WarriorMath outperforms strong baselines by 12.57% on\naverage, setting a new state-of-the-art. Our results demonstrate the\neffectiveness of a defect-aware, multi-expert framework for improving\nmathematical ability.", "AI": {"tldr": "WarriorMath\u63d0\u51fa\u4e86\u4e00\u79cd\u7f3a\u9677\u611f\u77e5\u7684\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u6846\u67b6\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u6570\u636e\u5408\u6210\u548c\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u63d0\u5347LLMs\u7684\u6570\u5b66\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6LLMs\u7684\u5177\u4f53\u5931\u8d25\u6a21\u5f0f\uff0c\u5bfc\u81f4\u5408\u6210\u95ee\u9898\u5bf9\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002", "method": "WarriorMath\u7ed3\u5408\u591a\u4e13\u5bb6LLMs\u534f\u4f5c\u751f\u6210\u3001\u6279\u8bc4\u548c\u6539\u8fdb\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6e10\u8fdb\u5f0f\u5b66\u4e60\u6846\u67b6\u9010\u6b65\u5fae\u8c03\u6a21\u578b\u3002", "result": "\u5728\u516d\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cWarriorMath\u5e73\u5747\u6027\u80fd\u63d0\u534712.57%\uff0c\u8fbe\u5230\u65b0SOTA\u3002", "conclusion": "\u7f3a\u9677\u611f\u77e5\u7684\u591a\u4e13\u5bb6\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347LLMs\u7684\u6570\u5b66\u80fd\u529b\u3002"}}
{"id": "2508.02096", "pdf": "https://arxiv.org/pdf/2508.02096", "abs": "https://arxiv.org/abs/2508.02096", "authors": ["Raj Mahmud", "Yufeng Wu", "Abdullah Bin Sawad", "Shlomo Berkovsky", "Mukesh Prasad", "A. Baki Kocaballi"], "title": "Evaluating User Experience in Conversational Recommender Systems: A Systematic Review Across Classical and LLM-Powered Approaches", "categories": ["cs.IR", "cs.AI", "cs.HC", "H.3.3; H.5.2; I.2.7"], "comment": "Accepted at OZCHI 2025. 23 pages, 1 figure, 5 tables", "summary": "Conversational Recommender Systems (CRSs) are receiving growing research\nattention across domains, yet their user experience (UX) evaluation remains\nlimited. Existing reviews largely overlook empirical UX studies, particularly\nin adaptive and large language model (LLM)-based CRSs. To address this gap, we\nconducted a systematic review following PRISMA guidelines, synthesising 23\nempirical studies published between 2017 and 2025. We analysed how UX has been\nconceptualised, measured, and shaped by domain, adaptivity, and LLM.\n  Our findings reveal persistent limitations: post hoc surveys dominate,\nturn-level affective UX constructs are rarely assessed, and adaptive behaviours\nare seldom linked to UX outcomes. LLM-based CRSs introduce further challenges,\nincluding epistemic opacity and verbosity, yet evaluations infrequently address\nthese issues. We contribute a structured synthesis of UX metrics, a comparative\nanalysis of adaptive and nonadaptive systems, and a forward-looking agenda for\nLLM-aware UX evaluation. These findings support the development of more\ntransparent, engaging, and user-centred CRS evaluation practices.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e862017-2025\u5e74\u95f423\u9879\u5b9e\u8bc1\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf(CRS)\u7528\u6237\u4f53\u9a8c(UX)\u8bc4\u4f30\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u586b\u8865\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf(CRS)\u7528\u6237\u4f53\u9a8c(UX)\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u7279\u522b\u662f\u5728\u81ea\u9002\u5e94\u548c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u7cfb\u7edf\u4e2d\u3002", "method": "\u9075\u5faaPRISMA\u6307\u5357\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\uff0c\u5206\u679023\u9879\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u53d1\u73b0UX\u8bc4\u4f30\u7684\u5c40\u9650\u6027\uff0c\u5982\u4e8b\u540e\u8c03\u67e5\u4e3b\u5bfc\u3001\u60c5\u611fUX\u6784\u9020\u8bc4\u4f30\u4e0d\u8db3\u3001\u81ea\u9002\u5e94\u884c\u4e3a\u4e0eUX\u7ed3\u679c\u5173\u8054\u5c11\uff0cLLM\u5f15\u5165\u7684\u65b0\u95ee\u9898\u672a\u5145\u5206\u8bc4\u4f30\u3002", "conclusion": "\u63d0\u51fa\u4e86UX\u8bc4\u4f30\u7684\u7ed3\u6784\u5316\u6846\u67b6\u548c\u6539\u8fdb\u65b9\u5411\uff0c\u652f\u6301\u66f4\u900f\u660e\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684CRS\u8bc4\u4f30\u5b9e\u8df5\u3002"}}
{"id": "2508.01031", "pdf": "https://arxiv.org/pdf/2508.01031", "abs": "https://arxiv.org/abs/2508.01031", "authors": ["Jingzhe Ni", "Xiaolong Yin", "Xintong Li", "Xingyu Lu", "Ji Wei", "Ruofeng Tong", "Min Tang", "Peng Du"], "title": "CADDesigner: Conceptual Design of CAD Models Based on General-Purpose Agent", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing\nbut typically requires a high level of expertise from designers. To lower the\nentry barrier and improve design efficiency, we present an agent for CAD\nconceptual design powered by large language models (LLMs). The agent accepts\nboth abstract textual descriptions and freehand sketches as input, engaging in\ninteractive dialogue with users to refine and clarify design requirements\nthrough comprehensive requirement analysis. Built upon a novel\nContext-Independent Imperative Paradigm (CIP), the agent generates high-quality\nCAD modeling code. During the generation process, the agent incorporates\niterative visual feedback to improve model quality. Generated design cases are\nstored in a structured knowledge base, enabling continuous improvement of the\nagent's code generation capabilities. Experimental results demonstrate that our\nmethod achieves state-of-the-art performance in CAD code generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684CAD\u6982\u5ff5\u8bbe\u8ba1\u4ee3\u7406\uff0c\u901a\u8fc7\u6587\u672c\u548c\u8349\u56fe\u8f93\u5165\uff0c\u7ed3\u5408\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u548c\u89c6\u89c9\u53cd\u9988\uff0c\u751f\u6210\u9ad8\u8d28\u91cfCAD\u5efa\u6a21\u4ee3\u7801\u3002", "motivation": "\u964d\u4f4eCAD\u8bbe\u8ba1\u7684\u95e8\u69db\uff0c\u63d0\u9ad8\u8bbe\u8ba1\u6548\u7387\uff0c\u51cf\u5c11\u5bf9\u4e13\u4e1a\u77e5\u8bc6\u7684\u4f9d\u8d56\u3002", "method": "\u91c7\u7528Context-Independent Imperative Paradigm\uff08CIP\uff09\uff0c\u7ed3\u5408\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u548c\u89c6\u89c9\u53cd\u9988\uff0c\u751f\u6210CAD\u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u77e5\u8bc6\u5e93\u6301\u7eed\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728CAD\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u8be5\u4ee3\u7406\u901a\u8fc7\u4ea4\u4e92\u5f0f\u8bbe\u8ba1\u548c\u6301\u7eed\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86CAD\u8bbe\u8ba1\u7684\u6548\u7387\u548c\u53ef\u8bbf\u95ee\u6027\u3002"}}
{"id": "2508.00881", "pdf": "https://arxiv.org/pdf/2508.00881", "abs": "https://arxiv.org/abs/2508.00881", "authors": ["Vijja Wichitwechkarn", "Charles Fox", "Ruchi Choudhary"], "title": "Hallucination Detection and Mitigation with Diffusion in Multi-Variate Time-Series Foundation Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Foundation models for natural language processing have many coherent\ndefinitions of hallucination and methods for its detection and mitigation.\nHowever, analogous definitions and methods do not exist for multi-variate\ntime-series (MVTS) foundation models. We propose new definitions for MVTS\nhallucination, along with new detection and mitigation methods using a\ndiffusion model to estimate hallucination levels. We derive relational datasets\nfrom popular time-series datasets to benchmark these relational hallucination\nlevels. Using these definitions and models, we find that open-source\npre-trained MVTS imputation foundation models relationally hallucinate on\naverage up to 59.5% as much as a weak baseline. The proposed mitigation method\nreduces this by up to 47.7% for these models. The definition and methods may\nimprove adoption and safe usage of MVTS foundation models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\uff08MVTS\uff09\u57fa\u7840\u6a21\u578b\u4e2d\u5e7b\u89c9\u7684\u65b0\u5b9a\u4e49\u3001\u68c0\u6d4b\u548c\u7f13\u89e3\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6269\u6563\u6a21\u578b\u4f30\u8ba1\u5e7b\u89c9\u6c34\u5e73\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u9884\u8bad\u7ec3\u7684MVTS\u586b\u8865\u6a21\u578b\u5e73\u5747\u5e7b\u89c9\u6c34\u5e73\u9ad8\u8fbe59.5%\uff0c\u800c\u63d0\u51fa\u7684\u7f13\u89e3\u65b9\u6cd5\u53ef\u964d\u4f4e47.7%\u3002", "motivation": "\u76ee\u524d\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u5bf9\u5e7b\u89c9\u6709\u660e\u786e\u5b9a\u4e49\u548c\u89e3\u51b3\u65b9\u6cd5\uff0c\u4f46MVTS\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u7c7b\u4f3c\u7684\u5b9a\u4e49\u548c\u65b9\u6cd5\uff0c\u963b\u788d\u4e86\u5176\u5b89\u5168\u5e94\u7528\u3002", "method": "\u63d0\u51faMVTS\u5e7b\u89c9\u7684\u65b0\u5b9a\u4e49\uff0c\u4f7f\u7528\u6269\u6563\u6a21\u578b\u4f30\u8ba1\u5e7b\u89c9\u6c34\u5e73\uff0c\u5e76\u901a\u8fc7\u5173\u7cfb\u6570\u636e\u96c6\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\u63d0\u51fa\u7f13\u89e3\u65b9\u6cd5\u4ee5\u51cf\u5c11\u5e7b\u89c9\u3002", "result": "\u9884\u8bad\u7ec3\u7684MVTS\u586b\u8865\u6a21\u578b\u5e73\u5747\u5e7b\u89c9\u6c34\u5e73\u8fbe59.5%\uff0c\u7f13\u89e3\u65b9\u6cd5\u53ef\u964d\u4f4e47.7%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aMVTS\u57fa\u7840\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9a\u4e49\u548c\u89e3\u51b3\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u5176\u66f4\u5b89\u5168\u548c\u5e7f\u6cdb\u7684\u5e94\u7528\u3002"}}
{"id": "2508.01263", "pdf": "https://arxiv.org/pdf/2508.01263", "abs": "https://arxiv.org/abs/2508.01263", "authors": ["Long S. T. Nguyen", "Khang H. N. Vo", "Thu H. A. Nguyen", "Tuan C. Bui", "Duc Q. Nguyen", "Thanh-Tung Tran", "Anh D. Nguyen", "Minh L. Nguyen", "Fabien Baldacci", "Thang H. Bui", "Emanuel Di Nardo", "Angelo Ciaramella", "Son H. Le", "Ihsan Ullah", "Lorenzo Di Rocco", "Tho T. Quan"], "title": "Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025", "categories": ["cs.CL"], "comment": "The XAI Challenge @ TRNS-AI Workshop, IJCNN 2025: Explainable AI for\n  Educational Question Answering. Website:\n  https://sites.google.com/view/trns-ai/challenge/", "summary": "The growing integration of Artificial Intelligence (AI) into education has\nintensified the need for transparency and interpretability. While hackathons\nhave long served as agile environments for rapid AI prototyping, few have\ndirectly addressed eXplainable AI (XAI) in real-world educational contexts.\nThis paper presents a comprehensive analysis of the XAI Challenge 2025, a\nhackathon-style competition jointly organized by Ho Chi Minh City University of\nTechnology (HCMUT) and the International Workshop on Trustworthiness and\nReliability in Neurosymbolic AI (TRNS-AI), held as part of the International\nJoint Conference on Neural Networks (IJCNN 2025). The challenge tasked\nparticipants with building Question-Answering (QA) systems capable of answering\nstudent queries about university policies while generating clear, logic-based\nnatural language explanations. To promote transparency and trustworthiness,\nsolutions were required to use lightweight Large Language Models (LLMs) or\nhybrid LLM-symbolic systems. A high-quality dataset was provided, constructed\nvia logic-based templates with Z3 validation and refined through expert student\nreview to ensure alignment with real-world academic scenarios. We describe the\nchallenge's motivation, structure, dataset construction, and evaluation\nprotocol. Situating the competition within the broader evolution of AI\nhackathons, we argue that it represents a novel effort to bridge LLMs and\nsymbolic reasoning in service of explainability. Our findings offer actionable\ninsights for future XAI-centered educational systems and competitive research\ninitiatives.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e862025\u5e74XAI\u6311\u6218\u8d5b\uff0c\u63a2\u8ba8\u4e86\u5728\u6559\u80b2\u4e2d\u7ed3\u5408\u8f7b\u91cf\u7ea7LLM\u548c\u7b26\u53f7\u63a8\u7406\u4ee5\u5b9e\u73b0\u53ef\u89e3\u91caAI\u7684\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u5728\u6559\u80b2\u4e2d\u7684\u666e\u53ca\uff0c\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u9700\u6c42\u589e\u52a0\uff0c\u4f46\u73b0\u6709hackathon\u5f88\u5c11\u76f4\u63a5\u89e3\u51b3\u6559\u80b2\u573a\u666f\u4e2d\u7684XAI\u95ee\u9898\u3002", "method": "\u901a\u8fc7hackathon\u5f62\u5f0f\uff0c\u8981\u6c42\u53c2\u4e0e\u8005\u6784\u5efa\u57fa\u4e8e\u8f7b\u91cf\u7ea7LLM\u6216\u6df7\u5408\u7cfb\u7edf\u7684\u95ee\u7b54\u7cfb\u7edf\uff0c\u751f\u6210\u903b\u8f91\u6e05\u6670\u7684\u89e3\u91ca\u3002", "result": "\u6311\u6218\u8d5b\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u5c55\u793a\u4e86LLM\u4e0e\u7b26\u53f7\u63a8\u7406\u7ed3\u5408\u5728XAI\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u6559\u80b2\u4e2d\u7684XAI\u7cfb\u7edf\u548c\u7ade\u8d5b\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u63a8\u52a8\u4e86\u53ef\u89e3\u91caAI\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.02222", "pdf": "https://arxiv.org/pdf/2508.02222", "abs": "https://arxiv.org/abs/2508.02222", "authors": ["Xuan Xu", "Beilin Chu", "Qinhong Lin", "Yixiao Zhong", "Fufang Wen", "Jiaqi Liu", "Binjie Fei", "Yu Li", "Zhongliang Yang", "Linna Zhou"], "title": "FinCPRG: A Bidirectional Generation Pipeline for Hierarchical Queries and Rich Relevance in Financial Chinese Passage Retrieval", "categories": ["cs.IR", "cs.AI", "cs.CE"], "comment": null, "summary": "In recent years, large language models (LLMs) have demonstrated significant\npotential in constructing passage retrieval datasets. However, existing methods\nstill face limitations in expressing cross-doc query needs and controlling\nannotation quality. To address these issues, this paper proposes a\nbidirectional generation pipeline, which aims to generate 3-level hierarchical\nqueries for both intra-doc and cross-doc scenarios and mine additional\nrelevance labels on top of direct mapping annotation. The pipeline introduces\ntwo query generation methods: bottom-up from single-doc text and top-down from\nmulti-doc titles. The bottom-up method uses LLMs to disassemble and generate\nstructured queries at both sentence-level and passage-level simultaneously from\nintra-doc passages. The top-down approach incorporates three key financial\nelements--industry, topic, and time--to divide report titles into clusters and\nprompts LLMs to generate topic-level queries from each cluster. For relevance\nannotation, our pipeline not only relies on direct mapping annotation from the\ngeneration relationship but also implements an indirect positives mining method\nto enrich the relevant query-passage pairs. Using this pipeline, we constructed\na Financial Passage Retrieval Generated dataset (FinCPRG) from almost 1.3k\nChinese financial research reports, which includes hierarchical queries and\nrich relevance labels. Through evaluations of mined relevance labels,\nbenchmarking and training experiments, we assessed the quality of FinCPRG and\nvalidated its effectiveness as a passage retrieval dataset for both training\nand benchmarking.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5411\u751f\u6210\u7ba1\u9053\uff0c\u7528\u4e8e\u6784\u5efa\u5c42\u6b21\u5316\u67e5\u8be2\u548c\u4e30\u5bcc\u76f8\u5173\u6027\u6807\u7b7e\u7684\u91d1\u878d\u6bb5\u843d\u68c0\u7d22\u6570\u636e\u96c6\uff08FinCPRG\uff09\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u8de8\u6587\u6863\u67e5\u8be2\u9700\u6c42\u8868\u8fbe\u548c\u6807\u6ce8\u8d28\u91cf\u63a7\u5236\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u53cc\u5411\u751f\u6210\u7ba1\u9053\uff0c\u5305\u62ec\u81ea\u4e0b\u800c\u4e0a\uff08\u4ece\u5355\u6587\u6863\u751f\u6210\u67e5\u8be2\uff09\u548c\u81ea\u4e0a\u800c\u4e0b\uff08\u4ece\u591a\u6587\u6863\u6807\u9898\u751f\u6210\u67e5\u8be2\uff09\u7684\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u76f4\u63a5\u6620\u5c04\u6807\u6ce8\u548c\u95f4\u63a5\u6b63\u4f8b\u6316\u6398\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b\u5c42\u6b21\u5316\u67e5\u8be2\u548c\u4e30\u5bcc\u76f8\u5173\u6027\u6807\u7b7e\u7684FinCPRG\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "FinCPRG\u5728\u6bb5\u843d\u68c0\u7d22\u7684\u8bad\u7ec3\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2508.01057", "pdf": "https://arxiv.org/pdf/2508.01057", "abs": "https://arxiv.org/abs/2508.01057", "authors": ["Fengze Yang", "Bo Yu", "Yang Zhou", "Xuewen Luo", "Zhengzhong Tu", "Chenxi Liu"], "title": "REACT: A Real-Time Edge-AI Based V2X Framework for Accident Avoidance in Autonomous Driving System", "categories": ["cs.AI", "cs.RO"], "comment": "24 pages, 6 tables, 7 figures", "summary": "Collisions caused by human error are the most common type of multi-vehicle\ncrash, highlighting the critical need for autonomous driving (AD) systems to\nleverage cooperative perception through Vehicle-to-Everything (V2X)\ncommunication. This capability extends situational awareness beyond the\nlimitations of onboard sensors. However, current transformer-based V2X\nframeworks suffer from limited generalization, shallow contextual reasoning,\nand reliance on mono-modal inputs. Vision-Language Models (VLMs) offer enhanced\nreasoning and multimodal integration but typically fall short of real-time\nperformance requirements in safety-critical applications. This paper presents\nREACT, a real-time, V2X-integrated trajectory optimization framework built upon\na fine-tuned lightweight VLM. REACT integrates a set of specialized modules\nthat process multimodal inputs into optimized, risk-aware trajectories. To\nensure real-time performance on edge devices, REACT incorporates edge\nadaptation strategies that reduce model complexity and accelerate inference.\nEvaluated on the DeepAccident benchmark, REACT achieves state-of-the-art\nperformance, a 77% collision rate reduction, a 48.2% Video Panoptic Quality\n(VPQ), and a 0.57-second inference latency on the Jetson AGX Orin. Ablation\nstudies validate the contribution of each input, module, and edge adaptation\nstrategy. These results demonstrate the feasibility of lightweight VLMs for\nreal-time edge-based cooperative planning and showcase the potential of\nlanguage-guided contextual reasoning to improve safety and responsiveness in\nautonomous driving.", "AI": {"tldr": "REACT\u662f\u4e00\u4e2a\u57fa\u4e8e\u8f7b\u91cf\u7ea7VLM\u7684\u5b9e\u65f6V2X\u8f68\u8ff9\u4f18\u5316\u6846\u67b6\uff0c\u663e\u8457\u51cf\u5c11\u78b0\u649e\u7387\u5e76\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u6027\u3002", "motivation": "\u4eba\u4e3a\u9519\u8bef\u5bfc\u81f4\u7684\u591a\u8f66\u78b0\u649e\u9891\u53d1\uff0c\u9700\u901a\u8fc7V2X\u901a\u4fe1\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u534f\u540c\u611f\u77e5\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6cdb\u5316\u6027\u5dee\u3001\u63a8\u7406\u6d45\u5c42\u548c\u5355\u6a21\u6001\u8f93\u5165\u4f9d\u8d56\u7b49\u95ee\u9898\u3002", "method": "REACT\u7ed3\u5408\u8f7b\u91cf\u7ea7VLM\u548c\u591a\u6a21\u6001\u8f93\u5165\u5904\u7406\u6a21\u5757\uff0c\u901a\u8fc7\u8fb9\u7f18\u9002\u914d\u7b56\u7565\u4f18\u5316\u5b9e\u65f6\u6027\u80fd\u3002", "result": "\u5728DeepAccident\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cREACT\u51cf\u5c1177%\u78b0\u649e\u7387\uff0cVPQ\u8fbe48.2%\uff0c\u63a8\u7406\u5ef6\u8fdf0.57\u79d2\u3002", "conclusion": "\u8f7b\u91cf\u7ea7VLM\u5728\u5b9e\u65f6\u8fb9\u7f18\u534f\u540c\u89c4\u5212\u4e2d\u53ef\u884c\uff0c\u8bed\u8a00\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u7684\u5b89\u5168\u6027\u548c\u54cd\u5e94\u901f\u5ea6\u3002"}}
{"id": "2508.00884", "pdf": "https://arxiv.org/pdf/2508.00884", "abs": "https://arxiv.org/abs/2508.00884", "authors": ["Zhenan Lin", "Yuni Lai", "Wai Lun Lo", "Richard Tai-Chiu Hsung", "Harris Sik-Ho Tsang", "Xiaoyu Xue", "Kai Zhou", "Yulin Zhu"], "title": "Multi-Grained Temporal-Spatial Graph Learning for Stable Traffic Flow Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time-evolving traffic flow forecasting are playing a vital role in\nintelligent transportation systems and smart cities. However, the dynamic\ntraffic flow forecasting is a highly nonlinear problem with complex\ntemporal-spatial dependencies. Although the existing methods has provided great\ncontributions to mine the temporal-spatial patterns in the complex traffic\nnetworks, they fail to encode the globally temporal-spatial patterns and are\nprone to overfit on the pre-defined geographical correlations, and thus hinder\nthe model's robustness on the complex traffic environment. To tackle this\nissue, in this work, we proposed a multi-grained temporal-spatial graph\nlearning framework to adaptively augment the globally temporal-spatial patterns\nobtained from a crafted graph transformer encoder with the local patterns from\nthe graph convolution by a crafted gated fusion unit with residual connection\ntechniques. Under these circumstances, our proposed model can mine the hidden\nglobal temporal-spatial relations between each monitor stations and balance the\nrelative importance of local and global temporal-spatial patterns. Experiment\nresults demonstrate the strong representation capability of our proposed method\nand our model consistently outperforms other strong baselines on various\nreal-world traffic networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7c92\u5ea6\u65f6\u7a7a\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u53d8\u6362\u7f16\u7801\u5668\u548c\u95e8\u63a7\u878d\u5408\u5355\u5143\u589e\u5f3a\u5168\u5c40\u548c\u5c40\u90e8\u65f6\u7a7a\u6a21\u5f0f\uff0c\u63d0\u5347\u4ea4\u901a\u6d41\u9884\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u52a8\u6001\u4ea4\u901a\u6d41\u9884\u6d4b\u5177\u6709\u9ad8\u5ea6\u975e\u7ebf\u6027\u548c\u590d\u6742\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u5168\u5c40\u65f6\u7a7a\u6a21\u5f0f\u4e14\u6613\u8fc7\u62df\u5408\u3002", "method": "\u4f7f\u7528\u56fe\u53d8\u6362\u7f16\u7801\u5668\u63d0\u53d6\u5168\u5c40\u65f6\u7a7a\u6a21\u5f0f\uff0c\u7ed3\u5408\u56fe\u5377\u79ef\u7684\u5c40\u90e8\u6a21\u5f0f\uff0c\u901a\u8fc7\u95e8\u63a7\u878d\u5408\u5355\u5143\u548c\u6b8b\u5dee\u8fde\u63a5\u6280\u672f\u5e73\u8861\u4e24\u8005\u91cd\u8981\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u771f\u5b9e\u4ea4\u901a\u7f51\u7edc\u4e0a\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u6709\u6548\u6316\u6398\u9690\u85cf\u7684\u5168\u5c40\u65f6\u7a7a\u5173\u7cfb\uff0c\u63d0\u5347\u4ea4\u901a\u6d41\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2508.01290", "pdf": "https://arxiv.org/pdf/2508.01290", "abs": "https://arxiv.org/abs/2508.01290", "authors": ["Zhichao Yan", "Jiapu Wang", "Jiaoyan Chen", "Yanyan Wang", "Hongye Tan", "Jiye Liang", "Xiaoli Li", "Ru Li", "Jeff Z. Pan"], "title": "Prompting Large Language Models with Partial Knowledge for Answering Questions with Unseen Entities", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) shows impressive performance by\nsupplementing and substituting parametric knowledge in Large Language Models\n(LLMs). Retrieved knowledge can be divided into three types: explicit answer\nevidence, implicit answer clue, and insufficient answer context which can be\nfurther categorized into totally irrelevant and partially relevant information.\nEffectively utilizing partially relevant knowledge remains a key challenge for\nRAG systems, especially in incomplete knowledge base retrieval. Contrary to the\nconventional view, we propose a new perspective: LLMs can be awakened via\npartially relevant knowledge already embedded in LLMs. To comprehensively\ninvestigate this phenomenon, the triplets located in the gold reasoning path\nand their variants are used to construct partially relevant knowledge by\nremoving the path that contains the answer. We provide theoretical analysis of\nthe awakening effect in LLMs and support our hypothesis with experiments on two\nKnowledge Graphs (KGs) Question Answering (QA) datasets. Furthermore, we\npresent a new task, Unseen Entity KGQA, simulating real-world challenges where\nentity linking fails due to KG incompleteness. Our awakening-based approach\ndemonstrates greater efficacy in practical applications, outperforms\ntraditional methods that rely on embedding-based similarity which are prone to\nreturning noisy information.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u89c6\u89d2\uff1a\u901a\u8fc7\u90e8\u5206\u76f8\u5173\u77e5\u8bc6\u5524\u9192LLMs\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86RAG\u7cfb\u7edf\u4e2d\u90e8\u5206\u76f8\u5173\u77e5\u8bc6\u5229\u7528\u7684\u6311\u6218\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3RAG\u7cfb\u7edf\u4e2d\u90e8\u5206\u76f8\u5173\u77e5\u8bc6\u5229\u7528\u7684\u96be\u9898\uff0c\u5c24\u5176\u662f\u5728\u77e5\u8bc6\u5e93\u4e0d\u5b8c\u6574\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u90e8\u5206\u76f8\u5173\u77e5\u8bc6\uff08\u79fb\u9664\u5305\u542b\u7b54\u6848\u7684\u8def\u5f84\uff09\uff0c\u5e76\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1LLMs\u7684\u5524\u9192\u6548\u5e94\u3002", "result": "\u5728\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u65b0\u4efb\u52a1Unseen Entity KGQA\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u90e8\u5206\u76f8\u5173\u77e5\u8bc6\u53ef\u4ee5\u5524\u9192LLMs\u7684\u80fd\u529b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.02242", "pdf": "https://arxiv.org/pdf/2508.02242", "abs": "https://arxiv.org/abs/2508.02242", "authors": ["Kaike Zhang", "Xiaobei Wang", "Xiaoyu Liu", "Shuchang Liu", "Hailan Yang", "Xiang Li", "Fei Sun", "Qi Cao"], "title": "From Generation to Consumption: Personalized List Value Estimation for Re-ranking", "categories": ["cs.IR"], "comment": null, "summary": "Re-ranking is critical in recommender systems for optimizing the order of\nrecommendation lists, thus improving user satisfaction and platform revenue.\nMost existing methods follow a generator-evaluator paradigm, where the\nevaluator estimates the overall value of each candidate list. However, they\noften ignore the fact that users may exit before consuming the full list,\nleading to a mismatch between estimated generation value and actual consumption\nvalue. To bridge this gap, we propose CAVE, a personalized Consumption-Aware\nlist Value Estimation framework. CAVE formulates the list value as the\nexpectation over sub-list values, weighted by user-specific exit probabilities\nat each position. The exit probability is decomposed into an interest-driven\ncomponent and a stochastic component, the latter modeled via a Weibull\ndistribution to capture random external factors such as fatigue. By jointly\nmodeling sub-list values and user exit behavior, CAVE yields a more faithful\nestimate of actual list consumption value. We further contribute three\nlarge-scale real-world list-wise benchmarks from the Kuaishou platform, varying\nin size and user activity patterns. Extensive experiments on these benchmarks,\ntwo Amazon datasets, and online A/B testing on Kuaishou show that CAVE\nconsistently outperforms strong baselines, highlighting the benefit of\nexplicitly modeling user exits in re-ranking.", "AI": {"tldr": "CAVE\u63d0\u51fa\u4e86\u4e00\u79cd\u4e2a\u6027\u5316\u6d88\u8d39\u611f\u77e5\u7684\u5217\u8868\u4ef7\u503c\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u7528\u6237\u9000\u51fa\u884c\u4e3a\u6765\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u63a8\u8350\u5217\u8868\u7684\u5b9e\u9645\u6d88\u8d39\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u7528\u6237\u53ef\u80fd\u5728\u6d88\u8d39\u5b8c\u6574\u5217\u8868\u524d\u9000\u51fa\u7684\u60c5\u51b5\uff0c\u5bfc\u81f4\u4f30\u8ba1\u503c\u4e0e\u5b9e\u9645\u6d88\u8d39\u503c\u4e0d\u5339\u914d\u3002", "method": "CAVE\u5c06\u5217\u8868\u4ef7\u503c\u5efa\u6a21\u4e3a\u5b50\u5217\u8868\u4ef7\u503c\u7684\u671f\u671b\uff0c\u52a0\u6743\u7528\u6237\u5728\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u9000\u51fa\u6982\u7387\uff0c\u5e76\u5206\u89e3\u9000\u51fa\u6982\u7387\u4e3a\u5174\u8da3\u9a71\u52a8\u548c\u968f\u673a\u56e0\u7d20\uff08\u5982\u75b2\u52b3\uff09\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0cCAVE\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u663e\u5f0f\u5efa\u6a21\u7528\u6237\u9000\u51fa\u884c\u4e3a\u80fd\u663e\u8457\u63d0\u5347\u91cd\u6392\u5e8f\u6548\u679c\u3002"}}
{"id": "2508.01073", "pdf": "https://arxiv.org/pdf/2508.01073", "abs": "https://arxiv.org/abs/2508.01073", "authors": ["Martin B\u00f6ckling", "Heiko Paulheim"], "title": "gpuRDF2vec -- Scalable GPU-based RDF2vec", "categories": ["cs.AI"], "comment": "18 pages, ISWC 2025", "summary": "Generating Knowledge Graph (KG) embeddings at web scale remains challenging.\nAmong existing techniques, RDF2vec combines effectiveness with strong\nscalability. We present gpuRDF2vec, an open source library that harnesses\nmodern GPUs and supports multi-node execution to accelerate every stage of the\nRDF2vec pipeline. Extensive experiments on both synthetically generated graphs\nand real-world benchmarks show that gpuRDF2vec achieves up to a substantial\nspeedup over the currently fastest alternative, i.e., jRDF2vec. In a\nsingle-node setup, our walk-extraction phase alone outperforms pyRDF2vec,\nSparkKGML, and jRDF2vec by a substantial margin using random walks on large/\ndense graphs, and scales very well to longer walks, which typically lead to\nbetter quality embeddings. Our implementation of gpuRDF2vec enables\npractitioners and researchers to train high-quality KG embeddings on\nlarge-scale graphs within practical time budgets and builds on top of Pytorch\nLightning for the scalable word2vec implementation.", "AI": {"tldr": "gpuRDF2vec\u662f\u4e00\u4e2a\u5f00\u6e90\u5e93\uff0c\u5229\u7528GPU\u548c\u591a\u8282\u70b9\u6267\u884c\u52a0\u901fRDF2vec\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u751f\u6210\u901f\u5ea6\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u751f\u6210\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u73b0\u4ee3GPU\u548c\u591a\u8282\u70b9\u6267\u884c\u4f18\u5316RDF2vec\u6d41\u7a0b\uff0c\u5305\u62ec\u968f\u673a\u6e38\u8d70\u548c\u5d4c\u5165\u8bad\u7ec3\u3002", "result": "\u5728\u5408\u6210\u56fe\u548c\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cgpuRDF2vec\u663e\u8457\u5feb\u4e8e\u73b0\u6709\u6700\u5feb\u65b9\u6848jRDF2vec\uff0c\u4e14\u80fd\u5904\u7406\u5927\u89c4\u6a21/\u5bc6\u96c6\u56fe\u3002", "conclusion": "gpuRDF2vec\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u9ad8\u6548\u8bad\u7ec3\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u7684\u5de5\u5177\u3002"}}
{"id": "2508.00886", "pdf": "https://arxiv.org/pdf/2508.00886", "abs": "https://arxiv.org/abs/2508.00886", "authors": ["Etienne Buehrle", "Christoph Stiller"], "title": "Stochastic Optimal Control via Measure Relaxations", "categories": ["cs.LG", "math.OC", "90C22, 93C10, 28A99"], "comment": "7 pages, 4 figures", "summary": "The optimal control problem of stochastic systems is commonly solved via\nrobust or scenario-based optimization methods, which are both challenging to\nscale to long optimization horizons. We cast the optimal control problem of a\nstochastic system as a convex optimization problem over occupation measures. We\ndemonstrate our method on a set of synthetic and real-world scenarios, learning\ncost functions from data via Christoffel polynomials. The code for our\nexperiments is available at https://github.com/ebuehrle/dpoc.", "AI": {"tldr": "\u5c06\u968f\u673a\u7cfb\u7edf\u7684\u6700\u4f18\u63a7\u5236\u95ee\u9898\u8f6c\u5316\u4e3a\u57fa\u4e8e\u5360\u7528\u6d4b\u5ea6\u7684\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7Christoffel\u591a\u9879\u5f0f\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u6210\u672c\u51fd\u6570\u3002", "motivation": "\u89e3\u51b3\u968f\u673a\u7cfb\u7edf\u6700\u4f18\u63a7\u5236\u95ee\u9898\u4e2d\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u9c81\u68d2\u6216\u57fa\u4e8e\u573a\u666f\u7684\u4f18\u5316\uff09\u96be\u4ee5\u6269\u5c55\u5230\u957f\u4f18\u5316\u65f6\u95f4\u7684\u95ee\u9898\u3002", "method": "\u5c06\u6700\u4f18\u63a7\u5236\u95ee\u9898\u8f6c\u5316\u4e3a\u5360\u7528\u6d4b\u5ea6\u7684\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5229\u7528Christoffel\u591a\u9879\u5f0f\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u6210\u672c\u51fd\u6570\u3002", "result": "\u5728\u5408\u6210\u548c\u5b9e\u9645\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5b9e\u9a8c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u968f\u673a\u7cfb\u7edf\u7684\u6700\u4f18\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.01302", "pdf": "https://arxiv.org/pdf/2508.01302", "abs": "https://arxiv.org/abs/2508.01302", "authors": ["Chenming Tang", "Yutong Yang", "Yunfang Wu"], "title": "KEDAS: Knowledge Editing Alignment with Diverse Augmentation and Self-adaptive Inference", "categories": ["cs.CL"], "comment": "Preprint", "summary": "Knowledge editing aims to modify outdated knowledge in large language models\n(LLMs) efficiently while retaining their powerful capabilities. Most existing\nmethods rely on either parameter-level editing or retrieval-based approaches.\nIn this work, we propose Knowledge Editing alignment with Diverse Augmentation\nand Self-adaptive inference (KEDAS) to better align LLMs with knowledge\nediting. In the alignment phase, LLMs learn to apply in-context edited\nknowledge via low-rank adaptation. During editing, we design a diverse edit\naugmentation technique to improve the recall of edits. After that, a\nself-adaptive post-alignment inference mechanism is proposed, in which a\nfilter-based smart retriever is employed to perform a dynamic selection of\ninference routing. Specifically, irrelevant queries will go through the\noriginal pre-alignment model directly, while relevant ones, together with their\nrelated edits, go through the model with aligned adapters activated. In\nexperiments, KEDAS secures the highest overall performance scores in 35 out of\n36 cases across four datasets with three LLMs on three settings, surpassing its\nstrong knowledge editing alignment counterpart by about 19.8 harmonic mean\nscores of edit success, locality and portability and outperforming both\nparameter editing and retrieval-based baselines significantly. Analysis of\ncomputational cost and performance on general tasks further validates the\nrobustness and efficiency of KEDAS, indicating that it presents an ideal\nparadigm of knowledge editing alignment.", "AI": {"tldr": "KEDAS\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u7f16\u8f91\u5bf9\u9f50\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6837\u589e\u5f3a\u548c\u81ea\u9002\u5e94\u63a8\u7406\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u7f16\u8f91\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u5728\u53c2\u6570\u7f16\u8f91\u548c\u68c0\u7d22\u5f0f\u65b9\u6cd5\u4e0a\u7684\u4e0d\u8db3\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u7f16\u8f91\u77e5\u8bc6\u7684\u5e94\u7528\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4f4e\u79e9\u9002\u5e94\u5b66\u4e60\u4e0a\u4e0b\u6587\u7f16\u8f91\u77e5\u8bc6\uff0c\u8bbe\u8ba1\u591a\u6837\u7f16\u8f91\u589e\u5f3a\u6280\u672f\u548c\u81ea\u9002\u5e94\u63a8\u7406\u673a\u5236\u3002", "result": "\u572836\u4e2a\u6848\u4f8b\u4e2d\u768435\u4e2a\u8868\u73b0\u6700\u4f73\uff0c\u7f16\u8f91\u6210\u529f\u7387\u548c\u901a\u7528\u4efb\u52a1\u6027\u80fd\u5747\u663e\u8457\u63d0\u5347\u3002", "conclusion": "KEDAS\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u77e5\u8bc6\u7f16\u8f91\u5bf9\u9f50\u8303\u5f0f\u3002"}}
{"id": "2508.02266", "pdf": "https://arxiv.org/pdf/2508.02266", "abs": "https://arxiv.org/abs/2508.02266", "authors": ["Yang Xu", "Kai Ming Ting"], "title": "Voronoi Diagram Encoded Hashing", "categories": ["cs.IR"], "comment": null, "summary": "The goal of learning to hash (L2H) is to derive data-dependent hash functions\nfrom a given data distribution in order to map data from the input space to a\nbinary coding space. Despite the success of L2H, two observations have cast\ndoubt on the source of the power of L2H, i.e., learning. First, a recent study\nshows that even using a version of locality sensitive hashing functions without\nlearning achieves binary representations that have comparable accuracy as those\nof L2H, but with less time cost. Second, existing L2H methods are constrained\nto three types of hash functions: thresholding, hyperspheres, and hyperplanes\nonly. In this paper, we unveil the potential of Voronoi diagrams in hashing.\nVoronoi diagram is a suitable candidate because of its three properties. This\ndiscovery has led us to propose a simple and efficient no-learning binary\nhashing method, called Voronoi Diagram Encoded Hashing (VDeH), which constructs\na set of hash functions through a data-dependent similarity measure and\nproduces independent binary bits through encoded hashing. We demonstrate\nthrough experiments on several benchmark datasets that VDeH achieves superior\nperformance and lower computational cost compared to existing state-of-the-art\nmethods under the same bit length.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eVoronoi\u56fe\u7684\u65e0\u5b66\u4e60\u54c8\u5e0c\u65b9\u6cd5VDeH\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\u3002", "motivation": "\u73b0\u6709\u5b66\u4e60\u54c8\u5e0c\u65b9\u6cd5\uff08L2H\uff09\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u6027\u80fd\u4e0e\u65e0\u5b66\u4e60\u65b9\u6cd5\u76f8\u5f53\u4e14\u4ec5\u652f\u6301\u4e09\u79cd\u54c8\u5e0c\u51fd\u6570\u7c7b\u578b\uff0c\u56e0\u6b64\u63a2\u7d22Voronoi\u56fe\u5728\u54c8\u5e0c\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u5229\u7528Voronoi\u56fe\u7684\u7279\u6027\uff0c\u63d0\u51faVDeH\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u4f9d\u8d56\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u6784\u5efa\u54c8\u5e0c\u51fd\u6570\uff0c\u5e76\u751f\u6210\u72ec\u7acb\u7684\u4e8c\u8fdb\u5236\u4f4d\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cVDeH\u5728\u76f8\u540c\u6bd4\u7279\u957f\u5ea6\u4e0b\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u6027\u80fd\u548c\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "VDeH\u5c55\u793a\u4e86Voronoi\u56fe\u5728\u54c8\u5e0c\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u65e0\u5b66\u4e60\u54c8\u5e0c\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.01097", "pdf": "https://arxiv.org/pdf/2508.01097", "abs": "https://arxiv.org/abs/2508.01097", "authors": ["Neil F. Johnson", "Frank Yingjie Huo"], "title": "Multispin Physics of AI Tipping Points and Hallucinations", "categories": ["cs.AI", "nlin.AO", "physics.comp-ph"], "comment": null, "summary": "Output from generative AI such as ChatGPT, can be repetitive and biased. But\nmore worrying is that this output can mysteriously tip mid-response from good\n(correct) to bad (misleading or wrong) without the user noticing. In 2024\nalone, this reportedly caused $67 billion in losses and several deaths.\nEstablishing a mathematical mapping to a multispin thermal system, we reveal a\nhidden tipping instability at the scale of the AI's 'atom' (basic Attention\nhead). We derive a simple but essentially exact formula for this tipping point\nwhich shows directly the impact of a user's prompt choice and the AI's training\nbias. We then show how the output tipping can get amplified by the AI's\nmultilayer architecture. As well as helping improve AI transparency,\nexplainability and performance, our results open a path to quantifying users'\nAI risk and legal liabilities.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\uff08\u5982ChatGPT\uff09\u7684\u8f93\u51fa\u53ef\u80fd\u91cd\u590d\u4e14\u6709\u504f\u89c1\uff0c\u66f4\u4ee4\u4eba\u62c5\u5fe7\u7684\u662f\u5176\u8f93\u51fa\u53ef\u80fd\u5728\u7528\u6237\u672a\u5bdf\u89c9\u65f6\u4ece\u6b63\u786e\u7a81\u53d8\u4e3a\u9519\u8bef\u30022024\u5e74\u56e0\u6b64\u9020\u6210670\u4ebf\u7f8e\u5143\u635f\u5931\u548c\u6570\u4eba\u6b7b\u4ea1\u3002\u901a\u8fc7\u5c06AI\u6620\u5c04\u5230\u591a\u81ea\u65cb\u70ed\u7cfb\u7edf\uff0c\u63ed\u793a\u4e86\u5176\u57fa\u672c\u6ce8\u610f\u529b\u5934\u7684\u9690\u85cf\u7a81\u53d8\u70b9\uff0c\u5e76\u63a8\u5bfc\u51fa\u516c\u5f0f\u91cf\u5316\u7528\u6237\u63d0\u793a\u548c\u8bad\u7ec3\u504f\u89c1\u7684\u5f71\u54cd\u3002\u7814\u7a76\u8fd8\u5c55\u793a\u4e86\u591a\u5c42\u67b6\u6784\u5982\u4f55\u653e\u5927\u8fd9\u79cd\u7a81\u53d8\uff0c\u4e3a\u63d0\u5347AI\u900f\u660e\u5ea6\u548c\u91cf\u5316\u98ce\u9669\u63d0\u4f9b\u4e86\u8def\u5f84\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u8f93\u51fa\u7a81\u53d8\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u540e\u679c\uff0c\u5982\u7ecf\u6d4e\u635f\u5931\u548c\u751f\u547d\u5371\u9669\uff0c\u56e0\u6b64\u9700\u8981\u63ed\u793a\u5176\u673a\u5236\u5e76\u91cf\u5316\u98ce\u9669\u3002", "method": "\u5c06AI\u6620\u5c04\u5230\u591a\u81ea\u65cb\u70ed\u7cfb\u7edf\uff0c\u63a8\u5bfc\u51fa\u7a81\u53d8\u70b9\u7684\u7cbe\u786e\u516c\u5f0f\uff0c\u5e76\u5206\u6790\u591a\u5c42\u67b6\u6784\u5bf9\u7a81\u53d8\u653e\u5927\u7684\u5f71\u54cd\u3002", "result": "\u63ed\u793a\u4e86AI\u8f93\u51fa\u7a81\u53d8\u7684\u9690\u85cf\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u91cf\u5316\u7528\u6237\u63d0\u793a\u548c\u8bad\u7ec3\u504f\u89c1\u5f71\u54cd\u7684\u516c\u5f0f\uff0c\u5e76\u5c55\u793a\u4e86\u591a\u5c42\u67b6\u6784\u7684\u653e\u5927\u6548\u5e94\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u5347AI\u900f\u660e\u5ea6\u3001\u89e3\u91ca\u6027\u548c\u6027\u80fd\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u4e3a\u91cf\u5316\u7528\u6237\u98ce\u9669\u548c\u6cd5\u5f8b\u8d23\u4efb\u5f00\u8f9f\u4e86\u8def\u5f84\u3002"}}
{"id": "2508.00887", "pdf": "https://arxiv.org/pdf/2508.00887", "abs": "https://arxiv.org/abs/2508.00887", "authors": ["Binrui Shen", "Yuan Liang", "Shengxin Zhu"], "title": "FRAM: Frobenius-Regularized Assignment Matching with Mixed-Precision Computing", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Graph matching, typically formulated as a Quadratic Assignment Problem (QAP),\nseeks to establish node correspondences between two graphs. To address the\nNP-hardness of QAP, some existing methods adopt projection-based relaxations\nthat embed the problem into the convex hull of the discrete domain. However,\nthese relaxations inevitably enlarge the feasible set, introducing two sources\nof error: numerical scale sensitivity and geometric misalignment between the\nrelaxed and original domains. To alleviate these errors, we propose a novel\nrelaxation framework by reformulating the projection step as a\nFrobenius-regularized Linear Assignment (FRA) problem, where a tunable\nregularization term mitigates feasible region inflation. This formulation\nenables normalization-based operations to preserve numerical scale invariance\nwithout compromising accuracy. To efficiently solve FRA, we propose the Scaling\nDoubly Stochastic Normalization (SDSN) algorithm. Building on its favorable\ncomputational properties, we develop a theoretically grounded mixed-precision\narchitecture to achieve substantial acceleration. Comprehensive CPU-based\nbenchmarks demonstrate that FRAM consistently outperforms all baseline methods\nunder identical precision settings. When combined with a GPU-based\nmixed-precision architecture, FRAM achieves up to 370X speedup over its\nCPU-FP64 counterpart, with negligible loss in solution accuracy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u5339\u914d\u677e\u5f1b\u6846\u67b6FRA\uff0c\u901a\u8fc7Frobenius\u6b63\u5219\u5316\u7ebf\u6027\u5206\u914d\u95ee\u9898\u51cf\u5c11\u8bef\u5dee\uff0c\u5e76\u8bbe\u8ba1\u4e86SDSN\u7b97\u6cd5\u548c\u6df7\u5408\u7cbe\u5ea6\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6295\u5f71\u677e\u5f1b\u65b9\u6cd5\u5728\u89e3\u51b3NP\u96be\u7684QAP\u95ee\u9898\u65f6\uff0c\u4f1a\u5f15\u5165\u6570\u503c\u5c3a\u5ea6\u654f\u611f\u6027\u548c\u51e0\u4f55\u4e0d\u5bf9\u9f50\u8bef\u5dee\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u8fd9\u4e9b\u8bef\u5dee\u3002", "method": "\u63d0\u51faFRA\u6846\u67b6\uff0c\u5c06\u6295\u5f71\u6b65\u9aa4\u91cd\u65b0\u8868\u8ff0\u4e3aFrobenius\u6b63\u5219\u5316\u7ebf\u6027\u5206\u914d\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1SDSN\u7b97\u6cd5\u548c\u6df7\u5408\u7cbe\u5ea6\u67b6\u6784\u4ee5\u9ad8\u6548\u6c42\u89e3\u3002", "result": "FRAM\u5728CPU\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7ed3\u5408GPU\u6df7\u5408\u7cbe\u5ea6\u67b6\u6784\u65f6\uff0c\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe370\u500d\uff0c\u4e14\u7cbe\u5ea6\u635f\u5931\u53ef\u5ffd\u7565\u3002", "conclusion": "FRA\u6846\u67b6\u548cSDSN\u7b97\u6cd5\u6709\u6548\u51cf\u5c11\u4e86\u677e\u5f1b\u8bef\u5dee\uff0c\u6df7\u5408\u7cbe\u5ea6\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u56fe\u5339\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.01309", "pdf": "https://arxiv.org/pdf/2508.01309", "abs": "https://arxiv.org/abs/2508.01309", "authors": ["Weibo Zhou", "Lingbo Li", "Shangsong Liang"], "title": "D-SCoRE: Document-Centric Segmentation and CoT Reasoning with Structured Export for QA-CoT Data Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The scarcity and high cost of high-quality question-answering (QA) datasets\nhinder supervised fine-tuning (SFT) for domain-specific large language models\n(LLMs). To address this, we introduce D-SCoRE, a training-free pipeline that\nutilizes LLMs and prompt engineering to produce diverse, high-quality QA\ndatasets from arbitrary textual sources. D-SCoRE integrates\n$\\textbf{D}$ocument-centric processing, $\\textbf{S}$egmentation, $\\textbf{Co}$T\n$\\textbf{R}$easoning, and structured $\\textbf{E}$xport to generate QA-COT\ndatasets tailored for domain-aware SFT. Multi-dimensional control mechanisms,\nsuch as semantic role transformation, question type balancing, and\ncounterfactual materials, enhance diversity and relevance, overcoming\nlimitations of existing QA generation. LLMs fine-tuned on D-SCoRE-generated QA\ndatasets, and human-annotated QA datasets (SQuAD, Covid-QA) are evaluated on\nSQuADShifts and Covid-QA test sets, with D-SCoRE outperforming across most\ndomains. D-SCoRE generates six QA-CoT pairs with four-option counterfactual\nmaterials per 100-200-word text in 90 seconds using an 8B LLM on consumer-grade\nhardware. Its simplicity and scalability enable efficient QA generation and\nhigh-performance fine-tuning across domains.", "AI": {"tldr": "D-SCoRE\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u6d41\u7a0b\uff0c\u5229\u7528LLM\u548c\u63d0\u793a\u5de5\u7a0b\u4ece\u4efb\u610f\u6587\u672c\u751f\u6210\u9ad8\u8d28\u91cfQA\u6570\u636e\u96c6\uff0c\u652f\u6301\u9886\u57df\u7279\u5b9aLLM\u7684\u76d1\u7763\u5fae\u8c03\u3002", "motivation": "\u89e3\u51b3\u9ad8\u8d28\u91cfQA\u6570\u636e\u96c6\u7a00\u7f3a\u4e14\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u652f\u6301\u9886\u57df\u7279\u5b9aLLM\u7684\u76d1\u7763\u5fae\u8c03\u3002", "method": "\u7ed3\u5408\u6587\u6863\u5904\u7406\u3001\u5206\u6bb5\u3001CoT\u63a8\u7406\u548c\u7ed3\u6784\u5316\u5bfc\u51fa\uff0c\u751f\u6210QA-CoT\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u591a\u7ef4\u63a7\u5236\u673a\u5236\u589e\u5f3a\u591a\u6837\u6027\u548c\u76f8\u5173\u6027\u3002", "result": "\u5728SQuADShifts\u548cCovid-QA\u6d4b\u8bd5\u96c6\u4e0a\uff0cD-SCoRE\u751f\u6210\u7684QA\u6570\u636e\u96c6\u8868\u73b0\u4f18\u4e8e\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u3002", "conclusion": "D-SCoRE\u7b80\u5355\u3001\u53ef\u6269\u5c55\uff0c\u80fd\u9ad8\u6548\u751f\u6210QA\u6570\u636e\u5e76\u652f\u6301\u8de8\u9886\u57df\u9ad8\u6027\u80fd\u5fae\u8c03\u3002"}}
{"id": "2508.02300", "pdf": "https://arxiv.org/pdf/2508.02300", "abs": "https://arxiv.org/abs/2508.02300", "authors": ["Kanishka Silva", "Marcel R. Ackermann", "Heike Fliegl", "Genet-Asefa Gesese", "Fidan Limani", "Philipp Mayr", "Peter Mutschke", "Allard Oelen", "Muhammad Asif Suryani", "Sharmila Upadhyaya", "Benjamin Zapilko", "Harald Sack", "Stefan Dietze"], "title": "Research Knowledge Graphs in NFDI4DataScience: Key Activities, Achievements, and Future Directions", "categories": ["cs.IR"], "comment": null, "summary": "As research in Artificial Intelligence and Data Science continues to grow in\nvolume and complexity, it becomes increasingly difficult to ensure\ntransparency, reproducibility, and discoverability. To address these\nchallenges, as research artifacts should be understandable and usable by\nmachines, the NFDI4DataScience consortium is developing and providing Research\nKnowledge Graphs (RKGs). Building upon earlier works, this paper presents\nrecent progress in creating semantically rich RKGs using standardized\nontologies, shared vocabularies, and automated Information Extraction\ntechniques. Key achievements include the development of the NFDI4DS ontology,\nmetadata standards, tools, and services designed to support the FAIR\nprinciples, as well as community-led projects and various implementations of\nRKGs. Together, these efforts aim to capture and connect the complex\nrelationships between datasets, models, software, and scientific publications.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86NFDI4DataScience\u8054\u76df\u5982\u4f55\u901a\u8fc7\u7814\u7a76\u77e5\u8bc6\u56fe\u8c31\uff08RKGs\uff09\u89e3\u51b3AI\u548c\u6570\u636e\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u900f\u660e\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u53ef\u53d1\u73b0\u6027\u95ee\u9898\u3002", "motivation": "\u968f\u7740AI\u548c\u6570\u636e\u79d1\u5b66\u7814\u7a76\u7684\u590d\u6742\u6027\u548c\u4f53\u91cf\u589e\u957f\uff0c\u786e\u4fdd\u7814\u7a76\u7684\u900f\u660e\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u53ef\u53d1\u73b0\u6027\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u5229\u7528\u6807\u51c6\u5316\u672c\u4f53\u3001\u5171\u4eab\u8bcd\u6c47\u548c\u81ea\u52a8\u5316\u4fe1\u606f\u63d0\u53d6\u6280\u672f\u6784\u5efa\u8bed\u4e49\u4e30\u5bcc\u7684\u7814\u7a76\u77e5\u8bc6\u56fe\u8c31\u3002", "result": "\u5f00\u53d1\u4e86NFDI4DS\u672c\u4f53\u3001\u5143\u6570\u636e\u6807\u51c6\u3001\u5de5\u5177\u548c\u670d\u52a1\uff0c\u652f\u6301FAIR\u539f\u5219\uff0c\u5e76\u5b9e\u73b0\u4e86\u591a\u4e2a\u793e\u533a\u9879\u76ee\u548cRKG\u5b9e\u4f8b\u3002", "conclusion": "\u8fd9\u4e9b\u52aa\u529b\u65e8\u5728\u6355\u6349\u548c\u8fde\u63a5\u6570\u636e\u96c6\u3001\u6a21\u578b\u3001\u8f6f\u4ef6\u548c\u79d1\u5b66\u51fa\u7248\u7269\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002"}}
{"id": "2508.01109", "pdf": "https://arxiv.org/pdf/2508.01109", "abs": "https://arxiv.org/abs/2508.01109", "authors": ["Satiyabooshan Murugaboopathy", "Connor T. Jerzak", "Adel Daoud"], "title": "Platonic Representations for Poverty Mapping: Unified Vision-Language Codes or Agent-Induced Novelty?", "categories": ["cs.AI", "68T07", "I.2; J.4"], "comment": "7 figures", "summary": "We investigate whether socio-economic indicators like household wealth leave\nrecoverable imprints in satellite imagery (capturing physical features) and\nInternet-sourced text (reflecting historical/economic narratives). Using\nDemographic and Health Survey (DHS) data from African neighborhoods, we pair\nLandsat images with LLM-generated textual descriptions conditioned on\nlocation/year and text retrieved by an AI search agent from web sources. We\ndevelop a multimodal framework predicting household wealth (International\nWealth Index) through five pipelines: (i) vision model on satellite images,\n(ii) LLM using only location/year, (iii) AI agent searching/synthesizing web\ntext, (iv) joint image-text encoder, (v) ensemble of all signals. Our framework\nyields three contributions. First, fusing vision and agent/LLM text outperforms\nvision-only baselines in wealth prediction (e.g., R-squared of 0.77 vs. 0.63 on\nout-of-sample splits), with LLM-internal knowledge proving more effective than\nagent-retrieved text, improving robustness to out-of-country and out-of-time\ngeneralization. Second, we find partial representational convergence: fused\nembeddings from vision/language modalities correlate moderately (median cosine\nsimilarity of 0.60 after alignment), suggesting a shared latent code of\nmaterial well-being while retaining complementary details, consistent with the\nPlatonic Representation Hypothesis. Although LLM-only text outperforms\nagent-retrieved data, challenging our Agent-Induced Novelty Hypothesis, modest\ngains from combining agent data in some splits weakly support the notion that\nagent-gathered information introduces unique representational structures not\nfully captured by static LLM knowledge. Third, we release a large-scale\nmultimodal dataset comprising more than 60,000 DHS clusters linked to satellite\nimages, LLM-generated descriptions, and agent-retrieved texts.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u536b\u661f\u56fe\u50cf\u548c\u7f51\u7edc\u6587\u672c\u9884\u6d4b\u5bb6\u5ead\u8d22\u5bcc\uff0c\u591a\u6a21\u6001\u6846\u67b6\u878d\u5408\u89c6\u89c9\u548c\u8bed\u8a00\u4fe1\u53f7\uff0c\u8868\u73b0\u4f18\u4e8e\u5355\u4e00\u65b9\u6cd5\uff0c\u5e76\u53d1\u73b0\u90e8\u5206\u8868\u5f81\u6536\u655b\u73b0\u8c61\u3002", "motivation": "\u63a2\u7d22\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\uff08\u5982\u5bb6\u5ead\u8d22\u5bcc\uff09\u662f\u5426\u80fd\u5728\u536b\u661f\u56fe\u50cf\u548c\u7f51\u7edc\u6587\u672c\u4e2d\u7559\u4e0b\u53ef\u6062\u590d\u7684\u75d5\u8ff9\uff0c\u4ee5\u63d0\u4f9b\u65b0\u7684\u6570\u636e\u6765\u6e90\u548c\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u975e\u6d32\u793e\u533a\u7684DHS\u6570\u636e\uff0c\u7ed3\u5408Landsat\u56fe\u50cf\u548cLLM\u751f\u6210\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u5f00\u53d1\u4e86\u4e94\u79cd\u9884\u6d4b\u7ba1\u9053\uff0c\u5305\u62ec\u89c6\u89c9\u6a21\u578b\u3001LLM\u6587\u672c\u3001AI\u4ee3\u7406\u68c0\u7d22\u6587\u672c\u3001\u8054\u5408\u7f16\u7801\u5668\u548c\u96c6\u6210\u4fe1\u53f7\u3002", "result": "\u591a\u6a21\u6001\u6846\u67b6\u5728\u8d22\u5bcc\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u4e00\u65b9\u6cd5\uff08R-squared 0.77 vs. 0.63\uff09\uff0cLLM\u5185\u90e8\u77e5\u8bc6\u6bd4\u4ee3\u7406\u68c0\u7d22\u6587\u672c\u66f4\u6709\u6548\uff0c\u90e8\u5206\u8868\u5f81\u6536\u655b\u73b0\u8c61\u88ab\u53d1\u73b0\u3002", "conclusion": "\u878d\u5408\u89c6\u89c9\u548c\u8bed\u8a00\u4fe1\u53f7\u80fd\u63d0\u9ad8\u8d22\u5bcc\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\u7684\u6f5c\u5728\u5171\u4eab\u8868\u5f81\uff0c\u5e76\u53d1\u5e03\u4e86\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6\u3002"}}
{"id": "2508.00888", "pdf": "https://arxiv.org/pdf/2508.00888", "abs": "https://arxiv.org/abs/2508.00888", "authors": ["Amir Hossein Kalantari", "Eleonora Papadimitriou", "Amir Pooyan Afghari"], "title": "A Dynamic, Context-Aware Framework for Risky Driving Prediction Using Naturalistic Data", "categories": ["cs.LG", "stat.AP", "stat.CO", "stat.ME"], "comment": "32 pages", "summary": "Naturalistic driving studies offer a powerful means for observing and\nquantifying real-world driving behaviour. One of their prominent applications\nin traffic safety is the continuous monitoring and classification of risky\ndriving behaviour. However, many existing frameworks rely on fixed time windows\nand static thresholds for distinguishing between safe and risky behaviour -\nlimiting their ability to respond to the stochastic nature of real-world\ndriving. This study proposes a dynamic and individualised framework for\nidentifying risky driving behaviour using Belgian naturalistic driving data.\nThe approach leverages a rolling time window and bi-level optimisation to\ndynamically calibrate both risk thresholds and model hyperparameters, capturing\nsubtle behavioural shifts. Two safety indicators, speed-weighted headway and\nharsh driving events, were evaluated using three data-driven models: Random\nForest, XGBoost, and Deep Neural Network (DNN). The DNN demonstrated strong\ncapability in capturing subtle changes in driving behaviour, particularly\nexcelling in high-recall tasks, making it promising for early-stage risk\ndetection. XGBoost provided the most balanced and stable performance across\ndifferent thresholds and evaluation metrics. While random forest showed more\nvariability, it responded sensitively to dynamic threshold adjustments, which\nmay be advantageous during model adaptation or tuning. Speed-weighted headway\nemerged as a more stable and context-sensitive risk indicator than harsh\ndriving events, likely due to its robustness to label sparsity and contextual\nvariation. Overall, the findings support the value of adaptive, personalised\nrisk detection approaches for enhancing real-time safety feedback and tailoring\ndriver support in intelligent transport systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u4e2a\u6027\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522b\u98ce\u9669\u9a7e\u9a76\u884c\u4e3a\uff0c\u5229\u7528\u6eda\u52a8\u65f6\u95f4\u7a97\u53e3\u548c\u53cc\u5c42\u4f18\u5316\u52a8\u6001\u6821\u51c6\u98ce\u9669\u9608\u503c\u548c\u6a21\u578b\u8d85\u53c2\u6570\uff0c\u8bc4\u4f30\u4e86\u4e09\u79cd\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c\u5176\u4e2dDNN\u5728\u9ad8\u53ec\u56de\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0cXGBoost\u8868\u73b0\u6700\u5e73\u8861\uff0c\u968f\u673a\u68ee\u6797\u5bf9\u52a8\u6001\u8c03\u6574\u654f\u611f\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u4f9d\u8d56\u56fa\u5b9a\u65f6\u95f4\u7a97\u53e3\u548c\u9759\u6001\u9608\u503c\uff0c\u96be\u4ee5\u5e94\u5bf9\u771f\u5b9e\u9a7e\u9a76\u7684\u968f\u673a\u6027\uff0c\u56e0\u6b64\u9700\u8981\u52a8\u6001\u4e2a\u6027\u5316\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6bd4\u5229\u65f6\u81ea\u7136\u9a7e\u9a76\u6570\u636e\uff0c\u91c7\u7528\u6eda\u52a8\u65f6\u95f4\u7a97\u53e3\u548c\u53cc\u5c42\u4f18\u5316\u52a8\u6001\u6821\u51c6\u98ce\u9669\u9608\u503c\u548c\u6a21\u578b\u8d85\u53c2\u6570\uff0c\u8bc4\u4f30\u4e86\u4e09\u79cd\u6a21\u578b\uff08\u968f\u673a\u68ee\u6797\u3001XGBoost\u3001DNN\uff09\u548c\u4e24\u79cd\u5b89\u5168\u6307\u6807\uff08\u901f\u5ea6\u52a0\u6743\u8f66\u8ddd\u548c\u6fc0\u70c8\u9a7e\u9a76\u4e8b\u4ef6\uff09\u3002", "result": "DNN\u5728\u9ad8\u53ec\u56de\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0cXGBoost\u8868\u73b0\u6700\u5e73\u8861\uff0c\u968f\u673a\u68ee\u6797\u5bf9\u52a8\u6001\u8c03\u6574\u654f\u611f\uff1b\u901f\u5ea6\u52a0\u6743\u8f66\u8ddd\u6bd4\u6fc0\u70c8\u9a7e\u9a76\u4e8b\u4ef6\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u81ea\u9002\u5e94\u4e2a\u6027\u5316\u98ce\u9669\u68c0\u6d4b\u65b9\u6cd5\u5bf9\u5b9e\u65f6\u5b89\u5168\u53cd\u9988\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u9a7e\u9a76\u5458\u652f\u6301\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2508.01317", "pdf": "https://arxiv.org/pdf/2508.01317", "abs": "https://arxiv.org/abs/2508.01317", "authors": ["Xuemiao Zhang", "Can Ren", "Chengying Tu", "Rongxiang Weng", "Hongfei Yan", "Jingang Wang", "Xunliang Cai"], "title": "LinkQA: Synthesizing Diverse QA from Multiple Seeds Strongly Linked by Knowledge Points", "categories": ["cs.CL"], "comment": null, "summary": "The advancement of large language models (LLMs) struggles with the scarcity\nof high-quality, diverse training data. To address this limitation, we propose\nLinkSyn, a novel knowledge point (KP) graph-based synthesis framework that\nenables flexible control over discipline and difficulty distributions while\nbalancing KP coverage and popularity. LinkSyn extracts KPs from\nquestion-answering (QA) seed data and constructs a KP graph to synthesize\ndiverse QA data from multiple seeds strongly linked by KPs and sampled from\ngraph walks. Specifically, LinkSyn incorporates (1) a knowledge distribution\nvalue function to guide the adjustment of path sampling probability and balance\nKP coverage and popularity during graph walks; (2) diffusion-based synthesis\nvia DeepSeek-R1 by leveraging multiple seeds with dense logical associations\nalong each path; and (3) high-difficulty QA enhancement within given\ndisciplines by flexible difficulty adjustments. By executing LinkSyn, we\nsynthesize LinkQA, a diverse multi-disciplinary QA dataset with 50B tokens.\nExtensive experiments on Llama-3 8B demonstrate that continual pre-training\nwith LinkQA yields an average improvement of $\\mathbf{11.51\\%}$ on MMLU and\nCMMLU, establishing new SOTA results. LinkQA consistently enhances performance\nacross model size and initial FLOPs scales.", "AI": {"tldr": "LinkSyn\u662f\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u5408\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u5316\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u4e14\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u3001\u8def\u5f84\u91c7\u6837\u6982\u7387\u8c03\u6574\u548c\u6269\u6563\u5408\u6210\u6280\u672f\uff0c\u751f\u6210\u591a\u5b66\u79d1\u3001\u591a\u96be\u5ea6\u7684QA\u6570\u636e\u3002", "result": "\u5408\u6210\u7684LinkQA\u6570\u636e\u96c6\uff0850B tokens\uff09\u663e\u8457\u63d0\u5347\u4e86Llama-3 8B\u5728MMLU\u548cCMMLU\u4e0a\u7684\u6027\u80fd\uff08\u5e73\u5747\u63d0\u534711.51%\uff09\u3002", "conclusion": "LinkSyn\u548cLinkQA\u4e3a\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002"}}
{"id": "2508.02342", "pdf": "https://arxiv.org/pdf/2508.02342", "abs": "https://arxiv.org/abs/2508.02342", "authors": ["Yashar Deldjoo", "Nima Rafiee", "Mahdyar Ravanbakhsh"], "title": "Agentic Personalized Fashion Recommendation in the Age of Generative AI: Challenges, Opportunities, and Evaluation", "categories": ["cs.IR"], "comment": null, "summary": "Fashion recommender systems (FaRS) face distinct challenges due to rapid\ntrend shifts, nuanced user preferences, intricate item-item compatibility, and\nthe complex interplay among consumers, brands, and influencers. Traditional\nrecommendation approaches, largely static and retrieval-focused, struggle to\neffectively capture these dynamic elements, leading to decreased user\nsatisfaction and elevated return rates. This paper synthesizes both academic\nand industrial viewpoints to map the distinctive output space and stakeholder\necosystem of modern FaRS, identifying the complex interplay among users,\nbrands, platforms, and influencers, and highlighting the unique data and\nmodeling challenges that arise.\n  We outline a research agenda for industrial FaRS, centered on five\nrepresentative scenarios spanning static queries, outfit composition, and\nmulti-turn dialogue, and argue that mixed-modality refinement-the ability to\ncombine image-based references (anchors) with nuanced textual constraints-is a\nparticularly critical task for real-world deployment. To this end, we propose\nan Agentic Mixed-Modality Refinement (AMMR) pipeline, which fuses multimodal\nencoders with agentic LLM planners and dynamic retrieval, bridging the gap\nbetween expressive user intent and fast-changing fashion inventories. Our work\nshows that moving beyond static retrieval toward adaptive, generative, and\nstakeholder-aware systems is essential to satisfy the evolving expectations of\nfashion consumers and brands.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u65f6\u5c1a\u63a8\u8350\u7cfb\u7edf\uff08FaRS\uff09\u9762\u4e34\u7684\u72ec\u7279\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6a21\u6001\u7ec6\u5316\uff08AMMR\uff09\u7ba1\u9053\uff0c\u4ee5\u89e3\u51b3\u52a8\u6001\u8d8b\u52bf\u548c\u7528\u6237\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u6355\u6349\u65f6\u5c1a\u9886\u57df\u7684\u52a8\u6001\u53d8\u5316\u548c\u590d\u6742\u5173\u7cfb\uff0c\u5bfc\u81f4\u7528\u6237\u6ee1\u610f\u5ea6\u4e0b\u964d\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6a21\u6001\u7ec6\u5316\uff08AMMR\uff09\u7ba1\u9053\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u7f16\u7801\u5668\u3001\u4ee3\u7406LLM\u89c4\u5212\u5668\u548c\u52a8\u6001\u68c0\u7d22\u3002", "result": "AMMR\u80fd\u591f\u66f4\u597d\u5730\u6ee1\u8db3\u7528\u6237\u548c\u54c1\u724c\u7684\u9700\u6c42\uff0c\u9002\u5e94\u5feb\u901f\u53d8\u5316\u7684\u65f6\u5c1a\u5e93\u5b58\u3002", "conclusion": "\u672a\u6765\u7684\u65f6\u5c1a\u63a8\u8350\u7cfb\u7edf\u9700\u8981\u5411\u81ea\u9002\u5e94\u3001\u751f\u6210\u5f0f\u548c\u5229\u76ca\u76f8\u5173\u8005\u611f\u77e5\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2508.01158", "pdf": "https://arxiv.org/pdf/2508.01158", "abs": "https://arxiv.org/abs/2508.01158", "authors": ["Yunlong Lin", "Zirui Li", "Guodong Du", "Xiaocong Zhao", "Cheng Gong", "Xinwei Wang", "Chao Lu", "Jianwei Gong"], "title": "H2C: Hippocampal Circuit-inspired Continual Learning for Lifelong Trajectory Prediction in Autonomous Driving", "categories": ["cs.AI"], "comment": "Open source code: https://github.com/BIT-Jack/H2C-lifelong", "summary": "Deep learning (DL) has shown state-of-the-art performance in trajectory\nprediction, which is critical to safe navigation in autonomous driving (AD).\nHowever, most DL-based methods suffer from catastrophic forgetting, where\nadapting to a new distribution may cause significant performance degradation in\npreviously learned ones. Such inability to retain learned knowledge limits\ntheir applicability in the real world, where AD systems need to operate across\nvarying scenarios with dynamic distributions. As revealed by neuroscience, the\nhippocampal circuit plays a crucial role in memory replay, effectively\nreconstructing learned knowledge based on limited resources. Inspired by this,\nwe propose a hippocampal circuit-inspired continual learning method (H2C) for\ntrajectory prediction across varying scenarios. H2C retains prior knowledge by\nselectively recalling a small subset of learned samples. First, two\ncomplementary strategies are developed to select the subset to represent\nlearned knowledge. Specifically, one strategy maximizes inter-sample diversity\nto represent the distinctive knowledge, and the other estimates the overall\nknowledge by equiprobable sampling. Then, H2C updates via a memory replay loss\nfunction calculated by these selected samples to retain knowledge while\nlearning new data. Experiments based on various scenarios from the INTERACTION\ndataset are designed to evaluate H2C. Experimental results show that H2C\nreduces catastrophic forgetting of DL baselines by 22.71% on average in a\ntask-free manner, without relying on manually informed distributional shifts.\nThe implementation is available at https://github.com/BIT-Jack/H2C-lifelong.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u6d77\u9a6c\u4f53\u542f\u53d1\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff08H2C\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u5728\u8f68\u8ff9\u9884\u6d4b\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u8bb0\u5fc6\u56de\u653e\u4fdd\u7559\u5148\u9a8c\u77e5\u8bc6\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u8f68\u8ff9\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u52a8\u6001\u5206\u5e03\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u53d7\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\uff0c\u6d77\u9a6c\u4f53\u5728\u8bb0\u5fc6\u56de\u653e\u4e2d\u7684\u4f5c\u7528\u4e3a\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u601d\u8def\u3002", "method": "H2C\u901a\u8fc7\u4e24\u79cd\u4e92\u8865\u7b56\u7565\u9009\u62e9\u4ee3\u8868\u6027\u6837\u672c\uff0c\u6700\u5927\u5316\u6837\u672c\u591a\u6837\u6027\u548c\u7b49\u6982\u7387\u91c7\u6837\uff0c\u5e76\u901a\u8fc7\u8bb0\u5fc6\u56de\u653e\u635f\u5931\u51fd\u6570\u66f4\u65b0\u6a21\u578b\u3002", "result": "\u5728INTERACTION\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cH2C\u5e73\u5747\u51cf\u5c11\u4e8622.71%\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4e14\u65e0\u9700\u624b\u52a8\u6807\u6ce8\u5206\u5e03\u53d8\u5316\u3002", "conclusion": "H2C\u6709\u6548\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u8f68\u8ff9\u9884\u6d4b\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u52a8\u6001\u573a\u666f\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.00897", "pdf": "https://arxiv.org/pdf/2508.00897", "abs": "https://arxiv.org/abs/2508.00897", "authors": ["Julien Simon de Kergunic", "Rony Abecidan", "Patrick Bas", "Vincent Itier"], "title": "Maximize margins for robust splicing detection", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "in French language. GRETSI 2025 - Colloque Francophone de Traitement\n  du Signal et des Images, https://gretsi.fr/colloque2025/, Aug 2025,\n  Strasbourg, France", "summary": "Despite recent progress in splicing detection, deep learning-based forensic\ntools remain difficult to deploy in practice due to their high sensitivity to\ntraining conditions. Even mild post-processing applied to evaluation images can\nsignificantly degrade detector performance, raising concerns about their\nreliability in operational contexts. In this work, we show that the same deep\narchitecture can react very differently to unseen post-processing depending on\nthe learned weights, despite achieving similar accuracy on in-distribution test\ndata. This variability stems from differences in the latent spaces induced by\ntraining, which affect how samples are separated internally. Our experiments\nreveal a strong correlation between the distribution of latent margins and a\ndetector's ability to generalize to post-processed images. Based on this\nobservation, we propose a practical strategy for building more robust\ndetectors: train several variants of the same model under different conditions,\nand select the one that maximizes latent margins.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u6df1\u5ea6\u5b66\u4e60\u68c0\u6d4b\u5668\u5bf9\u8bad\u7ec3\u6761\u4ef6\u7684\u9ad8\u654f\u611f\u6027\uff0c\u63d0\u51fa\u901a\u8fc7\u6700\u5927\u5316\u6f5c\u5728\u8fb9\u8ddd\u9009\u62e9\u6a21\u578b\u4ee5\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u68c0\u6d4b\u5668\u5bf9\u8bc4\u4f30\u56fe\u50cf\u7684\u8f7b\u5fae\u540e\u5904\u7406\u654f\u611f\uff0c\u5f71\u54cd\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u9760\u6027\u3002", "method": "\u8bad\u7ec3\u540c\u4e00\u6a21\u578b\u7684\u4e0d\u540c\u53d8\u4f53\uff0c\u9009\u62e9\u6f5c\u5728\u8fb9\u8ddd\u6700\u5927\u7684\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6f5c\u5728\u8fb9\u8ddd\u5206\u5e03\u4e0e\u68c0\u6d4b\u5668\u6cdb\u5316\u80fd\u529b\u5f3a\u76f8\u5173\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u6f5c\u5728\u8fb9\u8ddd\u53ef\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u68c0\u6d4b\u5668\u3002"}}
{"id": "2508.01326", "pdf": "https://arxiv.org/pdf/2508.01326", "abs": "https://arxiv.org/abs/2508.01326", "authors": ["Xuemiao Zhang", "Chengying Tu", "Can Ren", "Rongxiang Weng", "Hongfei Yan", "Jingang Wang", "Xunliang Cai"], "title": "Large-Scale Diverse Synthesis for Mid-Training", "categories": ["cs.CL"], "comment": null, "summary": "The scarcity of high-quality, knowledge-intensive training data hinders the\ndevelopment of large language models (LLMs), as traditional corpora provide\nlimited information. Previous studies have synthesized and integrated\ncorpora-dependent question-answering (QA) data to improve model performance but\nface challenges in QA data scalability and knowledge diversity, particularly in\ncross-domain contexts. Furthermore, leveraging our designed discipline and\ndifficulty annotation system, we probe model deficiencies in STEM disciplines\nand high-difficulty data. To overcome these limitations, we propose a novel\ndiversified pipeline to synthesize BoostQA, a 100B-token large-scale QA\ndataset. Our synthesis framework: (1) curates seed data from heterogeneous\nsources; (2) utilizes DeepSeek-R1 to implement STEM-focused multi-grade\nsynthesis to boost data diversity and high-difficulty synthesis to mitigate\ndifficulty degradation; (3) refines answers via DeepSeek-V3 to improve output\nquality. We utilize BoostQA in mid-training, a mid-stage between pre-training\nand post-training, to optimize domain-specific knowledge acquisition and\nenhance data quality. Our method enables Llama-3 8B, mid-trained on a 40B-token\ndataset, to achieve an average improvement of $\\mathbf{12.74\\%}$ on MMLU and\nCMMLU and establish SOTA average performance across 12 benchmarks. BoostQA also\ndemonstrates robust scalability, with performance consistently improving as\nmodel size, data volume, and initial FLOPs scale.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBoostQA\u7684\u65b0\u578b\u591a\u6837\u5316QA\u6570\u636e\u96c6\u5408\u6210\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027\u548c\u6a21\u578b\u5728STEM\u9886\u57df\u53ca\u9ad8\u96be\u5ea6\u6570\u636e\u4e0a\u7684\u4e0d\u8db3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u9ad8\u8d28\u91cf\u3001\u77e5\u8bc6\u5bc6\u96c6\u7684\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\uff0c\u4f20\u7edf\u8bed\u6599\u5e93\u4fe1\u606f\u6709\u9650\uff0c\u4e14\u73b0\u6709QA\u6570\u636e\u5728\u53ef\u6269\u5c55\u6027\u548c\u77e5\u8bc6\u591a\u6837\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u8de8\u9886\u57df\u548c\u9ad8\u96be\u5ea6\u6570\u636e\u4e0a\u3002", "method": "\u901a\u8fc7\u591a\u6e90\u79cd\u5b50\u6570\u636e\u6536\u96c6\u3001STEM\u591a\u7ea7\u5408\u6210\u548c\u9ad8\u96be\u5ea6\u5408\u6210\u6846\u67b6\uff0c\u7ed3\u5408DeepSeek\u6a21\u578b\u4f18\u5316\u7b54\u6848\u8d28\u91cf\uff0c\u6784\u5efa\u4e86100B-token\u7684BoostQA\u6570\u636e\u96c6\uff0c\u5e76\u7528\u4e8e\u4e2d\u8bad\u7ec3\u9636\u6bb5\u3002", "result": "Llama-3 8B\u6a21\u578b\u572840B-token\u6570\u636e\u96c6\u4e0a\u4e2d\u8bad\u7ec3\u540e\uff0cMMLU\u548cCMMLU\u5e73\u5747\u63d0\u534712.74%\uff0c\u5e76\u572812\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "conclusion": "BoostQA\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u89c4\u6a21\u548c\u8ba1\u7b97\u8d44\u6e90\u7684\u6a21\u578b\u3002"}}
{"id": "2508.02435", "pdf": "https://arxiv.org/pdf/2508.02435", "abs": "https://arxiv.org/abs/2508.02435", "authors": ["Shengbo Gong", "Xianfeng Tang", "Carl Yang", "Wei jin"], "title": "Beyond Chunks and Graphs: Retrieval-Augmented Generation through Triplet-Driven Thinking", "categories": ["cs.IR", "H.3"], "comment": "19 pages", "summary": "Retrieval-augmented generation (RAG) is critical for reducing hallucinations\nand incorporating external knowledge into Large Language Models (LLMs).\nHowever, advanced RAG systems face a trade-off between performance and\nefficiency. Multi-round RAG approaches achieve strong reasoning but incur\nexcessive LLM calls and token costs, while Graph RAG methods suffer from\ncomputationally expensive, error-prone graph construction and retrieval\nredundancy. To address these challenges, we propose T$^2$RAG, a novel framework\nthat operates on a simple, graph-free knowledge base of atomic triplets.\nT$^2$RAG leverages an LLM to decompose questions into searchable triplets with\nplaceholders, which it then iteratively resolves by retrieving evidence from\nthe triplet database. Empirical results show that T$^2$RAG significantly\noutperforms state-of-the-art multi-round and Graph RAG methods, achieving an\naverage performance gain of up to 11\\% across six datasets while reducing\nretrieval costs by up to 45\\%. Our code is available at\nhttps://github.com/rockcor/T2RAG", "AI": {"tldr": "T$^2$RAG\u662f\u4e00\u79cd\u65b0\u578b\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u539f\u5b50\u4e09\u5143\u7ec4\u7684\u7b80\u5355\u77e5\u8bc6\u5e93\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u591a\u8f6eRAG\u548cGraph RAG\u5728\u6027\u80fd\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u5229\u7528LLM\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u641c\u7d22\u7684\u4e09\u5143\u7ec4\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u68c0\u7d22\u4e09\u5143\u7ec4\u6570\u636e\u5e93\u4e2d\u7684\u8bc1\u636e\u6765\u89e3\u51b3\u95ee\u9898\u3002", "result": "\u5728\u516d\u4e2a\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u6027\u80fd\u63d0\u534711%\uff0c\u68c0\u7d22\u6210\u672c\u964d\u4f4e45%\u3002", "conclusion": "T$^2$RAG\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.01181", "pdf": "https://arxiv.org/pdf/2508.01181", "abs": "https://arxiv.org/abs/2508.01181", "authors": ["Zhiyuan Han", "Beier Zhu", "Yanlong Xu", "Peipei Song", "Xun Yang"], "title": "Benchmarking and Bridging Emotion Conflicts for Multimodal Emotion Reasoning", "categories": ["cs.AI", "cs.CV", "cs.MM", "cs.SD", "eess.AS", "68", "I.2.10"], "comment": "ACM Multimedia 2025", "summary": "Despite their strong performance in multimodal emotion reasoning, existing\nMultimodal Large Language Models (MLLMs) often overlook the scenarios involving\nemotion conflicts, where emotional cues from different modalities are\ninconsistent. To fill this gap, we first introduce CA-MER, a new benchmark\ndesigned to examine MLLMs under realistic emotion conflicts. It consists of\nthree subsets: video-aligned, audio-aligned, and consistent, where only one or\nall modalities reflect the true emotion. However, evaluations on our CA-MER\nreveal that current state-of-the-art emotion MLLMs systematically over-rely on\naudio signal during emotion conflicts, neglecting critical cues from visual\nmodality. To mitigate this bias, we propose MoSEAR, a parameter-efficient\nframework that promotes balanced modality integration. MoSEAR consists of two\nmodules: (1)MoSE, modality-specific experts with a regularized gating mechanism\nthat reduces modality bias in the fine-tuning heads; and (2)AR, an attention\nreallocation mechanism that rebalances modality contributions in frozen\nbackbones during inference. Our framework offers two key advantages: it\nmitigates emotion conflicts and improves performance on consistent\nsamples-without incurring a trade-off between audio and visual modalities.\nExperiments on multiple benchmarks-including MER2023, EMER, DFEW, and our\nCA-MER-demonstrate that MoSEAR achieves state-of-the-art performance,\nparticularly under modality conflict conditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86CA-MER\u57fa\u51c6\u6d4b\u8bd5\u548cMoSEAR\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u63a8\u7406\u4e2d\u7684\u60c5\u611f\u51b2\u7a81\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709MLLMs\u5728\u591a\u6a21\u6001\u60c5\u611f\u63a8\u7406\u4e2d\u5ffd\u89c6\u60c5\u611f\u51b2\u7a81\u573a\u666f\uff0c\u5bfc\u81f4\u5bf9\u97f3\u9891\u4fe1\u53f7\u7684\u8fc7\u5ea6\u4f9d\u8d56\u3002", "method": "\u63d0\u51faMoSEAR\u6846\u67b6\uff0c\u5305\u62ecMoSE\u6a21\u5757\uff08\u51cf\u5c11\u6a21\u6001\u504f\u89c1\u7684\u5fae\u8c03\u5934\uff09\u548cAR\u6a21\u5757\uff08\u91cd\u65b0\u5e73\u8861\u6a21\u6001\u8d21\u732e\u7684\u6ce8\u610f\u529b\u673a\u5236\uff09\u3002", "result": "MoSEAR\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u6a21\u6001\u51b2\u7a81\u6761\u4ef6\u4e0b\u3002", "conclusion": "MoSEAR\u6709\u6548\u89e3\u51b3\u4e86\u60c5\u611f\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u591a\u6a21\u6001\u60c5\u611f\u63a8\u7406\u7684\u6027\u80fd\u3002"}}
{"id": "2508.00901", "pdf": "https://arxiv.org/pdf/2508.00901", "abs": "https://arxiv.org/abs/2508.00901", "authors": ["Ruichen Xu", "Kexin Chen"], "title": "Filtering with Self-Attention and Storing with MLP: One-Layer Transformers Can Provably Acquire and Extract Knowledge", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Modern large language models excel in knowledge-intensive tasks, yet how\ntransformers acquire (store) knowledge during pre-training and extract\n(retrieve) it during post-fine-tuning inference remains theoretically opaque.\nWhile prior theoretical work has begun to investigate these questions through\nthe analysis of training dynamics, such studies are limited to single-layer,\nattention-only architectures. However, most existing studies suggest that MLPs\nare the most contributing components for storing knowledge in transformer-based\nlanguage models. Meanwhile, our empirical investigations reveal that such\nsimplified models, when trained using standard next-token prediction\nobjectives, may be incapable of acquiring or extracting factual knowledge. To\novercome this limitation, we introduce a tractable one-layer transformer\nframework that crucially incorporates both self-attention and MLP modules. By\ntracking its gradient dynamics, we establish convergence and generalization\nguarantees that illuminate the ability of knowledge acquisition and extraction.\nWe prove that 1) Transformers can achieve near-optimal training loss during\npre-training, signifying effective knowledge acquisition; 2) With a large\nfine-tuning dataset and specific data multiplicity conditions met, transformers\ncan achieve low generalization error when tested on factual knowledge learned\nduring pre-training but not reinforced during the fine-tuning, indicating\nsuccessful knowledge extraction; 3) When the conditions are not satisfied,\ntransformers exhibit high generalization loss, resulting in hallucinations. Our\nanalysis includes both full fine-tuning and low-rank fine-tuning. Furthermore,\nour analysis offers theoretical insights into several pertinent empirical\nphenomena, such as the role of learning rate schedules. Experiments on\nsynthetic and real-world PopQA datasets with GPT-2 and Llama-3.2-1B validate\nour results.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86Transformer\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u4e2d\u83b7\u53d6\u77e5\u8bc6\u53ca\u5728\u5fae\u8c03\u4e2d\u63d0\u53d6\u77e5\u8bc6\u7684\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u548cMLP\u7684\u5355\u5c42\u6846\u67b6\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u5bf9Transformer\u5982\u4f55\u83b7\u53d6\u548c\u63d0\u53d6\u77e5\u8bc6\u7684\u7814\u7a76\u5c40\u9650\u4e8e\u5355\u5c42\u6ce8\u610f\u529b\u67b6\u6784\uff0c\u4e14\u6807\u51c6\u8bad\u7ec3\u76ee\u6807\u53ef\u80fd\u65e0\u6cd5\u6709\u6548\u83b7\u53d6\u4e8b\u5b9e\u77e5\u8bc6\u3002", "method": "\u5f15\u5165\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u548cMLP\u7684\u5355\u5c42Transformer\u6846\u67b6\uff0c\u5206\u6790\u5176\u68af\u5ea6\u52a8\u6001\uff0c\u9a8c\u8bc1\u6536\u655b\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u8bc1\u660eTransformer\u5728\u9884\u8bad\u7ec3\u4e2d\u80fd\u6709\u6548\u83b7\u53d6\u77e5\u8bc6\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5fae\u8c03\u540e\u53ef\u6210\u529f\u63d0\u53d6\u77e5\u8bc6\uff0c\u5426\u5219\u4f1a\u51fa\u73b0\u5e7b\u89c9\u3002", "conclusion": "\u7814\u7a76\u4e3aTransformer\u7684\u77e5\u8bc6\u83b7\u53d6\u548c\u63d0\u53d6\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2508.01370", "pdf": "https://arxiv.org/pdf/2508.01370", "abs": "https://arxiv.org/abs/2508.01370", "authors": ["Roman Koshkin", "Pengyu Dai", "Nozomi Fujikawa", "Masahito Togami", "Marco Visentini-Scarzanella"], "title": "MaRGen: Multi-Agent LLM Approach for Self-Directed Market Research and Analysis", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "We present an autonomous framework that leverages Large Language Models\n(LLMs) to automate end-to-end business analysis and market report generation.\nAt its core, the system employs specialized agents - Researcher, Reviewer,\nWriter, and Retriever - that collaborate to analyze data and produce\ncomprehensive reports. These agents learn from real professional consultants'\npresentation materials at Amazon through in-context learning to replicate\nprofessional analytical methodologies. The framework executes a multi-step\nprocess: querying databases, analyzing data, generating insights, creating\nvisualizations, and composing market reports. We also introduce a novel\nLLM-based evaluation system for assessing report quality, which shows alignment\nwith expert human evaluations. Building on these evaluations, we implement an\niterative improvement mechanism that optimizes report quality through automated\nreview cycles. Experimental results show that report quality can be improved by\nboth automated review cycles and consultants' unstructured knowledge. In\nexperimental validation, our framework generates detailed 6-page reports in 7\nminutes at a cost of approximately \\$1. Our work could be an important step to\nautomatically create affordable market insights.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u7aef\u5230\u7aef\u5546\u4e1a\u5206\u6790\u548c\u5e02\u573a\u62a5\u544a\u751f\u6210\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\u548c\u8fed\u4ee3\u6539\u8fdb\u673a\u5236\u63d0\u5347\u62a5\u544a\u8d28\u91cf\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u5316\u6846\u67b6\u964d\u4f4e\u5e02\u573a\u5206\u6790\u6210\u672c\uff0c\u540c\u65f6\u590d\u5236\u4e13\u4e1a\u54a8\u8be2\u5e08\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u63d0\u4f9b\u9ad8\u6548\u4e14\u7ecf\u6d4e\u7684\u5e02\u573a\u6d1e\u5bdf\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u7814\u7a76\u8005\u3001\u5ba1\u9605\u8005\u3001\u64b0\u5199\u8005\u548c\u68c0\u7d22\u8005\u56db\u79cd\u4ee3\u7406\uff0c\u901a\u8fc7\u591a\u6b65\u9aa4\u6d41\u7a0b\uff08\u6570\u636e\u67e5\u8be2\u3001\u5206\u6790\u3001\u53ef\u89c6\u5316\u3001\u62a5\u544a\u751f\u6210\uff09\u548cLLM\u8bc4\u4f30\u7cfb\u7edf\u4f18\u5316\u62a5\u544a\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6846\u67b6\u57287\u5206\u949f\u5185\u751f\u62106\u9875\u8be6\u7ec6\u62a5\u544a\uff0c\u6210\u672c\u7ea61\u7f8e\u5143\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5ba1\u9605\u548c\u987e\u95ee\u77e5\u8bc6\u63d0\u5347\u62a5\u544a\u8d28\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u81ea\u52a8\u5316\u751f\u6210\u7ecf\u6d4e\u5b9e\u60e0\u7684\u5e02\u573a\u6d1e\u5bdf\u63d0\u4f9b\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2508.02451", "pdf": "https://arxiv.org/pdf/2508.02451", "abs": "https://arxiv.org/abs/2508.02451", "authors": ["Zhaoyu Hu", "Hao Guo", "Yuan Tian", "Erpeng Xue", "Jianyang Wang", "Xianyang Qi", "Hongxiang Lin", "Lei Wang", "Sheng Chen"], "title": "Dynamic Forgetting and Spatio-Temporal Periodic Interest Modeling for Local-Life Service Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "In the context of the booming digital economy, recommendation systems, as a\nkey link connecting users and numerous services, face challenges in modeling\nuser behavior sequences on local-life service platforms, including the sparsity\nof long sequences and strong spatio-temporal dependence. Such challenges can be\naddressed by drawing an analogy to the forgetting process in human memory. This\nis because users' responses to recommended content follow the recency effect\nand the cyclicality of memory. By exploring this, this paper introduces the\nforgetting curve and proposes Spatio-Temporal periodic Interest Modeling (STIM)\nwith long sequences for local-life service recommendation. STIM integrates\nthree key components: a dynamic masking module based on the forgetting curve,\nwhich is used to extract both recent spatiotemporal features and periodic\nspatiotemporal features; a query-based mixture of experts (MoE) approach that\ncan adaptively activate expert networks under different dynamic masks, enabling\nthe collaborative modeling of time, location, and items; and a hierarchical\nmulti-interest network unit, which captures multi-interest representations by\nmodeling the hierarchical interactions between the shallow and deep semantics\nof users' recent behaviors. By introducing the STIM method, we conducted online\nA/B tests and achieved a 1.54\\% improvement in gross transaction volume (GTV).\nIn addition, extended offline experiments also showed improvements. STIM has\nbeen deployed in a large-scale local-life service recommendation system,\nserving hundreds of millions of daily active users in core application\nscenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9057\u5fd8\u66f2\u7ebf\u7684\u65f6\u7a7a\u5468\u671f\u6027\u5174\u8da3\u5efa\u6a21\u65b9\u6cd5\uff08STIM\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u672c\u5730\u751f\u6d3b\u670d\u52a1\u5e73\u53f0\u4e2d\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u5efa\u6a21\u7684\u7a00\u758f\u6027\u548c\u65f6\u7a7a\u4f9d\u8d56\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ea4\u6613\u91cf\u3002", "motivation": "\u5728\u6570\u5b57\u7ecf\u6d4e\u7684\u80cc\u666f\u4e0b\uff0c\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u7a00\u758f\u6027\u548c\u5f3a\u65f6\u7a7a\u4f9d\u8d56\u6027\u7684\u6311\u6218\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8bb0\u5fc6\u7684\u9057\u5fd8\u8fc7\u7a0b\u6765\u6539\u8fdb\u63a8\u8350\u6548\u679c\u3002", "method": "STIM\u65b9\u6cd5\u5305\u62ec\u57fa\u4e8e\u9057\u5fd8\u66f2\u7ebf\u7684\u52a8\u6001\u63a9\u7801\u6a21\u5757\u3001\u67e5\u8be2\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u65b9\u6cd5\u548c\u5206\u5c42\u591a\u5174\u8da3\u7f51\u7edc\u5355\u5143\uff0c\u7528\u4e8e\u63d0\u53d6\u65f6\u7a7a\u7279\u5f81\u548c\u5efa\u6a21\u7528\u6237\u5174\u8da3\u3002", "result": "\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\uff0cSTIM\u65b9\u6cd5\u4f7f\u603b\u4ea4\u6613\u91cf\uff08GTV\uff09\u63d0\u5347\u4e861.54%\uff0c\u79bb\u7ebf\u5b9e\u9a8c\u4e5f\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "STIM\u65b9\u6cd5\u6210\u529f\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u672c\u5730\u751f\u6d3b\u670d\u52a1\u63a8\u8350\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6548\u679c\u3002"}}
{"id": "2508.01186", "pdf": "https://arxiv.org/pdf/2508.01186", "abs": "https://arxiv.org/abs/2508.01186", "authors": ["Chaojia Yu", "Zihan Cheng", "Hanwen Cui", "Yishuo Gao", "Zexu Luo", "Yijin Wang", "Hangbin Zheng", "Yong Zhao"], "title": "A Survey on Agent Workflow -- Status and Future", "categories": ["cs.AI", "cs.HC"], "comment": "12 pages, 3 figures, accepted to IEEE Conference,\n  ICAIBD(International Conference of Artificial Intelligence and Big Data)\n  2025. This is the author's version, not the publisher's. See\n  https://ieeexplore.ieee.org/document/11082076", "summary": "In the age of large language models (LLMs), autonomous agents have emerged as\na powerful paradigm for achieving general intelligence. These agents\ndynamically leverage tools, memory, and reasoning capabilities to accomplish\nuser-defined goals. As agent systems grow in complexity, agent\nworkflows-structured orchestration frameworks-have become central to enabling\nscalable, controllable, and secure AI behaviors. This survey provides a\ncomprehensive review of agent workflow systems, spanning academic frameworks\nand industrial implementations. We classify existing systems along two key\ndimensions: functional capabilities (e.g., planning, multi-agent collaboration,\nexternal API integration) and architectural features (e.g., agent roles,\norchestration flows, specification languages). By comparing over 20\nrepresentative systems, we highlight common patterns, potential technical\nchallenges, and emerging trends. We further address concerns related to\nworkflow optimization strategies and security. Finally, we outline open\nproblems such as standardization and multimodal integration, offering insights\nfor future research at the intersection of agent design, workflow\ninfrastructure, and safe automation.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\u4e0b\u81ea\u4e3b\u4ee3\u7406\u5de5\u4f5c\u6d41\u7cfb\u7edf\u7684\u529f\u80fd\u4e0e\u67b6\u6784\uff0c\u6bd4\u8f83\u4e8620\u591a\u4e2a\u4ee3\u8868\u6027\u7cfb\u7edf\uff0c\u5e76\u63a2\u8ba8\u4e86\u4f18\u5316\u3001\u5b89\u5168\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u4ee3\u7406\u7cfb\u7edf\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u5de5\u4f5c\u6d41\u6846\u67b6\u6210\u4e3a\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u63a7\u548c\u5b89\u5168AI\u884c\u4e3a\u7684\u5173\u952e\u3002\u672c\u6587\u65e8\u5728\u5168\u9762\u56de\u987e\u4ee3\u7406\u5de5\u4f5c\u6d41\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u73b0\u6709\u7cfb\u7edf\uff08\u529f\u80fd\u80fd\u529b\u548c\u67b6\u6784\u7279\u5f81\uff09\uff0c\u6bd4\u8f8320\u591a\u4e2a\u4ee3\u8868\u6027\u7cfb\u7edf\uff0c\u5206\u6790\u5171\u540c\u6a21\u5f0f\u3001\u6280\u672f\u6311\u6218\u548c\u8d8b\u52bf\u3002", "result": "\u603b\u7ed3\u4e86\u4ee3\u7406\u5de5\u4f5c\u6d41\u7cfb\u7edf\u7684\u529f\u80fd\u4e0e\u67b6\u6784\u7279\u5f81\uff0c\u63d0\u51fa\u4e86\u4f18\u5316\u7b56\u7565\u3001\u5b89\u5168\u95ee\u9898\u53ca\u5f00\u653e\u6027\u95ee\u9898\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u6807\u51c6\u5316\u548c\u591a\u6a21\u6001\u96c6\u6210\uff0c\u4ee5\u63a8\u52a8\u4ee3\u7406\u8bbe\u8ba1\u3001\u5de5\u4f5c\u6d41\u57fa\u7840\u8bbe\u65bd\u548c\u5b89\u5168\u81ea\u52a8\u5316\u7684\u4ea4\u53c9\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2508.00903", "pdf": "https://arxiv.org/pdf/2508.00903", "abs": "https://arxiv.org/abs/2508.00903", "authors": ["Advey Nandan", "Cheng-Ting Chou", "Amrit Kurakula", "Cole Blondin", "Kevin Zhu", "Vasu Sharma", "Sean O'Brien"], "title": "Universal Neurons in GPT-2: Emergence, Persistence, and Functional Impact", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "We investigate the phenomenon of neuron universality in independently trained\nGPT-2 Small models, examining how these universal neurons-neurons with\nconsistently correlated activations across models-emerge and evolve throughout\ntraining. By analyzing five GPT-2 models at three checkpoints (100k, 200k, 300k\nsteps), we identify universal neurons through pairwise correlation analysis of\nactivations over a dataset of 5 million tokens. Ablation experiments reveal\nsignificant functional impacts of universal neurons on model predictions,\nmeasured via loss and KL divergence. Additionally, we quantify neuron\npersistence, demonstrating high stability of universal neurons across training\ncheckpoints, particularly in deeper layers. These findings suggest stable and\nuniversal representational structures emerge during neural network training.", "AI": {"tldr": "\u7814\u7a76GPT-2 Small\u6a21\u578b\u4e2d\u795e\u7ecf\u5143\u666e\u904d\u6027\u73b0\u8c61\uff0c\u53d1\u73b0\u8bad\u7ec3\u4e2d\u666e\u904d\u795e\u7ecf\u5143\uff08\u8de8\u6a21\u578b\u6fc0\u6d3b\u76f8\u5173\uff09\u7684\u6f14\u5316\u53ca\u5176\u5bf9\u9884\u6d4b\u7684\u529f\u80fd\u5f71\u54cd\u3002", "motivation": "\u63a2\u8ba8\u72ec\u7acb\u8bad\u7ec3\u7684GPT-2\u6a21\u578b\u4e2d\u666e\u904d\u795e\u7ecf\u5143\u7684\u51fa\u73b0\u53ca\u5176\u7a33\u5b9a\u6027\uff0c\u63ed\u793a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u666e\u904d\u8868\u5f81\u7ed3\u6784\u3002", "method": "\u5206\u6790\u4e94\u4e2aGPT-2\u6a21\u578b\u5728\u4e09\u4e2a\u8bad\u7ec3\u9636\u6bb5\uff08100k\u3001200k\u3001300k\u6b65\uff09\uff0c\u901a\u8fc7\u6fc0\u6d3b\u76f8\u5173\u6027\u8bc6\u522b\u666e\u904d\u795e\u7ecf\u5143\uff0c\u5e76\u8fdb\u884c\u6d88\u878d\u5b9e\u9a8c\u8bc4\u4f30\u5176\u529f\u80fd\u5f71\u54cd\u3002", "result": "\u666e\u904d\u795e\u7ecf\u5143\u5bf9\u6a21\u578b\u9884\u6d4b\u6709\u663e\u8457\u529f\u80fd\u5f71\u54cd\uff0c\u4e14\u5728\u6df1\u5c42\u7f51\u7edc\u4e2d\u8868\u73b0\u51fa\u9ad8\u5ea6\u7a33\u5b9a\u6027\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u4f1a\u5f62\u6210\u7a33\u5b9a\u4e14\u666e\u904d\u7684\u795e\u7ecf\u5143\u8868\u5f81\u7ed3\u6784\u3002"}}
{"id": "2508.01401", "pdf": "https://arxiv.org/pdf/2508.01401", "abs": "https://arxiv.org/abs/2508.01401", "authors": ["Ahmad Rezaie Mianroodi", "Amirali Rezaie", "Niko Grisel Todorov", "Cyril Rakovski", "Frank Rudzicz"], "title": "MedSynth: Realistic, Synthetic Medical Dialogue-Note Pairs", "categories": ["cs.CL", "cs.AI"], "comment": "7 pages excluding references and appendices", "summary": "Physicians spend significant time documenting clinical encounters, a burden\nthat contributes to professional burnout. To address this, robust automation\ntools for medical documentation are crucial. We introduce MedSynth -- a novel\ndataset of synthetic medical dialogues and notes designed to advance the\nDialogue-to-Note (Dial-2-Note) and Note-to-Dialogue (Note-2-Dial) tasks.\nInformed by an extensive analysis of disease distributions, this dataset\nincludes over 10,000 dialogue-note pairs covering over 2000 ICD-10 codes. We\ndemonstrate that our dataset markedly enhances the performance of models in\ngenerating medical notes from dialogues, and dialogues from medical notes. The\ndataset provides a valuable resource in a field where open-access,\nprivacy-compliant, and diverse training data are scarce. Code is available at\nhttps://github.com/ahmadrezarm/MedSynth/tree/main and the dataset is available\nat https://huggingface.co/datasets/Ahmad0067/MedSynth.", "AI": {"tldr": "MedSynth\u662f\u4e00\u4e2a\u5408\u6210\u533b\u7597\u5bf9\u8bdd\u548c\u7b14\u8bb0\u6570\u636e\u96c6\uff0c\u65e8\u5728\u63d0\u5347Dial-2-Note\u548cNote-2-Dial\u4efb\u52a1\u6027\u80fd\uff0c\u5305\u542b10,000\u591a\u5bf9\u5bf9\u8bdd-\u7b14\u8bb0\u6570\u636e\uff0c\u8986\u76d62000\u591a\u79cdICD-10\u4ee3\u7801\u3002", "motivation": "\u51cf\u8f7b\u533b\u751f\u4e34\u5e8a\u8bb0\u5f55\u8d1f\u62c5\uff0c\u51cf\u5c11\u804c\u4e1a\u5026\u6020\uff0c\u63a8\u52a8\u533b\u7597\u6587\u6863\u81ea\u52a8\u5316\u5de5\u5177\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u5206\u6790\u75be\u75c5\u5206\u5e03\uff0c\u521b\u5efa\u5305\u542b\u591a\u6837\u5316\u5bf9\u8bdd-\u7b14\u8bb0\u5bf9\u7684\u5408\u6210\u6570\u636e\u96c6MedSynth\u3002", "result": "\u6570\u636e\u96c6\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u533b\u7597\u7b14\u8bb0\u751f\u6210\u548c\u5bf9\u8bdd\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "MedSynth\u4e3a\u533b\u7597\u9886\u57df\u63d0\u4f9b\u4e86\u5f00\u6e90\u3001\u9690\u79c1\u5408\u89c4\u4e14\u591a\u6837\u5316\u7684\u8bad\u7ec3\u6570\u636e\u8d44\u6e90\u3002"}}
{"id": "2508.02506", "pdf": "https://arxiv.org/pdf/2508.02506", "abs": "https://arxiv.org/abs/2508.02506", "authors": ["Xiaowei Yuan", "Lei Jin", "Haoxin Zhang", "Yan Gao", "Yi Wu", "Yao Hu", "Ziyang Huang", "Jun Zhao", "Kang Liu"], "title": "Decomposed Reasoning with Reinforcement Learning for Relevance Assessment in UGC Platforms", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) plays a critical role in user-generated\ncontent (UGC) platforms, but its effectiveness depends heavily on accurate\nrelevance assessment of query-document pairs. Despite recent advances in\napplying large language models (LLMs) to relevance modeling, UGC platforms\npresent unique challenges: 1) ambiguous user intent due to sparse user feedback\nin RAG scenarios, and 2) substantial noise introduced by informal and\nunstructured language. To address these issues, we propose the Reinforced\nReasoning Model for Relevance Assessment (R3A), which introduces a decomposed\nreasoning framework over queries and candidate documents before scoring. R3A\nfirst leverages auxiliary high-ranked documents within the platform to infer\nlatent query intent. It then performs verbatim fragment extraction to justify\nrelevance decisions, thereby reducing errors caused by noisy UGC. Based on a\nreinforcement learning framework, R3A is optimized to mitigate distortions\narising from ambiguous queries and unstructured content. Experimental results\nshow that R3A significantly outperforms existing baseline methods in terms of\nrelevance accuracy, across both offline benchmarks and online experiments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aR3A\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u89e3\u63a8\u7406\u6846\u67b6\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86UGC\u5e73\u53f0\u4e2d\u67e5\u8be2-\u6587\u6863\u5bf9\u76f8\u5173\u6027\u8bc4\u4f30\u7684\u6311\u6218\u3002", "motivation": "UGC\u5e73\u53f0\u4e2d\uff0c\u7528\u6237\u610f\u56fe\u6a21\u7cca\u548c\u5185\u5bb9\u566a\u58f0\u5927\uff0c\u5bfc\u81f4\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u76f8\u5173\u6027\u8bc4\u4f30\u6548\u679c\u4e0d\u4f73\u3002", "method": "R3A\u91c7\u7528\u5206\u89e3\u63a8\u7406\u6846\u67b6\uff0c\u5229\u7528\u9ad8\u6392\u540d\u6587\u6863\u63a8\u65ad\u67e5\u8be2\u610f\u56fe\uff0c\u5e76\u901a\u8fc7\u7247\u6bb5\u63d0\u53d6\u51cf\u5c11\u566a\u58f0\u5f71\u54cd\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cR3A\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u4e2d\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "R3A\u6709\u6548\u63d0\u5347\u4e86UGC\u5e73\u53f0\u4e2d\u76f8\u5173\u6027\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2508.01191", "pdf": "https://arxiv.org/pdf/2508.01191", "abs": "https://arxiv.org/abs/2508.01191", "authors": ["Chengshuai Zhao", "Zhen Tan", "Pingchuan Ma", "Dawei Li", "Bohan Jiang", "Yancheng Wang", "Yingzhen Yang", "Huan Liu"], "title": "Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Chain-of-Thought (CoT) prompting has been shown to improve Large Language\nModel (LLM) performance on various tasks. With this approach, LLMs appear to\nproduce human-like reasoning steps before providing answers (a.k.a., CoT\nreasoning), which often leads to the perception that they engage in deliberate\ninferential processes. However, some initial findings suggest that CoT\nreasoning may be more superficial than it appears, motivating us to explore\nfurther. In this paper, we study CoT reasoning via a data distribution lens and\ninvestigate if CoT reasoning reflects a structured inductive bias learned from\nin-distribution data, allowing the model to conditionally generate reasoning\npaths that approximate those seen during training. Thus, its effectiveness is\nfundamentally bounded by the degree of distribution discrepancy between the\ntraining data and the test queries. With this lens, we dissect CoT reasoning\nvia three dimensions: task, length, and format. To investigate each dimension,\nwe design DataAlchemy, an isolated and controlled environment to train LLMs\nfrom scratch and systematically probe them under various distribution\nconditions. Our results reveal that CoT reasoning is a brittle mirage that\nvanishes when it is pushed beyond training distributions. This work offers a\ndeeper understanding of why and when CoT reasoning fails, emphasizing the\nongoing challenge of achieving genuine and generalizable reasoning.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0cCoT\u63a8\u7406\u5728\u8d85\u51fa\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u65f6\u4f1a\u5931\u6548\uff0c\u8868\u660e\u5176\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u63a2\u7d22CoT\u63a8\u7406\u662f\u5426\u771f\u6b63\u53cd\u6620\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4f9d\u8d56\u8bad\u7ec3\u6570\u636e\u7684\u5206\u5e03\u3002", "method": "\u901a\u8fc7\u4efb\u52a1\u3001\u957f\u5ea6\u548c\u683c\u5f0f\u4e09\u4e2a\u7ef4\u5ea6\u5206\u6790CoT\u63a8\u7406\uff0c\u5e76\u4f7f\u7528DataAlchemy\u73af\u5883\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "CoT\u63a8\u7406\u5728\u8d85\u51fa\u8bad\u7ec3\u5206\u5e03\u65f6\u8868\u73b0\u8106\u5f31\uff0c\u65e0\u6cd5\u6cdb\u5316\u3002", "conclusion": "CoT\u63a8\u7406\u7684\u6cdb\u5316\u80fd\u529b\u53d7\u9650\uff0c\u5f3a\u8c03\u4e86\u5b9e\u73b0\u771f\u6b63\u901a\u7528\u63a8\u7406\u7684\u6311\u6218\u3002"}}
{"id": "2508.00909", "pdf": "https://arxiv.org/pdf/2508.00909", "abs": "https://arxiv.org/abs/2508.00909", "authors": ["Aitor S\u00e1nchez-Ferrera", "Usue Mori", "Borja Calvo", "Jose A. Lozano"], "title": "NeuCoReClass AD: Redefining Self-Supervised Time Series Anomaly Detection", "categories": ["cs.LG"], "comment": null, "summary": "Time series anomaly detection plays a critical role in a wide range of\nreal-world applications. Among unsupervised approaches, self-supervised\nlearning has gained traction for modeling normal behavior without the need of\nlabeled data. However, many existing methods rely on a single proxy task,\nlimiting their ability to capture meaningful patterns in normal data. Moreover,\nthey often depend on handcrafted transformations tailored specific domains,\nhindering their generalization accross diverse problems. To address these\nlimitations, we introduce NeuCoReClass AD, a self-supervised multi-task time\nseries anomaly detection framework that combines contrastive, reconstruction,\nand classification proxy tasks. Our method employs neural transformation\nlearning to generate augmented views that are informative, diverse, and\ncoherent, without requiring domain-specific knowledge. We evaluate NeuCoReClass\nAD across a wide range of benchmarks, demonstrating that it consistently\noutperforms both classical baselines and most deep-learning alternatives.\nFurthermore, it enables the characterization of distinct anomaly profiles in a\nfully unsupervised manner.", "AI": {"tldr": "NeuCoReClass AD\u662f\u4e00\u79cd\u81ea\u76d1\u7763\u591a\u4efb\u52a1\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u5bf9\u6bd4\u3001\u91cd\u5efa\u548c\u5206\u7c7b\u4ee3\u7406\u4efb\u52a1\uff0c\u65e0\u9700\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u5373\u53ef\u751f\u6210\u591a\u6837\u5316\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u589e\u5f3a\u89c6\u56fe\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u65b9\u6cd5\u591a\u4f9d\u8d56\u5355\u4e00\u4ee3\u7406\u4efb\u52a1\u548c\u9886\u57df\u7279\u5b9a\u8f6c\u6362\uff0c\u9650\u5236\u4e86\u5176\u5728\u591a\u6837\u5316\u95ee\u9898\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u8f6c\u6362\u5b66\u4e60\u751f\u6210\u591a\u6837\u5316\u589e\u5f3a\u89c6\u56fe\uff0c\u7ed3\u5408\u5bf9\u6bd4\u3001\u91cd\u5efa\u548c\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\u548c\u591a\u6570\u6df1\u5ea6\u5b66\u4e60\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u80fd\u65e0\u76d1\u7763\u5730\u8bc6\u522b\u5f02\u5e38\u7279\u5f81\u3002", "conclusion": "NeuCoReClass AD\u901a\u8fc7\u591a\u4efb\u52a1\u81ea\u76d1\u7763\u5b66\u4e60\u6709\u6548\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u3002"}}
{"id": "2508.01411", "pdf": "https://arxiv.org/pdf/2508.01411", "abs": "https://arxiv.org/abs/2508.01411", "authors": ["Rania Al-Sabbagh"], "title": "ArzEn-MultiGenre: An aligned parallel dataset of Egyptian Arabic song lyrics, novels, and subtitles, with English translations", "categories": ["cs.CL"], "comment": null, "summary": "ArzEn-MultiGenre is a parallel dataset of Egyptian Arabic song lyrics,\nnovels, and TV show subtitles that are manually translated and aligned with\ntheir English counterparts. The dataset contains 25,557 segment pairs that can\nbe used to benchmark new machine translation models, fine-tune large language\nmodels in few-shot settings, and adapt commercial machine translation\napplications such as Google Translate. Additionally, the dataset is a valuable\nresource for research in various disciplines, including translation studies,\ncross-linguistic analysis, and lexical semantics. The dataset can also serve\npedagogical purposes by training translation students and aid professional\ntranslators as a translation memory. The contributions are twofold: first, the\ndataset features textual genres not found in existing parallel Egyptian Arabic\nand English datasets, and second, it is a gold-standard dataset that has been\ntranslated and aligned by human experts.", "AI": {"tldr": "ArzEn-MultiGenre\u662f\u4e00\u4e2a\u57c3\u53ca\u963f\u62c9\u4f2f\u8bed\u4e0e\u82f1\u8bed\u5e73\u884c\u6570\u636e\u96c6\uff0c\u5305\u542b\u6b4c\u66f2\u6b4c\u8bcd\u3001\u5c0f\u8bf4\u548c\u7535\u89c6\u5267\u5b57\u5e55\uff0c\u53ef\u7528\u4e8e\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u8bc4\u4f30\u3001\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u53ca\u7ffb\u8bd1\u7814\u7a76\u3002", "motivation": "\u586b\u8865\u73b0\u6709\u57c3\u53ca\u963f\u62c9\u4f2f\u8bed\u548c\u82f1\u8bed\u5e73\u884c\u6570\u636e\u96c6\u4e2d\u7f3a\u4e4f\u7684\u6587\u672c\u7c7b\u578b\uff0c\u5e76\u4e3a\u673a\u5668\u7ffb\u8bd1\u3001\u7ffb\u8bd1\u7814\u7a76\u548c\u6559\u5b66\u63d0\u4f9b\u9ad8\u8d28\u91cf\u8d44\u6e90\u3002", "method": "\u6570\u636e\u96c6\u5305\u542b25,557\u4e2a\u624b\u52a8\u7ffb\u8bd1\u548c\u5bf9\u9f50\u7684\u6587\u672c\u7247\u6bb5\uff0c\u6db5\u76d6\u591a\u79cd\u6587\u4f53\u3002", "result": "\u6570\u636e\u96c6\u4e3a\u673a\u5668\u7ffb\u8bd1\u3001\u8de8\u8bed\u8a00\u5206\u6790\u548c\u7ffb\u8bd1\u6559\u5b66\u63d0\u4f9b\u4e86\u9ec4\u91d1\u6807\u51c6\u8d44\u6e90\u3002", "conclusion": "ArzEn-MultiGenre\u586b\u8865\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u5e76\u4e3a\u591a\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u3002"}}
{"id": "2508.02538", "pdf": "https://arxiv.org/pdf/2508.02538", "abs": "https://arxiv.org/abs/2508.02538", "authors": ["Zhengxin Pan", "Haishuai Wang", "Fangyu Wu", "Peng Zhang", "Jiajun Bu"], "title": "Hubness Reduction with Dual Bank Sinkhorn Normalization for Cross-Modal Retrieval", "categories": ["cs.IR", "H.3"], "comment": "ACMMM 2025", "summary": "The past decade has witnessed rapid advancements in cross-modal retrieval,\nwith significant progress made in accurately measuring the similarity between\ncross-modal pairs. However, the persistent hubness problem, a phenomenon where\na small number of targets frequently appear as nearest neighbors to numerous\nqueries, continues to hinder the precision of similarity measurements. Despite\nseveral proposed methods to reduce hubness, their underlying mechanisms remain\npoorly understood. To bridge this gap, we analyze the widely-adopted Inverted\nSoftmax approach and demonstrate its effectiveness in balancing target\nprobabilities during retrieval. Building on these insights, we propose a\nprobability-balancing framework for more effective hubness reduction. We\ncontend that balancing target probabilities alone is inadequate and, therefore,\nextend the framework to balance both query and target probabilities by\nintroducing Sinkhorn Normalization (SN). Notably, we extend SN to scenarios\nwhere the true query distribution is unknown, showing that current methods,\nwhich rely solely on a query bank to estimate target hubness, produce\nsuboptimal results due to a significant distributional gap between the query\nbank and targets. To mitigate this issue, we introduce Dual Bank Sinkhorn\nNormalization (DBSN), incorporating a corresponding target bank alongside the\nquery bank to narrow this distributional gap. Our comprehensive evaluation\nacross various cross-modal retrieval tasks, including image-text retrieval,\nvideo-text retrieval, and audio-text retrieval, demonstrates consistent\nperformance improvements, validating the effectiveness of both SN and DBSN. All\ncodes are publicly available at https://github.com/ppanzx/DBSN.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u7387\u5e73\u8861\u6846\u67b6\uff08DBSN\uff09\u6765\u89e3\u51b3\u8de8\u6a21\u6001\u68c0\u7d22\u4e2d\u7684hubness\u95ee\u9898\uff0c\u901a\u8fc7\u5e73\u8861\u67e5\u8be2\u548c\u76ee\u6807\u6982\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u7cbe\u5ea6\u3002", "motivation": "\u5c3d\u7ba1\u8de8\u6a21\u6001\u68c0\u7d22\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46hubness\u95ee\u9898\u4ecd\u5f71\u54cd\u76f8\u4f3c\u6027\u6d4b\u91cf\u7684\u51c6\u786e\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u673a\u5236\u4e0d\u660e\u786e\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5206\u6790\u4e86Inverted Softmax\u65b9\u6cd5\uff0c\u63d0\u51fa\u6982\u7387\u5e73\u8861\u6846\u67b6\uff0c\u5e76\u5f15\u5165Sinkhorn Normalization\uff08SN\uff09\u548cDual Bank Sinkhorn Normalization\uff08DBSN\uff09\u6765\u5e73\u8861\u67e5\u8be2\u548c\u76ee\u6807\u6982\u7387\u3002", "result": "\u5728\u591a\u79cd\u8de8\u6a21\u6001\u68c0\u7d22\u4efb\u52a1\u4e2d\uff08\u5982\u56fe\u6587\u3001\u89c6\u9891-\u6587\u672c\u3001\u97f3\u9891-\u6587\u672c\u68c0\u7d22\uff09\uff0cSN\u548cDBSN\u5747\u8868\u73b0\u51fa\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "DBSN\u901a\u8fc7\u5e73\u8861\u67e5\u8be2\u548c\u76ee\u6807\u6982\u7387\uff0c\u6709\u6548\u89e3\u51b3\u4e86hubness\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u8de8\u6a21\u6001\u68c0\u7d22\u7684\u7cbe\u5ea6\u3002"}}
{"id": "2508.01203", "pdf": "https://arxiv.org/pdf/2508.01203", "abs": "https://arxiv.org/abs/2508.01203", "authors": ["Junjie Shi", "Wei Ma", "Shi Ying", "Lingxiao Jiang", "Yang liu", "Bo Du"], "title": "Importance Sampling is All You Need: Predict LLM's performance on new benchmark by reusing existing benchmark", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid advancement of large language models , code generation has\nbecome a key benchmark for evaluating LLM capabilities. However, existing\nbenchmarks face two major challenges: (1) the escalating cost of constructing\nhigh-quality test suites and reference solutions, and (2) the increasing risk\nof data contamination, which undermines the reliability of benchmark-based\nevaluations. In this paper, we propose BIS, a prompt-centric evaluation\nframework that enables ground-truth-free prediction of LLM performance on code\ngeneration tasks. Rather than executing generated code, BIS estimates\nperformance metrics by analyzing the prompt distribution alone. Built on\nimportance sampling theory and implemented using Importance Weighted\nAutoencoders, our method reweights samples from existing annotated benchmarks\nto estimate performance on new, unseen benchmarks. To stabilize the estimation,\nwe introduce weight truncation strategies and compute marginal expectations\nacross the fitted distributions. BIS serves as a complementary tool that\nsupports benchmark development and validation under constrained resources,\noffering actionable and quick feedback for prompt selection and contamination\nassessment. We conduct extensive experiments involving 8,000 evaluation points\nacross 4 CodeLlama models and 9 diverse benchmarks. Our framework achieves an\naverage absolute prediction error of 1.1% for code correctness scores, with\nbest- and worst-case errors of 0.3% and 1.9%, respectively. It also generalizes\nwell to other metrics, attaining average absolute errors of 2.15% for pass@1.\nThese results demonstrate the reliability and broad applicability of BIS, which\ncan significantly reduce the cost and effort of benchmarking LLMs in\ncode-related tasks.", "AI": {"tldr": "\u63d0\u51faBIS\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u63d0\u793a\u5206\u5e03\u9884\u6d4bLLM\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u65e0\u9700\u771f\u5b9e\u6570\u636e\uff0c\u663e\u8457\u964d\u4f4e\u8bc4\u4f30\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u9762\u4e34\u9ad8\u6210\u672c\u6784\u5efa\u548c\u6570\u636e\u96c6\u6c61\u67d3\u95ee\u9898\uff0c\u9700\u4e00\u79cd\u65e0\u9700\u771f\u5b9e\u6570\u636e\u7684\u6027\u80fd\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u91cd\u8981\u6027\u91c7\u6837\u7406\u8bba\u548c\u91cd\u8981\u6027\u52a0\u6743\u81ea\u7f16\u7801\u5668\uff0c\u91cd\u65b0\u52a0\u6743\u73b0\u6709\u57fa\u51c6\u6837\u672c\u4ee5\u9884\u6d4b\u65b0\u57fa\u51c6\u6027\u80fd\uff0c\u5f15\u5165\u6743\u91cd\u622a\u65ad\u7b56\u7565\u7a33\u5b9a\u4f30\u8ba1\u3002", "result": "\u57284\u4e2aCodeLlama\u6a21\u578b\u548c9\u4e2a\u57fa\u51c6\u4e0a\u6d4b\u8bd5\uff0c\u9884\u6d4b\u4ee3\u7801\u6b63\u786e\u6027\u5f97\u5206\u5e73\u5747\u8bef\u5dee1.1%\uff0c\u6700\u4f73\u548c\u6700\u5dee\u8bef\u5dee\u5206\u522b\u4e3a0.3%\u548c1.9%\u3002", "conclusion": "BIS\u53ef\u9760\u4e14\u5e7f\u6cdb\u9002\u7528\uff0c\u663e\u8457\u964d\u4f4e\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e2dLLM\u57fa\u51c6\u6d4b\u8bd5\u7684\u6210\u672c\u548c\u52aa\u529b\u3002"}}
{"id": "2508.00912", "pdf": "https://arxiv.org/pdf/2508.00912", "abs": "https://arxiv.org/abs/2508.00912", "authors": ["Ziyao Wang", "Guoheng Sun", "Yexiao He", "Zheyu Shen", "Bowei Tian", "Ang Li"], "title": "Predictive Auditing of Hidden Tokens in LLM APIs via Reasoning Length Estimation", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Commercial LLM services often conceal internal reasoning traces while still\ncharging users for every generated token, including those from hidden\nintermediate steps, raising concerns of token inflation and potential\noverbilling. This gap underscores the urgent need for reliable token auditing,\nyet achieving it is far from straightforward: cryptographic verification (e.g.,\nhash-based signature) offers little assurance when providers control the entire\nexecution pipeline, while user-side prediction struggles with the inherent\nvariance of reasoning LLMs, where token usage fluctuates across domains and\nprompt styles. To bridge this gap, we present PALACE (Predictive Auditing of\nLLM APIs via Reasoning Token Count Estimation), a user-side framework that\nestimates hidden reasoning token counts from prompt-answer pairs without access\nto internal traces. PALACE introduces a GRPO-augmented adaptation module with a\nlightweight domain router, enabling dynamic calibration across diverse\nreasoning tasks and mitigating variance in token usage patterns. Experiments on\nmath, coding, medical, and general reasoning benchmarks show that PALACE\nachieves low relative error and strong prediction accuracy, supporting both\nfine-grained cost auditing and inflation detection. Taken together, PALACE\nrepresents an important first step toward standardized predictive auditing,\noffering a practical path to greater transparency, accountability, and user\ntrust.", "AI": {"tldr": "PALACE\u662f\u4e00\u4e2a\u7528\u6237\u7aef\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u9690\u85cf\u7684\u63a8\u7406\u4ee4\u724c\u6570\u91cf\uff0c\u89e3\u51b3\u5546\u4e1aLLM\u670d\u52a1\u4e2d\u4ee4\u724c\u81a8\u80c0\u548c\u6f5c\u5728\u8d85\u989d\u8ba1\u8d39\u7684\u95ee\u9898\u3002", "motivation": "\u5546\u4e1aLLM\u670d\u52a1\u9690\u85cf\u5185\u90e8\u63a8\u7406\u75d5\u8ff9\uff0c\u53ef\u80fd\u5bfc\u81f4\u4ee4\u724c\u81a8\u80c0\u548c\u8d85\u989d\u8ba1\u8d39\uff0c\u4e9f\u9700\u53ef\u9760\u7684\u4ee4\u724c\u5ba1\u8ba1\u65b9\u6cd5\u3002", "method": "PALACE\u901a\u8fc7GRPO\u589e\u5f3a\u7684\u9002\u914d\u6a21\u5757\u548c\u8f7b\u91cf\u7ea7\u9886\u57df\u8def\u7531\u5668\uff0c\u52a8\u6001\u6821\u51c6\u4e0d\u540c\u63a8\u7406\u4efb\u52a1\u7684\u4ee4\u724c\u4f7f\u7528\u6a21\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPALACE\u5728\u6570\u5b66\u3001\u7f16\u7801\u3001\u533b\u5b66\u548c\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u4f4e\u76f8\u5bf9\u8bef\u5dee\u548c\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "PALACE\u4e3a\u6807\u51c6\u5316\u9884\u6d4b\u5ba1\u8ba1\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u63d0\u5347\u4e86\u900f\u660e\u5ea6\u548c\u7528\u6237\u4fe1\u4efb\u3002"}}
{"id": "2508.01412", "pdf": "https://arxiv.org/pdf/2508.01412", "abs": "https://arxiv.org/abs/2508.01412", "authors": ["Jinhao Pan", "Chahat Raj", "Ziwei Zhu"], "title": "Discovering Bias Associations through Open-Ended LLM Generations", "categories": ["cs.CL"], "comment": null, "summary": "Social biases embedded in Large Language Models (LLMs) raise critical\nconcerns, resulting in representational harms -- unfair or distorted portrayals\nof demographic groups -- that may be expressed in subtle ways through generated\nlanguage. Existing evaluation methods often depend on predefined\nidentity-concept associations, limiting their ability to surface new or\nunexpected forms of bias. In this work, we present the Bias Association\nDiscovery Framework (BADF), a systematic approach for extracting both known and\npreviously unrecognized associations between demographic identities and\ndescriptive concepts from open-ended LLM outputs. Through comprehensive\nexperiments spanning multiple models and diverse real-world contexts, BADF\nenables robust mapping and analysis of the varied concepts that characterize\ndemographic identities. Our findings advance the understanding of biases in\nopen-ended generation and provide a scalable tool for identifying and analyzing\nbias associations in LLMs. Data, code, and results are available at\nhttps://github.com/JP-25/Discover-Open-Ended-Generation", "AI": {"tldr": "BADF\u6846\u67b6\u7528\u4e8e\u53d1\u73b0LLM\u4e2d\u5df2\u77e5\u548c\u672a\u77e5\u7684\u793e\u4f1a\u504f\u89c1\u5173\u8054\uff0c\u901a\u8fc7\u5f00\u653e\u751f\u6210\u5185\u5bb9\u5206\u6790\u504f\u89c1\u3002", "motivation": "\u73b0\u6709\u504f\u89c1\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u5173\u8054\uff0c\u65e0\u6cd5\u6355\u6349\u65b0\u504f\u89c1\u5f62\u5f0f\uff0cBADF\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "BADF\u7cfb\u7edf\u6027\u5730\u4eceLLM\u5f00\u653e\u751f\u6210\u5185\u5bb9\u4e2d\u63d0\u53d6\u8eab\u4efd\u4e0e\u6982\u5ff5\u7684\u5173\u8054\uff0c\u652f\u6301\u591a\u6a21\u578b\u548c\u591a\u6837\u5316\u573a\u666f\u5b9e\u9a8c\u3002", "result": "BADF\u80fd\u5168\u9762\u6620\u5c04\u548c\u5206\u6790\u504f\u89c1\u5173\u8054\uff0c\u4e3aLLM\u504f\u89c1\u7814\u7a76\u63d0\u4f9b\u65b0\u5de5\u5177\u548c\u6570\u636e\u652f\u6301\u3002", "conclusion": "BADF\u63d0\u5347\u4e86\u5f00\u653e\u751f\u6210\u4e2d\u504f\u89c1\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u8bc6\u522b\u548c\u5206\u6790\u504f\u89c1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u5de5\u5177\u3002"}}
{"id": "2508.00827", "pdf": "https://arxiv.org/pdf/2508.00827", "abs": "https://arxiv.org/abs/2508.00827", "authors": ["Hudson de Martim"], "title": "A Schema.org Mapping for Brazilian Legal Norms: Toward Interoperable Legal Graphs and Open Government Data", "categories": ["cs.DL", "cs.AI", "cs.CY", "cs.IR"], "comment": null, "summary": "Open Government Data (OGD) initiatives aim to enhance transparency and public\nparticipation by making government data openly accessible. However, structuring\nlegal norms for machine readability remains a critical challenge for advancing\nLegal Tech applications such as Legal Knowledge Graphs (LKGs). Focusing on the\nNormas.leg.br portal initiative by the Brazilian National Congress, we propose\na unified mapping of Brazilian legislation to the schema.org/Legislation\nvocabulary via JSON-LD and Linked Data. Our approach covers both the conceptual\n\"Norm\" entity (mapped to sdo:Legislation) and its digital publications or\nmanifestations (mapped to sdo:LegislationObject). We detail key properties for\neach type, providing concrete examples and considering URN identifiers (per the\nLexML standard), multilingual support, versioning in the Official Journal, and\ninter-norm relationships (e.g., citations and references). Our structured\nschema improves the quality and interoperability of Brazilian legal data,\nfosters integration within the global OGD ecosystem, and facilitates the\ncreation of a wor", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5df4\u897f\u6cd5\u5f8b\u6570\u636e\u6620\u5c04\u5230schema.org/Legislation\u8bcd\u6c47\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u6cd5\u5f8b\u6570\u636e\u7684\u673a\u5668\u53ef\u8bfb\u6027\u548c\u4e92\u64cd\u4f5c\u6027\u3002", "motivation": "\u89e3\u51b3\u6cd5\u5f8b\u6570\u636e\u673a\u5668\u53ef\u8bfb\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4fc3\u8fdb\u6cd5\u5f8b\u79d1\u6280\u5e94\u7528\uff08\u5982\u6cd5\u5f8b\u77e5\u8bc6\u56fe\u8c31\uff09\u7684\u53d1\u5c55\u3002", "method": "\u4f7f\u7528JSON-LD\u548cLinked Data\u6280\u672f\uff0c\u5c06\u5df4\u897f\u6cd5\u5f8b\u6570\u636e\u7edf\u4e00\u6620\u5c04\u5230schema.org/Legislation\u8bcd\u6c47\uff0c\u6db5\u76d6\u6982\u5ff5\u5b9e\u4f53\u548c\u6570\u5b57\u51fa\u7248\u7269\u3002", "result": "\u63d0\u51fa\u7684\u7ed3\u6784\u5316\u6a21\u5f0f\u63d0\u9ad8\u4e86\u5df4\u897f\u6cd5\u5f8b\u6570\u636e\u7684\u8d28\u91cf\u548c\u4e92\u64cd\u4f5c\u6027\uff0c\u652f\u6301\u5168\u7403\u5f00\u653e\u653f\u5e9c\u6570\u636e\u751f\u6001\u7cfb\u7edf\u7684\u96c6\u6210\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6cd5\u5f8b\u6570\u636e\u7684\u6807\u51c6\u5316\u548c\u673a\u5668\u53ef\u8bfb\u6027\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u6cd5\u5f8b\u79d1\u6280\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.01208", "pdf": "https://arxiv.org/pdf/2508.01208", "abs": "https://arxiv.org/abs/2508.01208", "authors": ["Mingchen Mei", "Yi Li", "YiYao Qian", "Zijun Jia"], "title": "Calibrated Prediction Set in Fault Detection with Risk Guarantees via Significance Tests", "categories": ["cs.AI"], "comment": null, "summary": "Fault detection is crucial for ensuring the safety and reliability of modern\nindustrial systems. However, a significant scientific challenge is the lack of\nrigorous risk control and reliable uncertainty quantification in existing\ndiagnostic models, particularly when facing complex scenarios such as\ndistributional shifts. To address this issue, this paper proposes a novel fault\ndetection method that integrates significance testing with the conformal\nprediction framework to provide formal risk guarantees. The method transforms\nfault detection into a hypothesis testing task by defining a nonconformity\nmeasure based on model residuals. It then leverages a calibration dataset to\ncompute p-values for new samples, which are used to construct prediction sets\nmathematically guaranteed to contain the true label with a user-specified\nprobability, $1-\\alpha$. Fault classification is subsequently performed by\nanalyzing the intersection of the constructed prediction set with predefined\nnormal and fault label sets. Experimental results on cross-domain fault\ndiagnosis tasks validate the theoretical properties of our approach. The\nproposed method consistently achieves an empirical coverage rate at or above\nthe nominal level ($1-\\alpha$), demonstrating robustness even when the\nunderlying point-prediction models perform poorly. Furthermore, the results\nreveal a controllable trade-off between the user-defined risk level ($\\alpha$)\nand efficiency, where higher risk tolerance leads to smaller average prediction\nset sizes. This research contributes a theoretically grounded framework for\nfault detection that enables explicit risk control, enhancing the\ntrustworthiness of diagnostic systems in safety-critical applications and\nadvancing the field from simple point predictions to informative,\nuncertainty-aware outputs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u663e\u8457\u6027\u68c0\u9a8c\u548c\u5171\u5f62\u9884\u6d4b\u6846\u67b6\u7684\u65b0\u578b\u6545\u969c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e25\u683c\u7684\u98ce\u9669\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u8bca\u65ad\u6a21\u578b\u5728\u590d\u6742\u573a\u666f\uff08\u5982\u5206\u5e03\u504f\u79fb\uff09\u4e0b\u7f3a\u4e4f\u4e25\u683c\u7684\u98ce\u9669\u63a7\u5236\u548c\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "method": "\u5c06\u6545\u969c\u68c0\u6d4b\u8f6c\u5316\u4e3a\u5047\u8bbe\u68c0\u9a8c\u4efb\u52a1\uff0c\u57fa\u4e8e\u6a21\u578b\u6b8b\u5dee\u5b9a\u4e49\u975e\u4e00\u81f4\u6027\u5ea6\u91cf\uff0c\u5229\u7528\u6821\u51c6\u6570\u636e\u96c6\u8ba1\u7b97\u65b0\u6837\u672c\u7684p\u503c\uff0c\u6784\u5efa\u6570\u5b66\u4fdd\u8bc1\u7684\u9884\u6d4b\u96c6\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u7406\u8bba\u6027\u8d28\uff0c\u8986\u76d6\u7387\u59cb\u7ec8\u8fbe\u5230\u6216\u8d85\u8fc7\u540d\u4e49\u6c34\u5e73\uff0c\u4e14\u5728\u9ad8\u98ce\u9669\u5bb9\u5fcd\u5ea6\u4e0b\u9884\u6d4b\u96c6\u66f4\u5c0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6545\u969c\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u660e\u786e\u7684\u98ce\u9669\u63a7\u5236\uff0c\u63d0\u5347\u4e86\u8bca\u65ad\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2508.00921", "pdf": "https://arxiv.org/pdf/2508.00921", "abs": "https://arxiv.org/abs/2508.00921", "authors": ["Khaled Eskaf"], "title": "SmartDate: AI-Driven Precision Sorting and Quality Control in Date Fruits", "categories": ["cs.LG", "cs.AI", "eess.IV", "I.2.1; I.2.6; I.2.9; I.4.8"], "comment": "6 pages, 2 figures, published in Proceedings of the 21st IEEE\n  International Conference on High Performance Computing and Networking (HONET\n  2024), Doha, Qatar, December 2024", "summary": "SmartDate is an AI-powered system for automated sorting and quality control\nof date fruits. It combines deep learning, genetic algorithms, and\nreinforcement learning to improve classification accuracy and predict shelf\nlife. The system uses high-resolution imaging and Visible-Near-Infrared\n(VisNIR) spectral sensors to evaluate key features such as moisture, sugar\ncontent, and texture. Reinforcement learning enables real-time adaptation to\nproduction conditions, while genetic algorithms optimize model parameters.\nSmartDate achieved 94.5 percent accuracy, 93.1 percent F1-score, and an AUC-ROC\nof 0.96. The system reduces waste and ensures that only high-quality dates\nreach the market, setting a new benchmark in smart agriculture.", "AI": {"tldr": "SmartDate\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u5206\u62e3\u548c\u8d28\u91cf\u63a7\u5236\u6930\u67a3\u3002\u5b83\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u3001\u9057\u4f20\u7b97\u6cd5\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u9ad8\u5206\u8fa8\u7387\u6210\u50cf\u548cVisNIR\u5149\u8c31\u4f20\u611f\u5668\u8bc4\u4f30\u5173\u952e\u7279\u5f81\uff0c\u5b9e\u73b0\u4e8694.5%\u7684\u51c6\u786e\u7387\u548c0.96\u7684AUC-ROC\u3002", "motivation": "\u63d0\u9ad8\u6930\u67a3\u5206\u7c7b\u51c6\u786e\u6027\u5e76\u9884\u6d4b\u4fdd\u8d28\u671f\uff0c\u51cf\u5c11\u6d6a\u8d39\uff0c\u786e\u4fdd\u5e02\u573a\u4ec5\u63a5\u6536\u9ad8\u8d28\u91cf\u4ea7\u54c1\u3002", "method": "\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u3001\u9057\u4f20\u7b97\u6cd5\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5229\u7528\u9ad8\u5206\u8fa8\u7387\u6210\u50cf\u548cVisNIR\u5149\u8c31\u4f20\u611f\u5668\u8bc4\u4f30\u6c34\u5206\u3001\u7cd6\u542b\u91cf\u548c\u8d28\u5730\u7b49\u7279\u5f81\u3002", "result": "\u7cfb\u7edf\u8fbe\u523094.5%\u7684\u51c6\u786e\u7387\u300193.1%\u7684F1\u5206\u6570\u548c0.96\u7684AUC-ROC\u3002", "conclusion": "SmartDate\u4e3a\u667a\u80fd\u519c\u4e1a\u8bbe\u7acb\u4e86\u65b0\u6807\u51c6\uff0c\u663e\u8457\u51cf\u5c11\u6d6a\u8d39\u5e76\u63d0\u5347\u4ea7\u54c1\u8d28\u91cf\u3002"}}
{"id": "2508.01424", "pdf": "https://arxiv.org/pdf/2508.01424", "abs": "https://arxiv.org/abs/2508.01424", "authors": ["Haonan Bian", "Yutao Qi", "Rui Yang", "Yuanxi Che", "Jiaqian Wang", "Heming Xia", "Ranran Zhen"], "title": "From Query to Logic: Ontology-Driven Multi-Hop Reasoning in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs), despite their success in question answering,\nexhibit limitations in complex multi-hop question answering (MQA) tasks that\nnecessitate non-linear, structured reasoning. This limitation stems from their\ninability to adequately capture deep conceptual relationships between entities.\nTo overcome this challenge, we present **ORACLE** (**O**ntology-driven\n**R**easoning **A**nd **C**hain for **L**ogical **E**ucidation), a\ntraining-free framework that combines LLMs' generative capabilities with the\nstructural benefits of knowledge graphs. Our approach operates through three\nstages: (1) dynamic construction of question-specific knowledge ontologies\nusing LLMs, (2) transformation of these ontologies into First-Order Logic\nreasoning chains, and (3) systematic decomposition of the original query into\nlogically coherent sub-questions. Experimental results on several standard MQA\nbenchmarks show that our framework achieves highly competitive performance,\nrivaling current state-of-the-art models like DeepSeek-R1. Detailed analyses\nfurther confirm the effectiveness of each component, while demonstrating that\nour method generates more logical and interpretable reasoning chains than\nexisting approaches.", "AI": {"tldr": "ORACLE\u6846\u67b6\u7ed3\u5408LLMs\u4e0e\u77e5\u8bc6\u56fe\u8c31\uff0c\u901a\u8fc7\u52a8\u6001\u6784\u5efa\u77e5\u8bc6\u672c\u4f53\u3001\u8f6c\u5316\u4e3a\u903b\u8f91\u63a8\u7406\u94fe\u548c\u5206\u89e3\u95ee\u9898\uff0c\u63d0\u5347\u591a\u8df3\u95ee\u7b54\u6027\u80fd\u3002", "motivation": "LLMs\u5728\u590d\u6742\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0c\u56e0\u65e0\u6cd5\u6355\u6349\u5b9e\u4f53\u95f4\u6df1\u5c42\u5173\u7cfb\u3002", "method": "ORACLE\u5206\u4e09\u9636\u6bb5\uff1a\u52a8\u6001\u6784\u5efa\u95ee\u9898\u77e5\u8bc6\u672c\u4f53\u3001\u8f6c\u5316\u4e3a\u4e00\u9636\u903b\u8f91\u63a8\u7406\u94fe\u3001\u5206\u89e3\u539f\u95ee\u9898\u4e3a\u5b50\u95ee\u9898\u3002", "result": "\u5728\u591a\u4e2aMQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5ab2\u7f8eDeepSeek-R1\uff0c\u63a8\u7406\u94fe\u66f4\u903b\u8f91\u4e14\u53ef\u89e3\u91ca\u3002", "conclusion": "ORACLE\u6709\u6548\u63d0\u5347LLMs\u5728\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u6027\u80fd\uff0c\u751f\u6210\u66f4\u5408\u7406\u7684\u63a8\u7406\u94fe\u3002"}}
{"id": "2508.00867", "pdf": "https://arxiv.org/pdf/2508.00867", "abs": "https://arxiv.org/abs/2508.00867", "authors": ["Kwok Leong Tang", "Yi Jiang"], "title": "Better Recommendations: Validating AI-generated Subject Terms Through LOC Linked Data Service", "categories": ["cs.DL", "cs.AI", "cs.IR"], "comment": null, "summary": "This article explores the integration of AI-generated subject terms into\nlibrary cataloging, focusing on validation through the Library of Congress\nLinked Data Service. It examines the challenges of traditional subject\ncataloging under the Library of Congress Subject Headings system, including\ninefficiencies and cataloging backlogs. While generative AI shows promise in\nexpediting cataloging workflows, studies reveal significant limitations in the\naccuracy of AI-assigned subject headings. The article proposes a hybrid\napproach combining AI technology with human validation through LOC Linked Data\nService, aiming to enhance the precision, efficiency, and overall quality of\nmetadata creation in library cataloging practices.", "AI": {"tldr": "\u63a2\u8ba8AI\u751f\u6210\u4e3b\u9898\u8bcd\u5728\u56fe\u4e66\u9986\u7f16\u76ee\u4e2d\u7684\u5e94\u7528\uff0c\u7ed3\u5408LOC\u5173\u8054\u6570\u636e\u670d\u52a1\u9a8c\u8bc1\uff0c\u63d0\u51fa\u6df7\u5408\u65b9\u6cd5\u63d0\u5347\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u4e3b\u9898\u7f16\u76ee\u6548\u7387\u4f4e\u4e14\u79ef\u538b\u4e25\u91cd\uff0cAI\u867d\u6709\u6f5c\u529b\u4f46\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u9700\u7ed3\u5408\u4eba\u5de5\u9a8c\u8bc1\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408AI\u6280\u672f\u4e0eLOC\u5173\u8054\u6570\u636e\u670d\u52a1\u7684\u4eba\u5de5\u9a8c\u8bc1\u3002", "result": "\u6df7\u5408\u65b9\u6cd5\u6709\u671b\u63d0\u5347\u7f16\u76ee\u7cbe\u786e\u6027\u3001\u6548\u7387\u548c\u5143\u6570\u636e\u8d28\u91cf\u3002", "conclusion": "AI\u4e0e\u4eba\u5de5\u9a8c\u8bc1\u7ed3\u5408\u662f\u4f18\u5316\u56fe\u4e66\u9986\u7f16\u76ee\u7684\u53ef\u884c\u65b9\u5411\u3002"}}
{"id": "2508.01237", "pdf": "https://arxiv.org/pdf/2508.01237", "abs": "https://arxiv.org/abs/2508.01237", "authors": ["Cheng Tan", "Qi Chen", "Jingxuan Wei", "Gaowei Wu", "Zhangyang Gao", "Siyuan Li", "Bihui Yu", "Ruifeng Guo", "Stan Z. Li"], "title": "SketchAgent: Generating Structured Diagrams from Hand-Drawn Sketches", "categories": ["cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Hand-drawn sketches are a natural and efficient medium for capturing and\nconveying ideas. Despite significant advancements in controllable natural image\ngeneration, translating freehand sketches into structured, machine-readable\ndiagrams remains a labor-intensive and predominantly manual task. The primary\nchallenge stems from the inherent ambiguity of sketches, which lack the\nstructural constraints and semantic precision required for automated diagram\ngeneration. To address this challenge, we introduce SketchAgent, a multi-agent\nsystem designed to automate the transformation of hand-drawn sketches into\nstructured diagrams. SketchAgent integrates sketch recognition, symbolic\nreasoning, and iterative validation to produce semantically coherent and\nstructurally accurate diagrams, significantly reducing the need for manual\neffort. To evaluate the effectiveness of our approach, we propose the\nSketch2Diagram Benchmark, a comprehensive dataset and evaluation framework\nencompassing eight diverse diagram categories, such as flowcharts, directed\ngraphs, and model architectures. The dataset comprises over 6,000 high-quality\nexamples with token-level annotations, standardized preprocessing, and rigorous\nquality control. By streamlining the diagram generation process, SketchAgent\nholds great promise for applications in design, education, and engineering,\nwhile offering a significant step toward bridging the gap between intuitive\nsketching and machine-readable diagram generation. The benchmark is released at\nhttps://huggingface.co/datasets/DiagramAgent/Sketch2Diagram-Benchmark.", "AI": {"tldr": "SketchAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u65e8\u5728\u5c06\u624b\u7ed8\u8349\u56fe\u81ea\u52a8\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u56fe\u8868\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3002", "motivation": "\u624b\u7ed8\u8349\u56fe\u867d\u7136\u76f4\u89c2\u9ad8\u6548\uff0c\u4f46\u7f3a\u4e4f\u7ed3\u6784\u7ea6\u675f\u548c\u8bed\u4e49\u7cbe\u786e\u6027\uff0c\u96be\u4ee5\u81ea\u52a8\u8f6c\u6362\u4e3a\u673a\u5668\u53ef\u8bfb\u7684\u56fe\u8868\u3002", "method": "SketchAgent\u7ed3\u5408\u8349\u56fe\u8bc6\u522b\u3001\u7b26\u53f7\u63a8\u7406\u548c\u8fed\u4ee3\u9a8c\u8bc1\uff0c\u751f\u6210\u8bed\u4e49\u8fde\u8d2f\u4e14\u7ed3\u6784\u51c6\u786e\u7684\u56fe\u8868\u3002", "result": "\u63d0\u51fa\u4e86Sketch2Diagram Benchmark\u6570\u636e\u96c6\uff0c\u5305\u542b6,000\u591a\u4e2a\u9ad8\u8d28\u91cf\u793a\u4f8b\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "SketchAgent\u5728\u8bbe\u8ba1\u3001\u6559\u80b2\u548c\u5de5\u7a0b\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\uff0c\u586b\u8865\u4e86\u8349\u56fe\u4e0e\u673a\u5668\u53ef\u8bfb\u56fe\u8868\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002"}}
{"id": "2508.00922", "pdf": "https://arxiv.org/pdf/2508.00922", "abs": "https://arxiv.org/abs/2508.00922", "authors": ["Jinsoo Bae", "Seoung Bum Kim", "Hyungrok Do"], "title": "CaliMatch: Adaptive Calibration for Improving Safe Semi-supervised Learning", "categories": ["cs.LG"], "comment": null, "summary": "Semi-supervised learning (SSL) uses unlabeled data to improve the performance\nof machine learning models when labeled data is scarce. However, its real-world\napplications often face the label distribution mismatch problem, in which the\nunlabeled dataset includes instances whose ground-truth labels are absent from\nthe labeled training dataset. Recent studies, referred to as safe SSL, have\naddressed this issue by using both classification and out-of-distribution (OOD)\ndetection. However, the existing methods may suffer from overconfidence in deep\nneural networks, leading to increased SSL errors because of high confidence in\nincorrect pseudo-labels or OOD detection. To address this, we propose a novel\nmethod, CaliMatch, which calibrates both the classifier and the OOD detector to\nfoster safe SSL. CaliMatch presents adaptive label smoothing and temperature\nscaling, which eliminates the need to manually tune the smoothing degree for\neffective calibration. We give a theoretical justification for why improving\nthe calibration of both the classifier and the OOD detector is crucial in safe\nSSL. Extensive evaluations on CIFAR-10, CIFAR-100, SVHN, TinyImageNet, and\nImageNet demonstrate that CaliMatch outperforms the existing methods in safe\nSSL tasks.", "AI": {"tldr": "CaliMatch\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u534a\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6821\u51c6\u5206\u7c7b\u5668\u548cOOD\u68c0\u6d4b\u5668\u6765\u89e3\u51b3\u6807\u7b7e\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u907f\u514d\u4e86\u73b0\u6709\u65b9\u6cd5\u56e0\u8fc7\u5ea6\u81ea\u4fe1\u5bfc\u81f4\u7684\u9519\u8bef\u3002", "motivation": "\u89e3\u51b3\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u6807\u7b7e\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u907f\u514d\u56e0\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8fc7\u5ea6\u81ea\u4fe1\u5bfc\u81f4\u7684\u4f2a\u6807\u7b7e\u6216OOD\u68c0\u6d4b\u9519\u8bef\u3002", "method": "\u63d0\u51faCaliMatch\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u6807\u7b7e\u5e73\u6ed1\u548c\u6e29\u5ea6\u7f29\u653e\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u5e73\u6ed1\u5ea6\uff0c\u5b9e\u73b0\u5206\u7c7b\u5668\u548cOOD\u68c0\u6d4b\u5668\u7684\u6821\u51c6\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\uff08\u5982CIFAR-10\u3001ImageNet\u7b49\uff09\u4e0a\u9a8c\u8bc1\uff0cCaliMatch\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CaliMatch\u901a\u8fc7\u6821\u51c6\u5206\u7c7b\u5668\u548cOOD\u68c0\u6d4b\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u534a\u76d1\u7763\u5b66\u4e60\u7684\u6027\u80fd\u3002"}}
{"id": "2508.01450", "pdf": "https://arxiv.org/pdf/2508.01450", "abs": "https://arxiv.org/abs/2508.01450", "authors": ["Xinlin Zhuang", "Feilong Tang", "Haolin Yang", "Ming Hu", "Huifa Li", "Haochen Xue", "Yichen Li", "Junjun He", "Zongyuan Ge", "Ying Qian", "Imran Razzak"], "title": "Towards Efficient Medical Reasoning with Minimal Fine-Tuning Data", "categories": ["cs.CL"], "comment": "preprint, under review", "summary": "Supervised Fine-Tuning (SFT) plays a pivotal role in adapting Large Language\nModels (LLMs) to specialized domains such as medical reasoning. However,\nexisting SFT practices often rely on unfiltered datasets that contain redundant\nand low-quality samples, leading to substantial computational costs and\nsuboptimal performance. Although existing methods attempt to alleviate this\nproblem by selecting data based on sample difficulty, defined by knowledge and\nreasoning complexity, they overlook each sample's optimization utility\nreflected in its gradient. Interestingly, we find that gradient-based influence\nalone favors easy-to-optimize samples that cause large parameter shifts but\nlack deep reasoning chains, while difficulty alone selects noisy or overly\ncomplex cases that fail to guide stable optimization. Based on this\nobservation, we propose a data selection strategy, Difficulty-Influence\nQuadrant (DIQ), which prioritizes samples in the high-difficulty-high-influence\nquadrant to balance complex clinical reasoning with substantial gradient\ninfluence, enabling efficient medical reasoning with minimal fine-tuning data.\nFurthermore, Human and LLM-as-a-judge evaluations show that DIQ-selected\nsubsets demonstrate higher data quality and generate clinical reasoning that is\nmore aligned with expert practices in differential diagnosis, safety check, and\nevidence citation, as DIQ emphasizes samples that foster expert-like reasoning\npatterns. Extensive experiments on medical reasoning benchmarks demonstrate\nthat DIQ enables models fine-tuned on only 1% of selected data to match\nfull-dataset performance, while using 10% consistently outperforms the\nbaseline, highlighting the superiority of principled data selection over\nbrute-force scaling. The code and data are available at\nhttps://github.com/mihara-bot/DIQ.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDIQ\u7684\u6570\u636e\u9009\u62e9\u7b56\u7565\uff0c\u901a\u8fc7\u7ed3\u5408\u6837\u672c\u96be\u5ea6\u548c\u68af\u5ea6\u5f71\u54cd\uff0c\u4f18\u5316\u533b\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u5fae\u8c03\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u65b9\u6cd5\u4f9d\u8d56\u672a\u8fc7\u6ee4\u6570\u636e\u96c6\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6027\u80fd\u4e0d\u4f73\u3002\u4f20\u7edf\u65b9\u6cd5\u4ec5\u57fa\u4e8e\u6837\u672c\u96be\u5ea6\u6216\u68af\u5ea6\u5f71\u54cd\u9009\u62e9\u6570\u636e\uff0c\u672a\u80fd\u5e73\u8861\u590d\u6742\u63a8\u7406\u4e0e\u4f18\u5316\u6548\u679c\u3002", "method": "\u63d0\u51faDifficulty-Influence Quadrant\uff08DIQ\uff09\u7b56\u7565\uff0c\u4f18\u5148\u9009\u62e9\u9ad8\u96be\u5ea6\u9ad8\u68af\u5ea6\u5f71\u54cd\u7684\u6837\u672c\uff0c\u4ee5\u5e73\u8861\u4e34\u5e8a\u63a8\u7406\u548c\u4f18\u5316\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDIQ\u4ec5\u97001%\u6570\u636e\u5373\u53ef\u5339\u914d\u5168\u6570\u636e\u96c6\u6027\u80fd\uff0c10%\u6570\u636e\u65f6\u4f18\u4e8e\u57fa\u7ebf\u3002\u4eba\u7c7b\u548cLLM\u8bc4\u4f30\u663e\u793a\u5176\u751f\u6210\u7ed3\u679c\u66f4\u7b26\u5408\u4e13\u5bb6\u5b9e\u8df5\u3002", "conclusion": "DIQ\u901a\u8fc7\u6709\u539f\u5219\u7684\u6570\u636e\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2508.00955", "pdf": "https://arxiv.org/pdf/2508.00955", "abs": "https://arxiv.org/abs/2508.00955", "authors": ["Yeong-Joon Ju", "Seong-Whan Lee"], "title": "From Generator to Embedder: Harnessing Innate Abilities of Multimodal LLMs via Building Zero-Shot Discriminative Embedding Model", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have emerged as a promising solution\nfor universal embedding tasks, yet adapting their generative nature for\ndiscriminative representation learning remains a significant challenge. The\ndominant paradigm of large-scale contrastive pre-training suffers from critical\ninefficiencies, including prohibitive computational costs and a failure to\nleverage the intrinsic, instruction-following capabilities of MLLMs. To\novercome these limitations, we propose an efficient framework for universal\nmultimodal embeddings, which bridges this gap by centering on two synergistic\ncomponents. First, our hierarchical embedding prompt template employs a\ntwo-level instruction architecture that forces the model to produce\ndiscriminative representations. Building on this strong foundation, our second\ncomponent, self-aware hard negative sampling, redefines the fine-tuning process\nby leveraging the model's own understanding to efficiently mine challenging\nnegatives while actively filtering out potential false negatives. Our\ncomprehensive experiments show that our hierarchical prompt achieves zero-shot\nperformance competitive with contrastively trained baselines and enhances the\nfine-tuning process by lifting a simple in-batch negative baseline by 4.8\npoints on the MMEB benchmark. We further boost the performance via our\nself-aware hard negative sampling, achieving the state-of-the-art performance\nwithout the contrative pre-training. Our work presents an effective and\nefficient pathway to adapt MLLMs for universal embedding tasks, significantly\nreducing training time.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u591a\u6a21\u6001\u5d4c\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u63d0\u793a\u6a21\u677f\u548c\u81ea\u611f\u77e5\u786c\u8d1f\u91c7\u6837\uff0c\u89e3\u51b3\u4e86\u751f\u6210\u5f0fMLLM\u5728\u5224\u522b\u5f0f\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u6311\u6218\uff0c\u65e0\u9700\u5bf9\u6bd4\u9884\u8bad\u7ec3\u5373\u53ef\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3MLLM\u5728\u5224\u522b\u5f0f\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u4f4e\u6548\u95ee\u9898\uff0c\u907f\u514d\u5927\u89c4\u6a21\u5bf9\u6bd4\u9884\u8bad\u7ec3\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u672a\u5145\u5206\u5229\u7528MLLM\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u7684\u95ee\u9898\u3002", "method": "1. \u5206\u5c42\u5d4c\u5165\u63d0\u793a\u6a21\u677f\uff1a\u901a\u8fc7\u4e24\u7ea7\u6307\u4ee4\u67b6\u6784\u751f\u6210\u5224\u522b\u5f0f\u8868\u793a\uff1b2. \u81ea\u611f\u77e5\u786c\u8d1f\u91c7\u6837\uff1a\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7406\u89e3\u9ad8\u6548\u6316\u6398\u56f0\u96be\u8d1f\u6837\u672c\u5e76\u8fc7\u6ee4\u5047\u8d1f\u6837\u672c\u3002", "result": "\u5206\u5c42\u63d0\u793a\u5728\u96f6\u6837\u672c\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0e\u5bf9\u6bd4\u8bad\u7ec3\u57fa\u7ebf\u76f8\u5f53\uff0c\u5fae\u8c03\u6027\u80fd\u63d0\u53474.8\u70b9\uff1b\u81ea\u611f\u77e5\u786c\u8d1f\u91c7\u6837\u8fdb\u4e00\u6b65\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aMLLM\u5728\u901a\u7528\u5d4c\u5165\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u8def\u5f84\uff0c\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u3002"}}
{"id": "2508.01261", "pdf": "https://arxiv.org/pdf/2508.01261", "abs": "https://arxiv.org/abs/2508.01261", "authors": ["Sushant Mehta", "Raj Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Unifying Mixture of Experts and Multi-Head Latent Attention for Efficient Language Models", "categories": ["cs.AI"], "comment": null, "summary": "We present MoE-MLA-RoPE, a novel architecture combination that combines\nMixture of Experts (MoE) with Multi-head Latent Attention (MLA) and Rotary\nPosition Embeddings (RoPE) for efficient language modeling. Our approach\naddresses the fundamental trade-off between model capacity and computational\nefficiency through three key innovations: (1) fine-grained expert routing with\n64 micro-experts and top-$k$ selection, enabling flexible specialization\nthrough 3.6 * 10^7 possible expert combinations; (2) shared expert isolation\nthat dedicates 2 always active experts for common patterns while routing to 6\nof 62 specialized experts; and (3) gradient-conflict-free load balancing that\nmaintains expert utilization without interfering with primary loss\noptimization.\n  Extensive experiments on models ranging from 17M to 202M parameters\ndemonstrate that MoE-MLA-RoPE with compression ratio r=d/2 achieves 68% KV\ncache memory reduction and 3.2x inference speedup while maintaining competitive\nperplexity (0.8% degradation). Compared to the parameters with 53.9M\nparameters, MoE-MLA-RoPE improves the validation loss by 6.9% over the vanilla\ntransformers while using 42% fewer active parameters per forward pass.\nFLOP-matched experiments reveal even larger gains: 11.1% improvement with 3.2x\ninference acceleration. Automated evaluation using GPT-4 as a judge confirms\nquality improvements in generation, with higher scores on coherence (8.1/10),\ncreativity (7.9/10) and grammatical correctness (8.2/10). Our results establish\nthat architectural novelty, not parameter scaling, defines the efficiency\nfrontier for resource-constrained language model deployment.", "AI": {"tldr": "MoE-MLA-RoPE\u7ed3\u5408\u4e86Mixture of Experts\u3001Multi-head Latent Attention\u548cRotary Position Embeddings\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u4e13\u5bb6\u8def\u7531\u3001\u5171\u4eab\u4e13\u5bb6\u9694\u79bb\u548c\u65e0\u68af\u5ea6\u51b2\u7a81\u8d1f\u8f7d\u5e73\u8861\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u8bed\u8a00\u5efa\u6a21\uff0c\u663e\u8457\u51cf\u5c11\u5185\u5b58\u548c\u52a0\u901f\u63a8\u7406\u3002", "motivation": "\u89e3\u51b3\u6a21\u578b\u5bb9\u91cf\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u6548\u7387\u3002", "method": "1. \u7ec6\u7c92\u5ea6\u4e13\u5bb6\u8def\u7531\uff0864\u5fae\u4e13\u5bb6\u548ctop-k\u9009\u62e9\uff09\uff1b2. \u5171\u4eab\u4e13\u5bb6\u9694\u79bb\uff082\u4e2a\u5e38\u7528\u4e13\u5bb6\u548c62\u4e2a\u4e13\u7528\u4e13\u5bb6\uff09\uff1b3. \u65e0\u68af\u5ea6\u51b2\u7a81\u8d1f\u8f7d\u5e73\u8861\u3002", "result": "68% KV\u7f13\u5b58\u5185\u5b58\u51cf\u5c11\uff0c3.2\u500d\u63a8\u7406\u52a0\u901f\uff0c\u9a8c\u8bc1\u635f\u5931\u964d\u4f4e6.9%\uff0c\u751f\u6210\u8d28\u91cf\u63d0\u5347\uff08GPT-4\u8bc4\u5206\u66f4\u9ad8\uff09\u3002", "conclusion": "\u67b6\u6784\u521b\u65b0\u800c\u975e\u53c2\u6570\u6269\u5c55\u5b9a\u4e49\u4e86\u8d44\u6e90\u53d7\u9650\u8bed\u8a00\u6a21\u578b\u7684\u6548\u7387\u524d\u6cbf\u3002"}}
{"id": "2508.00923", "pdf": "https://arxiv.org/pdf/2508.00923", "abs": "https://arxiv.org/abs/2508.00923", "authors": ["Jiazhen Pan", "Bailiang Jian", "Paul Hager", "Yundi Zhang", "Che Liu", "Friedrike Jungmann", "Hongwei Bran Li", "Chenyu You", "Junde Wu", "Jiayuan Zhu", "Fenglin Liu", "Yuyuan Liu", "Niklas Bubeck", "Christian Wachinger", "Chen", "Chen", "Zhenyu Gong", "Cheng Ouyang", "Georgios Kaissis", "Benedikt Wiestler", "Daniel Rueckert"], "title": "Beyond Benchmarks: Dynamic, Automatic And Systematic Red-Teaming Agents For Trustworthy Medical Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Ensuring the safety and reliability of large language models (LLMs) in\nclinical practice is critical to prevent patient harm and promote trustworthy\nhealthcare applications of AI. However, LLMs are advancing so rapidly that\nstatic safety benchmarks often become obsolete upon publication, yielding only\nan incomplete and sometimes misleading picture of model trustworthiness. We\ndemonstrate that a Dynamic, Automatic, and Systematic (DAS) red-teaming\nframework that continuously stress-tests LLMs can reveal significant weaknesses\nof current LLMs across four safety-critical domains: robustness, privacy,\nbias/fairness, and hallucination. A suite of adversarial agents is applied to\nautonomously mutate test cases, identify/evolve unsafe-triggering strategies,\nand evaluate responses, uncovering vulnerabilities in real time without human\nintervention. Applying DAS to 15 proprietary and open-source LLMs revealed a\nstark contrast between static benchmark performance and vulnerability under\nadversarial pressure. Despite a median MedQA accuracy exceeding 80\\%, 94\\% of\npreviously correct answers failed our dynamic robustness tests. We observed\nsimilarly high failure rates across other domains: privacy leaks were elicited\nin 86\\% of scenarios, cognitive-bias priming altered clinical recommendations\nin 81\\% of fairness tests, and we identified hallucination rates exceeding 66\\%\nin widely used models. Such profound residual risks are incompatible with\nroutine clinical practice. By converting red-teaming from a static checklist\ninto a dynamic stress-test audit, DAS red-teaming offers the surveillance that\nhospitals/regulators/technology vendors require as LLMs become embedded in\npatient chatbots, decision-support dashboards, and broader healthcare\nworkflows. Our framework delivers an evolvable, scalable, and reliable\nsafeguard for the next generation of medical AI.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u3001\u81ea\u52a8\u3001\u7cfb\u7edf\u7684\u7ea2\u961f\u6d4b\u8bd5\u6846\u67b6\uff08DAS\uff09\uff0c\u7528\u4e8e\u6301\u7eed\u68c0\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u5b89\u5168\u6027\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6355\u6349\u7684\u4e25\u91cd\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740LLMs\u5728\u533b\u7597\u9886\u57df\u7684\u5feb\u901f\u5e94\u7528\uff0c\u9759\u6001\u5b89\u5168\u6d4b\u8bd5\u5df2\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u4e9f\u9700\u52a8\u6001\u65b9\u6cd5\u5b9e\u65f6\u53d1\u73b0\u6a21\u578b\u5f31\u70b9\uff0c\u786e\u4fdd\u60a3\u8005\u5b89\u5168\u548cAI\u53ef\u4fe1\u5ea6\u3002", "method": "\u91c7\u7528DAS\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u4ee3\u7406\u81ea\u52a8\u751f\u6210\u548c\u6f14\u5316\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5b9e\u65f6\u8bc4\u4f30LLMs\u5728\u9c81\u68d2\u6027\u3001\u9690\u79c1\u3001\u504f\u89c1/\u516c\u5e73\u6027\u548c\u5e7b\u89c9\u56db\u4e2a\u5173\u952e\u9886\u57df\u7684\u5b89\u5168\u6027\u3002", "result": "\u6d4b\u8bd515\u4e2aLLMs\u53d1\u73b0\uff0c\u9759\u6001\u57fa\u51c6\u8868\u73b0\u4e0e\u5b9e\u9645\u6f0f\u6d1e\u5b58\u5728\u5de8\u5927\u5dee\u8ddd\uff1a94%\u7684\u6b63\u786e\u56de\u7b54\u5728\u52a8\u6001\u6d4b\u8bd5\u4e2d\u5931\u8d25\uff0c\u9690\u79c1\u6cc4\u9732\u738786%\uff0c\u504f\u89c1\u5f71\u54cd81%\uff0c\u5e7b\u89c9\u7387\u8d8566%\u3002", "conclusion": "DAS\u6846\u67b6\u4e3a\u533b\u7597AI\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u52a8\u6001\u5b89\u5168\u76d1\u6d4b\u5de5\u5177\uff0c\u5f25\u8865\u4e86\u9759\u6001\u6d4b\u8bd5\u7684\u4e0d\u8db3\uff0c\u662f\u672a\u6765\u4e34\u5e8a\u5e94\u7528\u4e2d\u4e0d\u53ef\u6216\u7f3a\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2508.01473", "pdf": "https://arxiv.org/pdf/2508.01473", "abs": "https://arxiv.org/abs/2508.01473", "authors": ["Yiming Zeng", "Jinghan Cao", "Zexin Li", "Yiming Chen", "Tao Ren", "Dawei Xiang", "Xidong Wu", "Shangqian Gao", "Tingting Yu"], "title": "TreeDiff: AST-Guided Code Generation with Diffusion LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in diffusion-based language models have opened new\npossibilities for controllable and bidirectional sequence generation. These\nmodels provide an alternative to traditional autoregressive approaches by\nframing text generation as an iterative denoising process. However, applying\ndiffusion models to structured domains such as source code remains a\nsignificant challenge. Programming languages differ from natural language in\nthat they follow strict syntactic and semantic rules, with hierarchical\norganization that must be preserved for correctness. Standard token-level\ncorruption techniques used during training often ignore this structure, which\nmay hinder the model's ability to learn meaningful representations of code. To\naddress this limitation, we propose a syntax-aware diffusion framework that\nincorporates structural priors from Abstract Syntax Trees (ASTs) into the\ndenoising process. Instead of masking individual tokens at random, we\nselectively corrupt syntactically meaningful code spans derived from AST\nsubtrees. This enables the model to reconstruct programs in a way that respects\ngrammatical boundaries and captures long-range dependencies. Experimental\nresults demonstrate that syntax-aware corruption significantly improves\nsyntactic correctness, reconstruction accuracy, and generalization to unseen\ncode patterns. These findings highlight the potential of incorporating\nstructural information into diffusion-based training and suggest that\nsyntax-guided denoising is a promising direction for advancing diffusion-based\nlanguage models in code generation tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u6cd5\u611f\u77e5\u7684\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u7684\u7ed3\u6784\u5148\u9a8c\uff0c\u6539\u8fdb\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6269\u6563\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6269\u6563\u6a21\u578b\u5728\u7ed3\u6784\u5316\u9886\u57df\uff08\u5982\u6e90\u4ee3\u7801\uff09\u4e2d\u7684\u5e94\u7528\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u7f16\u7a0b\u8bed\u8a00\u5177\u6709\u4e25\u683c\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u89c4\u5219\uff0c\u6807\u51c6\u6807\u8bb0\u7ea7\u566a\u58f0\u5904\u7406\u53ef\u80fd\u5ffd\u7565\u8fd9\u4e9b\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u8bed\u6cd5\u611f\u77e5\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u7834\u574fAST\u5b50\u6811\u4e2d\u7684\u8bed\u6cd5\u6709\u610f\u4e49\u4ee3\u7801\u7247\u6bb5\uff0c\u800c\u975e\u968f\u673a\u6807\u8bb0\uff0c\u4ee5\u5c0a\u91cd\u8bed\u6cd5\u8fb9\u754c\u5e76\u6355\u6349\u957f\u7a0b\u4f9d\u8d56\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8bed\u6cd5\u611f\u77e5\u566a\u58f0\u5904\u7406\u663e\u8457\u63d0\u9ad8\u4e86\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u91cd\u6784\u51c6\u786e\u6027\u548c\u5bf9\u672a\u89c1\u4ee3\u7801\u6a21\u5f0f\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7ed3\u5408\u7ed3\u6784\u4fe1\u606f\u7684\u6269\u6563\u8bad\u7ec3\u5177\u6709\u6f5c\u529b\uff0c\u8bed\u6cd5\u5f15\u5bfc\u7684\u53bb\u566a\u662f\u6539\u8fdb\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u6269\u6563\u6a21\u578b\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2508.00956", "pdf": "https://arxiv.org/pdf/2508.00956", "abs": "https://arxiv.org/abs/2508.00956", "authors": ["Chuan He", "Yang Chen", "Wuliang Huang", "Tianyi Zheng", "Jianhu Chen", "Bin Dou", "Yice Luo", "Yun Zhu", "Baokun Wang", "Yongchao Liu", "Xing Fu", "Yu Cheng", "Chuntao Hong", "Weiqiang Wang", "Xin-Wei Yao"], "title": "Learning Unified User Quantized Tokenizers for User Representation", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Multi-source user representation learning plays a critical role in enabling\npersonalized services on web platforms (e.g., Alipay). While prior works have\nadopted late-fusion strategies to combine heterogeneous data sources, they\nsuffer from three key limitations: lack of unified representation frameworks,\nscalability and storage issues in data compression, and inflexible cross-task\ngeneralization. To address these challenges, we propose U^2QT (Unified User\nQuantized Tokenizers), a novel framework that integrates cross-domain knowledge\ntransfer with early fusion of heterogeneous domains. Our framework employs a\ntwo-stage architecture: first, a causal Q-Former projects domain-specific\nfeatures into a shared causal representation space to preserve inter-modality\ndependencies; second, a multi-view RQ-VAE discretizes causal embeddings into\ncompact tokens through shared and source-specific codebooks, enabling efficient\nstorage while maintaining semantic coherence. Experimental results showcase\nU^2QT's advantages across diverse downstream tasks, outperforming task-specific\nbaselines in future behavior prediction and recommendation tasks while\nachieving efficiency gains in storage and computation. The unified tokenization\nframework enables seamless integration with language models and supports\nindustrial-scale applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faU^2QT\u6846\u67b6\uff0c\u901a\u8fc7\u65e9\u671f\u878d\u5408\u5f02\u6784\u6570\u636e\u548c\u7edf\u4e00\u8868\u5f81\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u591a\u6e90\u7528\u6237\u8868\u5f81\u5b66\u4e60\u4e2d\u7684\u5b58\u50a8\u3001\u6269\u5c55\u6027\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5f02\u6784\u6570\u636e\u878d\u5408\u4e2d\u5b58\u5728\u7edf\u4e00\u8868\u5f81\u6846\u67b6\u7f3a\u5931\u3001\u5b58\u50a8\u4e0e\u6269\u5c55\u6027\u95ee\u9898\u4ee5\u53ca\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u6311\u6218\u3002", "method": "U^2QT\u91c7\u7528\u4e24\u9636\u6bb5\u67b6\u6784\uff1a1\uff09\u56e0\u679cQ-Former\u5c06\u57df\u7279\u5b9a\u7279\u5f81\u6620\u5c04\u5230\u5171\u4eab\u56e0\u679c\u8868\u5f81\u7a7a\u95f4\uff1b2\uff09\u591a\u89c6\u56feRQ-VAE\u5c06\u8868\u5f81\u79bb\u6563\u5316\u4e3a\u7d27\u51d1\u4ee4\u724c\uff0c\u652f\u6301\u9ad8\u6548\u5b58\u50a8\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cU^2QT\u5728\u884c\u4e3a\u9884\u6d4b\u548c\u63a8\u8350\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u7ebf\uff0c\u540c\u65f6\u5728\u5b58\u50a8\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "U^2QT\u7684\u7edf\u4e00\u4ee4\u724c\u5316\u6846\u67b6\u652f\u6301\u4e0e\u8bed\u8a00\u6a21\u578b\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u7ea7\u5e94\u7528\u3002"}}
{"id": "2508.01268", "pdf": "https://arxiv.org/pdf/2508.01268", "abs": "https://arxiv.org/abs/2508.01268", "authors": ["Roya Arkhmammadova", "Hosein Madadi Tamar", "M. Emre Gursoy"], "title": "Win-k: Improved Membership Inference Attacks on Small Language Models", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "Small language models (SLMs) are increasingly valued for their efficiency and\ndeployability in resource-constrained environments, making them useful for\non-device, privacy-sensitive, and edge computing applications. On the other\nhand, membership inference attacks (MIAs), which aim to determine whether a\ngiven sample was used in a model's training, are an important threat with\nserious privacy and intellectual property implications. In this paper, we study\nMIAs on SLMs. Although MIAs were shown to be effective on large language models\n(LLMs), they are relatively less studied on emerging SLMs, and furthermore,\ntheir effectiveness decreases as models get smaller. Motivated by this finding,\nwe propose a new MIA called win-k, which builds on top of a state-of-the-art\nattack (min-k). We experimentally evaluate win-k by comparing it with five\nexisting MIAs using three datasets and eight SLMs. Results show that win-k\noutperforms existing MIAs in terms of AUROC, TPR @ 1% FPR, and FPR @ 99% TPR\nmetrics, especially on smaller models.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9488\u5bf9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08MIAs\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3awin-k\u7684\u65b0\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u3002", "motivation": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u56e0\u5176\u9ad8\u6548\u6027\u548c\u53ef\u90e8\u7f72\u6027\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u53d7\u5230\u91cd\u89c6\uff0c\u4f46\u6210\u5458\u63a8\u7406\u653b\u51fb\u5bf9\u5176\u9690\u79c1\u548c\u77e5\u8bc6\u4ea7\u6743\u6784\u6210\u5a01\u80c1\u3002\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u5728\u5c0f\u578b\u6a21\u578b\u4e0a\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u653b\u51fb\u65b9\u6cd5\uff08min-k\uff09\u7684\u65b0\u653b\u51fb\u65b9\u6cd5win-k\uff0c\u5e76\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u548c\u516b\u4e2aSLMs\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cwin-k\u5728AUROC\u3001TPR @ 1% FPR\u548cFPR @ 99% TPR\u7b49\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u66f4\u5c0f\u7684\u6a21\u578b\u4e0a\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "win-k\u662f\u4e00\u79cd\u6709\u6548\u7684\u9488\u5bf9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5c0f\u578b\u6a21\u578b\u4e0a\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2508.00926", "pdf": "https://arxiv.org/pdf/2508.00926", "abs": "https://arxiv.org/abs/2508.00926", "authors": ["Feng Xu", "Hui Wang", "Yuting Huang", "Danwei Zhang", "Zizhu Fan"], "title": "Hybrid Hypergraph Networks for Multimodal Sequence Data Classification", "categories": ["cs.LG"], "comment": "9 pages, 5 figures", "summary": "Modeling temporal multimodal data poses significant challenges in\nclassification tasks, particularly in capturing long-range temporal\ndependencies and intricate cross-modal interactions. Audiovisual data, as a\nrepresentative example, is inherently characterized by strict temporal order\nand diverse modalities. Effectively leveraging the temporal structure is\nessential for understanding both intra-modal dynamics and inter-modal\ncorrelations. However, most existing approaches treat each modality\nindependently and rely on shallow fusion strategies, which overlook temporal\ndependencies and hinder the model's ability to represent complex structural\nrelationships. To address the limitation, we propose the hybrid hypergraph\nnetwork (HHN), a novel framework that models temporal multimodal data via a\nsegmentation-first, graph-later strategy. HHN splits sequences into timestamped\nsegments as nodes in a heterogeneous graph. Intra-modal structures are captured\nvia hyperedges guided by a maximum entropy difference criterion, enhancing node\nheterogeneity and structural discrimination, followed by hypergraph convolution\nto extract high-order dependencies. Inter-modal links are established through\ntemporal alignment and graph attention for semantic fusion. HHN achieves\nstate-of-the-art (SOTA) results on four multimodal datasets, demonstrating its\neffectiveness in complex classification tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u8d85\u56fe\u7f51\u7edc\uff08HHN\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6bb5\u4f18\u5148\u3001\u56fe\u7ed3\u6784\u540e\u7eed\u7684\u7b56\u7565\u5efa\u6a21\u65f6\u5e8f\u591a\u6a21\u6001\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u65f6\u5e8f\u4f9d\u8d56\u548c\u6a21\u6001\u95f4\u590d\u6742\u5173\u7cfb\u7684\u95ee\u9898\u3002", "motivation": "\u65f6\u5e8f\u591a\u6a21\u6001\u6570\u636e\uff08\u5982\u89c6\u542c\u6570\u636e\uff09\u7684\u5206\u7c7b\u4efb\u52a1\u9762\u4e34\u957f\u7a0b\u65f6\u5e8f\u4f9d\u8d56\u548c\u8de8\u6a21\u6001\u4ea4\u4e92\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u6a21\u6001\u72ec\u7acb\u5904\u7406\u4e14\u878d\u5408\u7b56\u7565\u6d45\u5c42\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5bf9\u590d\u6742\u7ed3\u6784\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "HHN\u5c06\u5e8f\u5217\u5206\u5272\u4e3a\u65f6\u95f4\u6233\u6bb5\u4f5c\u4e3a\u5f02\u6784\u56fe\u8282\u70b9\uff0c\u901a\u8fc7\u6700\u5927\u71b5\u5dee\u5f02\u51c6\u5219\u6355\u83b7\u6a21\u6001\u5185\u7ed3\u6784\uff0c\u518d\u901a\u8fc7\u8d85\u56fe\u5377\u79ef\u63d0\u53d6\u9ad8\u9636\u4f9d\u8d56\uff0c\u5e76\u901a\u8fc7\u65f6\u5e8f\u5bf9\u9f50\u548c\u56fe\u6ce8\u610f\u529b\u5efa\u7acb\u6a21\u6001\u95f4\u94fe\u63a5\u3002", "result": "\u5728\u56db\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86SOTA\u7ed3\u679c\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u590d\u6742\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "HHN\u901a\u8fc7\u5206\u6bb5\u548c\u56fe\u7ed3\u6784\u7b56\u7565\u6709\u6548\u5efa\u6a21\u65f6\u5e8f\u591a\u6a21\u6001\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\u3002"}}
{"id": "2508.01480", "pdf": "https://arxiv.org/pdf/2508.01480", "abs": "https://arxiv.org/abs/2508.01480", "authors": ["Dimitra Panou", "Alexandros C. Dimopoulos", "Manolis Koubarakis", "Martin Reczko"], "title": "Harnessing Collective Intelligence of LLMs for Robust Biomedical QA: A Multi-Model Approach", "categories": ["cs.CL"], "comment": null, "summary": "Biomedical text mining and question-answering are essential yet highly\ndemanding tasks, particularly in the face of the exponential growth of\nbiomedical literature. In this work, we present our participation in the 13th\nedition of the BioASQ challenge, which involves biomedical semantic\nquestion-answering for Task 13b and biomedical question-answering for\ndeveloping topics for the Synergy task. We deploy a selection of open-source\nlarge language models (LLMs) as retrieval-augmented generators to answer\nbiomedical questions. Various models are used to process the questions. A\nmajority voting system combines their output to determine the final answer for\nYes/No questions, while for list and factoid type questions, the union of their\nanswers in used. We evaluated 13 state-of-the-art open source LLMs, exploring\nall possible model combinations to contribute to the final answer, resulting in\ntailored LLM pipelines for each question type. Our findings provide valuable\ninsight into which combinations of LLMs consistently produce superior results\nfor specific question types. In the four rounds of the 2025 BioASQ challenge,\nour system achieved notable results: in the Synergy task, we secured 1st place\nfor ideal answers and 2nd place for exact answers in round 2, as well as two\nshared 1st places for exact answers in round 3 and 4.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u5728BioASQ\u6311\u6218\u4e2d\u4f7f\u7528\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u751f\u7269\u533b\u5b66\u95ee\u7b54\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6570\u6295\u7968\u548c\u7b54\u6848\u8054\u5408\u7b56\u7565\u4f18\u5316\u7ed3\u679c\uff0c\u5e76\u57282025\u5e74\u6311\u6218\u4e2d\u53d6\u5f97\u4f18\u5f02\u6210\u7ee9\u3002", "motivation": "\u751f\u7269\u533b\u5b66\u6587\u672c\u6316\u6398\u548c\u95ee\u7b54\u4efb\u52a1\u9700\u6c42\u9ad8\uff0c\u4f46\u6587\u732e\u589e\u957f\u8fc5\u901f\uff0c\u9700\u8981\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5f00\u6e90LLMs\u4f5c\u4e3a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5668\uff0c\u7ed3\u5408\u591a\u6570\u6295\u7968\u548c\u7b54\u6848\u8054\u5408\u7b56\u7565\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u95ee\u9898\u3002", "result": "\u5728BioASQ\u6311\u6218\u4e2d\u53d6\u5f97\u591a\u9879\u4f18\u5f02\u6210\u7ee9\uff0c\u5305\u62ec\u7406\u60f3\u7b54\u6848\u7b2c\u4e00\u540d\u548c\u7cbe\u786e\u7b54\u6848\u7b2c\u4e8c\u540d\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7279\u5b9a\u95ee\u9898\u7c7b\u578b\u7684\u6700\u4f18LLM\u7ec4\u5408\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2508.01273", "pdf": "https://arxiv.org/pdf/2508.01273", "abs": "https://arxiv.org/abs/2508.01273", "authors": ["Xianda Zheng", "Zijian Huang", "Meng-Fen Chiang", "Michael J. Witbrock", "Kaiqi Zhao"], "title": "KCR: Resolving Long-Context Knowledge Conflicts via Reasoning in LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Knowledge conflicts commonly arise across diverse sources, and their\nprevalence has increased with the advent of LLMs. When dealing with conflicts\nbetween multiple contexts, also known as \\emph{inter-context knowledge\nconflicts}, LLMs are often confused by lengthy and conflicting contexts. To\naddress this challenge, we propose the Knowledge Conflict Reasoning (KCR)\nframework, which enhances the ability of LLMs to resolve conflicting knowledge.\nThe key idea of KCR is to train backbone LLMs to establish a correct reasoning\nprocess by rewarding them for selecting and adhering to the context with\nstronger logical consistency when presented with conflicting contexts.\nSpecifically, we first extract reasoning paths, represented by either text or\nlocal knowledge graphs, from the conflicting long contexts. Subsequently, we\nemploy Reinforcement Learning to encourage the model to learn the paradigm of\nreasoning process that follows correct reasoning paths rather than the\nincorrect counterparts. This enables the backbone models to genuinely acquire\nthe capability to resolve inter-context knowledge conflicts within long\ncontexts. Experimental results demonstrate that our framework significantly\nimproves the ability of various backbone models to resolve knowledge conflicts\nin long-context scenarios, yielding substantial performance gains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u77e5\u8bc6\u51b2\u7a81\u63a8\u7406\uff08KCR\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLMs\u5728\u957f\u6587\u672c\u51b2\u7a81\u4e2d\u9009\u62e9\u903b\u8f91\u4e00\u81f4\u7684\u4e0a\u4e0b\u6587\uff0c\u63d0\u5347\u5176\u89e3\u51b3\u77e5\u8bc6\u51b2\u7a81\u7684\u80fd\u529b\u3002", "motivation": "LLMs\u5728\u5904\u7406\u591a\u6e90\u77e5\u8bc6\u51b2\u7a81\u65f6\u5bb9\u6613\u6df7\u6dc6\uff0c\u5c24\u5176\u662f\u5728\u957f\u6587\u672c\u51b2\u7a81\u4e2d\uff0c\u9700\u8981\u63d0\u5347\u5176\u89e3\u51b3\u51b2\u7a81\u7684\u80fd\u529b\u3002", "method": "\u63d0\u53d6\u51b2\u7a81\u957f\u6587\u672c\u4e2d\u7684\u63a8\u7406\u8def\u5f84\uff08\u6587\u672c\u6216\u5c40\u90e8\u77e5\u8bc6\u56fe\u8c31\uff09\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u9009\u62e9\u903b\u8f91\u4e00\u81f4\u7684\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cKCR\u663e\u8457\u63d0\u5347\u4e86\u591a\u79cd\u9aa8\u5e72\u6a21\u578b\u5728\u957f\u6587\u672c\u573a\u666f\u4e2d\u89e3\u51b3\u77e5\u8bc6\u51b2\u7a81\u7684\u80fd\u529b\u3002", "conclusion": "KCR\u6846\u67b6\u6709\u6548\u589e\u5f3a\u4e86LLMs\u89e3\u51b3\u77e5\u8bc6\u51b2\u7a81\u7684\u80fd\u529b\uff0c\u5c24\u5176\u5728\u957f\u6587\u672c\u51b2\u7a81\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2508.00930", "pdf": "https://arxiv.org/pdf/2508.00930", "abs": "https://arxiv.org/abs/2508.00930", "authors": ["M. Ontivero-Ortega", "A. Fania", "A. Lacalamita", "R. Bellotti", "A. Monaco", "S. Stramaglia"], "title": "Cooperative effects in feature importance of individual patterns: application to air pollutants and Alzheimer disease", "categories": ["cs.LG", "physics.data-an"], "comment": null, "summary": "Leveraging recent advances in the analysis of synergy and redundancy in\nsystems of random variables, an adaptive version of the widely used metric\nLeave One Covariate Out (LOCO) has been recently proposed to quantify\ncooperative effects in feature importance (Hi-Fi), a key technique in\nexplainable artificial intelligence (XAI), so as to disentangle high-order\neffects involving a particular input feature in regression problems.\nDifferently from standard feature importance tools, where a single score\nmeasures the relevance of each feature, each feature is here characterized by\nthree scores, a two-body (unique) score and higher-order scores (redundant and\nsynergistic). This paper presents a framework to assign those three scores\n(unique, redundant, and synergistic) to each individual pattern of the data\nset, while comparing it with the well-known measure of feature importance named\n{\\it Shapley effect}. To illustrate the potential of the proposed framework, we\nfocus on a One-Health application: the relation between air pollutants and\nAlzheimer's disease mortality rate. Our main result is the synergistic\nassociation between features related to $O_3$ and $NO_2$ with mortality,\nespecially in the provinces of Bergamo e Brescia; notably also the density of\nurban green areas displays synergistic influence with pollutants for the\nprediction of AD mortality. Our results place local Hi-Fi as a promising tool\nof wide applicability, which opens new perspectives for XAI as well as to\nanalyze high-order relationships in complex systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7248\u672c\u7684LOCO\u65b9\u6cd5\uff08Hi-Fi\uff09\uff0c\u7528\u4e8e\u91cf\u5316\u7279\u5f81\u91cd\u8981\u6027\u4e2d\u7684\u534f\u540c\u6548\u5e94\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u5206\u6570\uff08\u552f\u4e00\u3001\u5197\u4f59\u548c\u534f\u540c\uff09\u63cf\u8ff0\u6bcf\u4e2a\u7279\u5f81\u3002\u4e0e\u6807\u51c6\u65b9\u6cd5\u4e0d\u540c\uff0c\u8be5\u65b9\u6cd5\u5728\u56de\u5f52\u95ee\u9898\u4e2d\u63ed\u793a\u4e86\u9ad8\u9636\u6548\u5e94\uff0c\u5e76\u4ee5\u4e00\u4e2a\u5065\u5eb7\u5e94\u7528\u4e3a\u4f8b\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u7279\u5f81\u91cd\u8981\u6027\u5de5\u5177\u4ec5\u901a\u8fc7\u5355\u4e00\u5206\u6570\u8861\u91cf\u7279\u5f81\u76f8\u5173\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u9ad8\u9636\u6548\u5e94\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7Hi-Fi\u65b9\u6cd5\uff0c\u91cf\u5316\u7279\u5f81\u7684\u534f\u540c\u548c\u5197\u4f59\u6548\u5e94\uff0c\u4ece\u800c\u66f4\u5168\u9762\u5730\u7406\u89e3\u7279\u5f81\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94LOCO\u65b9\u6cd5\uff08Hi-Fi\uff09\uff0c\u4e3a\u6bcf\u4e2a\u7279\u5f81\u5206\u914d\u4e09\u4e2a\u5206\u6570\uff08\u552f\u4e00\u3001\u5197\u4f59\u548c\u534f\u540c\uff09\uff0c\u5e76\u4e0eShapley\u6548\u5e94\u8fdb\u884c\u6bd4\u8f83\u3002\u5e94\u7528\u4e8e\u7a7a\u6c14\u6c61\u67d3\u7269\u4e0e\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u6b7b\u4ea1\u7387\u7684\u5173\u7cfb\u5206\u6790\u3002", "result": "\u53d1\u73b0O3\u548cNO2\u4e0e\u6b7b\u4ea1\u7387\u4e4b\u95f4\u5b58\u5728\u534f\u540c\u6548\u5e94\uff0c\u5c24\u5176\u5728Bergamo\u548cBrescia\u5730\u533a\u3002\u57ce\u5e02\u7eff\u5730\u5bc6\u5ea6\u4e5f\u4e0e\u6c61\u67d3\u7269\u534f\u540c\u5f71\u54cd\u6b7b\u4ea1\u7387\u9884\u6d4b\u3002", "conclusion": "Hi-Fi\u4f5c\u4e3a\u4e00\u79cd\u5e7f\u6cdb\u9002\u7528\u7684\u5de5\u5177\uff0c\u4e3aXAI\u548c\u590d\u6742\u7cfb\u7edf\u7684\u9ad8\u9636\u5173\u7cfb\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.01486", "pdf": "https://arxiv.org/pdf/2508.01486", "abs": "https://arxiv.org/abs/2508.01486", "authors": ["Vallabhaneni Raj Kumar", "Ashwin S", "Supriya Manna", "Niladri Sett", "Cheedella V S N M S Hema Harshitha", "Kurakula Harshitha", "Anand Kumar Sharma", "Basina Deepakraj", "Tanuj Sarkar", "Bondada Navaneeth Krishna", "Samanthapudi Shakeer"], "title": "TeSent: A Benchmark Dataset for Fairness-aware Explainable Sentiment Classification in Telugu", "categories": ["cs.CL"], "comment": "work under review", "summary": "In the Indian subcontinent, Telugu, one of India's six classical languages,\nis the most widely spoken Dravidian Language. Despite its 96 million speaker\nbase worldwide, Telugu remains underrepresented in the global NLP and Machine\nLearning landscape, mainly due to lack of high-quality annotated resources.\nThis work introduces TeSent, a comprehensive benchmark dataset for sentiment\nclassification, a key text classification problem, in Telugu. TeSent not only\nprovides ground truth labels for the sentences, but also supplements with\nprovisions for evaluating explainability and fairness, two critical\nrequirements in modern-day machine learning tasks. We scraped Telugu texts\ncovering multiple domains from various social media platforms, news websites\nand web-blogs to preprocess and generate 26,150 sentences, and developed a\ncustom-built annotation platform and a carefully crafted annotation protocol\nfor collecting the ground truth labels along with their human-annotated\nrationales. We then fine-tuned several SOTA pre-trained models in two ways:\nwith rationales, and without rationales. Further, we provide a detailed\nplausibility and faithfulness evaluation suite, which exploits the rationales,\nfor six widely used post-hoc explainers applied on the trained models. Lastly,\nwe curate TeEEC, Equity Evaluation Corpus in Telugu, a corpus to evaluate\nfairness of Telugu sentiment and emotion related NLP tasks, and provide a\nfairness evaluation suite for the trained classifier models. Our experimental\nresults suggest that training with rationales may improve model accuracy,\nreduce bias in models, and make the explainers' output more aligned to human\nreasoning.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86TeSent\uff0c\u4e00\u4e2a\u7528\u4e8e\u6cf0\u5362\u56fa\u8bed\u60c5\u611f\u5206\u7c7b\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u53ef\u89e3\u91ca\u6027\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u6cf0\u5362\u56fa\u8bed\u5728NLP\u9886\u57df\u8d44\u6e90\u532e\u4e4f\uff0c\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\uff0cTeSent\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u722c\u53d6\u591a\u9886\u57df\u6587\u672c\uff0c\u6784\u5efa26,150\u53e5\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u6807\u6ce8\u5e73\u53f0\u548c\u534f\u8bae\uff0c\u5e76\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u6807\u6ce8\u7406\u7531\u8bad\u7ec3\u6a21\u578b\u53ef\u63d0\u9ad8\u51c6\u786e\u6027\u3001\u51cf\u5c11\u504f\u89c1\uff0c\u5e76\u4f7f\u89e3\u91ca\u66f4\u7b26\u5408\u4eba\u7c7b\u63a8\u7406\u3002", "conclusion": "TeSent\u4e3a\u6cf0\u5362\u56fa\u8bedNLP\u4efb\u52a1\u63d0\u4f9b\u4e86\u8d44\u6e90\uff0c\u5e76\u5c55\u793a\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u516c\u5e73\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.01274", "pdf": "https://arxiv.org/pdf/2508.01274", "abs": "https://arxiv.org/abs/2508.01274", "authors": ["Jui-Ming Yao", "Bing-Cheng Xie", "Sheng-Wei Peng", "Hao-Yuan Chen", "He-Rong Zheng", "Bing-Jia Tan", "Peter Shaojui Wang", "Shun-Feng Su"], "title": "Multi-TW: Benchmarking Multimodal Models on Traditional Chinese Question Answering in Taiwan", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) process visual, acoustic, and\ntextual inputs, addressing the limitations of single-modality LLMs. However,\nexisting benchmarks often overlook tri-modal evaluation in Traditional Chinese\nand do not consider inference latency. To address this, we introduce Multi-TW,\nthe first Traditional Chinese benchmark for evaluating the performance and\nlatency of any-to-any multimodal models. Multi-TW includes 900 multiple-choice\nquestions (image and text, audio and text pairs) sourced from official\nproficiency tests developed with the Steering Committee for the Test of\nProficiency-Huayu (SC-TOP). We evaluated various any-to-any models and\nvision-language models (VLMs) with audio transcription. Our results show that\nclosed-source models generally outperform open-source ones across modalities,\nalthough open-source models can perform well in audio tasks. End-to-end\nany-to-any pipelines offer clear latency advantages compared to VLMs using\nseparate audio transcription. Multi-TW presents a comprehensive view of model\ncapabilities and highlights the need for Traditional Chinese fine-tuning and\nefficient multimodal architectures.", "AI": {"tldr": "Multi-TW\u662f\u9996\u4e2a\u9488\u5bf9\u4f20\u7edf\u4e2d\u6587\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u548c\u5ef6\u8fdf\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5e38\u5ffd\u7565\u4f20\u7edf\u4e2d\u6587\u7684\u4e09\u6a21\u6001\u8bc4\u4f30\u548c\u63a8\u7406\u5ef6\u8fdf\uff0cMulti-TW\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "Multi-TW\u5305\u542b900\u9053\u591a\u9009\u9898\uff08\u56fe\u6587\u3001\u97f3\u9891\u6587\u672c\u5bf9\uff09\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u591a\u6a21\u6001\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u95ed\u6e90\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u5f00\u6e90\u6a21\u578b\u5728\u97f3\u9891\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff1b\u7aef\u5230\u7aef\u591a\u6a21\u6001\u7ba1\u9053\u5ef6\u8fdf\u66f4\u4f4e\u3002", "conclusion": "Multi-TW\u63ed\u793a\u4e86\u4f20\u7edf\u4e2d\u6587\u5fae\u8c03\u548c\u9ad8\u6548\u591a\u6a21\u6001\u67b6\u6784\u7684\u9700\u6c42\u3002"}}
{"id": "2508.00933", "pdf": "https://arxiv.org/pdf/2508.00933", "abs": "https://arxiv.org/abs/2508.00933", "authors": ["Hanchen Yang", "Jiaqi Wang", "Jiannong Cao", "Wengen Li", "Jialun Zheng", "Yangning Li", "Chunyu Miao", "Jihong Guan", "Shuigeng Zhou", "Philip S. Yu"], "title": "OKG-LLM: Aligning Ocean Knowledge Graph with Observation Data via LLMs for Global Sea Surface Temperature Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sea surface temperature (SST) prediction is a critical task in ocean science,\nsupporting various applications, such as weather forecasting, fisheries\nmanagement, and storm tracking. While existing data-driven methods have\ndemonstrated significant success, they often neglect to leverage the rich\ndomain knowledge accumulated over the past decades, limiting further\nadvancements in prediction accuracy. The recent emergence of large language\nmodels (LLMs) has highlighted the potential of integrating domain knowledge for\ndownstream tasks. However, the application of LLMs to SST prediction remains\nunderexplored, primarily due to the challenge of integrating ocean domain\nknowledge and numerical data. To address this issue, we propose Ocean Knowledge\nGraph-enhanced LLM (OKG-LLM), a novel framework for global SST prediction. To\nthe best of our knowledge, this work presents the first systematic effort to\nconstruct an Ocean Knowledge Graph (OKG) specifically designed to represent\ndiverse ocean knowledge for SST prediction. We then develop a graph embedding\nnetwork to learn the comprehensive semantic and structural knowledge within the\nOKG, capturing both the unique characteristics of individual sea regions and\nthe complex correlations between them. Finally, we align and fuse the learned\nknowledge with fine-grained numerical SST data and leverage a pre-trained LLM\nto model SST patterns for accurate prediction. Extensive experiments on the\nreal-world dataset demonstrate that OKG-LLM consistently outperforms\nstate-of-the-art methods, showcasing its effectiveness, robustness, and\npotential to advance SST prediction. The codes are available in the online\nrepository.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6d77\u6d0b\u77e5\u8bc6\u56fe\u8c31\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08OKG-LLM\uff09\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u6d77\u8868\u6e29\u5ea6\uff08SST\uff09\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728SST\u9884\u6d4b\u4e2d\u5ffd\u89c6\u4e86\u9886\u57df\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u7cbe\u5ea6\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "\u6784\u5efa\u6d77\u6d0b\u77e5\u8bc6\u56fe\u8c31\uff08OKG\uff09\uff0c\u5f00\u53d1\u56fe\u5d4c\u5165\u7f51\u7edc\u5b66\u4e60\u8bed\u4e49\u548c\u7ed3\u6784\u77e5\u8bc6\uff0c\u5e76\u4e0e\u6570\u503c\u6570\u636e\u7ed3\u5408\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eOKG-LLM\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "OKG-LLM\u5c55\u793a\u4e86\u63d0\u5347SST\u9884\u6d4b\u7684\u6f5c\u529b\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.01491", "pdf": "https://arxiv.org/pdf/2508.01491", "abs": "https://arxiv.org/abs/2508.01491", "authors": ["Zhivar Sourati", "Alireza S. Ziabari", "Morteza Dehghani"], "title": "The Homogenizing Effect of Large Language Models on Human Expression and Thought", "categories": ["cs.CL"], "comment": null, "summary": "Cognitive diversity, reflected in variations of language, perspective, and\nreasoning, is essential to creativity and collective intelligence. This\ndiversity is rich and grounded in culture, history, and individual experience.\nYet as large language models (LLMs) become deeply embedded in people's lives,\nthey risk standardizing language and reasoning. This Review synthesizes\nevidence across linguistics, cognitive, and computer science to show how LLMs\nreflect and reinforce dominant styles while marginalizing alternative voices\nand reasoning strategies. We examine how their design and widespread use\ncontribute to this effect by mirroring patterns in their training data and\namplifying convergence as all people increasingly rely on the same models\nacross contexts. Unchecked, this homogenization risks flattening the cognitive\nlandscapes that drive collective intelligence and adaptability.", "AI": {"tldr": "LLMs\u53ef\u80fd\u6807\u51c6\u5316\u8bed\u8a00\u548c\u63a8\u7406\uff0c\u5bfc\u81f4\u8ba4\u77e5\u591a\u6837\u6027\u51cf\u5c11\uff0c\u5f71\u54cd\u96c6\u4f53\u667a\u6167\u548c\u521b\u9020\u529b\u3002", "motivation": "\u63a2\u8ba8LLMs\u5982\u4f55\u53cd\u6620\u548c\u5f3a\u5316\u4e3b\u6d41\u8bed\u8a00\u548c\u63a8\u7406\u6a21\u5f0f\uff0c\u540c\u65f6\u8fb9\u7f18\u5316\u5176\u4ed6\u58f0\u97f3\u548c\u7b56\u7565\u3002", "method": "\u7efc\u5408\u8bed\u8a00\u5b66\u3001\u8ba4\u77e5\u79d1\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u8bc1\u636e\uff0c\u5206\u6790LLMs\u7684\u8bbe\u8ba1\u548c\u5e7f\u6cdb\u4f7f\u7528\u3002", "result": "LLMs\u901a\u8fc7\u8bad\u7ec3\u6570\u636e\u548c\u5e7f\u6cdb\u4f7f\u7528\u52a0\u5267\u8bed\u8a00\u548c\u63a8\u7406\u7684\u8d8b\u540c\uff0c\u53ef\u80fd\u5bfc\u81f4\u8ba4\u77e5\u540c\u8d28\u5316\u3002", "conclusion": "\u9700\u8b66\u60d5LLMs\u5bf9\u8ba4\u77e5\u591a\u6837\u6027\u7684\u6f5c\u5728\u8d1f\u9762\u5f71\u54cd\uff0c\u4ee5\u4fdd\u62a4\u96c6\u4f53\u667a\u6167\u548c\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2508.01136", "pdf": "https://arxiv.org/pdf/2508.01136", "abs": "https://arxiv.org/abs/2508.01136", "authors": ["Wei Zhou", "Peng Sun", "Xuanhe Zhou", "Qianglei Zang", "Ji Xu", "Tieying Zhang", "Guoliang Li", "Fan Wu"], "title": "DBAIOps: A Reasoning LLM-Enhanced Database Operation and Maintenance System using Knowledge Graphs", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "comment": "DBAIOps supports 25 database systems and has been deployed in 20\n  real-world scenarios, covering domains like finance, energy, and healthcare.\n  See website at: https://www.dbaiops.com; See code at:\n  https://github.com/weAIDB/DBAIOps/", "summary": "The operation and maintenance (O&M) of database systems is critical to\nensuring system availability and performance, typically requiring expert\nexperience (e.g., identifying metric-to-anomaly relations) for effective\ndiagnosis and recovery. However, existing automatic database O&M methods,\nincluding commercial products, cannot effectively utilize expert experience. On\nthe one hand, rule-based methods only support basic O&M tasks (e.g.,\nmetric-based anomaly detection), which are mostly numerical equations and\ncannot effectively incorporate literal O&M experience (e.g., troubleshooting\nguidance in manuals). On the other hand, LLM-based methods, which retrieve\nfragmented information (e.g., standard documents + RAG), often generate\ninaccurate or generic results. To address these limitations, we present\nDBAIOps, a novel hybrid database O&M system that combines reasoning LLMs with\nknowledge graphs to achieve DBA-style diagnosis. First, DBAIOps introduces a\nheterogeneous graph model for representing the diagnosis experience, and\nproposes a semi-automatic graph construction algorithm to build that graph from\nthousands of documents. Second, DBAIOps develops a collection of (800+)\nreusable anomaly models that identify both directly alerted metrics and\nimplicitly correlated experience and metrics. Third, for each anomaly, DBAIOps\nproposes a two-stage graph evolution mechanism to explore relevant diagnosis\npaths and identify missing relations automatically. It then leverages a\nreasoning LLM (e.g., DeepSeek-R1) to infer root causes and generate clear\ndiagnosis reports for both DBAs and common users. Our evaluation over four\nmainstream database systems (Oracle, MySQL, PostgreSQL, and DM8) demonstrates\nthat DBAIOps outperforms state-of-the-art baselines, 34.85% and 47.22% higher\nin root cause and human evaluation accuracy, respectively.", "AI": {"tldr": "DBAIOps\u662f\u4e00\u79cd\u7ed3\u5408\u63a8\u7406LLM\u548c\u77e5\u8bc6\u56fe\u8c31\u7684\u6df7\u5408\u6570\u636e\u5e93\u8fd0\u7ef4\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u6570\u636e\u5e93\u8fd0\u7ef4\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5229\u7528\u4e13\u5bb6\u7ecf\u9a8c\uff0c\u89c4\u5219\u65b9\u6cd5\u4ec5\u652f\u6301\u57fa\u7840\u4efb\u52a1\uff0cLLM\u65b9\u6cd5\u751f\u6210\u7ed3\u679c\u4e0d\u51c6\u786e\u6216\u901a\u7528\u3002", "method": "DBAIOps\u91c7\u7528\u5f02\u6784\u56fe\u6a21\u578b\u8868\u793a\u8bca\u65ad\u7ecf\u9a8c\uff0c\u6784\u5efa\u534a\u81ea\u52a8\u56fe\u8c31\uff0c\u5f00\u53d1800+\u5f02\u5e38\u6a21\u578b\uff0c\u5e76\u5229\u7528\u4e24\u9636\u6bb5\u56fe\u6f14\u5316\u673a\u5236\u548c\u63a8\u7406LLM\u8fdb\u884c\u8bca\u65ad\u3002", "result": "\u5728\u56db\u79cd\u4e3b\u6d41\u6570\u636e\u5e93\u7cfb\u7edf\u4e2d\uff0cDBAIOps\u5728\u6839\u56e0\u548c\u4eba\u5de5\u8bc4\u4f30\u51c6\u786e\u6027\u4e0a\u5206\u522b\u6bd4\u57fa\u7ebf\u9ad834.85%\u548c47.22%\u3002", "conclusion": "DBAIOps\u901a\u8fc7\u7ed3\u5408\u63a8\u7406LLM\u548c\u77e5\u8bc6\u56fe\u8c31\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u5e93\u8fd0\u7ef4\u7684\u81ea\u52a8\u5316\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2508.01285", "pdf": "https://arxiv.org/pdf/2508.01285", "abs": "https://arxiv.org/abs/2508.01285", "authors": ["Yujing Ke", "Kevin George", "Kathan Pandya", "David Blumenthal", "Maximilian Sprang", "Gerrit Gro\u00dfmann", "Sebastian Vollmer", "David Antony Selby"], "title": "BioDisco: Multi-agent hypothesis generation with dual-mode evidence, iterative feedback and temporal evaluation", "categories": ["cs.AI", "cs.ET", "cs.IR", "stat.AP"], "comment": "7 pages main content + 11 pages appendices", "summary": "Identifying novel hypotheses is essential to scientific research, yet this\nprocess risks being overwhelmed by the sheer volume and complexity of available\ninformation. Existing automated methods often struggle to generate novel and\nevidence-grounded hypotheses, lack robust iterative refinement and rarely\nundergo rigorous temporal evaluation for future discovery potential. To address\nthis, we propose BioDisco, a multi-agent framework that draws upon language\nmodel-based reasoning and a dual-mode evidence system (biomedical knowledge\ngraphs and automated literature retrieval) for grounded novelty, integrates an\ninternal scoring and feedback loop for iterative refinement, and validates\nperformance through pioneering temporal and human evaluations and a\nBradley-Terry paired comparison model to provide statistically-grounded\nassessment. Our evaluations demonstrate superior novelty and significance over\nablated configurations representative of existing agentic architectures.\nDesigned for flexibility and modularity, BioDisco allows seamless integration\nof custom language models or knowledge graphs, and can be run with just a few\nlines of code. We anticipate researchers using this practical tool as a\ncatalyst for the discovery of new hypotheses.", "AI": {"tldr": "BioDisco\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u53cc\u6a21\u5f0f\u8bc1\u636e\u7cfb\u7edf\uff0c\u7528\u4e8e\u751f\u6210\u65b0\u9896\u4e14\u57fa\u4e8e\u8bc1\u636e\u7684\u79d1\u5b66\u5047\u8bbe\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u548c\u65f6\u95f4\u8bc4\u4f30\u9a8c\u8bc1\u6027\u80fd\u3002", "motivation": "\u79d1\u5b66\u5047\u8bbe\u7684\u751f\u6210\u5e38\u56e0\u4fe1\u606f\u91cf\u5927\u548c\u590d\u6742\u6027\u9ad8\u800c\u53d7\u9650\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u5728\u751f\u6210\u65b0\u9896\u4e14\u57fa\u4e8e\u8bc1\u636e\u7684\u5047\u8bbe\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002", "method": "BioDisco\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u53cc\u6a21\u5f0f\u8bc1\u636e\u7cfb\u7edf\uff08\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u548c\u6587\u732e\u68c0\u7d22\uff09\uff0c\u96c6\u6210\u5185\u90e8\u8bc4\u5206\u548c\u53cd\u9988\u5faa\u73af\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u5e76\u901a\u8fc7\u65f6\u95f4\u8bc4\u4f30\u548cBradley-Terry\u914d\u5bf9\u6bd4\u8f83\u6a21\u578b\u9a8c\u8bc1\u6027\u80fd\u3002", "result": "\u8bc4\u4f30\u663e\u793aBioDisco\u5728\u751f\u6210\u65b0\u9896\u6027\u548c\u663e\u8457\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5177\u6709\u7075\u6d3b\u6027\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\u3002", "conclusion": "BioDisco\u662f\u4e00\u4e2a\u5b9e\u7528\u5de5\u5177\uff0c\u6709\u671b\u63a8\u52a8\u65b0\u79d1\u5b66\u5047\u8bbe\u7684\u53d1\u73b0\u3002"}}
{"id": "2508.00954", "pdf": "https://arxiv.org/pdf/2508.00954", "abs": "https://arxiv.org/abs/2508.00954", "authors": ["Andy Hu", "Devika Prasad", "Luiz Pizzato", "Nicholas Foord", "Arman Abrahamyan", "Anna Leontjeva", "Cooper Doyle", "Dan Jermyn"], "title": "FeatureCuts: Feature Selection for Large Data by Optimizing the Cutoff", "categories": ["cs.LG"], "comment": "11 pages, 4 figures, appendix", "summary": "In machine learning, the process of feature selection involves finding a\nreduced subset of features that captures most of the information required to\ntrain an accurate and efficient model. This work presents FeatureCuts, a novel\nfeature selection algorithm that adaptively selects the optimal feature cutoff\nafter performing filter ranking. Evaluated on 14 publicly available datasets\nand one industry dataset, FeatureCuts achieved, on average, 15 percentage\npoints more feature reduction and up to 99.6% less computation time while\nmaintaining model performance, compared to existing state-of-the-art methods.\nWhen the selected features are used in a wrapper method such as Particle Swarm\nOptimization (PSO), it enables 25 percentage points more feature reduction,\nrequires 66% less computation time, and maintains model performance when\ncompared to PSO alone. The minimal overhead of FeatureCuts makes it scalable\nfor large datasets typically seen in enterprise applications.", "AI": {"tldr": "FeatureCuts\u662f\u4e00\u79cd\u65b0\u578b\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f18\u7279\u5f81\u622a\u65ad\u70b9\uff0c\u663e\u8457\u51cf\u5c11\u7279\u5f81\u6570\u91cf\u548c\u8ba1\u7b97\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u7279\u5f81\u9009\u62e9\u7684\u76ee\u6807\u662f\u627e\u5230\u80fd\u591f\u9ad8\u6548\u8bad\u7ec3\u6a21\u578b\u7684\u7279\u5f81\u5b50\u96c6\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u7279\u5f81\u51cf\u5c11\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "FeatureCuts\u901a\u8fc7\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f18\u7279\u5f81\u622a\u65ad\u70b9\uff0c\u7ed3\u5408\u8fc7\u6ee4\u6392\u540d\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u7279\u5f81\u9009\u62e9\u6548\u7387\u3002", "result": "\u572814\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u548c1\u4e2a\u884c\u4e1a\u6570\u636e\u96c6\u4e0a\uff0cFeatureCuts\u5e73\u5747\u51cf\u5c1115%\u7684\u7279\u5f81\u548c99.6%\u7684\u8ba1\u7b97\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002\u4e0ePSO\u7ed3\u5408\u65f6\uff0c\u8fdb\u4e00\u6b65\u51cf\u5c1125%\u7684\u7279\u5f81\u548c66%\u7684\u8ba1\u7b97\u65f6\u95f4\u3002", "conclusion": "FeatureCuts\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u4f01\u4e1a\u7ea7\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002"}}
{"id": "2508.01503", "pdf": "https://arxiv.org/pdf/2508.01503", "abs": "https://arxiv.org/abs/2508.01503", "authors": ["Clayton Cohn", "Surya Rayala", "Namrata Srivastava", "Joyce Horn Fonteles", "Shruti Jain", "Xinying Luo", "Divya Mereddy", "Naveeduddin Mohammed", "Gautam Biswas"], "title": "A Theory of Adaptive Scaffolding for LLM-Based Pedagogical Agents", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) present new opportunities for creating\npedagogical agents that engage in meaningful dialogue to support student\nlearning. However, the current use of LLM systems like ChatGPT in classrooms\noften lacks the solid theoretical foundation found in earlier intelligent\ntutoring systems. To bridge this gap, we propose a framework that combines\nEvidence-Centered Design with Social Cognitive Theory for adaptive scaffolding\nin LLM-based agents focused on STEM+C learning. We illustrate this framework\nwith Inquizzitor, an LLM-based formative assessment agent that integrates\nhuman-AI hybrid intelligence and provides feedback grounded in cognitive\nscience principles. Our findings show that Inquizzitor delivers high-quality\nassessment and interaction aligned with core learning theories, offering\nteachers effective guidance that students value. This research underscores the\npotential for theory-driven LLM integration in education, highlighting the\nability of these systems to provide adaptive and principled instruction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8bc1\u636e\u4e2d\u5fc3\u8bbe\u8ba1\u4e0e\u793e\u4f1a\u8ba4\u77e5\u7406\u8bba\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u4e8eLLM\u7684\u6559\u80b2\u4ee3\u7406\uff0c\u4ee5\u652f\u6301STEM+C\u5b66\u4e60\u3002", "motivation": "\u5f53\u524dLLM\u7cfb\u7edf\uff08\u5982ChatGPT\uff09\u5728\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\uff0c\u9700\u8981\u7ed3\u5408\u5b66\u4e60\u7406\u8bba\u63d0\u5347\u5176\u6559\u5b66\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408Evidence-Centered Design\u4e0eSocial Cognitive Theory\u7684\u6846\u67b6\uff0c\u5e76\u4ee5Inquizzitor\u4e3a\u4f8b\u5c55\u793a\u5176\u5e94\u7528\u3002", "result": "Inquizzitor\u80fd\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u8bc4\u4f30\u548c\u4e92\u52a8\uff0c\u7b26\u5408\u6838\u5fc3\u5b66\u4e60\u7406\u8bba\uff0c\u53d7\u5230\u5e08\u751f\u8ba4\u53ef\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u7406\u8bba\u9a71\u52a8\u7684LLM\u5728\u6559\u80b2\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u63d0\u4f9b\u81ea\u9002\u5e94\u548c\u539f\u5219\u6027\u7684\u6559\u5b66\u652f\u6301\u3002"}}
{"id": "2508.01300", "pdf": "https://arxiv.org/pdf/2508.01300", "abs": "https://arxiv.org/abs/2508.01300", "authors": ["Ma'ayan Armony", "Albert Mero\u00f1o-Pe\u00f1uela", "Gerard Canal"], "title": "How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective", "categories": ["cs.AI"], "comment": null, "summary": "The reasoning and planning abilities of Large Language Models (LLMs) have\nbeen a frequent topic of discussion in recent years. Their ability to take\nunstructured planning problems as input has made LLMs' integration into AI\nplanning an area of interest. Nevertheless, LLMs are still not reliable as\nplanners, with the generated plans often containing mistaken or hallucinated\nactions. Existing benchmarking and evaluation methods investigate planning with\nLLMs, focusing primarily on success rate as a quality indicator in various\nplanning tasks, such as validating plans or planning in relaxed conditions. In\nthis paper, we approach planning with LLMs as a natural language processing\n(NLP) task, given that LLMs are NLP models themselves. We propose a recovery\npipeline consisting of an NLP-based evaluation of the generated plans, along\nwith three stages to recover the plans through NLP manipulation of the\nLLM-generated plans, and eventually complete the plan using a symbolic planner.\nThis pipeline provides a holistic analysis of LLM capabilities in the context\nof AI task planning, enabling a broader understanding of the quality of invalid\nplans. Our findings reveal no clear evidence of underlying reasoning during\nplan generation, and that a pipeline comprising an NLP-based analysis of the\nplans, followed by a recovery mechanism, still falls short of the quality and\nreliability of classical planners. On average, only the first 2.65 actions of\nthe plan are executable, with the average length of symbolically generated\nplans being 8.4 actions. The pipeline still improves action quality and\nincreases the overall success rate from 21.9% to 27.5%.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u7684\u6062\u590d\u6d41\u7a0b\uff0c\u4ee5\u63d0\u9ad8\u751f\u6210\u8ba1\u5212\u7684\u8d28\u91cf\u548c\u6210\u529f\u7387\u3002", "motivation": "LLM\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u5e38\u751f\u6210\u9519\u8bef\u6216\u865a\u6784\u7684\u52a8\u4f5c\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6210\u529f\u7387\uff0c\u7f3a\u4e4f\u5bf9\u65e0\u6548\u8ba1\u5212\u7684\u5168\u9762\u5206\u6790\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u542bNLP\u8bc4\u4f30\u548c\u4e09\u9636\u6bb5\u6062\u590d\u6d41\u7a0b\u7684\u7ba1\u9053\uff0c\u6700\u7ec8\u901a\u8fc7\u7b26\u53f7\u89c4\u5212\u5668\u5b8c\u6210\u8ba1\u5212\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u5728\u8ba1\u5212\u751f\u6210\u4e2d\u7f3a\u4e4f\u660e\u786e\u63a8\u7406\uff0c\u6062\u590d\u6d41\u7a0b\u5c06\u6210\u529f\u7387\u4ece21.9%\u63d0\u5347\u81f327.5%\uff0c\u4f46\u8d28\u91cf\u4ecd\u4e0d\u53ca\u4f20\u7edf\u89c4\u5212\u5668\u3002", "conclusion": "LLM\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u6709\u9650\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u63d0\u9ad8\u5176\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\u3002"}}
{"id": "2508.01541", "pdf": "https://arxiv.org/pdf/2508.01541", "abs": "https://arxiv.org/abs/2508.01541", "authors": ["Sara C\u00e2mara", "Eduardo Luz", "Val\u00e9ria Carvalho", "Ivan Meneghini", "Gladston Moreira"], "title": "MOPrompt: Multi-objective Semantic Evolution for Prompt Optimization", "categories": ["cs.CL"], "comment": "8 pages", "summary": "Prompt engineering is crucial for unlocking the potential of Large Language\nModels (LLMs). Still, since manual prompt design is often complex,\nnon-intuitive, and time-consuming, automatic prompt optimization has emerged as\na research area. However, a significant challenge in prompt optimization is\nmanaging the inherent trade-off between task performance, such as accuracy, and\ncontext size. Most existing automated methods focus on a single objective,\ntypically performance, thereby failing to explore the critical spectrum of\nefficiency and effectiveness. This paper introduces the MOPrompt, a novel\nMulti-objective Evolutionary Optimization (EMO) framework designed to optimize\nprompts for both accuracy and context size (measured in tokens) simultaneously.\nOur framework maps the Pareto front of prompt solutions, presenting\npractitioners with a set of trade-offs between context size and performance, a\ncrucial tool for deploying Large Language Models (LLMs) in real-world\napplications. We evaluate MOPrompt on a sentiment analysis task in Portuguese,\nusing Gemma-2B and Sabiazinho-3 as evaluation models. Our findings show that\nMOPrompt substantially outperforms the baseline framework. For the Sabiazinho\nmodel, MOPrompt identifies a prompt that achieves the same peak accuracy (0.97)\nas the best baseline solution, but with a 31% reduction in token length.", "AI": {"tldr": "MOPrompt\u662f\u4e00\u79cd\u591a\u76ee\u6807\u8fdb\u5316\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u540c\u65f6\u4f18\u5316\u63d0\u793a\u7684\u51c6\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u5927\u5c0f\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u624b\u52a8\u8bbe\u8ba1\u63d0\u793a\u590d\u6742\u4e14\u8017\u65f6\uff0c\u73b0\u6709\u81ea\u52a8\u65b9\u6cd5\u591a\u5173\u6ce8\u5355\u4e00\u76ee\u6807\uff08\u5982\u6027\u80fd\uff09\uff0c\u5ffd\u7565\u4e86\u6548\u7387\u4e0e\u6548\u679c\u7684\u6743\u8861\u3002", "method": "\u63d0\u51faMOPrompt\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u8fdb\u5316\u4f18\u5316\u6620\u5c04Pareto\u524d\u6cbf\uff0c\u5e73\u8861\u4e0a\u4e0b\u6587\u5927\u5c0f\u4e0e\u6027\u80fd\u3002", "result": "\u5728\u8461\u8404\u7259\u8bed\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\uff0cMOPrompt\u5728\u4fdd\u6301\u5cf0\u503c\u51c6\u786e\u7387\uff080.97\uff09\u7684\u540c\u65f6\uff0c\u5c06\u6807\u8bb0\u957f\u5ea6\u51cf\u5c1131%\u3002", "conclusion": "MOPrompt\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2dLLM\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u5173\u952e\u5de5\u5177\uff0c\u5c55\u793a\u4e86\u6548\u7387\u4e0e\u6027\u80fd\u7684\u6743\u8861\u3002"}}
{"id": "2508.01306", "pdf": "https://arxiv.org/pdf/2508.01306", "abs": "https://arxiv.org/abs/2508.01306", "authors": ["Yelim Ahn", "Jaejin Lee"], "title": "PUZZLED: Jailbreaking LLMs through Word-Based Puzzles", "categories": ["cs.AI", "cs.CR"], "comment": "15 pages", "summary": "As large language models (LLMs) are increasingly deployed across diverse\ndomains, ensuring their safety has become a critical concern. In response,\nstudies on jailbreak attacks have been actively growing. Existing approaches\ntypically rely on iterative prompt engineering or semantic transformations of\nharmful instructions to evade detection. In this work, we introduce PUZZLED, a\nnovel jailbreak method that leverages the LLM's reasoning capabilities. It\nmasks keywords in a harmful instruction and presents them as word puzzles for\nthe LLM to solve. We design three puzzle types-word search, anagram, and\ncrossword-that are familiar to humans but cognitively demanding for LLMs. The\nmodel must solve the puzzle to uncover the masked words and then proceed to\ngenerate responses to the reconstructed harmful instruction. We evaluate\nPUZZLED on five state-of-the-art LLMs and observe a high average attack success\nrate (ASR) of 88.8%, specifically 96.5% on GPT-4.1 and 92.3% on Claude 3.7\nSonnet. PUZZLED is a simple yet powerful attack that transforms familiar\npuzzles into an effective jailbreak strategy by harnessing LLMs' reasoning\ncapabilities.", "AI": {"tldr": "PUZZLED\u662f\u4e00\u79cd\u65b0\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6709\u5bb3\u6307\u4ee4\u7684\u5173\u952e\u8bcd\u9690\u85cf\u4e3a\u5b57\u8c1c\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u7ed5\u8fc7\u5b89\u5168\u68c0\u6d4b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5404\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u6027\u6210\u4e3a\u5173\u952e\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u8fed\u4ee3\u63d0\u793a\u5de5\u7a0b\u6216\u8bed\u4e49\u8f6c\u6362\uff0c\u6548\u679c\u6709\u9650\u3002", "method": "PUZZLED\u8bbe\u8ba1\u4e86\u4e09\u79cd\u5b57\u8c1c\u7c7b\u578b\uff08\u5355\u8bcd\u641c\u7d22\u3001\u53d8\u4f4d\u8bcd\u3001\u586b\u5b57\u6e38\u620f\uff09\uff0c\u5c06\u6709\u5bb3\u6307\u4ee4\u7684\u5173\u952e\u8bcd\u9690\u85cf\u5176\u4e2d\uff0c\u6a21\u578b\u9700\u89e3\u8c1c\u540e\u751f\u6210\u54cd\u5e94\u3002", "result": "\u5728\u4e94\u79cd\u5148\u8fdbLLMs\u4e0a\u6d4b\u8bd5\uff0c\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\u8fbe88.8%\uff0c\u5176\u4e2dGPT-4.1\u4e3a96.5%\uff0cClaude 3.7 Sonnet\u4e3a92.3%\u3002", "conclusion": "PUZZLED\u901a\u8fc7\u5229\u7528LLMs\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5c06\u7b80\u5355\u5b57\u8c1c\u8f6c\u5316\u4e3a\u9ad8\u6548\u7684\u8d8a\u72f1\u7b56\u7565\uff0c\u5c55\u793a\u4e86\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2508.01554", "pdf": "https://arxiv.org/pdf/2508.01554", "abs": "https://arxiv.org/abs/2508.01554", "authors": ["Yujia Zheng", "Tianhao Li", "Haotian Huang", "Tianyu Zeng", "Jingyu Lu", "Chuangxin Chu", "Yuekai Huang", "Ziyou Jiang", "Qian Xiong", "Yuyao Ge", "Mingyang Li"], "title": "Are All Prompt Components Value-Neutral? Understanding the Heterogeneous Adversarial Robustness of Dissected Prompt in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": null, "summary": "Prompt-based adversarial attacks have become an effective means to assess the\nrobustness of large language models (LLMs). However, existing approaches often\ntreat prompts as monolithic text, overlooking their structural\nheterogeneity-different prompt components contribute unequally to adversarial\nrobustness. Prior works like PromptRobust assume prompts are value-neutral, but\nour analysis reveals that complex, domain-specific prompts with rich structures\nhave components with differing vulnerabilities. To address this gap, we\nintroduce PromptAnatomy, an automated framework that dissects prompts into\nfunctional components and generates diverse, interpretable adversarial examples\nby selectively perturbing each component using our proposed method, ComPerturb.\nTo ensure linguistic plausibility and mitigate distribution shifts, we further\nincorporate a perplexity (PPL)-based filtering mechanism. As a complementary\nresource, we annotate four public instruction-tuning datasets using the\nPromptAnatomy framework, verified through human review. Extensive experiments\nacross these datasets and five advanced LLMs demonstrate that ComPerturb\nachieves state-of-the-art attack success rates. Ablation studies validate the\ncomplementary benefits of prompt dissection and PPL filtering. Our results\nunderscore the importance of prompt structure awareness and controlled\nperturbation for reliable adversarial robustness evaluation in LLMs. Code and\ndata are available at https://github.com/Yujiaaaaa/PACP.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPromptAnatomy\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u63d0\u793a\u7684\u529f\u80fd\u7ec4\u4ef6\u5e76\u9009\u62e9\u6027\u6270\u52a8\uff08ComPerturb\uff09\u751f\u6210\u5bf9\u6297\u6837\u672c\uff0c\u7ed3\u5408PPL\u8fc7\u6ee4\u63d0\u5347\u653b\u51fb\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u5ffd\u89c6\u63d0\u793a\u7684\u7ed3\u6784\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u8bc4\u4f30\u4e0d\u5168\u9762\u3002", "method": "\u63d0\u51faPromptAnatomy\u6846\u67b6\uff0c\u5206\u89e3\u63d0\u793a\u4e3a\u529f\u80fd\u7ec4\u4ef6\uff0c\u4f7f\u7528ComPerturb\u9009\u62e9\u6027\u6270\u52a8\uff0c\u5e76\u5f15\u5165PPL\u8fc7\u6ee4\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548cLLM\u4e0a\uff0cComPerturb\u8fbe\u5230\u6700\u9ad8\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "\u63d0\u793a\u7ed3\u6784\u611f\u77e5\u548c\u53ef\u63a7\u6270\u52a8\u5bf9LLM\u5bf9\u6297\u9c81\u68d2\u6027\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.01987", "pdf": "https://arxiv.org/pdf/2508.01987", "abs": "https://arxiv.org/abs/2508.01987", "authors": ["Shutong Qiao", "Wei Yuan", "Junliang Yu", "Tong Chen", "Quoc Viet Hung Nguyen", "Hongzhi Yin"], "title": "Controllable and Stealthy Shilling Attacks via Dispersive Latent Diffusion", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Recommender systems (RSs) are now fundamental to various online platforms,\nbut their dependence on user-contributed data leaves them vulnerable to\nshilling attacks that can manipulate item rankings by injecting fake users.\nAlthough widely studied, most existing attack models fail to meet two critical\nobjectives simultaneously: achieving strong adversarial promotion of target\nitems while maintaining realistic behavior to evade detection. As a result, the\ntrue severity of shilling threats that manage to reconcile the two objectives\nremains underappreciated. To expose this overlooked vulnerability, we present\nDLDA, a diffusion-based attack framework that can generate highly effective yet\nindistinguishable fake users by enabling fine-grained control over target\npromotion. Specifically, DLDA operates in a pre-aligned collaborative embedding\nspace, where it employs a conditional latent diffusion process to iteratively\nsynthesize fake user profiles with precise target item control. To evade\ndetection, DLDA introduces a dispersive regularization mechanism that promotes\nvariability and realism in generated behavioral patterns. Extensive experiments\non three real-world datasets and five popular RS models demonstrate that,\ncompared to prior attacks, DLDA consistently achieves stronger item promotion\nwhile remaining harder to detect. These results highlight that modern RSs are\nmore vulnerable than previously recognized, underscoring the urgent need for\nmore robust defenses.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u653b\u51fb\u6846\u67b6DLDA\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u6548\u4e14\u96be\u4ee5\u68c0\u6d4b\u7684\u865a\u5047\u7528\u6237\uff0c\u63ed\u793a\u4e86\u63a8\u8350\u7cfb\u7edf\u5728\u5bf9\u6297\u653b\u51fb\u4e2d\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u73b0\u6709\u653b\u51fb\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u76ee\u6807\u9879\u76ee\u7684\u5f3a\u5bf9\u6297\u63a8\u5e7f\u548c\u907f\u514d\u68c0\u6d4b\u7684\u771f\u5b9e\u884c\u4e3a\uff0c\u5bfc\u81f4\u5bf9\u63a8\u8350\u7cfb\u7edf\u771f\u5b9e\u5a01\u80c1\u7684\u4f4e\u4f30\u3002", "method": "DLDA\u5728\u9884\u5bf9\u9f50\u7684\u534f\u4f5c\u5d4c\u5165\u7a7a\u95f4\u4e2d\uff0c\u901a\u8fc7\u6761\u4ef6\u6f5c\u5728\u6269\u6563\u8fc7\u7a0b\u8fed\u4ee3\u751f\u6210\u865a\u5047\u7528\u6237\u914d\u7f6e\u6587\u4ef6\uff0c\u5e76\u5f15\u5165\u5206\u6563\u6b63\u5219\u5316\u673a\u5236\u63d0\u9ad8\u884c\u4e3a\u6a21\u5f0f\u7684\u771f\u5b9e\u6027\u548c\u53ef\u53d8\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u548c\u4e94\u79cd\u6d41\u884c\u63a8\u8350\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDLDA\u76f8\u6bd4\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u66f4\u6709\u6548\u5730\u63a8\u5e7f\u76ee\u6807\u9879\u76ee\u4e14\u66f4\u96be\u88ab\u68c0\u6d4b\u3002", "conclusion": "\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u6bd4\u4ee5\u5f80\u8ba4\u4e3a\u7684\u66f4\u8106\u5f31\uff0c\u4e9f\u9700\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2508.01323", "pdf": "https://arxiv.org/pdf/2508.01323", "abs": "https://arxiv.org/abs/2508.01323", "authors": ["Faruk Alpay", "Bugra Kilictas", "Taylan Alpay", "Hamdi Alakkad"], "title": "Idempotent Equilibrium Analysis of Hybrid Workflow Allocation: A Mathematical Schema for Future Work", "categories": ["cs.AI", "cs.CY", "econ.GN", "q-fin.EC", "47H10, 06B10, 91B40, 91B55, 68T20", "I.2.0; I.2.11; F.4.1"], "comment": "25 pages, 9 figures, 4 tables. Proves existence/uniqueness of an\n  \"idempotent equilibrium\" for human-AI task allocation and provides\n  closed-form steady-state automation share", "summary": "The rapid advance of large-scale AI systems is reshaping how work is divided\nbetween people and machines. We formalise this reallocation as an iterated\ntask-delegation map and show that--under broad, empirically grounded\nassumptions--the process converges to a stable idempotent equilibrium in which\nevery task is performed by the agent (human or machine) with enduring\ncomparative advantage. Leveraging lattice-theoretic fixed-point tools (Tarski\nand Banach), we (i) prove existence of at least one such equilibrium and (ii)\nderive mild monotonicity conditions that guarantee uniqueness. In a stylised\ncontinuous model the long-run automated share takes the closed form $x^* =\n\\alpha / (\\alpha + \\beta)$, where $\\alpha$ captures the pace of automation and\n$\\beta$ the rate at which new, human-centric tasks appear; hence full\nautomation is precluded whenever $\\beta > 0$. We embed this analytic result in\nthree complementary dynamical benchmarks--a discrete linear update, an\nevolutionary replicator dynamic, and a continuous Beta-distributed task\nspectrum--each of which converges to the same mixed equilibrium and is\nreproducible from the provided code-free formulas. A 2025-to-2045 simulation\ncalibrated to current adoption rates projects automation rising from\napproximately 10% of work to approximately 65%, leaving a persistent one-third\nof tasks to humans. We interpret that residual as a new profession of workflow\nconductor: humans specialise in assigning, supervising and integrating AI\nmodules rather than competing with them. Finally, we discuss implications for\nskill development, benchmark design and AI governance, arguing that policies\nwhich promote \"centaur\" human-AI teaming can steer the economy toward the\nwelfare-maximising fixed point.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5f62\u5f0f\u5316\u4efb\u52a1\u5206\u914d\u8fc7\u7a0b\uff0c\u8bc1\u660e\u5728\u5e7f\u6cdb\u5047\u8bbe\u4e0b\u5b58\u5728\u7a33\u5b9a\u5747\u8861\uff0c\u957f\u671f\u81ea\u52a8\u5316\u4efd\u989d\u4e3ax*=\u03b1/(\u03b1+\u03b2)\uff0c\u5e76\u9884\u6d4b\u52302045\u5e74\u81ea\u52a8\u5316\u5c06\u5360\u5de5\u4f5c\u768465%\uff0c\u4eba\u7c7b\u5c06\u4e13\u6ce8\u4e8e\u76d1\u7763AI\u6a21\u5757\u3002", "motivation": "\u7814\u7a76\u5927\u89c4\u6a21AI\u7cfb\u7edf\u5982\u4f55\u6539\u53d8\u4eba\u4e0e\u673a\u5668\u7684\u4efb\u52a1\u5206\u914d\uff0c\u63a2\u7d22\u5176\u5747\u8861\u72b6\u6001\u53ca\u5bf9\u672a\u6765\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u683c\u8bba\u56fa\u5b9a\u70b9\u5de5\u5177\uff08Tarski\u548cBanach\uff09\u8bc1\u660e\u5747\u8861\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\uff0c\u5e76\u901a\u8fc7\u8fde\u7eed\u6a21\u578b\u548c\u52a8\u6001\u57fa\u51c6\u9a8c\u8bc1\u3002", "result": "\u5b58\u5728\u7a33\u5b9a\u5747\u8861\uff0c\u81ea\u52a8\u5316\u4efd\u989d\u4e3ax*=\u03b1/(\u03b1+\u03b2)\uff0c\u6a21\u62df\u9884\u6d4b2045\u5e74\u81ea\u52a8\u5316\u536065%\uff0c\u4eba\u7c7b\u8f6c\u5411\u76d1\u7763\u89d2\u8272\u3002", "conclusion": "\u4eba\u7c7b\u5c06\u4e13\u6ce8\u4e8eAI\u6a21\u5757\u7684\u76d1\u7763\u4e0e\u6574\u5408\uff0c\u653f\u7b56\u5e94\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\u4ee5\u5b9e\u73b0\u798f\u5229\u6700\u5927\u5316\u3002"}}
{"id": "2508.00957", "pdf": "https://arxiv.org/pdf/2508.00957", "abs": "https://arxiv.org/abs/2508.00957", "authors": ["Amrit Rajeev", "Udayaadithya Avadhanam", "Harshula Tulapurkar", "SaiBarath Sundar"], "title": "Small sample-based adaptive text classification through iterative and contrastive description refinement", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Zero-shot text classification remains a difficult task in domains with\nevolving knowledge and ambiguous category boundaries, such as ticketing\nsystems. Large language models (LLMs) often struggle to generalize in these\nscenarios due to limited topic separability, while few-shot methods are\nconstrained by insufficient data diversity. We propose a classification\nframework that combines iterative topic refinement, contrastive prompting, and\nactive learning. Starting with a small set of labeled samples, the model\ngenerates initial topic labels. Misclassified or ambiguous samples are then\nused in an iterative contrastive prompting process to refine category\ndistinctions by explicitly teaching the model to differentiate between closely\nrelated classes. The framework features a human-in-the-loop component, allowing\nusers to introduce or revise category definitions in natural language. This\nenables seamless integration of new, unseen categories without retraining,\nmaking the system well-suited for real-world, dynamic environments. The\nevaluations on AGNews and DBpedia demonstrate strong performance: 91% accuracy\non AGNews (3 seen, 1 unseen class) and 84% on DBpedia (8 seen, 1 unseen), with\nminimal accuracy shift after introducing unseen classes (82% and 87%,\nrespectively). The results highlight the effectiveness of prompt-based semantic\nreasoning for fine-grained classification with limited supervision.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8fed\u4ee3\u4e3b\u9898\u7ec6\u5316\u3001\u5bf9\u6bd4\u63d0\u793a\u548c\u4e3b\u52a8\u5b66\u4e60\u7684\u96f6\u6837\u672c\u6587\u672c\u5206\u7c7b\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u73af\u5883\uff0c\u5e76\u5728AGNews\u548cDBpedia\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u96f6\u6837\u672c\u5206\u7c7b\u5728\u52a8\u6001\u77e5\u8bc6\u9886\u57df\uff08\u5982\u7968\u52a1\u7cfb\u7edf\uff09\u4e2d\u7684\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6cdb\u5316\u548c\u6570\u636e\u591a\u6837\u6027\u4e0d\u8db3\u65f6\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u8fed\u4ee3\u5bf9\u6bd4\u63d0\u793a\u548c\u4e3b\u52a8\u5b66\u4e60\uff0c\u7ed3\u5408\u4eba\u5de5\u5e72\u9884\uff0c\u52a8\u6001\u4f18\u5316\u5206\u7c7b\u8fb9\u754c\u5e76\u5f15\u5165\u65b0\u7c7b\u522b\u3002", "result": "\u5728AGNews\u548cDBpedia\u4e0a\u5206\u522b\u8fbe\u523091%\u548c84%\u7684\u51c6\u786e\u7387\uff0c\u5f15\u5165\u65b0\u7c7b\u522b\u540e\u6027\u80fd\u7a33\u5b9a\u3002", "conclusion": "\u57fa\u4e8e\u63d0\u793a\u7684\u8bed\u4e49\u63a8\u7406\u5728\u6709\u9650\u76d1\u7763\u4e0b\u80fd\u6709\u6548\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u5206\u7c7b\u3002"}}
{"id": "2508.01630", "pdf": "https://arxiv.org/pdf/2508.01630", "abs": "https://arxiv.org/abs/2508.01630", "authors": ["Maziyar Panahi"], "title": "OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Named-entity recognition (NER) is fundamental to extracting structured\ninformation from the >80% of healthcare data that resides in unstructured\nclinical notes and biomedical literature. Despite recent advances with large\nlanguage models, achieving state-of-the-art performance across diverse entity\ntypes while maintaining computational efficiency remains a significant\nchallenge. We introduce OpenMed NER, a suite of open-source, domain-adapted\ntransformer models that combine lightweight domain-adaptive pre-training (DAPT)\nwith parameter-efficient Low-Rank Adaptation (LoRA). Our approach performs\ncost-effective DAPT on a 350k-passage corpus compiled from ethically sourced,\npublicly available research repositories and de-identified clinical notes\n(PubMed, arXiv, and MIMIC-III) using DeBERTa-v3, PubMedBERT, and BioELECTRA\nbackbones. This is followed by task-specific fine-tuning with LoRA, which\nupdates less than 1.5% of model parameters. We evaluate our models on 12\nestablished biomedical NER benchmarks spanning chemicals, diseases, genes, and\nspecies. OpenMed NER achieves new state-of-the-art micro-F1 scores on 10 of\nthese 12 datasets, with substantial gains across diverse entity types. Our\nmodels advance the state-of-the-art on foundational disease and chemical\nbenchmarks (e.g., BC5CDR-Disease, +2.70 pp), while delivering even larger\nimprovements of over 5.3 and 9.7 percentage points on more specialized gene and\nclinical cell line corpora. This work demonstrates that strategically adapted\nopen-source models can surpass closed-source solutions. This performance is\nachieved with remarkable efficiency: training completes in under 12 hours on a\nsingle GPU with a low carbon footprint (< 1.2 kg CO2e), producing permissively\nlicensed, open-source checkpoints designed to help practitioners facilitate\ncompliance with emerging data protection and AI regulations, such as the EU AI\nAct.", "AI": {"tldr": "OpenMed NER \u662f\u4e00\u79cd\u5f00\u6e90\u3001\u9886\u57df\u9002\u5e94\u7684\u8f6c\u6362\u5668\u6a21\u578b\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\uff08DAPT\uff09\u548c\u53c2\u6570\u9ad8\u6548\u7684\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u6280\u672f\uff0c\u5728\u751f\u7269\u533b\u5b66\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u7684\u5e73\u8861\u3002", "motivation": "\u89e3\u51b3\u751f\u7269\u533b\u5b66\u9886\u57df\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0c\u5982\u4f55\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u6311\u6218\u3002", "method": "\u7ed3\u5408\u8f7b\u91cf\u7ea7\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\uff08DAPT\uff09\u548c\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u6280\u672f\uff0c\u4f7f\u7528 DeBERTa-v3\u3001PubMedBERT \u548c BioELECTRA \u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u5728 350k \u6761\u516c\u5f00\u53ef\u7528\u7684\u7814\u7a76\u6587\u732e\u548c\u4e34\u5e8a\u7b14\u8bb0\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728 12 \u4e2a\u751f\u7269\u533b\u5b66 NER \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOpenMed NER \u5728 10 \u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u9ad8\u6027\u80fd\uff08micro-F1 \u5206\u6570\uff09\uff0c\u7279\u522b\u662f\u5728\u75be\u75c5\u548c\u5316\u5b66\u5b9e\u4f53\u8bc6\u522b\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "OpenMed NER \u5c55\u793a\u4e86\u5f00\u6e90\u6a21\u578b\u5728\u751f\u7269\u533b\u5b66 NER \u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u5177\u5907\u9ad8\u6548\u3001\u4f4e\u78b3\u6392\u653e\u548c\u5408\u89c4\u6027\u4f18\u52bf\u3002"}}
{"id": "2508.02243", "pdf": "https://arxiv.org/pdf/2508.02243", "abs": "https://arxiv.org/abs/2508.02243", "authors": ["Ziyan Liu", "Junwen Li", "Kaiwen Li", "Tong Ruan", "Chao Wang", "Xinyan He", "Zongyu Wang", "Xuezhi Cao", "Jingping Liu"], "title": "I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking", "categories": ["cs.CV", "cs.IR"], "comment": "10 pages, 6 figures, accepted by ACMMM 2025", "summary": "Multimodal entity linking plays a crucial role in a wide range of\napplications. Recent advances in large language model-based methods have become\nthe dominant paradigm for this task, effectively leveraging both textual and\nvisual modalities to enhance performance. Despite their success, these methods\nstill face two challenges, including unnecessary incorporation of image data in\ncertain scenarios and the reliance only on a one-time extraction of visual\nfeatures, which can undermine their effectiveness and accuracy. To address\nthese challenges, we propose a novel LLM-based framework for the multimodal\nentity linking task, called Intra- and Inter-modal Collaborative Reflections.\nThis framework prioritizes leveraging text information to address the task.\nWhen text alone is insufficient to link the correct entity through intra- and\ninter-modality evaluations, it employs a multi-round iterative strategy that\nintegrates key visual clues from various aspects of the image to support\nreasoning and enhance matching accuracy. Extensive experiments on three widely\nused public datasets demonstrate that our framework consistently outperforms\ncurrent state-of-the-art methods in the task, achieving improvements of 3.2%,\n5.1%, and 1.6%, respectively. Our code is available at\nhttps://github.com/ziyan-xiaoyu/I2CR/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u591a\u6a21\u6001\u5b9e\u4f53\u94fe\u63a5\u6846\u67b6I2CR\uff0c\u901a\u8fc7\u6587\u672c\u4f18\u5148\u548c\u89c6\u89c9\u8865\u5145\u7684\u591a\u8f6e\u8fed\u4ee3\u7b56\u7565\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u56fe\u50cf\u6570\u636e\u5197\u4f59\u548c\u89c6\u89c9\u7279\u5f81\u4e00\u6b21\u6027\u63d0\u53d6\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u6548\u679c\u548c\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faI2CR\u6846\u67b6\uff0c\u4f18\u5148\u5229\u7528\u6587\u672c\u4fe1\u606f\uff0c\u4e0d\u8db3\u65f6\u901a\u8fc7\u591a\u8f6e\u8fed\u4ee3\u6574\u5408\u89c6\u89c9\u7ebf\u7d22\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5206\u522b\u63d0\u53473.2%\u30015.1%\u548c1.6%\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "I2CR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5b9e\u4f53\u94fe\u63a5\u4e2d\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2508.01324", "pdf": "https://arxiv.org/pdf/2508.01324", "abs": "https://arxiv.org/abs/2508.01324", "authors": ["Ke Miao", "Yuke Hu", "Xiaochen Li", "Wenjie Bao", "Zhihao Liu", "Zhan Qin", "Kui Ren"], "title": "Towards Evaluation for Real-World LLM Unlearning", "categories": ["cs.AI"], "comment": null, "summary": "This paper analyzes the limitations of existing unlearning evaluation metrics\nin terms of practicality, exactness, and robustness in real-world LLM\nunlearning scenarios. To overcome these limitations, we propose a new metric\ncalled Distribution Correction-based Unlearning Evaluation (DCUE). It\nidentifies core tokens and corrects distributional biases in their confidence\nscores using a validation set. The evaluation results are quantified using the\nKolmogorov-Smirnov test. Experimental results demonstrate that DCUE overcomes\nthe limitations of existing metrics, which also guides the design of more\npractical and reliable unlearning algorithms in the future.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u6307\u6807DCUE\uff0c\u89e3\u51b3\u73b0\u6709LLM\u9057\u5fd8\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u9057\u5fd8\u8bc4\u4f30\u6307\u6807\u5728\u5b9e\u7528\u6027\u3001\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u6539\u8fdb\u4ee5\u9002\u5e94\u5b9e\u9645\u573a\u666f\u3002", "method": "\u63d0\u51faDCUE\u6307\u6807\uff0c\u901a\u8fc7\u9a8c\u8bc1\u96c6\u4fee\u6b63\u6838\u5fc3\u4ee4\u724c\u7684\u7f6e\u4fe1\u5ea6\u5206\u5e03\u504f\u5dee\uff0c\u5e76\u7528Kolmogorov-Smirnov\u68c0\u9a8c\u91cf\u5316\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDCUE\u514b\u670d\u4e86\u73b0\u6709\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u9057\u5fd8\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002", "conclusion": "DCUE\u662f\u4e00\u79cd\u66f4\u5b9e\u7528\u3001\u53ef\u9760\u7684\u9057\u5fd8\u8bc4\u4f30\u6307\u6807\uff0c\u63a8\u52a8\u76f8\u5173\u7b97\u6cd5\u53d1\u5c55\u3002"}}
{"id": "2508.00959", "pdf": "https://arxiv.org/pdf/2508.00959", "abs": "https://arxiv.org/abs/2508.00959", "authors": ["Rub\u00e9n Mu\u00f1oz-Sierra", "Manuel Doblar\u00e9", "Jacobo Ayensa-Jim\u00e9nez"], "title": "Enhancing material behavior discovery using embedding-oriented Physically-Guided Neural Networks with Internal Variables", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Physically Guided Neural Networks with Internal Variables are SciML tools\nthat use only observable data for training and and have the capacity to unravel\ninternal state relations. They incorporate physical knowledge both by\nprescribing the model architecture and using loss regularization, thus endowing\ncertain specific neurons with a physical meaning as internal state variables.\nDespite their potential, these models face challenges in scalability when\napplied to high-dimensional data such as fine-grid spatial fields or\ntime-evolving systems. In this work, we propose some enhancements to the PGNNIV\nframework that address these scalability limitations through reduced-order\nmodeling techniques. Specifically, we introduce alternatives to the original\ndecoder structure using spectral decomposition, POD, and pretrained\nautoencoder-based mappings. These surrogate decoders offer varying trade-offs\nbetween computational efficiency, accuracy, noise tolerance, and\ngeneralization, while improving drastically the scalability. Additionally, we\nintegrate model reuse via transfer learning and fine-tuning strategies to\nexploit previously acquired knowledge, supporting efficient adaptation to novel\nmaterials or configurations, and significantly reducing training time while\nmaintaining or improving model performance. To illustrate these various\ntechniques, we use a representative case governed by the nonlinear diffusion\nequation, using only observable data. Results demonstrate that the enhanced\nPGNNIV framework successfully identifies the underlying constitutive state\nequations while maintaining high predictive accuracy. It also improves\nrobustness to noise, mitigates overfitting, and reduces computational demands.\nThe proposed techniques can be tailored to various scenarios depending on data\navailability, resources, and specific modeling objectives, overcoming\nscalability challenges in all the scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684PGNNIV\u6846\u67b6\uff0c\u901a\u8fc7\u964d\u9636\u5efa\u6a21\u6280\u672f\u89e3\u51b3\u9ad8\u7ef4\u6570\u636e\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u591a\u79cd\u66ff\u4ee3\u89e3\u7801\u5668\u7ed3\u6784\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002", "motivation": "PGNNIV\u6a21\u578b\u5728\u5904\u7406\u9ad8\u7ef4\u6570\u636e\uff08\u5982\u7a7a\u95f4\u573a\u6216\u65f6\u53d8\u7cfb\u7edf\uff09\u65f6\u9762\u4e34\u6269\u5c55\u6027\u6311\u6218\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u63d0\u5347\u5176\u9002\u7528\u6027\u548c\u6548\u7387\u3002", "method": "\u91c7\u7528\u964d\u9636\u5efa\u6a21\u6280\u672f\uff0c\u5f15\u5165\u57fa\u4e8e\u8c31\u5206\u89e3\u3001POD\u548c\u9884\u8bad\u7ec3\u81ea\u7f16\u7801\u5668\u7684\u66ff\u4ee3\u89e3\u7801\u5668\uff0c\u5e76\u7ed3\u5408\u8fc1\u79fb\u5b66\u4e60\u548c\u5fae\u8c03\u7b56\u7565\u3002", "result": "\u6539\u8fdb\u540e\u7684PGNNIV\u6846\u67b6\u6210\u529f\u8bc6\u522b\u4e86\u672c\u6784\u72b6\u6001\u65b9\u7a0b\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3001\u566a\u58f0\u9c81\u68d2\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u8ba1\u7b97\u9700\u6c42\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u6839\u636e\u4e0d\u540c\u573a\u666f\u5b9a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86PGNNIV\u7684\u6269\u5c55\u6027\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5efa\u6a21\u76ee\u6807\u3002"}}
{"id": "2508.01656", "pdf": "https://arxiv.org/pdf/2508.01656", "abs": "https://arxiv.org/abs/2508.01656", "authors": ["Lucio La Cava", "Dominik Macko", "R\u00f3bert M\u00f3ro", "Ivan Srba", "Andrea Tagarelli"], "title": "Authorship Attribution in Multilingual Machine-Generated Texts", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "physics.soc-ph"], "comment": null, "summary": "As Large Language Models (LLMs) have reached human-like fluency and\ncoherence, distinguishing machine-generated text (MGT) from human-written\ncontent becomes increasingly difficult. While early efforts in MGT detection\nhave focused on binary classification, the growing landscape and diversity of\nLLMs require a more fine-grained yet challenging authorship attribution (AA),\ni.e., being able to identify the precise generator (LLM or human) behind a\ntext. However, AA remains nowadays confined to a monolingual setting, with\nEnglish being the most investigated one, overlooking the multilingual nature\nand usage of modern LLMs. In this work, we introduce the problem of\nMultilingual Authorship Attribution, which involves attributing texts to human\nor multiple LLM generators across diverse languages. Focusing on 18 languages\n-- covering multiple families and writing scripts -- and 8 generators (7 LLMs\nand the human-authored class), we investigate the multilingual suitability of\nmonolingual AA methods, their cross-lingual transferability, and the impact of\ngenerators on attribution performance. Our results reveal that while certain\nmonolingual AA methods can be adapted to multilingual settings, significant\nlimitations and challenges remain, particularly in transferring across diverse\nlanguage families, underscoring the complexity of multilingual AA and the need\nfor more robust approaches to better match real-world scenarios.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u591a\u8bed\u8a00\u4f5c\u8005\u5f52\u5c5e\u95ee\u9898\uff0c\u7814\u7a76\u4e86\u5982\u4f55\u5c06\u6587\u672c\u5f52\u5c5e\u5230\u4eba\u7c7b\u6216\u591a\u79cdLLM\u751f\u6210\u5668\uff0c\u5e76\u5206\u6790\u4e86\u5355\u8bed\u8a00\u65b9\u6cd5\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u968f\u7740LLM\u751f\u6210\u6587\u672c\u4e0e\u4eba\u7c7b\u5199\u4f5c\u8d8a\u6765\u8d8a\u96be\u4ee5\u533a\u5206\uff0c\u4f20\u7edf\u7684\u4e8c\u5143\u5206\u7c7b\u65b9\u6cd5\u5df2\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u4f5c\u8005\u5f52\u5c5e\u65b9\u6cd5\u3002\u5f53\u524d\u7814\u7a76\u5c40\u9650\u4e8e\u5355\u8bed\u8a00\uff08\u4e3b\u8981\u662f\u82f1\u8bed\uff09\uff0c\u5ffd\u89c6\u4e86LLM\u7684\u591a\u8bed\u8a00\u7279\u6027\u3002", "method": "\u7814\u7a76\u8986\u76d618\u79cd\u8bed\u8a00\u548c8\u79cd\u751f\u6210\u5668\uff087\u79cdLLM\u548c\u4eba\u7c7b\uff09\uff0c\u8bc4\u4f30\u5355\u8bed\u8a00AA\u65b9\u6cd5\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u3001\u8de8\u8bed\u8a00\u8fc1\u79fb\u80fd\u529b\u53ca\u751f\u6210\u5668\u5bf9\u5f52\u5c5e\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u67d0\u4e9b\u5355\u8bed\u8a00AA\u65b9\u6cd5\u53ef\u9002\u5e94\u591a\u8bed\u8a00\u73af\u5883\uff0c\u4f46\u5728\u8de8\u8bed\u8a00\u5bb6\u65cf\u8fc1\u79fb\u65f6\u5b58\u5728\u663e\u8457\u5c40\u9650\uff0c\u51f8\u663e\u4e86\u591a\u8bed\u8a00AA\u7684\u590d\u6742\u6027\u3002", "conclusion": "\u591a\u8bed\u8a00\u4f5c\u8005\u5f52\u5c5e\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9700\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u65b9\u6cd5\u4ee5\u9002\u5e94\u73b0\u5b9e\u573a\u666f\u3002"}}
{"id": "2508.02328", "pdf": "https://arxiv.org/pdf/2508.02328", "abs": "https://arxiv.org/abs/2508.02328", "authors": ["Raj Mahmud", "Shlomo Berkovsky", "Mukesh Prasad", "A. Baki Kocaballi"], "title": "Understanding User Preferences for Interaction Styles in Conversational Recommender Systems: The Predictive Role of System Qualities, User Experience, and Traits", "categories": ["cs.HC", "cs.CL", "cs.IR", "H.5.2; I.2.7; H.1.2"], "comment": "Accepted at OZCHI 2025. 21 pages, 9 figures, 8 tables", "summary": "Conversational Recommender Systems (CRSs) deliver personalised\nrecommendations through multi-turn natural language dialogue and increasingly\nsupport both task-oriented and exploratory interactions. Yet, the factors\nshaping user interaction preferences remain underexplored. In this\nwithin-subjects study (\\(N = 139\\)), participants experienced two scripted CRS\ndialogues, rated their experiences, and indicated the importance of eight\nsystem qualities. Logistic regression revealed that preference for the\nexploratory interaction was predicted by enjoyment, usefulness, novelty, and\nconversational quality. Unexpectedly, perceived effectiveness was also\nassociated with exploratory preference. Clustering uncovered five latent user\nprofiles with distinct dialogue style preferences. Moderation analyses\nindicated that age, gender, and control preference significantly influenced\nthese choices. These findings integrate affective, cognitive, and trait-level\npredictors into CRS user modelling and inform autonomy-sensitive,\nvalue-adaptive dialogue design. The proposed predictive and adaptive framework\napplies broadly to conversational AI systems seeking to align dynamically with\nevolving user needs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u7528\u6237\u5bf9\u63a2\u7d22\u6027\u5bf9\u8bdd\u7684\u504f\u597d\u53d7\u4eab\u53d7\u5ea6\u3001\u5b9e\u7528\u6027\u3001\u65b0\u9896\u6027\u548c\u5bf9\u8bdd\u8d28\u91cf\u5f71\u54cd\uff0c\u4e14\u5e74\u9f84\u3001\u6027\u522b\u548c\u63a7\u5236\u504f\u597d\u663e\u8457\u5f71\u54cd\u9009\u62e9\u3002", "motivation": "\u63a2\u8ba8\u5f71\u54cd\u7528\u6237\u5bf9\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff08CRS\uff09\u4ea4\u4e92\u504f\u597d\u7684\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u88ab\u8bd5\u5185\u8bbe\u8ba1\uff08N=139\uff09\uff0c\u53c2\u4e0e\u8005\u4f53\u9a8c\u4e24\u79cd\u811a\u672c\u5316CRS\u5bf9\u8bdd\u5e76\u8bc4\u5206\uff0c\u901a\u8fc7\u903b\u8f91\u56de\u5f52\u548c\u805a\u7c7b\u5206\u6790\u6570\u636e\u3002", "result": "\u63a2\u7d22\u6027\u504f\u597d\u7531\u4eab\u53d7\u5ea6\u3001\u5b9e\u7528\u6027\u3001\u65b0\u9896\u6027\u548c\u5bf9\u8bdd\u8d28\u91cf\u9884\u6d4b\uff1b\u53d1\u73b0\u4e94\u79cd\u6f5c\u5728\u7528\u6237\u6863\u6848\uff1b\u5e74\u9f84\u3001\u6027\u522b\u548c\u63a7\u5236\u504f\u597d\u663e\u8457\u5f71\u54cd\u9009\u62e9\u3002", "conclusion": "\u7814\u7a76\u4e3aCRS\u7528\u6237\u5efa\u6a21\u6574\u5408\u4e86\u60c5\u611f\u3001\u8ba4\u77e5\u548c\u7279\u8d28\u9884\u6d4b\u56e0\u5b50\uff0c\u5e76\u652f\u6301\u52a8\u6001\u9002\u5e94\u7528\u6237\u9700\u6c42\u7684\u5bf9\u8bdd\u8bbe\u8ba1\u3002"}}
{"id": "2508.01330", "pdf": "https://arxiv.org/pdf/2508.01330", "abs": "https://arxiv.org/abs/2508.01330", "authors": ["Zihan Zheng", "Tianle Cui", "Chuwen Xie", "Jiahui Zhang", "Jiahui Pan", "Lewei He", "Qianglong Chen"], "title": "NatureGAIA: Pushing the Frontiers of GUI Agents with a Challenging Benchmark and High-Quality Trajectory Dataset", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of Large Language Model (LLM)-driven Graphical User\nInterface (GUI) agents is significantly hampered by the profound limitations of\nexisting evaluation benchmarks in terms of accuracy, reproducibility, and\nscalability. To address this critical gap, we introduce \\Benchmark, a novel\nbenchmark engineered on the principle of Causal Pathways. This design paradigm\nstructures complex tasks into a series of programmatically verifiable atomic\nsteps, ensuring a rigorous, fully automated, and reproducible standard for\nassessment. Concurrently, to mitigate the inherent capability deficits of\nagents, we developed \\Agent, a hierarchical agent architecture specifically\noptimized for long-horizon tasks. We leveraged this agent to generate a\nhigh-quality, human-verified trajectory dataset that uniquely captures diverse\nand even self-correcting interaction patterns of LLMs. We then utilized this\ndataset to perform Reinforcement Fine-Tuning (RFT) on the Qwen2.5-VL-7B model.\nOur experiments reveal that \\Benchmark~presents a formidable challenge to\ncurrent state-of-the-art LLMs; even the top-performing Claude-sonnet-4 achieved\na Weighted Pathway Success Rate (WPSR) of only 34.6\\%. Moreover, while RFT\nsubstantially improved the smaller model's GUI execution capabilities (WPSR\nincreased from 3.3\\% to 10.8\\%), its performance degraded sharply when handling\ncomplex scenarios. This outcome highlights the inherent capability ceiling of\nsmaller models when faced with comprehensive tasks that integrate perception,\ndecision-making, and execution. This research contributes a rigorous evaluation\nstandard and a high-quality dataset to the community, aiming to guide the\nfuture development of GUI agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u8def\u5f84\u539f\u5219\u7684\u65b0\u57fa\u51c6\\Benchmark\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u5728\u51c6\u786e\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u7684\u4e0d\u8db3\uff0c\u5e76\u5f00\u53d1\u4e86\u5206\u5c42\u4ee3\u7406\u67b6\u6784\\Agent\u4ee5\u4f18\u5316\u957f\u4efb\u52a1\u3002\u901a\u8fc7\u5f3a\u5316\u5fae\u8c03\uff08RFT\uff09\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u53d1\u73b0\u8f83\u5c0f\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5b58\u5728\u80fd\u529b\u4e0a\u9650\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684GUI\u4ee3\u7406\u8bc4\u4f30\u57fa\u51c6\u5728\u51c6\u786e\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\\Benchmark\u57fa\u51c6\uff0c\u57fa\u4e8e\u56e0\u679c\u8def\u5f84\u539f\u5219\u8bbe\u8ba1\u4efb\u52a1\uff1b\u5f00\u53d1\u5206\u5c42\u4ee3\u7406\u67b6\u6784\\Agent\u751f\u6210\u9ad8\u8d28\u91cf\u8f68\u8ff9\u6570\u636e\u96c6\uff1b\u4f7f\u7528RFT\u5bf9Qwen2.5-VL-7B\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\\Benchmark\u5bf9\u5f53\u524d\u6700\u5148\u8fdbLLM\u6784\u6210\u6311\u6218\uff08Claude-sonnet-4\u7684WPSR\u4ec5\u4e3a34.6%\uff09\uff1bRFT\u663e\u8457\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd\uff08WPSR\u4ece3.3%\u5347\u81f310.8%\uff09\uff0c\u4f46\u5728\u590d\u6742\u573a\u666f\u4e0b\u6027\u80fd\u6025\u5267\u4e0b\u964d\u3002", "conclusion": "\u7814\u7a76\u4e3aGUI\u4ee3\u7406\u9886\u57df\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u8bc4\u4f30\u6807\u51c6\u548c\u9ad8\u8d28\u6570\u636e\u96c6\uff0c\u63ed\u793a\u4e86\u5c0f\u6a21\u578b\u5728\u7efc\u5408\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u4e0a\u9650\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2508.00960", "pdf": "https://arxiv.org/pdf/2508.00960", "abs": "https://arxiv.org/abs/2508.00960", "authors": ["Sudip K. Seal", "Maksudul Alam", "Jorge Ramirez", "Sajal Dash", "Hao Lu"], "title": "Compression-Induced Communication-Efficient Large Model Training and Inferencing", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Energy efficiency of training and inferencing with large neural network\nmodels is a critical challenge facing the future of sustainable large-scale\nmachine learning workloads. This paper introduces an alternative strategy,\ncalled phantom parallelism, to minimize the net energy consumption of\ntraditional tensor (model) parallelism, the most energy-inefficient component\nof large neural network training. The approach is presented in the context of\nfeed-forward network architectures as a preliminary, but comprehensive,\nproof-of-principle study of the proposed methodology. We derive new forward and\nbackward propagation operators for phantom parallelism, implement them as\ncustom autograd operations within an end-to-end phantom parallel training\npipeline and compare its parallel performance and energy-efficiency against\nthose of conventional tensor parallel training pipelines. Formal analyses that\npredict lower bandwidth and FLOP counts are presented with supporting empirical\nresults on up to 256 GPUs that corroborate these gains. Experiments are shown\nto deliver ~50% reduction in the energy consumed to train FFNs using the\nproposed phantom parallel approach when compared with conventional tensor\nparallel methods. Additionally, the proposed approach is shown to train smaller\nphantom models to the same model loss on smaller GPU counts as larger tensor\nparallel models on larger GPU counts offering the possibility for even greater\nenergy savings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cphantom parallelism\u201d\u7684\u65b0\u7b56\u7565\uff0c\u65e8\u5728\u51cf\u5c11\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u80fd\u8017\uff0c\u7279\u522b\u662f\u4f20\u7edf\u5f20\u91cf\u5e76\u884c\u65b9\u6cd5\u7684\u4f4e\u6548\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u80fd\u6e90\u6548\u7387\u662f\u53ef\u6301\u7eed\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60\u7684\u5173\u952e\u6311\u6218\uff0c\u4f20\u7edf\u5f20\u91cf\u5e76\u884c\u65b9\u6cd5\u80fd\u8017\u9ad8\u3002", "method": "\u63d0\u51fa\u4e86phantom parallelism\u65b9\u6cd5\uff0c\u5305\u62ec\u65b0\u7684\u524d\u5411\u548c\u53cd\u5411\u4f20\u64ad\u7b97\u5b50\uff0c\u5e76\u5728\u7aef\u5230\u7aef\u8bad\u7ec3\u6d41\u7a0b\u4e2d\u5b9e\u73b0\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cphantom parallelism\u80fd\u51cf\u5c11\u7ea650%\u7684\u80fd\u8017\uff0c\u5e76\u5728\u8f83\u5c11GPU\u4e0a\u8bad\u7ec3\u8f83\u5c0f\u6a21\u578b\u8fbe\u5230\u76f8\u540c\u6548\u679c\u3002", "conclusion": "phantom parallelism\u662f\u4e00\u79cd\u9ad8\u6548\u8282\u80fd\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u6709\u671b\u663e\u8457\u964d\u4f4e\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u80fd\u6e90\u6d88\u8017\u3002"}}
{"id": "2508.01674", "pdf": "https://arxiv.org/pdf/2508.01674", "abs": "https://arxiv.org/abs/2508.01674", "authors": ["Tae Soo Kim", "Yoonjoo Lee", "Yoonah Park", "Jiho Kim", "Young-Ho Kim", "Juho Kim"], "title": "CUPID: Evaluating Personalized and Contextualized Alignment of LLMs from Interactions", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "Accepted to COLM 2025. Project Website: https://cupid.kixlab.org/", "summary": "Personalization of Large Language Models (LLMs) often assumes users hold\nstatic preferences that reflect globally in all tasks. In reality, humans hold\ndynamic preferences that change depending on the context. As users interact\nwith an LLM in various contexts, they naturally reveal their contextual\npreferences, which a model must infer and apply in future contexts to ensure\nalignment. To assess this, we introduce CUPID, a benchmark of 756 human-curated\ninteraction session histories between users and LLM-based chat assistants. In\neach interaction session, the user provides a request in a specific context and\nexpresses their preference through multi-turn feedback. Given a new user\nrequest and prior interaction sessions, our benchmark assesses whether LLMs can\ninfer the preference relevant to this request and generate a response that\nsatisfies this preference. With CUPID, we evaluated 10 open and proprietary\nLLMs, revealing that state-of-the-art LLMs struggle to infer preferences from\nmulti-turn interactions and fail to discern what previous context is relevant\nto a new request -- under 50% precision and 65% recall. Our work highlights the\nneed to advance LLM capabilities for more contextually personalized\ninteractions and proposes CUPID as a resource to drive these improvements.", "AI": {"tldr": "CUPID\u662f\u4e00\u4e2a\u8bc4\u4f30LLMs\u662f\u5426\u80fd\u4ece\u591a\u8f6e\u4ea4\u4e92\u4e2d\u63a8\u65ad\u7528\u6237\u52a8\u6001\u504f\u597d\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u5148\u8fdb\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u4eba\u7c7b\u504f\u597d\u662f\u52a8\u6001\u4e14\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\uff0c\u800c\u73b0\u6709LLMs\u5047\u8bbe\u504f\u597d\u662f\u9759\u6001\u7684\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u5b9e\u73b0\u4e2a\u6027\u5316\u4ea4\u4e92\u3002", "method": "\u5f15\u5165CUPID\u57fa\u51c6\uff0c\u5305\u542b756\u4e2a\u4eba\u5de5\u6807\u6ce8\u7684\u4ea4\u4e92\u4f1a\u8bdd\u5386\u53f2\uff0c\u8bc4\u4f30LLMs\u5728\u65b0\u8bf7\u6c42\u4e2d\u63a8\u65ad\u548c\u5e94\u7528\u504f\u597d\u7684\u80fd\u529b\u3002", "result": "\u8bc4\u4f3010\u4e2aLLMs\uff0c\u53d1\u73b0\u5176\u63a8\u65ad\u504f\u597d\u548c\u8bc6\u522b\u76f8\u5173\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\u4e0d\u8db3\uff08\u7cbe\u786e\u5ea6<50%\uff0c\u53ec\u56de\u7387<65%\uff09\u3002", "conclusion": "LLMs\u9700\u63d0\u5347\u4e0a\u4e0b\u6587\u4e2a\u6027\u5316\u80fd\u529b\uff0cCUPID\u53ef\u4f5c\u4e3a\u63a8\u52a8\u6539\u8fdb\u7684\u8d44\u6e90\u3002"}}
{"id": "2508.02340", "pdf": "https://arxiv.org/pdf/2508.02340", "abs": "https://arxiv.org/abs/2508.02340", "authors": ["Fan Hu", "Zijie Xin", "Xirong Li"], "title": "Learning Partially-Decorrelated Common Spaces for Ad-hoc Video Search", "categories": ["cs.CV", "cs.IR", "cs.MM"], "comment": "Accepted by ACMMM2025", "summary": "Ad-hoc Video Search (AVS) involves using a textual query to search for\nmultiple relevant videos in a large collection of unlabeled short videos. The\nmain challenge of AVS is the visual diversity of relevant videos. A simple\nquery such as \"Find shots of a man and a woman dancing together indoors\" can\nspan a multitude of environments, from brightly lit halls and shadowy bars to\ndance scenes in black-and-white animations. It is therefore essential to\nretrieve relevant videos as comprehensively as possible. Current solutions for\nthe AVS task primarily fuse multiple features into one or more common spaces,\nyet overlook the need for diverse spaces. To fully exploit the expressive\ncapability of individual features, we propose LPD, short for Learning Partially\nDecorrelated common spaces. LPD incorporates two key innovations:\nfeature-specific common space construction and the de-correlation loss.\nSpecifically, LPD learns a separate common space for each video and text\nfeature, and employs de-correlation loss to diversify the ordering of negative\nsamples across different spaces. To enhance the consistency of multi-space\nconvergence, we designed an entropy-based fair multi-space triplet ranking\nloss. Extensive experiments on the TRECVID AVS benchmarks (2016-2023) justify\nthe effectiveness of LPD. Moreover, diversity visualizations of LPD's spaces\nhighlight its ability to enhance result diversity.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLPD\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u90e8\u5206\u89e3\u76f8\u5173\u7684\u516c\u5171\u7a7a\u95f4\u6765\u89e3\u51b3\u89c6\u9891\u641c\u7d22\u4e2d\u7684\u89c6\u89c9\u591a\u6837\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u89c6\u9891\u641c\u7d22\u4e2d\u56e0\u89c6\u89c9\u591a\u6837\u6027\u5bfc\u81f4\u7684\u68c0\u7d22\u4e0d\u5168\u9762\u95ee\u9898\u3002", "method": "LPD\u65b9\u6cd5\u5305\u62ec\u7279\u5f81\u7279\u5b9a\u7684\u516c\u5171\u7a7a\u95f4\u6784\u5efa\u548c\u89e3\u76f8\u5173\u635f\u5931\uff0c\u4ee5\u53ca\u57fa\u4e8e\u71b5\u7684\u591a\u7a7a\u95f4\u4e09\u5143\u7ec4\u6392\u5e8f\u635f\u5931\u3002", "result": "\u5728TRECVID AVS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86LPD\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u589e\u5f3a\u7ed3\u679c\u591a\u6837\u6027\u7684\u80fd\u529b\u3002", "conclusion": "LPD\u901a\u8fc7\u591a\u6837\u5316\u516c\u5171\u7a7a\u95f4\u663e\u8457\u63d0\u5347\u4e86\u89c6\u9891\u641c\u7d22\u7684\u5168\u9762\u6027\u548c\u591a\u6837\u6027\u3002"}}
{"id": "2508.01368", "pdf": "https://arxiv.org/pdf/2508.01368", "abs": "https://arxiv.org/abs/2508.01368", "authors": ["Zhehong Ren", "Tianluo Zhang", "Yiheng Lu", "Yushen Liang", "Promethee Spathis"], "title": "Relation-Aware LNN-Transformer for Intersection-Centric Next-Step Prediction", "categories": ["cs.AI"], "comment": "8 pages, 5 figures", "summary": "Next-step location prediction plays a pivotal role in modeling human\nmobility, underpinning applications from personalized navigation to strategic\nurban planning. However, approaches that assume a closed world - restricting\nchoices to a predefined set of points of interest (POIs) - often fail to\ncapture exploratory or target-agnostic behavior and the topological constraints\nof urban road networks. Hence, we introduce a road-node-centric framework that\nrepresents road-user trajectories on the city's road-intersection graph,\nthereby relaxing the closed-world constraint and supporting next-step\nforecasting beyond fixed POI sets. To encode environmental context, we\nintroduce a sector-wise directional POI aggregation that produces compact\nfeatures capturing distance, bearing, density and presence cues. By combining\nthese cues with structural graph embeddings, we obtain semantically grounded\nnode representations. For sequence modeling, we integrate a Relation-Aware\nLNN-Transformer - a hybrid of a Continuous-time Forgetting Cell CfC-LNN and a\nbearing-biased self-attention module - to capture both fine-grained temporal\ndynamics and long-range spatial dependencies. Evaluated on city-scale road-user\ntrajectories, our model outperforms six state-of-the-art baselines by up to 17\npercentage points in accuracy at one hop and 10 percentage points in MRR, and\nmaintains high resilience under noise, losing only 2.4 percentage points in\naccuracy at one under 50 meter GPS perturbation and 8.9 percentage points in\naccuracy at one hop under 25 percent POI noise.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9053\u8def\u8282\u70b9\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u7528\u6237\u7684\u4e0b\u4e00\u4e2a\u4f4d\u7f6e\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u5c01\u95ed\u4e16\u754c\u5047\u8bbe\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u57ce\u5e02\u89c4\u6a21\u8f68\u8ff9\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5047\u8bbe\u5c01\u95ed\u4e16\u754c\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u7684\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u63a2\u7d22\u6027\u884c\u4e3a\u6216\u57ce\u5e02\u9053\u8def\u7f51\u7edc\u7684\u62d3\u6251\u7ea6\u675f\u3002", "method": "\u91c7\u7528\u9053\u8def\u8282\u70b9\u4e2d\u5fc3\u6846\u67b6\uff0c\u7ed3\u5408\u65b9\u5411\u6027POI\u805a\u5408\u548c\u7ed3\u6784\u56fe\u5d4c\u5165\uff0c\u4f7f\u7528\u5173\u7cfb\u611f\u77e5\u7684LNN-Transformer\u8fdb\u884c\u5e8f\u5217\u5efa\u6a21\u3002", "result": "\u6a21\u578b\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u4e14\u5728\u566a\u58f0\u73af\u5883\u4e0b\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u57ce\u5e02\u89c4\u6a21\u7684\u4e0b\u4e00\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00961", "pdf": "https://arxiv.org/pdf/2508.00961", "abs": "https://arxiv.org/abs/2508.00961", "authors": ["Xiang Li", "Penglei Sun", "Wanyun Zhou", "Zikai Wei", "Yongqi Zhang", "Xiaowen Chu"], "title": "FinKario: Event-Enhanced Automated Construction of Financial Knowledge Graph", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Individual investors are significantly outnumbered and disadvantaged in\nfinancial markets, overwhelmed by abundant information and lacking professional\nanalysis. Equity research reports stand out as crucial resources, offering\nvaluable insights. By leveraging these reports, large language models (LLMs)\ncan enhance investors' decision-making capabilities and strengthen financial\nanalysis. However, two key challenges limit their effectiveness: (1) the rapid\nevolution of market events often outpaces the slow update cycles of existing\nknowledge bases, (2) the long-form and unstructured nature of financial reports\nfurther hinders timely and context-aware integration by LLMs. To address these\nchallenges, we tackle both data and methodological aspects. First, we introduce\nthe Event-Enhanced Automated Construction of Financial Knowledge Graph\n(FinKario), a dataset comprising over 305,360 entities, 9,625 relational\ntriples, and 19 distinct relation types. FinKario automatically integrates\nreal-time company fundamentals and market events through prompt-driven\nextraction guided by professional institutional templates, providing structured\nand accessible financial insights for LLMs. Additionally, we propose a\nTwo-Stage, Graph-Based retrieval strategy (FinKario-RAG), optimizing the\nretrieval of evolving, large-scale financial knowledge to ensure efficient and\nprecise data access. Extensive experiments show that FinKario with FinKario-RAG\nachieves superior stock trend prediction accuracy, outperforming financial LLMs\nby 18.81% and institutional strategies by 17.85% on average in backtesting.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFinKario\u548cFinKario-RAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u65f6\u6574\u5408\u5e02\u573a\u4e8b\u4ef6\u548c\u7ed3\u6784\u5316\u91d1\u878d\u77e5\u8bc6\uff0c\u63d0\u5347LLMs\u5728\u91d1\u878d\u5206\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e2a\u4f53\u6295\u8d44\u8005\u5728\u91d1\u878d\u5e02\u573a\u4e2d\u5904\u4e8e\u52a3\u52bf\uff0c\u7f3a\u4e4f\u4e13\u4e1a\u5206\u6790\u80fd\u529b\u3002\u73b0\u6709\u91d1\u878d\u7814\u7a76\u62a5\u544a\u66f4\u65b0\u6162\u4e14\u975e\u7ed3\u6784\u5316\uff0c\u9650\u5236\u4e86LLMs\u7684\u51b3\u7b56\u652f\u6301\u6548\u679c\u3002", "method": "\u63d0\u51faFinKario\u6570\u636e\u96c6\uff08\u5305\u542b\u5927\u91cf\u5b9e\u4f53\u548c\u5173\u7cfb\uff09\u548cFinKario-RAG\u68c0\u7d22\u7b56\u7565\uff0c\u5b9e\u65f6\u6574\u5408\u5e02\u573a\u4e8b\u4ef6\u548c\u7ed3\u6784\u5316\u91d1\u878d\u77e5\u8bc6\u3002", "result": "FinKario\u4e0eFinKario-RAG\u5728\u80a1\u7968\u8d8b\u52bf\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5206\u522b\u8d85\u8d8a\u91d1\u878dLLMs\u548c\u673a\u6784\u7b56\u756518.81%\u548c17.85%\u3002", "conclusion": "FinKario\u548cFinKario-RAG\u6709\u6548\u89e3\u51b3\u4e86\u91d1\u878d\u77e5\u8bc6\u66f4\u65b0\u6162\u548c\u975e\u7ed3\u6784\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u91d1\u878d\u5206\u6790\u80fd\u529b\u3002"}}
{"id": "2508.01682", "pdf": "https://arxiv.org/pdf/2508.01682", "abs": "https://arxiv.org/abs/2508.01682", "authors": ["Lingyin Zhang", "Jun Gao", "Xiaoxue Ren", "Ziqiang Cao"], "title": "The Bidirectional Process Reward Model", "categories": ["cs.CL"], "comment": null, "summary": "Process Reward Models (PRMs) have emerged as a promising approach to enhance\nthe reasoning quality of Large Language Models (LLMs) by assigning fine-grained\nscores to intermediate reasoning steps within a solution trajectory. However,\nexisting PRMs predominantly adopt a unidirectional left-to-right (L2R)\nevaluation paradigm, which limits their ability to leverage global context,\nmaking it challenging to verify the consistency of earlier steps based on later\nones. In light of these challenges, we propose a novel bidirectional evaluation\nparadigm, named Bidirectional Process Reward Model (BiPRM). BiPRM seamlessly\nincorporates a parallel right-to-left (R2L) evaluation stream alongside the\nconventional L2R flow, enabling later reasoning steps to help assess earlier\nones in real time. Notably, the built-in R2L evaluation is implemented solely\nthrough prompt modifications that reverse the original reasoning trajectory,\nwithout any additional parameters or inference latency introduced. This ensures\nBiPRM remains both efficient and broadly compatible with existing PRM studies.\nWe conduct extensive experiments on two mathematical reasoning benchmarks using\nsamples generated by three different policy models. Our method, BiPRM, is\nevaluated across three backbones and three distinct PRM objectives. Across all\nsettings, BiPRM consistently outperforms unidirectional baselines, achieving up\nto a 31.9% improvement in stepwise reward evaluation. Generally, our results\nhighlight BiPRM's effectiveness, robustness, and general applicability,\noffering a promising new direction for process-based reward modeling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5411\u8bc4\u4f30\u8303\u5f0fBiPRM\uff0c\u901a\u8fc7\u7ed3\u5408\u4ece\u5de6\u5230\u53f3\u548c\u4ece\u53f3\u5230\u5de6\u7684\u8bc4\u4f30\u6d41\uff0c\u63d0\u5347\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u7684\u63a8\u7406\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u91c7\u7528\u5355\u5411\u8bc4\u4f30\u8303\u5f0f\uff0c\u65e0\u6cd5\u5229\u7528\u5168\u5c40\u4e0a\u4e0b\u6587\u9a8c\u8bc1\u63a8\u7406\u6b65\u9aa4\u7684\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51faBiPRM\uff0c\u901a\u8fc7\u53cd\u5411\u63a8\u7406\u8f68\u8ff9\u5b9e\u73b0\u53cc\u5411\u8bc4\u4f30\uff0c\u65e0\u9700\u989d\u5916\u53c2\u6570\u6216\u5ef6\u8fdf\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBiPRM\u663e\u8457\u4f18\u4e8e\u5355\u5411\u57fa\u7ebf\uff0c\u6700\u9ad8\u63d0\u534731.9%\u3002", "conclusion": "BiPRM\u9ad8\u6548\u3001\u517c\u5bb9\u6027\u5f3a\uff0c\u4e3a\u8fc7\u7a0b\u5956\u52b1\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.02374", "pdf": "https://arxiv.org/pdf/2508.02374", "abs": "https://arxiv.org/abs/2508.02374", "authors": ["Shuo Lu", "Yanyin Chen", "Wei Feng", "Jiahao Fan", "Fengheng Li", "Zheng Zhang", "Jingjing Lv", "Junjie Shen", "Ching Law", "Jian Liang"], "title": "Uni-Layout: Integrating Human Feedback in Unified Layout Generation and Evaluation", "categories": ["cs.CV", "cs.IR", "cs.LG"], "comment": "Accepted to ACM MM 2025", "summary": "Layout generation plays a crucial role in enhancing both user experience and\ndesign efficiency. However, current approaches suffer from task-specific\ngeneration capabilities and perceptually misaligned evaluation metrics, leading\nto limited applicability and ineffective measurement. In this paper, we propose\n\\textit{Uni-Layout}, a novel framework that achieves unified generation,\nhuman-mimicking evaluation and alignment between the two. For universal\ngeneration, we incorporate various layout tasks into a single taxonomy and\ndevelop a unified generator that handles background or element contents\nconstrained tasks via natural language prompts. To introduce human feedback for\nthe effective evaluation of layouts, we build \\textit{Layout-HF100k}, the first\nlarge-scale human feedback dataset with 100,000 expertly annotated layouts.\nBased on \\textit{Layout-HF100k}, we introduce a human-mimicking evaluator that\nintegrates visual and geometric information, employing a Chain-of-Thought\nmechanism to conduct qualitative assessments alongside a confidence estimation\nmodule to yield quantitative measurements. For better alignment between the\ngenerator and the evaluator, we integrate them into a cohesive system by\nadopting Dynamic-Margin Preference Optimization (DMPO), which dynamically\nadjusts margins based on preference strength to better align with human\njudgments. Extensive experiments show that \\textit{Uni-Layout} significantly\noutperforms both task-specific and general-purpose methods. Our code is\npublicly available at https://github.com/JD-GenX/Uni-Layout.", "AI": {"tldr": "Uni-Layout\u662f\u4e00\u4e2a\u7edf\u4e00\u5e03\u5c40\u751f\u6210\u4e0e\u8bc4\u4f30\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u5904\u7406\u591a\u79cd\u5e03\u5c40\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u5927\u89c4\u6a21\u4eba\u7c7b\u53cd\u9988\u6570\u636e\u96c6Layout-HF100k\uff0c\u7ed3\u5408\u89c6\u89c9\u548c\u51e0\u4f55\u4fe1\u606f\u8fdb\u884c\u5b9a\u6027\u5b9a\u91cf\u8bc4\u4f30\uff0c\u52a8\u6001\u4f18\u5316\u5bf9\u9f50\u751f\u6210\u4e0e\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u5e03\u5c40\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u4efb\u52a1\u7279\u5b9a\u6027\u5f3a\u3001\u8bc4\u4f30\u6307\u6807\u4e0e\u611f\u77e5\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u9002\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faUni-Layout\u6846\u67b6\uff0c\u5305\u62ec\u7edf\u4e00\u751f\u6210\u5668\u3001\u57fa\u4e8eLayout-HF100k\u7684\u4eba\u7c7b\u6a21\u62df\u8bc4\u4f30\u5668\uff0c\u4ee5\u53ca\u52a8\u6001\u8fb9\u9645\u504f\u597d\u4f18\u5316\uff08DMPO\uff09\u5bf9\u9f50\u4e24\u8005\u3002", "result": "\u5b9e\u9a8c\u8868\u660eUni-Layout\u663e\u8457\u4f18\u4e8e\u4efb\u52a1\u7279\u5b9a\u548c\u901a\u7528\u65b9\u6cd5\u3002", "conclusion": "Uni-Layout\u901a\u8fc7\u7edf\u4e00\u751f\u6210\u4e0e\u8bc4\u4f30\uff0c\u7ed3\u5408\u4eba\u7c7b\u53cd\u9988\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e03\u5c40\u751f\u6210\u7684\u9002\u7528\u6027\u548c\u6548\u679c\u3002"}}
{"id": "2508.01432", "pdf": "https://arxiv.org/pdf/2508.01432", "abs": "https://arxiv.org/abs/2508.01432", "authors": ["Yuanzhe Shen", "Kaimin Wang", "Changze Lv", "Xiaoqing Zheng", "Xuanjing Huang"], "title": "TripTailor: A Real-World Benchmark for Personalized Travel Planning", "categories": ["cs.AI"], "comment": "Accepted to ACL 2025 Findings", "summary": "The continuous evolution and enhanced reasoning capabilities of large\nlanguage models (LLMs) have elevated their role in complex tasks, notably in\ntravel planning, where demand for personalized, high-quality itineraries is\nrising. However, current benchmarks often rely on unrealistic simulated data,\nfailing to reflect the differences between LLM-generated and real-world\nitineraries. Existing evaluation metrics, which primarily emphasize\nconstraints, fall short of providing a comprehensive assessment of the overall\nquality of travel plans. To address these limitations, we introduce TripTailor,\na benchmark designed specifically for personalized travel planning in\nreal-world scenarios. This dataset features an extensive collection of over\n500,000 real-world points of interest (POIs) and nearly 4,000 diverse travel\nitineraries, complete with detailed information, providing a more authentic\nevaluation framework. Experiments show that fewer than 10\\% of the itineraries\ngenerated by the latest state-of-the-art LLMs achieve human-level performance.\nMoreover, we identify several critical challenges in travel planning, including\nthe feasibility, rationality, and personalized customization of the proposed\nsolutions. We hope that TripTailor will drive the development of travel\nplanning agents capable of understanding and meeting user needs while\ngenerating practical itineraries. Our code and dataset are available at\nhttps://github.com/swxkfm/TripTailor", "AI": {"tldr": "TripTailor\u662f\u4e00\u4e2a\u9488\u5bf9\u771f\u5b9e\u573a\u666f\u4e2a\u6027\u5316\u65c5\u884c\u89c4\u5212\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u5927\u91cf\u771f\u5b9ePOI\u548c\u65c5\u884c\u884c\u7a0b\u6570\u636e\uff0c\u5b9e\u9a8c\u663e\u793a\u5f53\u524dLLM\u751f\u6210\u7684\u884c\u7a0b\u4e2d\u4ec5\u6709\u4e0d\u523010%\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4f9d\u8d56\u6a21\u62df\u6570\u636e\uff0c\u65e0\u6cd5\u53cd\u6620LLM\u751f\u6210\u884c\u7a0b\u4e0e\u771f\u5b9e\u884c\u7a0b\u7684\u5dee\u5f02\uff0c\u4e14\u8bc4\u4f30\u6307\u6807\u4e0d\u5168\u9762\u3002", "method": "\u5f15\u5165TripTailor\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b50\u4e07+\u771f\u5b9ePOI\u548c\u8fd14000\u6761\u591a\u6837\u5316\u884c\u7a0b\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6700\u65b0LLM\u751f\u6210\u7684\u884c\u7a0b\u4e2d\u4ec5\u6709\u4e0d\u523010%\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\uff0c\u4e14\u5b58\u5728\u53ef\u884c\u6027\u3001\u5408\u7406\u6027\u548c\u4e2a\u6027\u5316\u5b9a\u5236\u7b49\u6311\u6218\u3002", "conclusion": "TripTailor\u6709\u671b\u63a8\u52a8\u65c5\u884c\u89c4\u5212\u4ee3\u7406\u7684\u53d1\u5c55\uff0c\u751f\u6210\u66f4\u7b26\u5408\u7528\u6237\u9700\u6c42\u7684\u5b9e\u7528\u884c\u7a0b\u3002"}}
{"id": "2508.00963", "pdf": "https://arxiv.org/pdf/2508.00963", "abs": "https://arxiv.org/abs/2508.00963", "authors": ["Timothy Oladunni", "Alex Wong"], "title": "Rethinking Multimodality: Optimizing Multimodal Deep Learning for Biomedical Signal Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study proposes a novel perspective on multimodal deep learning for\nbiomedical signal classification, systematically analyzing how complementary\nfeature domains impact model performance. While fusing multiple domains often\npresumes enhanced accuracy, this work demonstrates that adding modalities can\nyield diminishing returns, as not all fusions are inherently advantageous. To\nvalidate this, five deep learning models were designed, developed, and\nrigorously evaluated: three unimodal (1D-CNN for time, 2D-CNN for\ntime-frequency, and 1D-CNN-Transformer for frequency) and two multimodal\n(Hybrid 1, which fuses 1D-CNN and 2D-CNN; Hybrid 2, which combines 1D-CNN,\n2D-CNN, and a Transformer). For ECG classification, bootstrapping and Bayesian\ninference revealed that Hybrid 1 consistently outperformed the 2D-CNN baseline\nacross all metrics (p-values < 0.05, Bayesian probabilities > 0.90), confirming\nthe synergistic complementarity of the time and time-frequency domains.\nConversely, Hybrid 2's inclusion of the frequency domain offered no further\nimprovement and sometimes a marginal decline, indicating representational\nredundancy; a phenomenon further substantiated by a targeted ablation study.\nThis research redefines a fundamental principle of multimodal design in\nbiomedical signal analysis. We demonstrate that optimal domain fusion isn't\nabout the number of modalities, but the quality of their inherent\ncomplementarity. This paradigm-shifting concept moves beyond purely heuristic\nfeature selection. Our novel theoretical contribution, \"Complementary Feature\nDomains in Multimodal ECG Deep Learning,\" presents a mathematically\nquantifiable framework for identifying ideal domain combinations, demonstrating\nthat optimal multimodal performance arises from the intrinsic\ninformation-theoretic complementarity among fused domains.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5206\u6790\u4e92\u8865\u7279\u5f81\u57df\u5bf9\u751f\u7269\u533b\u5b66\u4fe1\u53f7\u5206\u7c7b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5e76\u975e\u6240\u6709\u6a21\u6001\u878d\u5408\u90fd\u6709\u76ca\u3002", "motivation": "\u63a2\u8ba8\u591a\u6a21\u6001\u878d\u5408\u5728\u751f\u7269\u533b\u5b66\u4fe1\u53f7\u5206\u7c7b\u4e2d\u7684\u5b9e\u9645\u6548\u679c\uff0c\u9a8c\u8bc1\u4e92\u8865\u7279\u5f81\u57df\u7684\u91cd\u8981\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e94\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u4e09\u79cd\u5355\u6a21\u6001\u548c\u4e24\u79cd\u591a\u6a21\u6001\uff09\uff0c\u901a\u8fc7ECG\u5206\u7c7b\u4efb\u52a1\u9a8c\u8bc1\u6027\u80fd\u3002", "result": "Hybrid 1\uff08\u878d\u5408\u65f6\u95f4\u548c\u65f6\u9891\u57df\uff09\u8868\u73b0\u6700\u4f73\uff0c\u800cHybrid 2\uff08\u989d\u5916\u52a0\u5165\u9891\u57df\uff09\u672a\u5e26\u6765\u6539\u8fdb\uff0c\u751a\u81f3\u7565\u6709\u4e0b\u964d\u3002", "conclusion": "\u591a\u6a21\u6001\u8bbe\u8ba1\u7684\u6838\u5fc3\u5728\u4e8e\u7279\u5f81\u57df\u7684\u4e92\u8865\u6027\u800c\u975e\u6570\u91cf\uff0c\u63d0\u51fa\u4e86\u91cf\u5316\u4e92\u8865\u6027\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2508.01696", "pdf": "https://arxiv.org/pdf/2508.01696", "abs": "https://arxiv.org/abs/2508.01696", "authors": ["Yi Jiang", "Sendong Zhao", "Jianbo Li", "Haochun Wang", "Lizhe Zhang", "Yan Liu", "Bin Qin"], "title": "Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge Synergy", "categories": ["cs.CL", "cs.AI"], "comment": "code available at https://github.com/liunian-Jay/CoCoA", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a promising framework for\nenhancing the capabilities of Large Language Models (LLMs), especially in\nknowledge-intensive tasks. Despite its advantages, current RAG methods often\nstruggle to *fully exploit knowledge during generation*. In particular, the\nsynergy between the model's internal parametric knowledge and external\nretrieved knowledge remains limited. Retrieved contents may sometimes mislead\ngeneration, while certain generated content can guide the model toward more\naccurate outputs. In this work, we propose Collaborative Chain-of-Agents, a\nframework designed to enhance explicitly synergy over both parametric and\nretrieved knowledge. Specifically, we first introduce CoCoA-zero, a multi-agent\nRAG framework that first performs conditional knowledge induction and then\nreasons answers. Building on this, we develop CoCoA, a long-chain training\nstrategy that synthesizes extended multi-agent reasoning trajectories from\nCoCoA-zero to fine-tune the LLM. This strategy enhances the model's capability\nto explicitly integrate and jointly leverage parametric and retrieved\nknowledge. Experiments results show that CoCoA-zero and CoCoA achieve superior\nperformance on open-domain and multi-hop QA tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCollaborative Chain-of-Agents\uff08CoCoA\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u540c\u589e\u5f3a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e2d\u53c2\u6570\u5316\u77e5\u8bc6\u4e0e\u68c0\u7d22\u77e5\u8bc6\u7684\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f00\u653e\u9886\u57df\u548c\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524dRAG\u65b9\u6cd5\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u672a\u80fd\u5145\u5206\u5229\u7528\u77e5\u8bc6\uff0c\u53c2\u6570\u5316\u77e5\u8bc6\u4e0e\u68c0\u7d22\u77e5\u8bc6\u4e4b\u95f4\u7684\u534f\u540c\u4f5c\u7528\u6709\u9650\uff0c\u751a\u81f3\u68c0\u7d22\u5185\u5bb9\u53ef\u80fd\u8bef\u5bfc\u751f\u6210\u3002", "method": "\u63d0\u51faCoCoA-zero\uff08\u591a\u667a\u80fd\u4f53RAG\u6846\u67b6\uff09\u548cCoCoA\uff08\u957f\u94fe\u8bad\u7ec3\u7b56\u7565\uff09\uff0c\u901a\u8fc7\u6761\u4ef6\u77e5\u8bc6\u5f52\u7eb3\u548c\u63a8\u7406\u589e\u5f3a\u77e5\u8bc6\u878d\u5408\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCoCoA-zero\u548cCoCoA\u5728\u5f00\u653e\u9886\u57df\u548c\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "CoCoA\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u77e5\u8bc6\u878d\u5408\u80fd\u529b\uff0c\u4e3aRAG\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2508.02383", "pdf": "https://arxiv.org/pdf/2508.02383", "abs": "https://arxiv.org/abs/2508.02383", "authors": ["Changjie Sheng", "Zhichao Zhang", "Wei Yao"], "title": "Graph Embedding in the Graph Fractional Fourier Transform Domain", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Spectral graph embedding plays a critical role in graph representation\nlearning by generating low-dimensional vector representations from graph\nspectral information. However, the embedding space of traditional spectral\nembedding methods often exhibit limited expressiveness, failing to exhaustively\ncapture latent structural features across alternative transform domains. To\naddress this issue, we use the graph fractional Fourier transform to extend the\nexisting state-of-the-art generalized frequency filtering embedding (GEFFE)\ninto fractional domains, giving birth to the generalized fractional filtering\nembedding (GEFRFE), which enhances embedding informativeness via the graph\nfractional domain. The GEFRFE leverages graph fractional domain filtering and a\nnonlinear composition of eigenvector components derived from a fractionalized\ngraph Laplacian. To dynamically determine the fractional order, two parallel\nstrategies are introduced: search-based optimization and a ResNet18-based\nadaptive learning. Extensive experiments on six benchmark datasets demonstrate\nthat the GEFRFE captures richer structural features and significantly enhance\nclassification performance. Notably, the proposed method retains computational\ncomplexity comparable to GEFFE approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u5206\u6570\u5085\u91cc\u53f6\u53d8\u6362\u7684\u5e7f\u4e49\u5206\u6570\u6ee4\u6ce2\u5d4c\u5165\u65b9\u6cd5\uff08GEFRFE\uff09\uff0c\u901a\u8fc7\u6269\u5c55\u4f20\u7edf\u8c31\u5d4c\u5165\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u5d4c\u5165\u7a7a\u95f4\u7684\u8868\u73b0\u529b\u3002", "motivation": "\u4f20\u7edf\u8c31\u5d4c\u5165\u65b9\u6cd5\u5728\u6355\u6349\u6f5c\u5728\u7ed3\u6784\u7279\u5f81\u65b9\u9762\u8868\u73b0\u6709\u9650\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u53d8\u6362\u57df\u7684\u4fe1\u606f\u3002", "method": "\u5229\u7528\u56fe\u5206\u6570\u5085\u91cc\u53f6\u53d8\u6362\u6269\u5c55GEFFE\u65b9\u6cd5\uff0c\u5f15\u5165\u5206\u6570\u57df\u6ee4\u6ce2\u548c\u975e\u7ebf\u6027\u7279\u5f81\u7ec4\u5408\uff0c\u5e76\u901a\u8fc7\u641c\u7d22\u4f18\u5316\u548cResNet18\u81ea\u9002\u5e94\u5b66\u4e60\u52a8\u6001\u786e\u5b9a\u5206\u6570\u9636\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGEFRFE\u80fd\u6355\u6349\u66f4\u4e30\u5bcc\u7684\u7ed3\u6784\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u5206\u7c7b\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e0eGEFFE\u76f8\u5f53\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "GEFRFE\u901a\u8fc7\u5206\u6570\u57df\u6269\u5c55\u663e\u8457\u63d0\u5347\u4e86\u8c31\u5d4c\u5165\u7684\u8868\u73b0\u529b\uff0c\u4e3a\u56fe\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.01475", "pdf": "https://arxiv.org/pdf/2508.01475", "abs": "https://arxiv.org/abs/2508.01475", "authors": ["Zhen Wu", "Ritam Dutt", "Luke M. Breitfeller", "Armineh Nourbakhsh", "Siddharth Parekh", "Carolyn Ros\u00e9"], "title": "$R^2$-CoD: Understanding Text-Graph Complementarity in Relational Reasoning via Knowledge Co-Distillation", "categories": ["cs.AI"], "comment": null, "summary": "Relational reasoning lies at the core of many NLP tasks, drawing on\ncomplementary signals from text and graphs. While prior research has\ninvestigated how to leverage this dual complementarity, a detailed and\nsystematic understanding of text-graph interplay and its effect on hybrid\nmodels remains underexplored. We take an analysis-driven approach to\ninvestigate text-graph representation complementarity via a unified\narchitecture that supports knowledge co-distillation (CoD). We explore five\ntasks involving relational reasoning that differ in how text and graph\nstructures encode the information needed to solve that task. By tracking how\nthese dual representations evolve during training, we uncover interpretable\npatterns of alignment and divergence, and provide insights into when and why\ntheir integration is beneficial.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7edf\u4e00\u67b6\u6784\u7814\u7a76\u6587\u672c\u4e0e\u56fe\u8868\u793a\u7684\u4e92\u8865\u6027\uff0c\u63a2\u7d22\u4e94\u79cd\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\uff0c\u63ed\u793a\u8bad\u7ec3\u4e2d\u53cc\u8868\u793a\u7684\u6f14\u5316\u6a21\u5f0f\u3002", "motivation": "\u7814\u7a76\u6587\u672c\u4e0e\u56fe\u7ed3\u6784\u5728\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4e92\u8865\u6027\u53ca\u5176\u5bf9\u6df7\u5408\u6a21\u578b\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u5171\u84b8\u998f\uff08CoD\uff09\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u5206\u6790\u4e94\u79cd\u4efb\u52a1\u4e2d\u6587\u672c\u4e0e\u56fe\u7684\u8868\u793a\u6f14\u5316\u3002", "result": "\u63ed\u793a\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53cc\u8868\u793a\u7684\u6821\u51c6\u4e0e\u5206\u6b67\u6a21\u5f0f\uff0c\u660e\u786e\u4e86\u6574\u5408\u7684\u9002\u7528\u6761\u4ef6\u4e0e\u539f\u56e0\u3002", "conclusion": "\u6587\u672c\u4e0e\u56fe\u8868\u793a\u7684\u6574\u5408\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u80fd\u663e\u8457\u63d0\u5347\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2508.00965", "pdf": "https://arxiv.org/pdf/2508.00965", "abs": "https://arxiv.org/abs/2508.00965", "authors": ["Roie Kazoom", "Ofir Cohen", "Rami Puzis", "Asaf Shabtai", "Ofer Hadar"], "title": "VAULT: Vigilant Adversarial Updates via LLM-Driven Retrieval-Augmented Generation for NLI", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce VAULT, a fully automated adversarial RAG pipeline that\nsystematically uncovers and remedies weaknesses in NLI models through three\nstages: retrieval, adversarial generation, and iterative retraining. First, we\nperform balanced few-shot retrieval by embedding premises with both semantic\n(BGE) and lexical (BM25) similarity. Next, we assemble these contexts into LLM\nprompts to generate adversarial hypotheses, which are then validated by an LLM\nensemble for label fidelity. Finally, the validated adversarial examples are\ninjected back into the training set at increasing mixing ratios, progressively\nfortifying a zero-shot RoBERTa-base model.On standard benchmarks, VAULT\nelevates RoBERTa-base accuracy from 88.48% to 92.60% on SNLI +4.12%, from\n75.04% to 80.95% on ANLI +5.91%, and from 54.67% to 71.99% on MultiNLI +17.32%.\nIt also consistently outperforms prior in-context adversarial methods by up to\n2.0% across datasets. By automating high-quality adversarial data curation at\nscale, VAULT enables rapid, human-independent robustness improvements in NLI\ninference tasks.", "AI": {"tldr": "VAULT\u662f\u4e00\u4e2a\u5168\u81ea\u52a8\u5bf9\u6297\u6027RAG\u6d41\u7a0b\uff0c\u901a\u8fc7\u68c0\u7d22\u3001\u5bf9\u6297\u751f\u6210\u548c\u8fed\u4ee3\u8bad\u7ec3\u4e09\u4e2a\u9636\u6bb5\u63d0\u5347NLI\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3NLI\u6a21\u578b\u5728\u5bf9\u6297\u6027\u6570\u636e\u4e0b\u7684\u5f31\u70b9\uff0c\u63d0\u5347\u5176\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a\u5e73\u8861\u5c11\u6837\u672c\u68c0\u7d22\uff08\u7ed3\u5408\u8bed\u4e49\u548c\u8bcd\u6c47\u76f8\u4f3c\u6027\uff09\u3001LLM\u751f\u6210\u5bf9\u6297\u6027\u5047\u8bbe\u5e76\u901a\u8fc7\u9a8c\u8bc1\u3001\u8fed\u4ee3\u6ce8\u5165\u8bad\u7ec3\u96c6\u9010\u6b65\u589e\u5f3a\u6a21\u578b\u3002", "result": "\u5728SNLI\u3001ANLI\u548cMultiNLI\u6570\u636e\u96c6\u4e0a\u5206\u522b\u63d0\u53474.12%\u30015.91%\u548c17.32%\u7684\u51c6\u786e\u6027\uff0c\u4e14\u4f18\u4e8e\u73b0\u6709\u5bf9\u6297\u6027\u65b9\u6cd5\u3002", "conclusion": "VAULT\u901a\u8fc7\u81ea\u52a8\u5316\u9ad8\u8d28\u91cf\u5bf9\u6297\u6570\u636e\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86NLI\u4efb\u52a1\u7684\u9c81\u68d2\u6027\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002"}}
{"id": "2508.01708", "pdf": "https://arxiv.org/pdf/2508.01708", "abs": "https://arxiv.org/abs/2508.01708", "authors": ["Berkay K\u00f6pr\u00fc", "Mehrzad Mashal", "Yigit Gurses", "Akos Kadar", "Maximilian Schmitt", "Ditty Mathew", "Felix Burkhardt", "Florian Eyben", "Bj\u00f6rn W. Schuller"], "title": "Am I Blue or Is My Hobby Counting Teardrops? Expression Leakage in Large Language Models as a Symptom of Irrelevancy Disruption", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have advanced natural language processing (NLP)\nskills such as through next-token prediction and self-attention, but their\nability to integrate broad context also makes them prone to incorporating\nirrelevant information. Prior work has focused on semantic leakage, bias\nintroduced by semantically irrelevant context. In this paper, we introduce\nexpression leakage, a novel phenomenon where LLMs systematically generate\nsentimentally charged expressions that are semantically unrelated to the input\ncontext. To analyse the expression leakage, we collect a benchmark dataset\nalong with a scheme to automatically generate a dataset from free-form text\nfrom common-crawl. In addition, we propose an automatic evaluation pipeline\nthat correlates well with human judgment, which accelerates the benchmarking by\ndecoupling from the need of annotation for each analysed model. Our experiments\nshow that, as the model scales in the parameter space, the expression leakage\nreduces within the same LLM family. On the other hand, we demonstrate that\nexpression leakage mitigation requires specific care during the model building\nprocess, and cannot be mitigated by prompting. In addition, our experiments\nindicate that, when negative sentiment is injected in the prompt, it disrupts\nthe generation process more than the positive sentiment, causing a higher\nexpression leakage rate.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u8868\u8fbe\u6cc4\u6f0f\u73b0\u8c61\uff0c\u5373\u6a21\u578b\u751f\u6210\u4e0e\u8f93\u5165\u4e0a\u4e0b\u6587\u8bed\u4e49\u65e0\u5173\u7684\u60c5\u611f\u5316\u8868\u8fbe\u3002\u901a\u8fc7\u6784\u5efa\u6570\u636e\u96c6\u548c\u81ea\u52a8\u8bc4\u4f30\u6d41\u7a0b\uff0c\u53d1\u73b0\u6a21\u578b\u89c4\u6a21\u6269\u5927\u80fd\u51cf\u5c11\u8868\u8fbe\u6cc4\u6f0f\uff0c\u4f46\u9700\u5728\u6a21\u578b\u6784\u5efa\u8fc7\u7a0b\u4e2d\u4e13\u95e8\u5904\u7406\uff0c\u63d0\u793a\u65e0\u6cd5\u7f13\u89e3\u3002\u8d1f\u5411\u60c5\u611f\u63d0\u793a\u4f1a\u5bfc\u81f4\u66f4\u9ad8\u7684\u8868\u8fbe\u6cc4\u6f0f\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bb9\u6613\u5f15\u5165\u65e0\u5173\u4fe1\u606f\u3002\u6b64\u524d\u7814\u7a76\u5173\u6ce8\u8bed\u4e49\u6cc4\u6f0f\uff0c\u672c\u6587\u63d0\u51fa\u8868\u8fbe\u6cc4\u6f0f\u73b0\u8c61\uff0c\u5373\u6a21\u578b\u751f\u6210\u4e0e\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u60c5\u611f\u5316\u8868\u8fbe\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5f71\u54cd\u548c\u7f13\u89e3\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u81ea\u52a8\u751f\u6210\u6570\u636e\u96c6\u7684\u65b9\u6848\u3002\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e0e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u76f8\u5173\u7684\u81ea\u52a8\u8bc4\u4f30\u6d41\u7a0b\uff0c\u52a0\u901f\u6a21\u578b\u5206\u6790\u3002\u5b9e\u9a8c\u5206\u6790\u4e86\u6a21\u578b\u89c4\u6a21\u3001\u63d0\u793a\u65b9\u5f0f\u5bf9\u8868\u8fbe\u6cc4\u6f0f\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u89c4\u6a21\u6269\u5927\u65f6\uff0c\u540c\u4e00\u5bb6\u65cf\u5185\u7684\u8868\u8fbe\u6cc4\u6f0f\u51cf\u5c11\uff1b\u8868\u8fbe\u6cc4\u6f0f\u65e0\u6cd5\u901a\u8fc7\u63d0\u793a\u7f13\u89e3\uff0c\u9700\u5728\u6a21\u578b\u6784\u5efa\u8fc7\u7a0b\u4e2d\u4e13\u95e8\u5904\u7406\uff1b\u8d1f\u5411\u60c5\u611f\u63d0\u793a\u6bd4\u6b63\u5411\u60c5\u611f\u63d0\u793a\u5bfc\u81f4\u66f4\u9ad8\u7684\u8868\u8fbe\u6cc4\u6f0f\u7387\u3002", "conclusion": "\u8868\u8fbe\u6cc4\u6f0f\u662fLLM\u4e2d\u9700\u4e13\u95e8\u5904\u7406\u7684\u95ee\u9898\uff0c\u6a21\u578b\u89c4\u6a21\u6269\u5927\u6709\u52a9\u4e8e\u7f13\u89e3\uff0c\u4f46\u9700\u5728\u6784\u5efa\u8fc7\u7a0b\u4e2d\u4f18\u5316\u3002\u8d1f\u5411\u60c5\u611f\u5bf9\u751f\u6210\u7684\u5e72\u6270\u66f4\u5f3a\uff0c\u63d0\u793a\u65e0\u6cd5\u6709\u6548\u7f13\u89e3\u8868\u8fbe\u6cc4\u6f0f\u3002"}}
{"id": "2508.02455", "pdf": "https://arxiv.org/pdf/2508.02455", "abs": "https://arxiv.org/abs/2508.02455", "authors": ["Daniele Cipollone", "Egor Bogomolov", "Arie van Deursen", "Maliheh Izadi"], "title": "TreeRanker: Fast and Model-agnostic Ranking System for Code Suggestions in IDEs", "categories": ["cs.SE", "cs.AI", "cs.IR"], "comment": null, "summary": "Token-level code completion is one of the most critical features in modern\nIntegrated Development Environments (IDEs). It assists developers by suggesting\nrelevant identifiers and APIs during coding. While completions are typically\nderived from static analysis, their usefulness depends heavily on how they are\nranked, as correct predictions buried deep in the list are rarely seen by\nusers. Most current systems rely on hand-crafted heuristics or lightweight\nmachine learning models trained on user logs, which can be further improved to\ncapture context information and generalize across projects and coding styles.\nIn this work, we propose a new scoring approach to ranking static completions\nusing language models in a lightweight and model-agnostic way. Our method\norganizes all valid completions into a prefix tree and performs a single greedy\ndecoding pass to collect token-level scores across the tree. This enables a\nprecise token-aware ranking without needing beam search, prompt engineering, or\nmodel adaptations. The approach is fast, architecture-agnostic, and compatible\nwith already deployed models for code completion. These findings highlight a\npractical and effective pathway for integrating language models into already\nexisting tools within IDEs, and ultimately providing smarter and more\nresponsive developer assistance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u3001\u6a21\u578b\u65e0\u5173\u7684\u4ee3\u7801\u8865\u5168\u6392\u540d\u65b9\u6cd5\uff0c\u901a\u8fc7\u524d\u7f00\u6811\u548c\u8d2a\u5a6a\u89e3\u7801\u4f18\u5316\u8865\u5168\u5efa\u8bae\u7684\u6392\u540d\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u8865\u5168\u7cfb\u7edf\u4f9d\u8d56\u624b\u5de5\u542f\u53d1\u5f0f\u6216\u8f7b\u91cf\u7ea7\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u96be\u4ee5\u6355\u6349\u4e0a\u4e0b\u6587\u4fe1\u606f\u5e76\u6cdb\u5316\u5230\u4e0d\u540c\u9879\u76ee\u548c\u7f16\u7801\u98ce\u683c\u3002", "method": "\u5c06\u6240\u6709\u6709\u6548\u8865\u5168\u7ec4\u7ec7\u4e3a\u524d\u7f00\u6811\uff0c\u901a\u8fc7\u5355\u6b21\u8d2a\u5a6a\u89e3\u7801\u6536\u96c6\u4ee4\u724c\u7ea7\u5206\u6570\uff0c\u5b9e\u73b0\u65e0\u9700\u675f\u641c\u7d22\u3001\u63d0\u793a\u5de5\u7a0b\u6216\u6a21\u578b\u8c03\u6574\u7684\u7cbe\u786e\u6392\u540d\u3002", "result": "\u65b9\u6cd5\u5feb\u901f\u3001\u67b6\u6784\u65e0\u5173\uff0c\u4e14\u517c\u5bb9\u73b0\u6709\u4ee3\u7801\u8865\u5168\u6a21\u578b\uff0c\u4e3aIDE\u5de5\u5177\u96c6\u6210\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aIDE\u63d0\u4f9b\u4e86\u66f4\u667a\u80fd\u3001\u54cd\u5e94\u66f4\u5feb\u7684\u5f00\u53d1\u8005\u8f85\u52a9\u5de5\u5177\uff0c\u5c55\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u6709\u5de5\u5177\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.01476", "pdf": "https://arxiv.org/pdf/2508.01476", "abs": "https://arxiv.org/abs/2508.01476", "authors": ["Arindam Khanda", "Anurag Satpathy", "Amit Jha", "Sajal K. Das"], "title": "CARGO: A Co-Optimization Framework for EV Charging and Routing in Goods Delivery Logistics", "categories": ["cs.AI"], "comment": null, "summary": "With growing interest in sustainable logistics, electric vehicle (EV)-based\ndeliveries offer a promising alternative for urban distribution. However, EVs\nface challenges due to their limited battery capacity, requiring careful\nplanning for recharging. This depends on factors such as the charging point\n(CP) availability, cost, proximity, and vehicles' state of charge (SoC). We\npropose CARGO, a framework addressing the EV-based delivery route planning\nproblem (EDRP), which jointly optimizes route planning and charging for\ndeliveries within time windows. After proving the problem's NP-hardness, we\npropose a mixed integer linear programming (MILP)-based exact solution and a\ncomputationally efficient heuristic method. Using real-world datasets, we\nevaluate our methods by comparing the heuristic to the MILP solution, and\nbenchmarking it against baseline strategies, Earliest Deadline First (EDF) and\nNearest Delivery First (NDF). The results show up to 39% and 22% reductions in\nthe charging cost over EDF and NDF, respectively, while completing comparable\ndeliveries.", "AI": {"tldr": "CARGO\u6846\u67b6\u4f18\u5316\u7535\u52a8\u8f66\u8f86\u914d\u9001\u8def\u7ebf\u548c\u5145\u7535\u8ba1\u5212\uff0c\u663e\u8457\u964d\u4f4e\u5145\u7535\u6210\u672c\u3002", "motivation": "\u7535\u52a8\u8f66\u8f86\u914d\u9001\u56e0\u7535\u6c60\u5bb9\u91cf\u6709\u9650\u9700\u4f18\u5316\u5145\u7535\u8ba1\u5212\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u5145\u7535\u70b9\u53ef\u7528\u6027\u3001\u6210\u672c\u7b49\u56e0\u7d20\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u7cbe\u786e\u89e3\u548c\u9ad8\u6548\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u89e3\u51b3\u914d\u9001\u8def\u7ebf\u548c\u5145\u7535\u8054\u5408\u4f18\u5316\u95ee\u9898\u3002", "result": "\u76f8\u6bd4\u57fa\u51c6\u7b56\u7565\uff0c\u5145\u7535\u6210\u672c\u964d\u4f4e39%\uff08EDF\uff09\u548c22%\uff08NDF\uff09\uff0c\u540c\u65f6\u5b8c\u6210\u7c7b\u4f3c\u914d\u9001\u91cf\u3002", "conclusion": "CARGO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u7535\u52a8\u8f66\u8f86\u914d\u9001\u4e2d\u7684\u5145\u7535\u548c\u8def\u7ebf\u89c4\u5212\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.00969", "pdf": "https://arxiv.org/pdf/2508.00969", "abs": "https://arxiv.org/abs/2508.00969", "authors": ["Lucas Robinet", "Ahmad Berjaoui", "Elizabeth Cohen-Jonathan Moyal"], "title": "Masked Omics Modeling for Multimodal Representation Learning across Histopathology and Molecular Profiles", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Self-supervised learning has driven major advances in computational pathology\nby enabling models to learn rich representations from hematoxylin and eosin\n(H&E)-stained cancer tissue. However, histopathology alone often falls short\nfor molecular characterization and understanding clinical outcomes, as\nimportant information is contained in high-dimensional omics profiles like\ntranscriptomics, methylomics, or genomics. In this work, we introduce MORPHEUS,\na unified transformer-based pre-training framework that encodes both\nhistopathology and multi-omics data into a shared latent space. At its core,\nMORPHEUS relies on a masked modeling objective applied to randomly selected\nomics portions, encouraging the model to learn biologically meaningful\ncross-modal relationships. The same pre-trained network can be applied to\nhistopathology alone or in combination with any subset of omics modalities,\nseamlessly adapting to the available inputs. Additionally, MORPHEUS enables\nany-to-any omics generation, enabling one or more omics profiles to be inferred\nfrom any subset of modalities, including H&E alone. Pre-trained on a large\npan-cancer cohort, MORPHEUS consistently outperforms state-of-the-art methods\nacross diverse modality combinations and tasks, positioning itself as a\npromising framework for developing multimodal foundation models in oncology.\nThe code is available at: https://github.com/Lucas-rbnt/MORPHEUS", "AI": {"tldr": "MORPHEUS\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u6574\u5408\u4e86\u7ec4\u7ec7\u75c5\u7406\u5b66\u548c\u591a\u7ec4\u5b66\u6570\u636e\uff0c\u901a\u8fc7\u63a9\u7801\u5efa\u6a21\u5b66\u4e60\u8de8\u6a21\u6001\u5173\u7cfb\uff0c\u5e76\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7ec4\u7ec7\u75c5\u7406\u5b66\u6570\u636e\u4e0d\u8db3\u4ee5\u5168\u9762\u8868\u5f81\u5206\u5b50\u7279\u5f81\u548c\u4e34\u5e8a\u7ed3\u679c\uff0c\u800c\u591a\u7ec4\u5b66\u6570\u636e\uff08\u5982\u8f6c\u5f55\u7ec4\u3001\u7532\u57fa\u5316\u7ec4\u6216\u57fa\u56e0\u7ec4\uff09\u5305\u542b\u91cd\u8981\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\u6765\u6574\u5408\u8fd9\u4e9b\u6570\u636e\u3002", "method": "MORPHEUS\u901a\u8fc7\u63a9\u7801\u5efa\u6a21\u76ee\u6807\u968f\u673a\u9009\u62e9\u7ec4\u5b66\u90e8\u5206\uff0c\u5b66\u4e60\u8de8\u6a21\u6001\u5173\u7cfb\uff0c\u5e76\u652f\u6301\u4ece\u4efb\u4f55\u5b50\u6a21\u6001\u63a8\u65ad\u7ec4\u5b66\u6570\u636e\u3002", "result": "MORPHEUS\u5728\u591a\u79cd\u6a21\u6001\u7ec4\u5408\u548c\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u80bf\u7624\u5b66\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "MORPHEUS\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u80bf\u7624\u5b66\u7814\u7a76\u548c\u4e34\u5e8a\u5e94\u7528\u3002"}}
{"id": "2508.01710", "pdf": "https://arxiv.org/pdf/2508.01710", "abs": "https://arxiv.org/abs/2508.01710", "authors": ["Raviraj Joshi", "Rakesh Paul", "Kanishk Singla", "Anusha Kamath", "Michael Evans", "Katherine Luna", "Shaona Ghosh", "Utkarsh Vaidya", "Eileen Long", "Sanjay Singh Chauhan", "Niranjan Wartikar"], "title": "CultureGuard: Towards Culturally-Aware Dataset and Guard Model for Multilingual Safety Applications", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The increasing use of Large Language Models (LLMs) in agentic applications\nhighlights the need for robust safety guard models. While content safety in\nEnglish is well-studied, non-English languages lack similar advancements due to\nthe high cost of collecting culturally aligned labeled datasets. We present\nCultureGuard, a novel solution for curating culturally aligned, high-quality\nsafety datasets across multiple languages. Our approach introduces a four-stage\nsynthetic data generation and filtering pipeline: cultural data segregation,\ncultural data adaptation, machine translation, and quality filtering. This\npipeline enables the conversion and expansion of the\nNemotron-Content-Safety-Dataset-V2 English safety dataset into eight distinct\nlanguages: Arabic, German, Spanish, French, Hindi, Japanese, Thai, and Chinese.\nThe resulting dataset, Nemotron-Content-Safety-Dataset-Multilingual-v1,\ncomprises 386,661 samples in 9 languages and facilitates the training of\nLlama-3.1-Nemotron-Safety-Guard-Multilingual-8B-v1 via LoRA-based fine-tuning.\nThe final model achieves state-of-the-art performance on several multilingual\ncontent safety benchmarks. We also benchmark the latest open LLMs on\nmultilingual safety and observe that these LLMs are more prone to give unsafe\nresponses when prompted in non-English languages. This work represents a\nsignificant step toward closing the safety gap in multilingual LLMs by enabling\nthe development of culturally aware safety guard models.", "AI": {"tldr": "CultureGuard\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u8bed\u8a00\u6587\u5316\u5bf9\u9f50\u7684\u5b89\u5168\u6570\u636e\u96c6\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u548c\u8fc7\u6ee4\u6d41\u7a0b\uff0c\u6269\u5c55\u4e86\u82f1\u8bed\u5b89\u5168\u6570\u636e\u96c6\u52308\u79cd\u8bed\u8a00\uff0c\u5e76\u8bad\u7ec3\u4e86\u4e00\u4e2a\u591a\u8bed\u8a00\u5b89\u5168\u6a21\u578b\uff0c\u586b\u8865\u4e86\u975e\u82f1\u8bed\u8bed\u8a00\u7684\u5b89\u5168\u7a7a\u767d\u3002", "motivation": "\u975e\u82f1\u8bed\u8bed\u8a00\u7f3a\u4e4f\u6587\u5316\u5bf9\u9f50\u7684\u5b89\u5168\u6570\u636e\u96c6\uff0c\u5bfc\u81f4\u591a\u8bed\u8a00LLM\u5728\u5b89\u5168\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u56db\u9636\u6bb5\u5408\u6210\u6570\u636e\u751f\u6210\u548c\u8fc7\u6ee4\u6d41\u7a0b\uff1a\u6587\u5316\u6570\u636e\u9694\u79bb\u3001\u6587\u5316\u6570\u636e\u9002\u5e94\u3001\u673a\u5668\u7ffb\u8bd1\u548c\u8d28\u91cf\u8fc7\u6ee4\u3002", "result": "\u751f\u6210\u4e86\u5305\u542b386,661\u6837\u672c\u76849\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u5728\u591a\u8bed\u8a00\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u591a\u8bed\u8a00LLM\u7684\u5b89\u5168\u7a7a\u767d\uff0c\u63a8\u52a8\u4e86\u6587\u5316\u611f\u77e5\u5b89\u5168\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.01495", "pdf": "https://arxiv.org/pdf/2508.01495", "abs": "https://arxiv.org/abs/2508.01495", "authors": ["Jingtian Yan", "Stephen F. Smith", "Jiaoyang Li"], "title": "WinkTPG: An Execution Framework for Multi-Agent Path Finding Using Temporal Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Planning collision-free paths for a large group of agents is a challenging\nproblem with numerous real-world applications. While recent advances in\nMulti-Agent Path Finding (MAPF) have shown promising progress, standard MAPF\nalgorithms rely on simplified kinodynamic models, preventing agents from\ndirectly following the generated MAPF plan. To bridge this gap, we propose\nkinodynamic Temporal Plan Graph Planning (kTPG), a multi-agent speed\noptimization algorithm that efficiently refines a MAPF plan into a\nkinodynamically feasible plan while accounting for uncertainties and preserving\ncollision-freeness. Building on kTPG, we propose Windowed kTPG (WinkTPG), a\nMAPF execution framework that incrementally refines MAPF plans using a\nwindow-based mechanism, dynamically incorporating agent information during\nexecution to reduce uncertainty. Experiments show that WinkTPG can generate\nspeed profiles for up to 1,000 agents in 1 second and improves solution quality\nby up to 51.7% over existing MAPF execution methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3akTPG\u7684\u591a\u667a\u80fd\u4f53\u901f\u5ea6\u4f18\u5316\u7b97\u6cd5\uff0c\u4ee5\u53ca\u5176\u6269\u5c55\u6846\u67b6WinkTPG\uff0c\u7528\u4e8e\u5c06MAPF\u8ba1\u5212\u4f18\u5316\u4e3a\u52a8\u529b\u5b66\u53ef\u884c\u7684\u8def\u5f84\uff0c\u5e76\u52a8\u6001\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cWinkTPG\u80fd\u57281\u79d2\u5185\u4e3a1000\u4e2a\u667a\u80fd\u4f53\u751f\u6210\u901f\u5ea6\u66f2\u7ebf\uff0c\u4e14\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u63d0\u5347\u9ad8\u8fbe51.7%\u3002", "motivation": "\u73b0\u6709MAPF\u7b97\u6cd5\u4f9d\u8d56\u7b80\u5316\u7684\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5bfc\u81f4\u667a\u80fd\u4f53\u65e0\u6cd5\u76f4\u63a5\u6267\u884c\u751f\u6210\u7684\u8def\u5f84\u8ba1\u5212\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5c06MAPF\u8ba1\u5212\u4f18\u5316\u4e3a\u52a8\u529b\u5b66\u53ef\u884c\u7684\u8def\u5f84\u3002", "method": "\u63d0\u51fakTPG\u7b97\u6cd5\uff0c\u5c06MAPF\u8ba1\u5212\u4f18\u5316\u4e3a\u52a8\u529b\u5b66\u53ef\u884c\u7684\u8def\u5f84\uff1b\u8fdb\u4e00\u6b65\u63d0\u51faWinkTPG\u6846\u67b6\uff0c\u901a\u8fc7\u7a97\u53e3\u673a\u5236\u52a8\u6001\u4f18\u5316MAPF\u8ba1\u5212\u3002", "result": "WinkTPG\u80fd\u57281\u79d2\u5185\u4e3a1000\u4e2a\u667a\u80fd\u4f53\u751f\u6210\u901f\u5ea6\u66f2\u7ebf\uff0c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u63d0\u5347\u9ad8\u8fbe51.7%\u3002", "conclusion": "kTPG\u548cWinkTPG\u6709\u6548\u89e3\u51b3\u4e86MAPF\u8ba1\u5212\u52a8\u529b\u5b66\u53ef\u884c\u6027\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6267\u884c\u6548\u7387\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3002"}}
{"id": "2508.01002", "pdf": "https://arxiv.org/pdf/2508.01002", "abs": "https://arxiv.org/abs/2508.01002", "authors": ["Agrim Bari", "Parikshit Hegde", "Gustavo de Veciana"], "title": "Optimal Scheduling Algorithms for LLM Inference: Theory and Practice", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "With the growing use of Large Language Model (LLM)-based tools like ChatGPT,\nPerplexity, and Gemini across industries, there is a rising need for efficient\nLLM inference systems. These systems handle requests with a unique two-phase\ncomputation structure: a prefill-phase that processes the full input prompt and\na decode-phase that autoregressively generates tokens one at a time. This\nstructure calls for new strategies for routing and scheduling requests.\n  In this paper, we take a comprehensive approach to this challenge by\ndeveloping a theoretical framework that models routing and scheduling in LLM\ninference systems. We identify two key design principles-optimal tiling and\ndynamic resource allocation-that are essential for achieving high throughput.\nGuided by these principles, we propose the Resource-Aware Dynamic (RAD)\nscheduler and prove that it achieves throughput optimality under mild\nconditions. To address practical Service Level Objectives (SLOs) such as\nserving requests with different Time Between Token (TBT) constraints, we design\nthe SLO-Aware LLM Inference (SLAI) scheduler. SLAI uses real-time measurements\nto prioritize decode requests that are close to missing their TBT deadlines and\nreorders prefill requests based on known prompt lengths to further reduce the\nTime To First Token (TTFT) delays.\n  We evaluate SLAI on the Openchat ShareGPT4 dataset using the Mistral-7B model\non an NVIDIA RTX ADA 6000 GPU. Compared to Sarathi-Serve, SLAI reduces the\nmedian TTFT by 53% and increases the maximum serving capacity by 26% such that\nmedian TTFT is below 0.5 seconds, while meeting tail TBT latency constraints.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u7cfb\u7edf\u7684\u8c03\u5ea6\u6846\u67b6\uff0c\u5305\u62ec\u7406\u8bba\u6a21\u578b\u548c\u5b9e\u9645\u8c03\u5ea6\u5668\uff08RAD\u548cSLAI\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u548c\u54cd\u5e94\u65f6\u95f4\u3002", "motivation": "\u968f\u7740LLM\u5de5\u5177\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u72ec\u7279\u7684\u53cc\u9636\u6bb5\u8ba1\u7b97\u7ed3\u6784\uff08\u9884\u586b\u5145\u548c\u89e3\u7801\uff09\u9700\u8981\u65b0\u7684\u8def\u7531\u548c\u8c03\u5ea6\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u4e24\u5927\u539f\u5219\uff08\u6700\u4f18\u5206\u5757\u548c\u52a8\u6001\u8d44\u6e90\u5206\u914d\uff09\uff0c\u5e76\u5f00\u53d1\u4e86RAD\u548cSLAI\u8c03\u5ea6\u5668\u3002", "result": "\u5728Mistral-7B\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0cSLAI\u5c06TTFT\u4e2d\u4f4d\u6570\u964d\u4f4e53%\uff0c\u670d\u52a1\u5bb9\u91cf\u63d0\u534726%\uff0c\u540c\u65f6\u6ee1\u8db3\u5c3e\u90e8TBT\u5ef6\u8fdf\u7ea6\u675f\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aLLM\u63a8\u7406\u7cfb\u7edf\u7684\u9ad8\u6548\u8c03\u5ea6\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u652f\u6301\uff0c\u663e\u8457\u4f18\u5316\u4e86\u6027\u80fd\u3002"}}
{"id": "2508.01739", "pdf": "https://arxiv.org/pdf/2508.01739", "abs": "https://arxiv.org/abs/2508.01739", "authors": ["Cheng Wang", "ziru Liu", "Pengcheng Tang", "Mingyu Zhang", "Quanyu Dai", "Yue Zhu"], "title": "Enhancing the Preference Extractor in Multi-turn Dialogues: From Annotating Disasters to Accurate Preference Extraction", "categories": ["cs.CL"], "comment": null, "summary": "Identifying user preferences in dialogue systems is a pivotal aspect of\nproviding satisfying services. Current research shows that using large language\nmodels (LLMs) to fine-tune a task-specific preference extractor yields\nexcellent results in terms of accuracy and generalization. However, the primary\nchallenge stems from the inherent difficulty in obtaining high-quality labeled\nmulti-turn dialogue data. Accurately tracking user preference transitions\nacross turns not only demands intensive domain expertise and contextual\nconsistency maintenance for annotators (termed \\textbf{``Annotating\nDisaster''}) but also complicates model training due to error propagation in\nsequential dependency learning. Inspired by the observation that multi-turn\npreference extraction can be decomposed into iterative executions of one-turn\nextraction processes. We propose a novel dialogue data generation framework\nnamed \\textbf{IterChat}. First, we construct a new data format that categorizes\nthe dialogue data into attributed historical preferences and one-turn\ndialogues. This reduces the probability of annotation errors and improves\nannotation efficiency. Then, to generate a high-quality and diverse dialogue\ndataset, we adopt GPT4 to pre-define the preference slots in the target\npreference extractor task and then randomly sample the subset of the slots and\ntheir corresponding schema values to create the dialogue datasets. Experimental\nresults indicate that fine-tuning or only few-shot prompting with the new\ndialogue format yields superior performance compared to the original multi-turn\ndialogues. Additionally, the new data format improves annotator efficiency with\na win rate of 28.4\\% higher than the original multi-turn dialogues.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIterChat\u7684\u5bf9\u8bdd\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u591a\u8f6e\u504f\u597d\u63d0\u53d6\u4e3a\u5355\u8f6e\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u6807\u6ce8\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u6807\u6ce8\u5b58\u5728\u56f0\u96be\uff08\u6807\u6ce8\u707e\u96be\uff09\uff0c\u4e14\u6a21\u578b\u8bad\u7ec3\u6613\u53d7\u9519\u8bef\u4f20\u64ad\u5f71\u54cd\u3002\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u6784\u5efa\u65b0\u6570\u636e\u683c\u5f0f\uff0c\u5c06\u5bf9\u8bdd\u5206\u4e3a\u5386\u53f2\u504f\u597d\u548c\u5355\u8f6e\u5bf9\u8bdd\uff0c\u5229\u7528GPT4\u9884\u5b9a\u4e49\u504f\u597d\u69fd\u5e76\u968f\u673a\u91c7\u6837\u751f\u6210\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u6570\u636e\u683c\u5f0f\u5728\u5fae\u8c03\u6216\u5c11\u6837\u672c\u63d0\u793a\u4e0b\u6027\u80fd\u4f18\u4e8e\u539f\u59cb\u591a\u8f6e\u5bf9\u8bdd\uff0c\u6807\u6ce8\u6548\u7387\u63d0\u9ad828.4%\u3002", "conclusion": "IterChat\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6e\u504f\u597d\u63d0\u53d6\u7684\u6807\u6ce8\u548c\u8bad\u7ec3\u96be\u9898\uff0c\u63d0\u5347\u4e86\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2508.01543", "pdf": "https://arxiv.org/pdf/2508.01543", "abs": "https://arxiv.org/abs/2508.01543", "authors": ["Derin Cayir", "Renjie Tao", "Rashi Rungta", "Kai Sun", "Sean Chen", "Haidar Khan", "Minseok Kim", "Julia Reinspach", "Yue Liu"], "title": "Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable progress through\npreference-based fine-tuning, which critically depends on the quality of the\nunderlying training data. While human feedback is essential for improving data\nquality, it is costly and does not scale well. In this paper, we introduce\nRefine-n-Judge, an automated iterative approach that leverages a single LLM as\nboth a refiner and a judge to enhance dataset quality. Unlike existing\niterative refinement methods, Refine-n-Judge employs an LLM to both generate\nrefinements and explicitly evaluate each improvement, ensuring that every\niteration meaningfully enhances the dataset without requiring additional human\nannotation or a separate reward model. At each step, the LLM refines a response\nand judges whether the refinement is an improvement over the previous answer.\nThis process continues until the LLM prefers the initial answer over the\nrefinement, indicating no further improvements. This produces sequences of\nincreasing quality, preference-labeled responses ideal for fine-tuning.\n  We demonstrate the effectiveness of Refine-n-Judge across a range of public\ndatasets spanning five corpora, targeting tasks such as coding, math, and\nconversation. Models (Llama 3.1-8B and Llama 3.3-70B) fine-tuned on\nRefine-n-Judge-enhanced datasets were preferred by LLM judges in over 74% of\ncomparisons against models tuned on the original dataset by GPT-4.\nAdditionally, we report performance gains: +5% on AlpacaEval and AlpacaEval\n2.0, and +19% on MT-Bench. Our results indicate that Refine-n-Judge produces\nhigh-quality datasets and scalable model improvements.", "AI": {"tldr": "Refine-n-Judge\u662f\u4e00\u79cd\u81ea\u52a8\u8fed\u4ee3\u65b9\u6cd5\uff0c\u5229\u7528\u5355\u4e00LLM\u4f5c\u4e3a\u6570\u636e\u7cbe\u70bc\u5668\u548c\u8bc4\u4f30\u5668\uff0c\u63d0\u5347\u6570\u636e\u96c6\u8d28\u91cf\uff0c\u65e0\u9700\u989d\u5916\u4eba\u5de5\u6807\u6ce8\u6216\u5956\u52b1\u6a21\u578b\u3002", "motivation": "\u4eba\u7c7b\u53cd\u9988\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u73b0\u6709\u8fed\u4ee3\u65b9\u6cd5\u9700\u8981\u989d\u5916\u8d44\u6e90\uff0cRefine-n-Judge\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u5316\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "LLM\u540c\u65f6\u751f\u6210\u7cbe\u70bc\u7ed3\u679c\u5e76\u8bc4\u4f30\u6539\u8fdb\uff0c\u8fed\u4ee3\u76f4\u81f3\u65e0\u8fdb\u4e00\u6b65\u4f18\u5316\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u504f\u597d\u6807\u8bb0\u6570\u636e\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u6a21\u578b\u504f\u597d\u7387\u8d8574%\uff0c\u6027\u80fd\u63d0\u5347\u663e\u8457\uff08AlpacaEval +5%\uff0cMT-Bench +19%\uff09\u3002", "conclusion": "Refine-n-Judge\u80fd\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.01010", "pdf": "https://arxiv.org/pdf/2508.01010", "abs": "https://arxiv.org/abs/2508.01010", "authors": ["Gnankan Landry Regis N'guessan"], "title": "v-PuNNs: van der Put Neural Networks for Transparent Ultrametric Representation Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Conventional deep learning models embed data in Euclidean space\n$\\mathbb{R}^d$, a poor fit for strictly hierarchical objects such as taxa, word\nsenses, or file systems. We introduce van der Put Neural Networks (v-PuNNs),\nthe first architecture whose neurons are characteristic functions of p-adic\nballs in $\\mathbb{Z}_p$. Under our Transparent Ultrametric Representation\nLearning (TURL) principle every weight is itself a p-adic number, giving exact\nsubtree semantics. A new Finite Hierarchical Approximation Theorem shows that a\ndepth-K v-PuNN with $\\sum_{j=0}^{K-1}p^{\\,j}$ neurons universally represents\nany K-level tree. Because gradients vanish in this discrete space, we propose\nValuation-Adaptive Perturbation Optimization (VAPO), with a fast deterministic\nvariant (HiPaN-DS) and a moment-based one (HiPaN / Adam-VAPO). On three\ncanonical benchmarks our CPU-only implementation sets new state-of-the-art:\nWordNet nouns (52,427 leaves) 99.96% leaf accuracy in 16 min; GO\nmolecular-function 96.9% leaf / 100% root in 50 s; NCBI Mammalia Spearman $\\rho\n= -0.96$ with true taxonomic distance. The learned metric is perfectly\nultrametric (zero triangle violations), and its fractal and\ninformation-theoretic properties are analyzed. Beyond classification we derive\nstructural invariants for quantum systems (HiPaQ) and controllable generative\ncodes for tabular data (Tab-HiPaN). v-PuNNs therefore bridge number theory and\ndeep learning, offering exact, interpretable, and efficient models for\nhierarchical data.", "AI": {"tldr": "v-PuNNs\u662f\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5229\u7528p-adic\u6570\u8868\u793a\u5c42\u6b21\u7ed3\u6784\u6570\u636e\uff0c\u901a\u8fc7TURL\u539f\u5219\u548cVAPO\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u8868\u793a\u5c42\u6b21\u7ed3\u6784\u6570\u636e\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u786e\u3001\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fav-PuNNs\u67b6\u6784\uff0c\u795e\u7ecf\u5143\u4e3ap-adic\u7403\u7684\u7279\u5f81\u51fd\u6570\uff0c\u91c7\u7528TURL\u539f\u5219\u548cVAPO\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u5728WordNet\u3001GO\u548cNCBI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u9ad8\u7cbe\u5ea6\uff0c\u5b66\u4e60\u5230\u7684\u5ea6\u91cf\u5177\u6709\u5b8c\u7f8e\u8d85\u5ea6\u91cf\u6027\u8d28\u3002", "conclusion": "v-PuNNs\u7ed3\u5408\u6570\u8bba\u4e0e\u6df1\u5ea6\u5b66\u4e60\uff0c\u4e3a\u5c42\u6b21\u6570\u636e\u63d0\u4f9b\u4e86\u7cbe\u786e\u3001\u53ef\u89e3\u91ca\u4e14\u9ad8\u6548\u7684\u6a21\u578b\u3002"}}
