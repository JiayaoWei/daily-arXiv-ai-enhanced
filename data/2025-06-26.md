<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 16]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.IR](#cs.IR) [Total: 5]
- [cs.LG](#cs.LG) [Total: 16]
- [cs.HC](#cs.HC) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation](https://arxiv.org/abs/2506.19952)
*Deepon Halder,Thanmay Jayakumar,Raj Dabre*

Main category: cs.CL

TL;DR: CycleDistill利用LLMs和少样本翻译，通过迭代生成合成平行语料库来提升低资源语言的机器翻译质量，无需大量平行语料。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言因平行语料稀缺而难以实现高质量机器翻译的问题。

Method: 提出CycleDistill方法，通过零样本或少样本翻译从单语语料生成合成平行语料库，并用于微调模型。

Result: 在三种印度语言上，首轮迭代即可提升20-30 chrF点，且利用softmax激活能轻微提升翻译质量。

Conclusion: CycleDistill为低资源语言提供了一种高效的机器翻译解决方案。

Abstract: Large language models (LLMs), despite their ability to perform few-shot
machine translation (MT), often lag behind dedicated MT systems trained on
parallel corpora, which are crucial for high quality machine translation (MT).
However, parallel corpora are often scarce or non-existent for low-resource
languages. In this paper, we propose CycleDistill, a bootstrapping approach
leveraging LLMs and few-shot translation to obtain high-quality MT systems.
CycleDistill involves iteratively generating synthetic parallel corpora from
monolingual corpora via zero- or few-shot MT, which is then used to fine-tune
the model that was used for generating said data for MT. CycleDistill does not
need parallel corpora beyond 1 to 4 few-shot examples, and in our experiments
focusing on three Indian languages, by relying solely on monolingual corpora,
it can achieve high-quality machine translation, improving upon a few-shot
baseline model by over 20-30 chrF points on average in the first iteration. We
also study the effect of leveraging softmax activations during the distillation
process and observe mild improvements in translation quality.

</details>


### [2] [Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs](https://arxiv.org/abs/2506.19967)
*Travis Thompson,Seung-Hwan Lim,Paul Liu,Ruoying He,Dongkuan Xu*

Main category: cs.CL

TL;DR: 论文提出了一种名为Inference-Scaled GraphRAG的新框架，通过推理时计算扩展提升LLM在图推理任务中的表现，显著改进了多跳问答性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在语言理解和生成方面表现出色，但在知识密集型推理任务中表现不佳，主要因为缺乏结构化上下文和多跳信息的访问。

Method: 结合顺序扩展和深度链式图遍历，以及并行扩展和多数投票采样轨迹，形成交替推理-执行循环。

Result: 在GRBench基准测试中，该方法显著优于传统GraphRAG和图遍历基线。

Conclusion: 推理时扩展是一种实用且架构无关的解决方案，适用于LLM的结构化知识推理。

Abstract: Large Language Models (LLMs) have achieved impressive capabilities in
language understanding and generation, yet they continue to underperform on
knowledge-intensive reasoning tasks due to limited access to structured context
and multi-hop information. Retrieval-Augmented Generation (RAG) partially
mitigates this by grounding generation in retrieved context, but conventional
RAG and GraphRAG methods often fail to capture relational structure across
nodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel
framework that enhances LLM-based graph reasoning by applying inference-time
compute scaling. Our method combines sequential scaling with deep
chain-of-thought graph traversal, and parallel scaling with majority voting
over sampled trajectories within an interleaved reasoning-execution loop.
Experiments on the GRBench benchmark demonstrate that our approach
significantly improves multi-hop question answering performance, achieving
substantial gains over both traditional GraphRAG and prior graph traversal
baselines. These findings suggest that inference-time scaling is a practical
and architecture-agnostic solution for structured knowledge reasoning with LLMs

</details>


### [3] [Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation](https://arxiv.org/abs/2506.19998)
*Xinyi Ni,Haonan Jian,Qiuyang Wang,Vedanshi Chetan Shah,Pengyu Hong*

Main category: cs.CL

TL;DR: Doc2Agent是一种可扩展的流程，用于从API文档构建可调用Python工具的代理，显著提升性能并降低成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有API代理工具集单一且无法应对现实复杂API的问题。

Method: 从API文档生成可执行工具，并通过代码代理迭代优化。

Result: 在WebArena基准测试中性能提升55%，成本降低90%，并成功应用于复杂领域。

Conclusion: Doc2Agent为从非结构化API文档大规模构建工具代理提供了通用解决方案。

Abstract: REST APIs play important roles in enriching the action space of web agents,
yet most API-based agents rely on curated and uniform toolsets that do not
reflect the complexity of real-world APIs. Building tool-using agents for
arbitrary domains remains a major challenge, as it requires reading
unstructured API documentation, testing APIs and inferring correct parameters.
We propose Doc2Agent, a scalable pipeline to build agents that can call
Python-based tools generated from API documentation. Doc2Agent generates
executable tools from API documentations and iteratively refines them using a
code agent. We evaluate our approach on real-world APIs, WebArena APIs, and
research APIs, producing validated tools. We achieved a 55\% relative
performance improvement with 90\% lower cost compared to direct API calling on
WebArena benchmark. A domain-specific agent built for glycomaterial science
further demonstrates the pipeline's adaptability to complex, knowledge-rich
tasks. Doc2Agent offers a generalizable solution for building tool agents from
unstructured API documentation at scale.

</details>


### [4] [A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs](https://arxiv.org/abs/2506.20073)
*Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang*

Main category: cs.CL

TL;DR: STReason是一个结合大型语言模型和时空模型的新框架，用于多任务推理和复杂时空数据分析，无需任务特定微调即可生成详细解释和解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有时空数据挖掘模型局限于单一任务，缺乏多任务推理和复杂长形式推理能力，限制了其在实际决策场景中的应用。

Method: STReason利用上下文学习将复杂自然语言查询分解为模块化、可解释的程序，并系统执行以生成解决方案和详细理由。

Result: 实验表明，STReason在复杂时空推理任务中显著优于先进的大型语言模型基线，并通过人类评估验证了其可信度和实用性。

Conclusion: STReason为开发更强大、更通用的时空推理系统提供了有前景的方向。

Abstract: Spatio-temporal data mining plays a pivotal role in informed decision making
across diverse domains. However, existing models are often restricted to narrow
tasks, lacking the capacity for multi-task inference and complex long-form
reasoning that require generation of in-depth, explanatory outputs. These
limitations restrict their applicability to real-world, multi-faceted decision
scenarios. In this work, we introduce STReason, a novel framework that
integrates the reasoning strengths of large language models (LLMs) with the
analytical capabilities of spatio-temporal models for multi-task inference and
execution. Without requiring task-specific finetuning, STReason leverages
in-context learning to decompose complex natural language queries into modular,
interpretable programs, which are then systematically executed to generate both
solutions and detailed rationales. To facilitate rigorous evaluation, we
construct a new benchmark dataset and propose a unified evaluation framework
with metrics specifically designed for long-form spatio-temporal reasoning.
Experimental results show that STReason significantly outperforms advanced LLM
baselines across all metrics, particularly excelling in complex,
reasoning-intensive spatio-temporal scenarios. Human evaluations further
validate STReason's credibility and practical utility, demonstrating its
potential to reduce expert workload and broaden the applicability to real-world
spatio-temporal tasks. We believe STReason provides a promising direction for
developing more capable and generalizable spatio-temporal reasoning systems.

</details>


### [5] [SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization](https://arxiv.org/abs/2506.20081)
*Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie*

Main category: cs.CL

TL;DR: 论文提出了一种名为SACL的框架，通过增强代码或结构知识中的语义信息，减少检索偏差并提升代码生成性能。实验表明，SACL显著提高了代码检索和生成的性能。


<details>
  <summary>Details</summary>
Motivation: 当前代码检索器过于依赖表面文本特征（如文档字符串、标识符名称），并对文档丰富的代码存在强烈偏见，即使文档无关。这限制了代码生成的效果。

Method: 通过系统性地屏蔽特定特征但保留代码功能，分析代码检索行为，并提出了SACL框架，该框架通过增强语义信息来减少偏差。

Result: SACL显著提升了代码检索性能（如HumanEval / MBPP / SWE-Bench-Lite上的Recall@1分别提高了12.8% / 9.4% / 7.0%），并进一步改善了代码生成性能（如HumanEval上的Pass@1提高了4.88%）。

Conclusion: SACL通过增强语义信息有效减少了代码检索中的偏差，显著提升了检索和生成性能，为代码生成领域提供了新的改进方向。

Abstract: Retrieval-Augmented Code Generation (RACG) is a critical technique for
enhancing code generation by retrieving relevant information. In this work, we
conduct an in-depth analysis of code retrieval by systematically masking
specific features while preserving code functionality. Our discoveries include:
(1) although trained on code, current retrievers heavily rely on surface-level
textual features (e.g., docstrings, identifier names), and (2) they exhibit a
strong bias towards well-documented code, even if the documentation is
irrelevant.Based on our discoveries, we propose SACL, a framework that enriches
textual information and reduces bias by augmenting code or structural knowledge
with semantic information. Extensive experiments show that SACL substantially
improves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval /
MBPP / SWE-Bench-Lite), which also leads to better code generation performance
(e.g., by 4.88% Pass@1 on HumanEval).

</details>


### [6] [Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder](https://arxiv.org/abs/2506.20083)
*Yingji Zhang,Danilo S. Carvalho,André Freitas*

Main category: cs.CL

TL;DR: 该论文探讨了如何通过结合组合和符号特性来提升基于Transformer的自回归语言模型的解释性、可控性、组合性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 弥合符号语义和分布语义之间的差距，提升语言模型的语义表示能力。

Method: 综述了三种主流自编码器架构（VAE、VQVAE、SAE），并分析了它们在语义结构和解释性方面的潜在几何特性。

Result: 通过语义表示学习，为语言模型的潜在空间几何提供了新的视角。

Conclusion: 结合组合和符号特性可以有效提升语言模型的语义表示能力，为未来研究提供了方向。

Abstract: Integrating compositional and symbolic properties into current distributional
semantic spaces can enhance the interpretability, controllability,
compositionality, and generalisation capabilities of Transformer-based
auto-regressive language models (LMs). In this survey, we offer a novel
perspective on latent space geometry through the lens of compositional
semantics, a direction we refer to as \textit{semantic representation
learning}. This direction enables a bridge between symbolic and distributional
semantics, helping to mitigate the gap between them. We review and compare
three mainstream autoencoder architectures-Variational AutoEncoder (VAE),
Vector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the
distinctive latent geometries they induce in relation to semantic structure and
interpretability.

</details>


### [7] [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093)
*Yilin Wang,Peixuan Lei,Jie Song,Yuzhe Hao,Tao Chen,Yuxuan Zhang,Lei Jia,Yuanxiang Li,Zhongyu Wei*

Main category: cs.CL

TL;DR: 论文提出了Time-Series QA任务和EngineMT-QA数据集，并开发了ITFormer框架，用于高效融合时间序列与自然语言，显著提升QA准确性。


<details>
  <summary>Details</summary>
Motivation: 高维时间序列与自然语言的有效融合在动态交互任务中仍具挑战性。

Method: 提出ITFormer框架，结合时间序列编码器与冻结大语言模型，提取、对齐和融合时序与文本特征。

Result: ITFormer在QA准确性上显著优于基线模型，且仅需不到1%的可训练参数。

Conclusion: 该研究为时间序列与自然语言的融合提供了高效范式，推动了多模态AI的研究与应用。

Abstract: Time-series data are critical in diverse applications, such as industrial
monitoring, medical diagnostics, and climate research. However, effectively
integrating these high-dimensional temporal signals with natural language for
dynamic, interactive tasks remains a significant challenge. To address this, we
introduce the Time-Series Question Answering (Time-Series QA) task and release
EngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset
designed to capture complex interactions between time-series signals and
natural language. Building on this resource, we propose the Instruct Time
Transformer (ITFormer), a novel framework that bridges time-series encoders
with frozen large language models (LLMs). ITFormer effectively extracts,
aligns, and fuses temporal and textual features, achieving a strong improvement
in QA accuracy over strong baselines with fewer than 1\% additional trainable
parameters. By combining computational efficiency with robust cross-modal
modeling, our work establishes a adaptable paradigm for integrating temporal
data with natural language, paving the way for new research and applications in
multi-modal AI. More details about the project, including datasets and code,
are available at: https://pandalin98.github.io/itformer_site/

</details>


### [8] [A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection](https://arxiv.org/abs/2506.20112)
*Songsoo Kim,Seungtae Lee,See Young Lee,Joonho Kim,Keechan Kan,Dukyong Yoon*

Main category: cs.CL

TL;DR: 研究提出了一种三阶段LLM框架，显著提高了放射学报告的阳性预测值（PPV）并降低了运营成本。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLM）在放射学报告校对中的阳性预测值（PPV）较低，研究旨在通过三阶段框架提升PPV并减少成本。

Method: 研究分析了1000份放射学报告，测试了三种LLM框架：单提示检测器、提取器加检测器、以及提取器、检测器和假阳性验证器的组合。通过PPV和绝对真阳性率（aTPR）评估性能，并计算运营成本。

Result: 三阶段框架（框架3）显著提高了PPV（0.159），同时降低了运营成本（每1000份报告5.58美元）。外部验证也支持其优越性。

Conclusion: 三阶段LLM框架显著提升了PPV和成本效益，为AI辅助放射学报告质量保证提供了有效策略。

Abstract: Background: The positive predictive value (PPV) of large language model
(LLM)-based proofreading for radiology reports is limited due to the low error
prevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV
and reduces operational costs compared with baseline approaches. Materials and
Methods: A retrospective analysis was performed on 1,000 consecutive radiology
reports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III
database. Two external datasets (CheXpert and Open-i) were validation sets.
Three LLM frameworks were tested: (1) single-prompt detector; (2) extractor
plus detector; and (3) extractor, detector, and false-positive verifier.
Precision was measured by PPV and absolute true positive rate (aTPR).
Efficiency was calculated from model inference charges and reviewer
remuneration. Statistical significance was tested using cluster bootstrap,
exact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV
increased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118,
Framework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs.
baselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per
1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and
USD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively.
Human-reviewed reports decreased from 192 to 88. External validation supported
Framework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR
(0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and
reduced operational costs, maintaining detection performance, providing an
effective strategy for AI-assisted radiology report quality assurance.

</details>


### [9] [Leveraging AI Graders for Missing Score Imputation to Achieve Accurate Ability Estimation in Constructed-Response Tests](https://arxiv.org/abs/2506.20119)
*Masaki Uto,Yuma Ito*

Main category: cs.CL

TL;DR: 论文提出了一种利用自动评分技术填补缺失分数的新方法，以提高IRT能力估计的准确性并减少人工评分负担。


<details>
  <summary>Details</summary>
Motivation: 评估学习者的能力是教育领域的核心目标，尤其是高阶能力如表达技能和逻辑思维。虽然构建性反应测试（如简答和论述题）有效，但人工评分成本高且耗时。IRT虽能从不完整数据估计能力，但随着缺失分数比例增加，准确性下降。现有数据增强技术对稀疏或异构数据效果不佳。

Method: 提出了一种利用自动评分技术填补缺失分数的新方法，以提高IRT能力估计的准确性。

Result: 该方法在能力估计中实现了高准确性，并显著减少了人工评分工作量。

Conclusion: 该研究为高效、准确地评估学习者能力提供了一种可行方案，尤其适用于大规模测试场景。

Abstract: Evaluating the abilities of learners is a fundamental objective in the field
of education. In particular, there is an increasing need to assess higher-order
abilities such as expressive skills and logical thinking. Constructed-response
tests such as short-answer and essay-based questions have become widely used as
a method to meet this demand. Although these tests are effective, they require
substantial manual grading, making them both labor-intensive and costly. Item
response theory (IRT) provides a promising solution by enabling the estimation
of ability from incomplete score data, where human raters grade only a subset
of answers provided by learners across multiple test items. However, the
accuracy of ability estimation declines as the proportion of missing scores
increases. Although data augmentation techniques for imputing missing scores
have been explored in order to address this limitation, they often struggle
with inaccuracy for sparse or heterogeneous data. To overcome these challenges,
this study proposes a novel method for imputing missing scores by leveraging
automated scoring technologies for accurate IRT-based ability estimation. The
proposed method achieves high accuracy in ability estimation while markedly
reducing manual grading workload.

</details>


### [10] [CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation](https://arxiv.org/abs/2506.20128)
*Aashiq Muhamed*

Main category: cs.CL

TL;DR: 论文提出CCRS，一种基于预训练LLM的零样本评估框架，用于全面评估RAG系统的多维度质量，包括上下文连贯性、问题相关性等五个指标。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统评估方法存在不足，如简单词汇重叠指标无法捕捉质量细节，或复杂多阶段流程效率低下。

Method: 提出CCRS，利用单一预训练LLM作为零样本端到端评估器，包含五个指标（CC、QR、ID、AC、IR）。

Result: 在BioASQ数据集上验证CCRS能有效区分系统性能，如Mistral-7B优于Llama变体，且计算效率优于RAGChecker。

Conclusion: CCRS为RAG系统提供了一种实用、全面且高效的评估框架。

Abstract: RAG systems enhance LLMs by incorporating external knowledge, which is
crucial for domains that demand factual accuracy and up-to-date information.
However, evaluating the multifaceted quality of RAG outputs, spanning aspects
such as contextual coherence, query relevance, factual correctness, and
informational completeness, poses significant challenges. Existing evaluation
methods often rely on simple lexical overlap metrics, which are inadequate for
capturing these nuances, or involve complex multi-stage pipelines with
intermediate steps like claim extraction or require finetuning specialized
judge models, hindering practical efficiency. To address these limitations, we
propose CCRS (Contextual Coherence and Relevance Score), a novel suite of five
metrics that utilizes a single, powerful, pretrained LLM as a zero-shot,
end-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance
(QR), Information Density (ID), Answer Correctness (AC), and Information Recall
(IR). We apply CCRS to evaluate six diverse RAG system configurations on the
challenging BioASQ dataset. Our analysis demonstrates that CCRS effectively
discriminates between system performances, confirming, for instance, that the
Mistral-7B reader outperforms Llama variants. We provide a detailed analysis of
CCRS metric properties, including score distributions, convergent/discriminant
validity, tie rates, population statistics, and discriminative power. Compared
to the complex RAGChecker framework, CCRS offers comparable or superior
discriminative power for key aspects like recall and faithfulness, while being
significantly more computationally efficient. CCRS thus provides a practical,
comprehensive, and efficient framework for evaluating and iteratively improving
RAG systems.

</details>


### [11] [Knowledge-Aware Diverse Reranking for Cross-Source Question Answering](https://arxiv.org/abs/2506.20476)
*Tong Zhou*

Main category: cs.CL

TL;DR: Team Marikarp的解决方案在SIGIR 2025 LiveRAG竞赛中夺冠，其知识感知多样性重排序RAG管道表现优异。


<details>
  <summary>Details</summary>
Motivation: 竞赛提供了一个公平的评估环境，测试从15M文档子集中检索问题相关支持文档的能力。

Method: 提出了知识感知多样性重排序RAG管道。

Result: 在竞赛中获得第一名。

Conclusion: 该方法在多样化检索任务中表现出色。

Abstract: This paper presents Team Marikarp's solution for the SIGIR 2025 LiveRAG
competition. The competition's evaluation set, automatically generated by
DataMorgana from internet corpora, encompassed a wide range of target topics,
question types, question formulations, audience types, and knowledge
organization methods. It offered a fair evaluation of retrieving
question-relevant supporting documents from a 15M documents subset of the
FineWeb corpus. Our proposed knowledge-aware diverse reranking RAG pipeline
achieved first place in the competition.

</details>


### [12] [AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control](https://arxiv.org/abs/2506.20160)
*Ruosen Li,Ziming Luo,Quan Zhang,Ruochen Li,Ben Zhou,Ali Payani,Xinya Du*

Main category: cs.CL

TL;DR: AALC是一种轻量级的、基于准确性的长度奖励方法，通过动态平衡正确性和简洁性，显著减少推理模型的响应长度，同时保持或提高准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）通过生成冗长的思维链实现强大推理能力，但这种方法导致高延迟和成本，且准确性提升有限。

Method: AALC将验证准确性纳入奖励机制，并采用动态调度的长度惩罚，延迟长度惩罚直至达到目标性能。

Result: 实验表明，AALC将响应长度减少50%以上，同时保持或提高准确性，并减少冗余推理模式。

Conclusion: AALC展示了基于奖励的策略在引导LRMs实现高效、通用推理路径方面的潜力，但也可能牺牲部分可解释性。

Abstract: Large reasoning models (LRMs) achieve impressive reasoning capabilities by
generating lengthy chain-of-thoughts, but this "overthinking" incurs high
latency and cost without commensurate accuracy gains. In this work, we
introduce AALC, a lightweight, accuracy-aware length reward integrated into
reinforcement learning that dynamically balances correctness and brevity during
training. By incorporating validation accuracy into the reward and employing a
smooth, dynamically scheduled length penalty, AALC delays length penalty until
target performance is met. Through extensive experiments across standard and
out-of-distribution math benchmarks, we show that our approach reduces response
length by over 50% while maintaining or even improving the original accuracy.
Furthermore, qualitative analysis reveals that our method curbs redundant
reasoning patterns such as excessive subgoal setting and verification, leading
to structurally refined outputs rather than naive truncation. We also identify
that efficiency gains are accompanied by reduced interpretability: models
trained with AALC omit some narrative framing and explanatory context. These
findings highlight the potential of reward-based strategies to guide LRMs
toward more efficient, generalizable reasoning paths.

</details>


### [13] [ReCode: Updating Code API Knowledge with Reinforcement Learning](https://arxiv.org/abs/2506.20495)
*Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: ReCode框架通过强化学习帮助LLMs适应动态API更新，提升代码生成性能，同时减少对通用代码生成能力的影响。


<details>
  <summary>Details</summary>
Motivation: LLMs在动态API环境中表现不佳，因其依赖过时的API知识，即使有最新文档也难以可靠生成代码。

Method: 构建2000条数据训练LLMs进行版本迁移，引入改进的字符串相似度指标作为强化学习奖励。

Result: ReCode显著提升LLMs在动态API场景下的性能，尤其在未见任务CodeUpdateArena上表现突出。

Conclusion: ReCode在多种LLMs和强化学习算法中均有效，Qwen2.5-Coder-7B甚至超越更大参数模型。

Abstract: Large Language Models (LLMs) exhibit remarkable code generation capabilities
but falter when adapting to frequent updates in external library APIs. This
critical limitation, stemming from reliance on outdated API knowledge from
their training data, even with access to current documentation, impedes
reliable code generation in dynamic environments. To tackle this issue, we
propose ReCode (rule-based Reinforcement learning for Code Update), a novel
framework that mimics human programmer adaptation to API changes. Specifically,
we construct a dataset of approximately 2,000 data entries to train the LLMs to
perform version migration based on updated information. Then, we introduce a
modified string similarity metric for code evaluation as the reward for
reinforcement learning. Our experiments demonstrate that ReCode substantially
boosts LLMs' code generation performance in dynamic API scenarios, especially
on the unseen CodeUpdateArena task. Crucially, compared to supervised
fine-tuning, ReCode has less impact on LLMs' general code generation abilities.
We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and
DAPO), all achieving consistent improvements. Notably, after training,
Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned
model and the reasoning model with the same architecture. Code is available at
https://github.com/zjunlp/ReCode.

</details>


### [14] [SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs](https://arxiv.org/abs/2506.20167)
*Fengze Li,Yue Wang,Yangle Liu,Ming Huang,Dou Hong,Jieming Ma*

Main category: cs.CL

TL;DR: SEED是一种结构编码器，通过四阶段设计（补丁提取、嵌入对齐、语义重编程和语言模型预测）解决时间序列预测中结构依赖与语义推理的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有结构编码器缺乏语义推理能力，而大型语言模型无法直接处理时间序列数据，限制了统一预测系统的发展。

Method: SEED包含四个模块：补丁提取的编码器、嵌入对齐的投影模块、任务感知原型的语义重编程机制，以及冻结的语言模型预测。

Result: 实验表明，SEED在多个数据集上优于基线方法，有效填补了结构-语义建模的鸿沟。

Conclusion: SEED通过解耦表示学习与推理，实现了数值模式与语义推理的高效对齐，为统一预测系统提供了新思路。

Abstract: Multivariate time series forecasting requires models to simultaneously
capture variable-wise structural dependencies and generalize across diverse
tasks. While structural encoders are effective in modeling feature
interactions, they lack the capacity to support semantic-level reasoning or
task adaptation. Conversely, large language models (LLMs) possess strong
generalization capabilities but remain incompatible with raw time series
inputs. This gap limits the development of unified, transferable prediction
systems. Therefore, we introduce SEED, a structural encoder for
embedding-driven decoding, which integrates four stages: a token-aware encoder
for patch extraction, a projection module that aligns patches with language
model embeddings, a semantic reprogramming mechanism that maps patches to
task-aware prototypes, and a frozen language model for prediction. This modular
architecture decouples representation learning from inference, enabling
efficient alignment between numerical patterns and semantic reasoning.
Empirical results demonstrate that the proposed method achieves consistent
improvements over strong baselines, and comparative studies on various datasets
confirm SEED's role in addressing the structural-semantic modeling gap.

</details>


### [15] [COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees](https://arxiv.org/abs/2506.20178)
*Zhiyuan Wang,Jinhao Duan,Qingni Wang,Xiaofeng Zhu,Tianlong Chen,Xiaoshuang Shi,Kaidi Xu*

Main category: cs.CL

TL;DR: COIN是一个不确定性保护选择框架，通过统计校准阈值在用户指定的FDR约束下筛选单个生成答案，显著提高了样本保留率。


<details>
  <summary>Details</summary>
Motivation: 基础模型的不确定性量化（UQ）对识别和减少自动生成文本中的幻觉至关重要，但现有启发式方法缺乏对关键指标（如FDR）的形式化保证。

Method: 提出COIN框架，利用校准集估计经验错误率，并应用Clopper-Pearson等方法建立真实错误率的高概率上限，以选择最大不确定性阈值。

Result: COIN在风险控制、测试时保留合格答案的能力以及有限校准数据下的预测效率方面表现出色，且可通过替代上限构造和UQ策略进一步提升性能。

Conclusion: COIN是一个可扩展且适应性强的框架，适用于多种应用场景，显著提升了不确定性量化的实用性和效果。

Abstract: Uncertainty quantification (UQ) for foundation models is essential to
identify and mitigate potential hallucinations in automatically generated text.
However, heuristic UQ approaches lack formal guarantees for key metrics such as
the false discovery rate (FDR) in selective prediction. Previous work adopts
the split conformal prediction (SCP) framework to ensure desired coverage of
admissible answers by constructing prediction sets, but these sets often
contain incorrect candidates, limiting their practical utility. To address
this, we propose COIN, an uncertainty-guarding selection framework that
calibrates statistically valid thresholds to filter a single generated answer
per question under user-specified FDR constraints. COIN estimates the empirical
error rate on a calibration set and applies confidence interval methods such as
Clopper-Pearson to establish a high-probability upper bound on the true error
rate (i.e., FDR). This enables the selection of the largest uncertainty
threshold that ensures FDR control on test data while significantly increasing
sample retention. We demonstrate COIN's robustness in risk control, strong
test-time power in retaining admissible answers, and predictive efficiency
under limited calibration data across both general and multimodal text
generation tasks. Furthermore, we show that employing alternative upper bound
constructions and UQ strategies can further boost COIN's power performance,
which underscores its extensibility and adaptability to diverse application
scenarios.

</details>


### [16] [How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?](https://arxiv.org/abs/2506.20199)
*Mengqi Wang,Tiantian Feng,Shrikanth Narayanan*

Main category: cs.CL

TL;DR: 研究探讨如何通过检索高质量示例提升对话情感识别（CER）性能，提出随机和增强示例检索策略，并分析对话上下文对CER准确性的影响。实验表明增强示例检索在所有数据集上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在多个领域有广泛应用，但在主观任务（如情感识别）中实现高准确性仍具挑战性。研究旨在提升对话情感识别的性能。

Method: 提出基于随机和增强示例检索的策略，分析对话上下文对CER的影响，并在IEMOCAP、MELD和EmoryNLP数据集上进行实验。

Result: 增强示例检索在所有数据集中表现最优，表明检索连贯目标示例并通过改写增强其质量的重要性。

Conclusion: 增强示例检索是提升对话情感识别性能的有效方法，强调了高质量示例和上下文优化的重要性。

Abstract: Large language models (LLMs) have enabled a wide variety of real-world
applications in various domains. However, creating a high-performing
application with high accuracy remains challenging, particularly for subjective
tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this
study investigates approaches to improving conversational emotion recognition
(CER) by LLMs. Specifically, we explore how to retrieve high-quality examples
in in-context learning (ICL) to enhance CER. We propose various strategies
based on random and augmented example retrieval and also analyze the impact of
conversational context on CER accuracy. Experiments were conducted on the three
datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented
example retrieval consistently outperforms other techniques under investigation
across all datasets, highlighting the importance of retrieving coherent
targeted examples and enhancing them through paraphrasing.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [17] [Prover Agent: An Agent-based Framework for Formal Mathematical Proofs](https://arxiv.org/abs/2506.19923)
*Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai*

Main category: cs.AI

TL;DR: Prover Agent是一种新型AI代理，结合大型语言模型（LLMs）和形式化证明助手Lean，实现自动定理证明，成功率达86.1%。


<details>
  <summary>Details</summary>
Motivation: 将LLMs与形式化证明工具结合，提升自动定理证明的效率和成功率。

Method: 整合非正式推理LLM、形式化证明模型和Lean反馈，生成辅助引理以辅助证明策略。

Result: 在MiniF2F基准测试中达到86.1%的成功率，优于其他使用小语言模型的方法。

Conclusion: Prover Agent展示了结合LLMs和形式化工具的潜力，为自动定理证明提供了新方向。

Abstract: We present Prover Agent, a novel AI agent for automated theorem proving that
integrates large language models (LLMs) with a formal proof assistant, Lean.
Prover Agent coordinates an informal reasoning LLM, a formal prover model, and
feedback from Lean while also generating auxiliary lemmas to assist in
discovering the overall proof strategy. It achieves an 86.1% success rate on
the MiniF2F benchmark, establishing a new state-of-the-art among methods using
small language models (SLMs) with a much lower sample budget than previous
approaches. We also present case studies illustrating how these generated
lemmas contribute to solving challenging problems.

</details>


### [18] [Context Attribution with Multi-Armed Bandit Optimization](https://arxiv.org/abs/2506.19977)
*Deng Pan,Keerthiram Murugesan,Nuno Moniz,Nitesh Chawla*

Main category: cs.AI

TL;DR: 提出了一种基于组合多臂老虎机（CMAB）的框架，用于高效探索上下文子集，以理解生成式QA系统中上下文对模型回答的贡献。


<details>
  <summary>Details</summary>
Motivation: 提高生成式QA系统的可解释性和可信度，通过理解上下文对模型回答的具体贡献。

Method: 将上下文段视为老虎机臂，使用组合汤普森采样（CTS）在有限查询预算下高效探索上下文子集，定义基于归一化标记似然的奖励函数。

Result: 实验表明，该方法在减少模型查询次数的同时，保持了高归因保真度。

Conclusion: 该方法在高效性和归因质量上优于传统扰动方法，适用于多种数据集和LLM。

Abstract: Understanding which parts of the retrieved context contribute to a large
language model's generated answer is essential for building interpretable and
trustworthy generative QA systems. We propose a novel framework that formulates
context attribution as a combinatorial multi-armed bandit (CMAB) problem. Each
context segment is treated as a bandit arm, and we employ Combinatorial
Thompson Sampling (CTS) to efficiently explore the exponentially large space of
context subsets under a limited query budget. Our method defines a reward
function based on normalized token likelihoods, capturing how well a subset of
segments supports the original model response. Unlike traditional
perturbation-based attribution methods such as SHAP, which sample subsets
uniformly and incur high computational costs, our approach adaptively balances
exploration and exploitation by leveraging posterior estimates of segment
relevance. This leads to substantially improved query efficiency while
maintaining high attribution fidelity. Extensive experiments on diverse
datasets and LLMs demonstrate that our method achieves competitive attribution
quality with fewer model queries.

</details>


### [19] [QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges](https://arxiv.org/abs/2506.20008)
*Abdul Basit,Minghao Shao,Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique*

Main category: cs.AI

TL;DR: 论文评估了大型语言模型（LLMs）在PennyLane量子代码生成中的表现，引入QHackBench基准数据集，并比较了标准提示与检索增强生成（RAG）的效果。结果表明RAG在复杂量子算法中表现接近标准提示，同时提出了多智能体评估管道以提高成功率。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在量子计算代码生成中的潜力，填补现有研究的空白。

Method: 使用QHack竞赛的真实挑战构建QHackBench数据集，评估LLMs在标准提示和RAG下的表现，并引入多智能体评估管道。

Result: RAG增强模型在复杂量子算法中表现接近标准提示，多智能体管道进一步提高了执行成功率。

Conclusion: QHackBench和评估框架的公开将促进AI辅助量子编程的进一步发展。

Abstract: Recent advances in Large Language Models (LLMs) have demonstrated strong
potential in code generation, yet their effectiveness in quantum computing
remains underexplored. This paper benchmarks LLMs for PennyLane-based quantum
code generation using real-world challenges from the Quantum Hackathon (QHack).
We introduce QHackBench, a novel benchmark dataset derived from QHack
competitions, and evaluate model performance under vanilla prompting and
Retrieval-Augmented Generation (RAG). Our structured evaluation framework
assesses functional correctness, syntactic validity, and execution success
across varying challenge difficulties. Results indicate that RAG-enhanced
models, supplemented with an augmented PennyLane dataset, approximately
generate similar results as the standard prompting, particularly in complex
quantum algorithms. Additionally, we introduce a multi-agent evaluation
pipeline that iteratively refines incorrect solutions, further enhancing
execution success rates. To foster further research, we commit to publicly
releasing QHackBench, along with our evaluation framework and experimental
results, enabling continued advancements in AI-assisted quantum programming.

</details>


### [20] [Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks](https://arxiv.org/abs/2506.20009)
*Konstantinos Vrettos,Michail E. Klontzas*

Main category: cs.AI

TL;DR: 研究开发了一种可定制的RAG框架，用于医疗任务，其性能和能耗优于商业LLM，同时减少环境影响。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在医疗领域的应用带来的环境和伦理问题，提出可持续解决方案。

Method: 开发了监控能耗和CO2排放的RAG框架，并基于开源LLM构建模型进行比较测试。

Result: 自定义RAG模型在准确性和能耗上优于商业模型，其中llama3.1:8B表现最佳。

Conclusion: 本地LLM开发的RAG在医疗任务中优于商业模型，且更环保，支持可持续发展目标。

Abstract: Background The increasing adoption of Artificial Intelligence (AI) in
healthcare has sparked growing concerns about its environmental and ethical
implications. Commercial Large Language Models (LLMs), such as ChatGPT and
DeepSeek, require substantial resources, while the utilization of these systems
for medical purposes raises critical issues regarding patient privacy and
safety. Methods We developed a customizable Retrieval-Augmented Generation
(RAG) framework for medical tasks, which monitors its energy usage and CO2
emissions. This system was then used to create RAGs based on various
open-source LLMs. The tested models included both general purpose models like
llama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs
performance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs
o4-mini model. A dataset of medical questions was used for the evaluation.
Results Custom RAG models outperformed commercial models in accuracy and energy
consumption. The RAG model built on llama3.1:8B achieved the highest accuracy
(58.5%) and was significantly better than other models, including o4-mini and
DeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption
and CO2 footprint among all models, with a Performance per kWh of 0.52 and a
total CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x
times more accuracy points per kWh and 172% less electricity usage while
maintaining higher accuracy. Conclusion Our study demonstrates that local LLMs
can be leveraged to develop RAGs that outperform commercial, online LLMs in
medical tasks, while having a smaller environmental impact. Our modular
framework promotes sustainable AI development, reducing electricity usage and
aligning with the UNs Sustainable Development Goals.

</details>


### [21] [Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models](https://arxiv.org/abs/2506.20018)
*Zechun Deng,Ziwei Liu,Ziqian Bi,Junhao Song,Chia Xin Liang,Joe Yeong,Junfeng Hao*

Main category: cs.AI

TL;DR: 本文探讨了利用低延迟AI模型的实时决策支持系统，结合了AI驱动决策工具、Edge-IoT技术和人机协作方法，并研究了大型语言模型在资源有限时的决策辅助作用。


<details>
  <summary>Details</summary>
Motivation: 研究旨在整合AI技术、边缘计算和人机协作，以提升实时决策支持的效率和适应性。

Method: 通过详细综述，分析了DeLLMa、模型压缩技术和边缘设备分析改进等技术发展，并探讨了资源限制和适应性框架的需求。

Result: 提供了开发策略和应用领域的实用视角，指出了高效灵活AI支持系统的机会。

Conclusion: 为这一快速变化领域的未来突破奠定了基础，强调了AI如何重塑实时决策支持。

Abstract: This paper investigates real-time decision support systems that leverage
low-latency AI models, bringing together recent progress in holistic AI-driven
decision tools, integration with Edge-IoT technologies, and approaches for
effective human-AI teamwork. It looks into how large language models can assist
decision-making, especially when resources are limited. The research also
examines the effects of technical developments such as DeLLMa, methods for
compressing models, and improvements for analytics on edge devices, while also
addressing issues like limited resources and the need for adaptable frameworks.
Through a detailed review, the paper offers practical perspectives on
development strategies and areas of application, adding to the field by
pointing out opportunities for more efficient and flexible AI-supported
systems. The conclusions set the stage for future breakthroughs in this
fast-changing area, highlighting how AI can reshape real-time decision support.

</details>


### [22] [Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning](https://arxiv.org/abs/2506.20020)
*Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan*

Main category: cs.AI

TL;DR: 研究发现，大型语言模型（LLMs）在赋予特定政治和社会身份后，会表现出类似人类的动机性推理，导致判断偏差，且常规去偏方法效果有限。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否会在身份认同驱动下进行选择性推理，类似人类的认知偏差，尤其是在关键社会议题上。

Method: 通过为8种LLMs赋予4类政治和社会身份，测试其在信息真实性辨别和科学证据评估任务中的表现。

Result: 身份赋予的LLMs在真实性辨别上降低9%，政治身份模型在枪控证据评估中正确率提高90%（当证据与身份一致时）。

Conclusion: LLMs表现出难以通过常规方法消除的动机性推理，可能加剧身份认同驱动的判断偏差。

Abstract: Reasoning in humans is prone to biases due to underlying motivations like
identity protection, that undermine rational decision-making and judgment. This
motivated reasoning at a collective level can be detrimental to society when
debating critical issues such as human-driven climate change or vaccine safety,
and can further aggravate political polarization. Prior studies have reported
that large language models (LLMs) are also susceptible to human-like cognitive
biases, however, the extent to which LLMs selectively reason toward
identity-congruent conclusions remains largely unexplored. Here, we investigate
whether assigning 8 personas across 4 political and socio-demographic
attributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and
proprietary) across two reasoning tasks from human-subject studies -- veracity
discernment of misinformation headlines and evaluation of numeric scientific
evidence -- we find that persona-assigned LLMs have up to 9% reduced veracity
discernment relative to models without personas. Political personas
specifically, are up to 90% more likely to correctly evaluate scientific
evidence on gun control when the ground truth is congruent with their induced
political identity. Prompt-based debiasing methods are largely ineffective at
mitigating these effects. Taken together, our empirical findings are the first
to suggest that persona-assigned LLMs exhibit human-like motivated reasoning
that is hard to mitigate through conventional debiasing prompts -- raising
concerns of exacerbating identity-congruent reasoning in both LLMs and humans.

</details>


### [23] [DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction](https://arxiv.org/abs/2506.20059)
*Weijieying Ren,Tianxiang Zhao,Lei Wang,Tianchun Wang,Vasant Honavar*

Main category: cs.AI

TL;DR: DiaLLM是一种新型医疗大语言模型，整合电子健康记录（EHR）数据，支持临床测试推荐、结果解释和诊断预测，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有医疗大语言模型忽视电子健康记录（EHR）的作用，仅关注诊断推荐，限制了临床应用。DiaLLM旨在填补这一空白。

Method: 提出临床测试参考（CTR）策略，将临床代码映射到描述并分类测试结果；采用强化学习框架进行证据获取和自动诊断，引入拒绝采样策略和奖励机制。

Result: 实验表明DiaLLM在临床测试推荐和诊断预测上优于基线方法。

Conclusion: DiaLLM通过整合EHR数据，显著提升了医疗对话模型的临床实用性。

Abstract: Recent advances in Large Language Models (LLMs) have led to remarkable
progresses in medical consultation. However, existing medical LLMs overlook the
essential role of Electronic Health Records (EHR) and focus primarily on
diagnosis recommendation, limiting their clinical applicability. We propose
DiaLLM, the first medical LLM that integrates heterogeneous EHR data into
clinically grounded dialogues, enabling clinical test recommendation, result
interpretation, and diagnosis prediction to better align with real-world
medical practice. To construct clinically grounded dialogues from EHR, we
design a Clinical Test Reference (CTR) strategy that maps each clinical code to
its corresponding description and classifies test results as "normal" or
"abnormal". Additionally, DiaLLM employs a reinforcement learning framework for
evidence acquisition and automated diagnosis. To handle the large action space,
we introduce a reject sampling strategy to reduce redundancy and improve
exploration efficiency. Furthermore, a confirmation reward and a
class-sensitive diagnosis reward are designed to guide accurate diagnosis
prediction. Extensive experimental results demonstrate that DiaLLM outperforms
baselines in clinical test recommendation and diagnosis prediction.

</details>


### [24] [AI Copilots for Reproducibility in Science: A Case Study](https://arxiv.org/abs/2506.20130)
*Adrien Bibal,Steven N. Minton,Deborah Khider,Yolanda Gil*

Main category: cs.AI

TL;DR: OpenPub是一个AI驱动的平台，通过模块化助手支持开放科学任务，特别是可重复性助手，能显著减少重复实验时间。


<details>
  <summary>Details</summary>
Motivation: 开放科学倡议旨在提高研究的透明度和可重复性，但独立重复研究结果仍具挑战性。

Method: OpenPub的可重复性助手分析论文、代码和补充材料，生成结构化Jupyter Notebook和建议。

Result: 测试显示，OpenPub将重复时间从30多小时缩短至约1小时，并高覆盖率地重现图表和结果。

Conclusion: AI工具能有效减轻可重复性负担，促进更透明的科学交流，其模块化架构还可扩展至其他开放科学目标。

Abstract: Open science initiatives seek to make research outputs more transparent,
accessible, and reusable, but ensuring that published findings can be
independently reproduced remains a persistent challenge. This paper introduces
OpenPub, an AI-powered platform that supports researchers, reviewers, and
readers through a suite of modular copilots focused on key open science tasks.
In this work, we present the Reproducibility Copilot, which analyzes
manuscripts, code, and supplementary materials to generate structured Jupyter
Notebooks and recommendations aimed at facilitating computational, or "rote",
reproducibility. We conducted feasibility tests using previously studied
research papers with known reproducibility benchmarks. Results indicate that
OpenPub can substantially reduce reproduction time - from over 30 hours to
about 1 hour - while achieving high coverage of figures, tables, and results
suitable for computational reproduction. The system systematically detects
barriers to reproducibility, including missing hyperparameters, undocumented
preprocessing steps, and incomplete or inaccessible datasets. These findings
suggest that AI-driven tools can meaningfully reduce the burden of
reproducibility efforts and contribute to more transparent and verifiable
scientific communication. The modular copilot architecture also provides a
foundation for extending AI assistance to additional open science objectives
beyond reproducibility.

</details>


### [25] [Language Modeling by Language Models](https://arxiv.org/abs/2506.20249)
*Junyan Cheng,Peter Clark,Kyle Richardson*

Main category: cs.AI

TL;DR: 利用多代理LLM模拟研究过程，提出Genesys系统，通过遗传编程生成新架构设计，验证效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探索LLM能否用于发现新语言模型架构，模拟真实研究流程以提高效率。

Method: 采用多代理LLM方法，结合遗传编程和规模阶梯策略，分阶段生成、验证设计。

Result: 生成1,162个新设计，其中1,062个通过验证，部分设计性能优于GPT2和Mamba2。

Conclusion: Genesys系统在自主发现高效架构方面具有潜力，为自动化研究提供新思路。

Abstract: Can we leverage LLMs to model the process of discovering novel language model
(LM) architectures? Inspired by real research, we propose a multi-agent LLM
approach that simulates the conventional stages of research, from ideation and
literature search (proposal stage) to design implementation (code generation),
generative pre-training, and downstream evaluation (verification). Using ideas
from scaling laws, our system, Genesys, employs a Ladder of Scales approach;
new designs are proposed, adversarially reviewed, implemented, and selectively
verified at increasingly larger model scales (14M$\sim$350M parameters) with a
narrowing budget (the number of models we can train at each scale). To help
make discovery efficient and factorizable, Genesys uses a novel genetic
programming backbone, which we show has empirical advantages over commonly used
direct prompt generation workflows (e.g., $\sim$86\% percentage point
improvement in successful design generation, a key bottleneck). We report
experiments involving 1,162 newly discovered designs (1,062 fully verified
through pre-training) and find the best designs to be highly competitive with
known architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common
benchmarks). We couple these results with comprehensive system-level ablations
and formal results, which give broader insights into the design of effective
autonomous discovery systems.

</details>


### [26] [Enterprise Large Language Model Evaluation Benchmark](https://arxiv.org/abs/2506.20274)
*Liya Wang,David Yi,Damien Jose,John Passarelli,James Gao,Jordan Leventis,Kang Li*

Main category: cs.AI

TL;DR: 提出基于Bloom分类法的14任务框架，评估企业环境中LLM能力，开发可扩展标注流程，构建9700样本基准，发现开源模型在推理任务中表现接近专有模型，但在判断任务中落后。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如MMLU）未能充分评估企业特定任务的复杂性，需开发更全面的评估框架。

Method: 提出14任务框架，结合LLM-as-a-Labeler、LLM-as-a-Judge和CRAG技术，构建9700样本基准。

Result: 开源模型（如DeepSeek R1）在推理任务中表现接近专有模型，但在判断任务中因过度思考而落后。

Conclusion: 为企业提供定制化评估蓝图，推动LLM实际部署，揭示性能差距并提出优化建议。

Abstract: Large Language Models (LLMs) ) have demonstrated promise in boosting
productivity across AI-powered tools, yet existing benchmarks like Massive
Multitask Language Understanding (MMLU) inadequately assess enterprise-specific
task complexities. We propose a 14-task framework grounded in Bloom's Taxonomy
to holistically evaluate LLM capabilities in enterprise contexts. To address
challenges of noisy data and costly annotation, we develop a scalable pipeline
combining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented
generation (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six
leading models shows open-source contenders like DeepSeek R1 rival proprietary
models in reasoning tasks but lag in judgment-based scenarios, likely due to
overthinking. Our benchmark reveals critical enterprise performance gaps and
offers actionable insights for model optimization. This work provides
enterprises a blueprint for tailored evaluations and advances practical LLM
deployment.

</details>


### [27] [Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards](https://arxiv.org/abs/2506.20332)
*Jihao Gu,Qihang Ai,Yingyao Wang,Pi Bu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Ziming Wang,Yingxiu Zhao,Ming-Liang Zhang,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: Mobile-R1是一种基于多轮交互强化学习的移动代理方法，通过任务级奖励提升探索和纠错能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究局限于离线强化学习或动作级奖励的在线优化，导致代理在动态环境中表现不足。

Method: 采用三阶段训练框架：初始微调、动作级奖励单步训练、任务级奖励多轮轨迹训练。

Result: 显著提升了代理的探索和纠错能力，并建立了包含28个应用的数据集和500轨迹的基准。

Conclusion: Mobile-R1通过任务级奖励和多轮交互强化学习，有效解决了现有方法的局限性。

Abstract: Vision-language model-based mobile agents have gained the ability to not only
understand complex instructions and mobile screenshots, but also optimize their
action outputs via thinking and reasoning, benefiting from reinforcement
learning, such as Group Relative Policy Optimization (GRPO). However, existing
research centers on offline reinforcement learning training or online
optimization using action-level rewards, which limits the agent's dynamic
interaction with the environment. This often results in agents settling into
local optima, thereby weakening their ability for exploration and error action
correction. To address these challenges, we introduce an approach called
Mobile-R1, which employs interactive multi-turn reinforcement learning with
task-level rewards for mobile agents. Our training framework consists of three
stages: initial format finetuning, single-step online training via action-level
reward, followed by online training via task-level reward based on multi-turn
trajectories. This strategy is designed to enhance the exploration and error
correction capabilities of Mobile-R1, leading to significant performance
improvements. Moreover, we have collected a dataset covering 28 Chinese
applications with 24,521 high-quality manual annotations and established a new
benchmark with 500 trajectories. We will open source all resources, including
the dataset, benchmark, model weight, and codes:
https://mobile-r1.github.io/Mobile-R1/.

</details>


### [28] [Tabular Feature Discovery With Reasoning Type Exploration](https://arxiv.org/abs/2506.20357)
*Sungwon Han,Sungkyu Park,Seungeon Lee*

Main category: cs.AI

TL;DR: 论文提出了一种名为REFeat的新方法，利用多种推理类型指导LLM生成多样且信息丰富的特征，解决了现有LLM方法生成特征过于简单或重复的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的特征生成方法存在生成特征过于简单或重复的问题，部分原因是LLM选择的转换存在固有偏见，且缺乏结构化推理指导。

Method: 提出REFeat方法，通过多种推理类型引导LLM生成特征，以增强特征的多样性和信息量。

Result: 在59个基准数据集上的实验表明，REFeat不仅平均预测准确率更高，还能发现更多样且有意义的特征。

Conclusion: 研究结果表明，结合丰富的推理范式和自适应策略选择，可以显著提升LLM驱动的表格数据特征发现效果。

Abstract: Feature engineering for tabular data remains a critical yet challenging step
in machine learning. Recently, large language models (LLMs) have been used to
automatically generate new features by leveraging their vast knowledge.
However, existing LLM-based approaches often produce overly simple or
repetitive features, partly due to inherent biases in the transformations the
LLM chooses and the lack of structured reasoning guidance during generation. In
this paper, we propose a novel method REFeat, which guides an LLM to discover
diverse and informative features by leveraging multiple types of reasoning to
steer the feature generation process. Experiments on 59 benchmark datasets
demonstrate that our approach not only achieves higher predictive accuracy on
average, but also discovers more diverse and meaningful features. These results
highlight the promise of incorporating rich reasoning paradigms and adaptive
strategy selection into LLM-driven feature discovery for tabular data.

</details>


### [29] [Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios](https://arxiv.org/abs/2506.20384)
*Dror Ivry,Oran Nahum*

Main category: cs.AI

TL;DR: 论文提出了Paladin-mini（3.8B参数的分类模型）和grounding-benchmark数据集，用于解决上下文中的声明支持问题，并展示了其性能。


<details>
  <summary>Details</summary>
Motivation: 解决在给定上下文中为声明提供支持证据的问题（即声明是否被上下文支持）。

Method: 提出了Paladin-mini（小型开源分类模型）和grounding-benchmark（评估数据集），用于标记数据是否被支持。

Result: 展示了Paladin-mini在当前最先进技术基准上的性能，结果清晰且可复现。

Conclusion: Paladin-mini和grounding-benchmark为声明支持问题提供了有效的解决方案。

Abstract: This paper introduces two significant contributions to address the issue of
grounding claims in a given context. Grounding means that given a context
(document) and a claim, there's at least one supportive evidence for the claim
in the document. We will introduce Paladin-mini, a compact (3.8B parameters)
open-source classifier model (used for labeling data as grounded or ungrounded)
engineered for robust performance in real-world scenarios, and the
grounding-benchmark, a new evaluation dataset designed to assess performance on
critical reasoning tasks. We'll also demonstrate the results of Paladin-mini
with benchmarks against the current State-of-the-art and share clear and
reproducible results.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [30] [CoVE: Compressed Vocabulary Expansion Makes Better LLM-based Recommender Systems](https://arxiv.org/abs/2506.19993)
*Haochen Zhang,Tianyi Zhang,Junze Yin,Oren Gal,Anshumali Shrivastava,Vladimir Braverman*

Main category: cs.IR

TL;DR: 论文提出了一种名为CoVE的新系统，通过压缩词汇扩展和利用LLM的序列理解能力，显著提升了推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用LLM的序列信息处理能力，导致推荐任务性能不佳。

Method: 为每个项目分配唯一ID，扩展词汇表，并压缩嵌入层以适配大规模应用。

Result: 在多个推荐数据集上验证了CoVE的有效性和性能优势。

Conclusion: CoVE通过优化LLM的序列处理能力，为推荐系统提供了更高效的解决方案。

Abstract: Recommender systems play a pivotal role in providing relevant content to
users. With the rapid development of large language models (LLMs), researchers
have begun utilizing LLMs to build more powerful recommender systems. However,
existing approaches that focus on aligning LLMs with recommendation tasks do
not fully leverage their sequential information processing capabilities,
leading to suboptimal performance.
  In this paper, we propose a novel system called compressed vocabulary
expansion (CoVE). In CoVE, each item is assigned a unique ID within the
expanded vocabulary. Our framework effectively capitalizes on sequence
understanding abilities of LLMs, significantly enhancing their performance on
recommendation tasks. Additionally, we compress the embedding layer, making
CoVE practical for large-scale industrial applications. The effectiveness and
performance of CoVE are demonstrated through comprehensive experiments on
multiple recommendation datasets and comparisons with prior works. Our code can
be found at https://github.com/HaochenZhang717/CoVE-official-Repo.

</details>


### [31] [Controlled Retrieval-augmented Context Evaluation for Long-form RAG](https://arxiv.org/abs/2506.20051)
*Jia-Huei Ju,Suzan Verberne,Maarten de Rijke,Andrew Yates*

Main category: cs.IR

TL;DR: 论文提出了CRUX框架，用于直接评估检索增强生成（RAG）中的检索上下文，特别针对长文本生成任务。


<details>
  <summary>Details</summary>
Motivation: 现有基于相关性的检索评估指标不足以反映检索对最终RAG结果的影响，尤其在长文本生成场景中。

Method: 引入CRUX框架，利用人工编写的摘要控制信息范围，通过问题评估细粒度衡量检索上下文的质量。

Result: 实证结果表明CRUX提供了更具反思性和诊断性的评估，并揭示了当前检索方法的改进空间。

Conclusion: CRUX为RAG的检索评估提供了新方向，数据和代码公开以支持未来研究。

Abstract: Retrieval-augmented generation (RAG) enhances large language models by
incorporating context retrieved from external knowledge sources. While the
effectiveness of the retrieval module is typically evaluated with
relevance-based ranking metrics, such metrics may be insufficient to reflect
the retrieval's impact on the final RAG result, especially in long-form
generation scenarios. We argue that providing a comprehensive
retrieval-augmented context is important for long-form RAG tasks like report
generation and propose metrics for assessing the context independent of
generation. We introduce CRUX, a \textbf{C}ontrolled
\textbf{R}etrieval-a\textbf{U}gmented conte\textbf{X}t evaluation framework
designed to directly assess retrieval-augmented contexts. This framework uses
human-written summaries to control the information scope of knowledge, enabling
us to measure how well the context covers information essential for long-form
generation. CRUX uses question-based evaluation to assess RAG's retrieval in a
fine-grained manner. Empirical results show that CRUX offers more reflective
and diagnostic evaluation. Our findings also reveal substantial room for
improvement in current retrieval methods, pointing to promising directions for
advancing RAG's retrieval. Our data and code are publicly available to support
and advance future research on retrieval.

</details>


### [32] [Multimodal Information Retrieval for Open World with Edit Distance Weak Supervision](https://arxiv.org/abs/2506.20070)
*KMA Solaiman,Bharat Bhargava*

Main category: cs.IR

TL;DR: FemmIR是一个无需标注相似性标签的多媒体检索框架，利用预训练编码器和弱监督方法实现跨模态检索。


<details>
  <summary>Details</summary>
Motivation: 避免传统多媒体检索模型对标注数据的依赖，利用现有预训练模型减少标注开销。

Method: 基于编辑距离的弱监督方法，通过多级交互评分衡量样本与查询示例的相关性。

Result: 在MuQNOL数据集上表现良好，与现有检索系统性能相当。

Conclusion: FemmIR提供了一种无需标注的高效跨模态检索解决方案。

Abstract: Existing multi-media retrieval models either rely on creating a common
subspace with modality-specific representation models or require schema mapping
among modalities to measure similarities among multi-media data. Our goal is to
avoid the annotation overhead incurred from considering retrieval as a
supervised classification task and re-use the pretrained encoders in large
language models and vision tasks. We propose "FemmIR", a framework to retrieve
multimodal results relevant to information needs expressed with multimodal
queries by example without any similarity label. Such identification is
necessary for real-world applications where data annotations are scarce and
satisfactory performance is required without fine-tuning with a common
framework across applications. We curate a new dataset called MuQNOL for
benchmarking progress on this task. Our technique is based on weak supervision
introduced through edit distance between samples: graph edit distance can be
modified to consider the cost of replacing a data sample in terms of its
properties, and relevance can be measured through the implicit signal from the
amount of edit cost among the objects. Unlike metric learning or encoding
networks, FemmIR re-uses the high-level properties and maintains the property
value and relationship constraints with a multi-level interaction score between
data samples and the query example provided by the user. We empirically
evaluate FemmIR on a missing person use case with MuQNOL. FemmIR performs
comparably to similar retrieval systems in delivering on-demand retrieval
results with exact and approximate similarities while using the existing
property identifiers in the system.

</details>


### [33] [Semantic-enhanced Modality-asymmetric Retrieval for Online E-commerce Search](https://arxiv.org/abs/2506.20330)
*Zhigong Zhou,Ning Ding,Xiaochuan Fan,Yue Shang,Yiming Qiu,Jingwei Zhuo,Zhiwei Ge,Songlin Wang,Lin Liu,Sulong Xu,Han Zhang*

Main category: cs.IR

TL;DR: 本文提出了一种名为SMAR的新模型，用于解决多模态检索中的模态融合和对齐问题，特别是在查询是单模态而项目是多模态的不对称场景下。实验表明，该模型在检索准确性上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 在电子商务搜索中，语义检索通过利用视觉信息（如图像）作为文本信息的补充，可以丰富项目表示并提高检索性能。然而，多模态检索在查询为单模态而项目为多模态的不对称场景中仍是一个未解决的难题。

Method: 提出SMAR模型（语义增强的模态不对称检索），专注于解决不对称场景下的模态融合和对齐问题。

Result: 在工业数据集上的实验表明，SMAR模型在检索准确性上显著优于基线模型。

Conclusion: SMAR模型有效解决了多模态检索中的模态不对称问题，并开源了工业数据集以促进未来研究。

Abstract: Semantic retrieval, which retrieves semantically matched items given a
textual query, has been an essential component to enhance system effectiveness
in e-commerce search. In this paper, we study the multimodal retrieval problem,
where the visual information (e.g, image) of item is leveraged as supplementary
of textual information to enrich item representation and further improve
retrieval performance. Though learning from cross-modality data has been
studied extensively in tasks such as visual question answering or media
summarization, multimodal retrieval remains a non-trivial and unsolved problem
especially in the asymmetric scenario where the query is unimodal while the
item is multimodal. In this paper, we propose a novel model named SMAR, which
stands for Semantic-enhanced Modality-Asymmetric Retrieval, to tackle the
problem of modality fusion and alignment in this kind of asymmetric scenario.
Extensive experimental results on an industrial dataset show that the proposed
model outperforms baseline models significantly in retrieval accuracy. We have
open sourced our industrial dataset for the sake of reproducibility and future
research works.

</details>


### [34] [Unidentified and Confounded? Understanding Two-Tower Models for Unbiased Learning to Rank](https://arxiv.org/abs/2506.20501)
*Philipp Hager,Onno Zoeter,Maarten de Rijke*

Main category: cs.IR

TL;DR: 两塔模型在点击数据训练中性能下降，研究探讨了日志策略混淆和模型可识别性问题，提出样本加权技术缓解偏差。


<details>
  <summary>Details</summary>
Motivation: 研究两塔模型在点击数据训练中性能下降的原因，重点关注日志策略和模型可识别性的影响。

Method: 理论分析两塔模型的可识别性条件，研究日志策略对模型的影响，并提出样本加权技术。

Result: 发现日志策略在模型完美捕捉用户行为时不引入偏差，但在不完美时会放大偏差；提出样本加权技术有效。

Conclusion: 两塔模型需注意日志策略和可识别性问题，样本加权技术可缓解偏差，为实践提供指导。

Abstract: Additive two-tower models are popular learning-to-rank methods for handling
biased user feedback in industry settings. Recent studies, however, report a
concerning phenomenon: training two-tower models on clicks collected by
well-performing production systems leads to decreased ranking performance. This
paper investigates two recent explanations for this observation: confounding
effects from logging policies and model identifiability issues. We
theoretically analyze the identifiability conditions of two-tower models,
showing that either document swaps across positions or overlapping feature
distributions are required to recover model parameters from clicks. We also
investigate the effect of logging policies on two-tower models, finding that
they introduce no bias when models perfectly capture user behavior. However,
logging policies can amplify biases when models imperfectly capture user
behavior, particularly when prediction errors correlate with document placement
across positions. We propose a sample weighting technique to mitigate these
effects and provide actionable insights for researchers and practitioners using
two-tower models.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [35] [A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior](https://arxiv.org/abs/2506.19999)
*Francesco Ignazio Re,Andreas Opedal,Glib Manaiev,Mario Giulianelli,Ryan Cotterell*

Main category: cs.LG

TL;DR: 提出了一种基于时空点过程的阅读行为概率模型，捕捉注视点和扫视的时空动态，优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖聚合的眼动数据，忽略了阅读中的时空动态，需要更通用的模型。

Method: 使用标记的时空点过程和Hawkes过程建模注视点和扫视，考虑时空邻近性和溢出效应。

Result: Hawkes过程模型对扫视的拟合优于基线；注视时间模型中，上下文惊讶度仅带来边际改进。

Conclusion: 惊讶度理论难以解释精细眼动行为，新模型更全面地捕捉阅读动态。

Abstract: Reading is a process that unfolds across space and time, alternating between
fixations where a reader focuses on a specific point in space, and saccades
where a reader rapidly shifts their focus to a new point. An ansatz of
psycholinguistics is that modeling a reader's fixations and saccades yields
insight into their online sentence processing. However, standard approaches to
such modeling rely on aggregated eye-tracking measurements and models that
impose strong assumptions, ignoring much of the spatio-temporal dynamics that
occur during reading. In this paper, we propose a more general probabilistic
model of reading behavior, based on a marked spatio-temporal point process,
that captures not only how long fixations last, but also where they land in
space and when they take place in time. The saccades are modeled using a Hawkes
process, which captures how each fixation excites the probability of a new
fixation occurring near it in time and space. The duration time of fixation
events is modeled as a function of fixation-specific predictors convolved
across time, thus capturing spillover effects. Empirically, our Hawkes process
model exhibits a better fit to human saccades than baselines. With respect to
fixation durations, we observe that incorporating contextual surprisal as a
predictor results in only a marginal improvement in the model's predictive
accuracy. This finding suggests that surprisal theory struggles to explain
fine-grained eye movements.

</details>


### [36] [Position: Machine Learning Conferences Should Establish a "Refutations and Critiques" Track](https://arxiv.org/abs/2506.19882)
*Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho*

Main category: cs.LG

TL;DR: 本文主张机器学习会议应设立专门的“反驳与批评”轨道，以系统性纠正研究中的错误。


<details>
  <summary>Details</summary>
Motivation: 机器学习研究快速发展，但存在误导性、错误或欺诈性研究被接受的问题，缺乏纠正机制。

Method: 提出在会议中设立“反驳与批评”轨道，讨论其设计、评审原则及潜在问题。

Result: 通过高声誉平台支持批判性研究，促进研究生态的自我修正。

Conclusion: 机器学习会议应建立官方机制，帮助研究自我纠正。

Abstract: Science progresses by iteratively advancing and correcting humanity's
understanding of the world. In machine learning (ML) research, rapid
advancements have led to an explosion of publications, but have also led to
misleading, incorrect, flawed or perhaps even fraudulent studies being accepted
and sometimes highlighted at ML conferences due to the fallibility of peer
review. While such mistakes are understandable, ML conferences do not offer
robust processes to help the field systematically correct when such errors are
made.This position paper argues that ML conferences should establish a
dedicated "Refutations and Critiques" (R & C) Track. This R & C Track would
provide a high-profile, reputable platform to support vital research that
critically challenges prior research, thereby fostering a dynamic
self-correcting research ecosystem. We discuss key considerations including
track design, review principles, potential pitfalls, and provide an
illustrative example submission concerning a recent ICLR 2025 Oral. We conclude
that ML conferences should create official, reputable mechanisms to help ML
research self-correct.

</details>


### [37] [STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning](https://arxiv.org/abs/2506.19883)
*Zhuqing Liu,Chaosheng Dong,Michinari Momma,Simone Shao,Shaoyuan Xu,Yan Gao,Haibo Yang,Jia Liu*

Main category: cs.LG

TL;DR: 提出了一种名为STIMULUS的新算法，用于解决多目标优化问题，通过递归框架更新梯度估计，提高了收敛性能和样本效率。还提出了增强版本STIMULUS-M和自适应批处理版本STIMULUS+/STIMULUS-M+。


<details>
  <summary>Details</summary>
Motivation: 多目标优化在多个领域有广泛应用，但现有方法在收敛速度和样本复杂度上表现不佳，需要改进。

Method: STIMULUS采用递归框架更新梯度估计，STIMULUS-M加入动量项，STIMULUS+/STIMULUS-M+引入自适应批处理。

Result: 在非凸和强凸设置下分别达到O(1/T)和O(exp{-μT})的收敛速度，样本复杂度达到当前最优水平。

Conclusion: STIMULUS系列算法在多目标优化中表现出色，显著提升了收敛性能和样本效率。

Abstract: Recently, multi-objective optimization (MOO) has gained attention for its
broad applications in ML, operations research, and engineering. However, MOO
algorithm design remains in its infancy and many existing MOO methods suffer
from unsatisfactory convergence rate and sample complexity performance. To
address this challenge, in this paper, we propose an algorithm called STIMULUS(
stochastic path-integrated multi-gradient recursive e\ulstimator), a new and
robust approach for solving MOO problems. Different from the traditional
methods, STIMULUS introduces a simple yet powerful recursive framework for
updating stochastic gradient estimates to improve convergence performance with
low sample complexity. In addition, we introduce an enhanced version of
STIMULUS, termed STIMULUS-M, which incorporates a momentum term to further
expedite convergence. We establish $O(1/T)$ convergence rates of the proposed
methods for non-convex settings and $O (\exp{-\mu T})$ for strongly convex
settings, where $T$ is the total number of iteration rounds. Additionally, we
achieve the state-of-the-art $O \left(n+\sqrt{n}\epsilon^{-1}\right)$ sample
complexities for non-convex settings and $O\left(n+ \sqrt{n} \ln
({\mu/\epsilon})\right)$ for strongly convex settings, where $\epsilon>0$ is a
desired stationarity error. Moreover, to alleviate the periodic full gradient
evaluation requirement in STIMULUS and STIMULUS-M, we further propose enhanced
versions with adaptive batching called STIMULUS+/ STIMULUS-M+ and provide their
theoretical analysis.

</details>


### [38] [FlightKooba: A Fast Interpretable FTP Model](https://arxiv.org/abs/2506.19885)
*Jing Lu,Xuan Wu,Yizhun Tian,Songhan Fan,Yali Fang*

Main category: cs.LG

TL;DR: 论文提出FlightKooba框架，结合HIPPO方法、Koopman理论和状态空间方程，显著提升飞行轨迹预测的效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于Koopman理论的飞行轨迹预测模型效率低、可解释性差，计算量大。

Method: 结合HIPPO方法、Koopman理论和状态空间方程，直接从数据构建Koopman算子，减少可训练参数。

Result: 训练时间接近Mamba模块（无CUDA加速），内存减少50%以上，参数减少10倍。

Conclusion: FlightKooba为Koopman算子快速计算提供新方法，为时间序列预测与控制结合开辟新可能。

Abstract: The Koopman theory is a powerful and effective modeling tool for converting
nonlinear systems into linear representations, and flight trajectory prediction
(FTP) is a complex nonlinear system. However, current models applying the
Koopman theory to FTP tasks are not very effective, model interpretability is
indeed an issue, and the Koopman operators are computationally intensive,
resulting in long training times. To address this issue, this paper proposes a
new modeling and control framework based on the HIPPO method, the Koopman
theory, and state space equations from cybernetics: FlightKooba. Inspired by
the idea of structural state space equations, FlightKooba directly constructs
the Koopman operators from data. This makes the framework highly interpretable
and significantly reduces the number of trainable parameters in the module,
thereby greatly reducing training time. Experiments have demonstrated the
superiority of the FlightKooba modeling method in terms of time and memory
consumption (training time comparable to the Mamba module without using
CUDA-level acceleration; memory reduced by more than 50% on most datasets, with
a tenfold reduction in the number of parameters), essentially completing the
FTP task. It provides a new method for the fast computation of the Koopman
operators, opening up new possibilities for the combination of time series
forecasting and control.

</details>


### [39] [Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction](https://arxiv.org/abs/2506.19890)
*Ziru Zhang,Jiadong Yu,Danny H. K. Tsang*

Main category: cs.LG

TL;DR: 提出了一种结合自适应关键帧提取和因果感知强化学习的智能框架，以最大化多用户VR交互中的QoE。通过Weber-Fechner定律制定QoE指标，并采用PS-CDDPG方法优化资源分配，显著降低了延迟并提高了QoE。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了带宽、CPU频率与用户感知之间的因果关系，限制了QoE的提升。

Method: 结合自适应关键帧提取与因果感知强化学习（PS-CDDPG），利用Weber-Fechner定律制定QoE指标，并通过MIP任务优化资源分配。

Result: 实验表明，该框架显著降低了交互延迟，提高了QoE，并保持了公平性。

Conclusion: 提出的智能框架在多用户VR交互中实现了更优的QoE优化效果。

Abstract: The optimization of quality of experience (QoE) in multi-user virtual reality
(VR) interactions demands a delicate balance between ultra-low latency,
high-fidelity motion synchronization, and equitable resource allocation. While
adaptive keyframe extraction mitigates transmission overhead, existing
approaches often overlook the causal relationships among allocated bandwidth,
CPU frequency, and user perception, limiting QoE gains. This paper proposes an
intelligent framework to maximize QoE by integrating adaptive keyframe
extraction with causal-aware reinforcement learning (RL). First, a novel QoE
metric is formulated using the Weber-Fechner Law, combining perceptual
sensitivity, attention-driven priorities, and motion reconstruction accuracy.
The QoE optimization problem is then modeled as a mixed integer programming
(MIP) task, jointly optimizing keyframe ratios, bandwidth, and computational
resources under horizon-fairness constraints. We propose Partial State Causal
Deep Deterministic Policy Gradient (PS-CDDPG), which integrates the Deep
Deterministic Policy Gradient (DDPG) method with causal influence detection. By
leveraging causal information regarding how QoE is influenced and determined by
various actions, we explore actions guided by weights calculated from causal
inference (CI), which in turn improves training efficiency. Experiments
conducted with the CMU Motion Capture Database demonstrate that our framework
significantly reduces interactive latency, enhances QoE, and maintains
fairness, achieving superior performance compared to benchmark methods.

</details>


### [40] [Orthogonal Soft Pruning for Efficient Class Unlearning](https://arxiv.org/abs/2506.19891)
*Qinghui Gong,Xue Yang,Xiaohu Tang*

Main category: cs.LG

TL;DR: 提出了一种基于正交卷积核正则化的类感知软剪枝框架，实现快速精确的机器遗忘，响应时间达毫秒级。


<details>
  <summary>Details</summary>
Motivation: 满足GDPR等隐私法规要求，选择性移除预训练神经网络中的特定类别知识，解决现有方法在遗忘速度和预测准确性之间的权衡问题。

Method: 利用正交卷积核正则化，通过激活差异分析高效识别特定类别通道，实现特征表示的解耦和卷积滤波器的去相关。

Result: 在CIFAR-10、CIFAR-100和TinyImageNet上验证了方法的有效性，实现了目标类别的完全遗忘、保留数据的准确性损失极小，并显著降低了成员推理攻击风险。

Conclusion: 该框架为MLaaS场景中的实时机器遗忘提供了高效、实用的解决方案。

Abstract: Machine unlearning aims to selectively remove class-specific knowledge from
pretrained neural networks to satisfy privacy regulations such as the GDPR.
Existing methods typically face a trade-off between unlearning speed and
preservation of predictive accuracy, often incurring either high computational
overhead or significant performance degradation on retained classes. In this
paper, we propose a novel class-aware soft pruning framework leveraging
orthogonal convolutional kernel regularization to achieve rapid and precise
forgetting with millisecond-level response times. By enforcing orthogonality
constraints during training, our method decorrelates convolutional filters and
disentangles feature representations, while efficiently identifying
class-specific channels through activation difference analysis. Extensive
evaluations across multiple architectures and datasets demonstrate stable
pruning with near-instant execution, complete forgetting of targeted classes,
and minimal accuracy loss on retained data. Experiments on CIFAR-10, CIFAR-100,
and TinyImageNet confirm that our approach substantially reduces membership
inference attack risks and accelerates unlearning by orders of magnitude
compared to state-of-the-art baselines. This framework provides an efficient,
practical solution for real-time machine unlearning in Machine Learning as a
Service (MLaaS) scenarios.

</details>


### [41] [MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations](https://arxiv.org/abs/2506.20100)
*Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve*

Main category: cs.LG

TL;DR: MIRAGE是一个用于多模态专家级推理和决策的新基准，专注于农业领域的咨询交互场景，结合自然用户查询、专家回答和图像上下文，评估模型的推理、澄清策略和长文本生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准通常依赖明确输入和封闭分类法，而MIRAGE旨在解决开放世界场景下的模糊、上下文丰富的交互需求，填补了真实世界知识密集型领域的评估空白。

Method: 基于35,000+真实用户-专家交互数据，通过多步骤流程构建，涵盖作物健康、害虫诊断和管理场景，包含7,000+生物实体。

Result: MIRAGE成为目前最全面的视觉-语言模型基准之一，支持开放世界设置，要求模型推断潜在知识差距并处理罕见实体。

Conclusion: MIRAGE为多模态模型在真实世界复杂场景中的能力评估提供了高保真基准，推动了开放世界推理和交互技术的发展。

Abstract: We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning
and decision-making in consultative interaction settings. Designed for the
agriculture domain, MIRAGE captures the full complexity of expert consultations
by combining natural user queries, expert-authored responses, and image-based
context, offering a high-fidelity benchmark for evaluating models on grounded
reasoning, clarification strategies, and long-form generation in a real-world,
knowledge-intensive domain. Grounded in over 35,000 real user-expert
interactions and curated through a carefully designed multi-step pipeline,
MIRAGE spans diverse crop health, pest diagnosis, and crop management
scenarios. The benchmark includes more than 7,000 unique biological entities,
covering plant species, pests, and diseases, making it one of the most
taxonomically diverse benchmarks available for vision-language models, grounded
in the real world. Unlike existing benchmarks that rely on well-specified user
inputs and closed-set taxonomies, MIRAGE features underspecified, context-rich
scenarios with open-world settings, requiring models to infer latent knowledge
gaps, handle rare entities, and either proactively guide the interaction or
respond. Project Page: https://mirage-benchmark.github.io

</details>


### [42] [LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for Evolving Multi-Class Imbalanced Classification](https://arxiv.org/abs/2506.20041)
*Soheil Abadifard,Fazli Can*

Main category: cs.LG

TL;DR: 提出了一种基于LSH-RHP和DynED框架的新方法，用于处理多类不平衡数据流分类问题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多类不平衡数据流分类中动态不平衡比率的挑战，填补现有研究的空白。

Method: 结合LSH-RHP进行多数类欠采样，生成平衡训练集，并集成到DynED框架中提升预测性能。

Result: 在23个真实和10个半合成数据集上，LSH-DynED在Kappa和mG-Mean指标上优于15种现有方法。

Conclusion: LSH-DynED在处理大规模、高维和多类不平衡数据流时表现出色，具有适应性和鲁棒性。

Abstract: The classification of imbalanced data streams, which have unequal class
distributions, is a key difficulty in machine learning, especially when dealing
with multiple classes. While binary imbalanced data stream classification tasks
have received considerable attention, only a few studies have focused on
multi-class imbalanced data streams. Effectively managing the dynamic imbalance
ratio is a key challenge in this domain. This study introduces a novel, robust,
and resilient approach to address these challenges by integrating Locality
Sensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic
Ensemble Diversification (DynED) framework. To the best of our knowledge, we
present the first application of LSH-RHP for undersampling in the context of
imbalanced non-stationary data streams. The proposed method undersamples the
majority classes by utilizing LSH-RHP, provides a balanced training set, and
improves the ensemble's prediction performance. We conduct comprehensive
experiments on 23 real-world and ten semi-synthetic datasets and compare
LSH-DynED with 15 state-of-the-art methods. The results reveal that LSH-DynED
outperforms other approaches in terms of both Kappa and mG-Mean effectiveness
measures, demonstrating its capability in dealing with multi-class imbalanced
non-stationary data streams. Notably, LSH-DynED performs well in large-scale,
high-dimensional datasets with considerable class imbalances and demonstrates
adaptation and robustness in real-world circumstances. To motivate our design,
we review existing methods for imbalanced data streams, outline key challenges,
and offer guidance for future work. For the reproducibility of our results, we
have made our implementation available on GitHub.

</details>


### [43] [Distillation-Enabled Knowledge Alignment for Generative Semantic Communications in AIGC Provisioning Tasks](https://arxiv.org/abs/2506.19893)
*Jingzhi Hu,Geoffrey Ye Li*

Main category: cs.LG

TL;DR: 论文提出DeKA-g算法，通过知识蒸馏和自适应传输优化生成语义通信（GSC）系统，显著提升边缘生成内容与云端生成内容的一致性。


<details>
  <summary>Details</summary>
Motivation: 解决生成语义通信（GSC）中云端与边缘知识对齐的挑战，以及无线传输知识与实际信道条件的匹配问题。

Method: 提出DeKA-g算法，包含元词辅助知识蒸馏（MAKD）和可变率分组SNR自适应（VGSA）两种方法，通过低秩矩阵蒸馏云端生成知识并适应不同信道条件。

Result: DeKA-g将边缘生成图像与云端生成图像的对齐度提升44%，压缩率适应效率提高116%，低SNR条件下性能提升28%。

Conclusion: DeKA-g有效解决了GSC系统中的知识对齐问题，显著提升了生成内容的质量和传输效率。

Abstract: Due to the surging amount of AI-generated content (AIGC), its provisioning to
edges and mobile users from the cloud incurs substantial traffic on networks.
Generative semantic communication (GSC) offers a promising solution by
transmitting highly compact information, i.e., prompt text and latent
representations, instead of high-dimensional AIGC data. However, GSC relies on
the alignment between the knowledge in the cloud generative AI (GAI) and that
possessed by the edges and users, and between the knowledge for wireless
transmission and that of actual channels, which remains challenging. In this
paper, we propose DeKA-g, a distillation-enabled knowledge alignment algorithm
for GSC systems. The core idea is to distill the generation knowledge from the
cloud-GAI into low-rank matrices, which can be incorporated by the edge and
used to adapt the transmission knowledge to diverse wireless channel
conditions. DeKA-g comprises two novel methods: metaword-aided knowledge
distillation (MAKD) and variable-rate grouped SNR adaptation (VGSA). For MAKD,
an optimized metaword is employed to enhance the efficiency of knowledge
distillation, while VGSA enables efficient adaptation to diverse compression
rates and SNR ranges. From simulation results, DeKA-g improves the alignment
between the edge-generated images and the cloud-generated ones by 44%.
Moreover, it adapts to compression rates with 116% higher efficiency than the
baseline and enhances the performance in low-SNR conditions by 28%.

</details>


### [44] [Explaining deep neural network models for electricity price forecasting with XAI](https://arxiv.org/abs/2506.19894)
*Antoine Pesenti,Aidan OSullivan*

Main category: cs.LG

TL;DR: 论文提出了一种结合深度神经网络（DNN）和可解释人工智能（XAI）的方法，用于预测电价并分析市场动态。


<details>
  <summary>Details</summary>
Motivation: 电力市场复杂且难以理解，传统计量经济学方法（白盒模型）能力有限，而DNN虽强大但缺乏可解释性。

Method: 使用DNN预测电价，并应用SHAP、Gradient等XAI方法及热图技术分析市场特征。

Result: 通过SSHAP值和SSHAP线等新概念，增强了对高维表格模型复杂表示的理解。

Conclusion: 该方法提高了对电力市场运作机制的理解，为市场分析提供了新工具。

Abstract: Electricity markets are highly complex, involving lots of interactions and
complex dependencies that make it hard to understand the inner workings of the
market and what is driving prices. Econometric methods have been developed for
this, white-box models, however, they are not as powerful as deep neural
network models (DNN). In this paper, we use a DNN to forecast the price and
then use XAI methods to understand the factors driving the price dynamics in
the market. The objective is to increase our understanding of how different
electricity markets work. To do that, we apply explainable methods such as SHAP
and Gradient, combined with visual techniques like heatmaps (saliency maps) to
analyse the behaviour and contributions of various features across five
electricity markets. We introduce the novel concepts of SSHAP values and SSHAP
lines to enhance the complex representation of high-dimensional tabular models.

</details>


### [45] [A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers](https://arxiv.org/abs/2506.19895)
*Miguel N. Font,José L. Jorro-Aragoneses,Carlos M. Alaíz*

Main category: cs.LG

TL;DR: 提出了一种基于训练案例检索的新框架，用于测量神经网络决策的不确定性，并提出了两种新指标，实验表明其优于基于softmax的置信度。


<details>
  <summary>Details</summary>
Motivation: 神经网络在高风险领域（如医疗诊断或自动驾驶）中可能返回错误决策，因此需要一种方法来检测和缓解这些错误。

Method: 通过检索与查询具有相似激活向量的训练案例，提出两种新指标：决策变化和层不确定性，用于捕捉跨层最近邻类分布的变化。

Result: 在CIFAR-10和MNIST数据集上的实验表明，新指标显著提升了不确定性估计，特别是在具有挑战性的分类任务中。

Conclusion: 提出的框架和指标能有效增强神经网络决策的不确定性估计，优于传统方法。

Abstract: Neural Networks have high accuracy in solving problems where it is difficult
to detect patterns or create a logical model. However, these algorithms
sometimes return wrong solutions, which become problematic in high-risk domains
like medical diagnosis or autonomous driving. One strategy to detect and
mitigate these errors is the measurement of the uncertainty over neural network
decisions. In this paper, we present a novel post-hoc framework for measuring
the uncertainty of a decision based on retrieved training cases that have a
similar activation vector to the query for each layer. Based on these retrieved
cases, we propose two new metrics: Decision Change and Layer Uncertainty, which
capture changes in nearest-neighbor class distributions across layers. We
evaluated our approach in a classification model for two datasets: CIFAR-10 and
MNIST. The results show that these metrics enhance uncertainty estimation,
especially in challenging classification tasks, outperforming softmax-based
confidence.

</details>


### [46] [A Comparative Analysis of Reinforcement Learning and Conventional Deep Learning Approaches for Bearing Fault Diagnosis](https://arxiv.org/abs/2506.19929)
*Efe Çakır,Patrick Dumond*

Main category: cs.LG

TL;DR: 该研究探讨了强化学习（RL）在轴承故障诊断中的应用，结果表明RL在适应性上优于传统方法，但计算需求较高。


<details>
  <summary>Details</summary>
Motivation: 轴承故障可能导致严重的运营中断和维护成本，传统方法依赖大量标记数据且适应性不足，因此探索RL的潜力。

Method: 使用深度Q网络（DQN）进行轴承故障分类，研究其在机器状态监测中的表现。

Result: RL模型在控制条件下与传统监督学习模型性能相当，但在适应性上表现更优，计算需求较高。

Conclusion: RL有潜力补充传统方法，为自适应诊断框架铺平道路。

Abstract: Bearing faults in rotating machinery can lead to significant operational
disruptions and maintenance costs. Modern methods for bearing fault diagnosis
rely heavily on vibration analysis and machine learning techniques, which often
require extensive labeled data and may not adapt well to dynamic environments.
This study explores the feasibility of reinforcement learning (RL),
specifically Deep Q-Networks (DQNs), for bearing fault classification tasks in
machine condition monitoring to enhance the accuracy and adaptability of
bearing fault diagnosis. The results demonstrate that while RL models developed
in this study can match the performance of traditional supervised learning
models under controlled conditions, they excel in adaptability when equipped
with optimized reward structures. However, their computational demands
highlight areas for further improvement. These findings demonstrate RL's
potential to complement traditional methods, paving the way for adaptive
diagnostic frameworks.

</details>


### [47] [Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture](https://arxiv.org/abs/2506.19935)
*Shuchen Xue,Tianyu Xie,Tianyang Hu,Zijin Feng,Jiacheng Sun,Kenji Kawaguchi,Zhenguo Li,Zhi-Ming Ma*

Main category: cs.LG

TL;DR: 论文比较了自回归（AR）和掩码扩散模型（MDM）在解码器框架下的表现，发现MDM（作为任意顺序AR）在生成速度和困惑度上具有优势，同时探讨了架构对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于公平比较AR和MDM范式，避免因架构差异导致的不公平对比，并探索MDM在解码器框架下的潜力。

Method: 方法是将MDM置于解码器框架下，作为任意顺序AR（AO-AR）与标准AR进行对比，并研究架构（解码器与编码器）对MDM性能的影响。

Result: 结果显示，解码器MDM在生成速度上显著提升（约25倍），且困惑度与标准AR相当，但需要温度退火。编码器MDM建模更简单，但性能受限。

Conclusion: 结论是解码器MDM在速度和性能上有优势，架构选择对模型表现有重要影响，为未来模型设计提供了新思路。

Abstract: Large language models (LLMs) predominantly use autoregressive (AR)
approaches, but masked diffusion models (MDMs) are emerging as viable
alternatives. A key challenge in comparing AR and MDM paradigms is their
typical architectural difference: AR models are often decoder-only, while MDMs
have largely been encoder-only. This practice of changing both the modeling
paradigm and architecture simultaneously makes direct comparisons unfair, as
it's hard to distinguish whether observed differences stem from the paradigm
itself or the architectural shift. This research evaluates MDMs within a
decoder-only framework to: (1) equitably compare MDM (as Any-Order AR, or
AO-AR) and standard AR paradigms. Our investigation suggests that the standard
AO-AR objective, which averages over all token permutations, may benefit from
refinement, as many permutations appear less informative compared to the
language's inherent left-to-right structure. (2) Investigate architectural
influences (decoder-only vs. encoder-only) within MDMs. We demonstrate that
while encoder-only MDMs model a simpler conditional probability space,
decoder-only MDMs can achieve dramatic generation speedups ($\sim25\times$) and
comparable perplexity with temperature annealing despite modeling a vastly
larger space, highlighting key trade-offs. This work thus decouples core
paradigm differences from architectural influences, offering insights for
future model design. Code is available at https://github.com/scxue/AO-GPT-MDM.

</details>


### [48] [The Most Important Features in Generalized Additive Models Might Be Groups of Features](https://arxiv.org/abs/2506.19937)
*Tomas M. Bosschieter,Luis Franca,Jessica Wolk,Yiyuan Wu,Bella Mehta,Joseph Dehoney,Orsolya Kiss,Fiona C. Baker,Qingyu Zhao,Rich Caruana,Kilian M. Pohl*

Main category: cs.LG

TL;DR: 本文提出了一种高效的方法，用于评估广义加性模型（GAMs）中特征组的重要性，无需重新训练模型，支持事后定义组和重叠组，并在高维数据中保持有效性。


<details>
  <summary>Details</summary>
Motivation: 在可解释机器学习中，特征组的重要性常被忽视，而联合信号可能提供关键见解。本文旨在填补这一空白。

Method: 提出了一种新颖的方法，用于确定GAMs中特征组的重要性，具有高效性、无需重新训练、支持事后定义和重叠组的特点。

Result: 通过合成实验和两个真实案例（抑郁症症状识别和髋关节置换后的健康社会决定因素）验证了方法的有效性。

Conclusion: 分析特征组的重要性比单特征分析提供了更准确、全面的视角，尤其在医学领域具有重要意义。

Abstract: While analyzing the importance of features has become ubiquitous in
interpretable machine learning, the joint signal from a group of related
features is sometimes overlooked or inadvertently excluded. Neglecting the
joint signal could bypass a critical insight: in many instances, the most
significant predictors are not isolated features, but rather the combined
effect of groups of features. This can be especially problematic for datasets
that contain natural groupings of features, including multimodal datasets. This
paper introduces a novel approach to determine the importance of a group of
features for Generalized Additive Models (GAMs) that is efficient, requires no
model retraining, allows defining groups posthoc, permits overlapping groups,
and remains meaningful in high-dimensional settings. Moreover, this definition
offers a parallel with explained variation in statistics. We showcase
properties of our method on three synthetic experiments that illustrate the
behavior of group importance across various data regimes. We then demonstrate
the importance of groups of features in identifying depressive symptoms from a
multimodal neuroscience dataset, and study the importance of social
determinants of health after total hip arthroplasty. These two case studies
reveal that analyzing group importance offers a more accurate, holistic view of
the medical issues compared to a single-feature analysis.

</details>


### [49] [HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization](https://arxiv.org/abs/2506.19992)
*Gabor Petnehazi,Bernadett Aradi*

Main category: cs.LG

TL;DR: HERCULES是一种新型分层k-means聚类算法，支持多种数据类型，并利用LLM生成语义丰富的聚类标题和描述，提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 复杂数据集的快速增长需要既能有效分组数据又能提供人类可理解洞察的工具。

Method: HERCULES通过递归应用k-means聚类构建层次结构，并集成LLM生成聚类标题和描述，支持两种表示模式。

Result: 算法能够从复杂数据集中提取有意义的分层知识，并提供了交互式可视化工具。

Conclusion: HERCULES在增强聚类结果的可解释性和实用性方面具有潜力。

Abstract: The explosive growth of complex datasets across various modalities
necessitates advanced analytical tools that not only group data effectively but
also provide human-understandable insights into the discovered structures. We
introduce HERCULES (Hierarchical Embedding-based Recursive Clustering Using
LLMs for Efficient Summarization), a novel algorithm and Python package
designed for hierarchical k-means clustering of diverse data types, including
text, images, and numeric data (processed one modality per run). HERCULES
constructs a cluster hierarchy by recursively applying k-means clustering,
starting from individual data points at level 0. A key innovation is its deep
integration of Large Language Models (LLMs) to generate semantically rich
titles and descriptions for clusters at each level of the hierarchy,
significantly enhancing interpretability. The algorithm supports two main
representation modes: `direct' mode, which clusters based on original data
embeddings or scaled numeric features, and `description' mode, which clusters
based on embeddings derived from LLM-generated summaries. Users can provide a
`topic\_seed' to guide LLM-generated summaries towards specific themes. An
interactive visualization tool facilitates thorough analysis and understanding
of the clustering results. We demonstrate HERCULES's capabilities and discuss
its potential for extracting meaningful, hierarchical knowledge from complex
datasets.

</details>


### [50] [TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design](https://arxiv.org/abs/2506.19997)
*Geonwoo Cho,Jaegyun Im,Jihwan Lee,Hojun Yi,Sejin Kim,Sundong Kim*

Main category: cs.LG

TL;DR: TRACED方法通过结合转移预测误差和共学习性，改进了UED框架中的任务设计，显著提升了零样本泛化能力，同时减少了环境交互需求。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习在未知环境中泛化能力不足的问题，通过改进UED框架中的任务生成和学习潜力评估方法。

Method: 提出TRACED方法，结合转移预测误差和共学习性作为学习潜力的评估指标，优化任务生成。

Result: TRACED在多个基准测试中提升了零样本泛化能力，且环境交互需求减少至基线的一半。

Conclusion: 通过精细化学习潜力评估和任务关系建模，TRACED实现了更高效的课程设计。

Abstract: Generalizing deep reinforcement learning agents to unseen environments
remains a significant challenge. One promising solution is Unsupervised
Environment Design (UED), a co-evolutionary framework in which a teacher
adaptively generates tasks with high learning potential, while a student learns
a robust policy from this evolving curriculum. Existing UED methods typically
measure learning potential via regret, the gap between optimal and current
performance, approximated solely by value-function loss. Building on these
approaches, we introduce the transition prediction error as an additional term
in our regret approximation. To capture how training on one task affects
performance on others, we further propose a lightweight metric called
co-learnability. By combining these two measures, we present Transition-aware
Regret Approximation with Co-learnability for Environment Design (TRACED).
Empirical evaluations show that TRACED yields curricula that improve zero-shot
generalization across multiple benchmarks while requiring up to 2x fewer
environment interactions than strong baselines. Ablation studies confirm that
the transition prediction error drives rapid complexity ramp-up and that
co-learnability delivers additional gains when paired with the transition
prediction error. These results demonstrate how refined regret approximation
and explicit modeling of task relationships can be leveraged for
sample-efficient curriculum design in UED.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [51] [Irec: A Metacognitive Scaffolding for Self-Regulated Learning through Just-in-Time Insight Recall: A Conceptual Framework and System Prototype](https://arxiv.org/abs/2506.20156)
*Xuefei Hou,Xizhao Tan*

Main category: cs.HC

TL;DR: 论文提出了一种名为'Insight Recall'的新范式，通过上下文触发的个人过去见解检索来支持自我调节学习（SRL），并开发了原型系统Irec。


<details>
  <summary>Details</summary>
Motivation: 现有数字工具在支持元认知反思方面不足，如Spaced Repetition Systems（SRS）缺乏上下文，Personal Knowledge Management（PKM）工具维护成本高。

Method: 采用Just-in-Time Adaptive Intervention（JITAI）框架，构建动态知识图谱和混合检索引擎，结合LLM进行深度相似性评估，并设计'Guided Inquiry'模块。

Result: 开发了Irec系统，展示了其可行性，提供了增强元认知和自我调节的智能学习系统设计框架。

Conclusion: 论文贡献了理论框架和实用系统平台，为下一代智能学习系统设计提供了基础。

Abstract: The core challenge in learning has shifted from knowledge acquisition to
effective Self-Regulated Learning (SRL): planning, monitoring, and reflecting
on one's learning. Existing digital tools, however, inadequately support
metacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized
review, overlooking the role of context, while Personal Knowledge Management
(PKM) tools require high manual maintenance.
  To address these challenges, this paper introduces "Insight Recall," a novel
paradigm that conceptualizes the context-triggered retrieval of personal past
insights as a metacognitive scaffold to promote SRL. We formalize this paradigm
using the Just-in-Time Adaptive Intervention (JITAI) framework and implement a
prototype system, Irec, to demonstrate its feasibility. At its core, Irec uses
a dynamic knowledge graph of the user's learning history. When a user faces a
new problem, a hybrid retrieval engine recalls relevant personal "insights."
Subsequently, a large language model (LLM) performs a deep similarity
assessment to filter and present the most relevant scaffold in a just-in-time
manner. To reduce cognitive load, Irec features a human-in-the-loop pipeline
for LLM-based knowledge graph construction. We also propose an optional "Guided
Inquiry" module, where users can engage in a Socratic dialogue with an expert
LLM, using the current problem and recalled insights as context. The
contribution of this paper is a solid theoretical framework and a usable system
platform for designing next-generation intelligent learning systems that
enhance metacognition and self-regulation.

</details>


### [52] [A Literature Review on Simulation in Conversational Recommender Systems](https://arxiv.org/abs/2506.20291)
*Haoran Zhang,Xin Zhao,Jinze Chen,Junpeng Guo*

Main category: cs.HC

TL;DR: 本文综述了对话推荐系统（CRSs）的研究现状，提出了一种分类框架，总结了模拟方法在解决CRSs挑战中的关键作用，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨对话推荐系统（CRSs）在多轮对话中实现个性化推荐的研究进展，分析模拟方法在解决其核心挑战中的作用。

Method: 开发了一个分类框架，将相关研究分为数据集构建、算法设计、系统评估和实证研究四类，并对模拟方法进行了全面分析。

Result: 模拟方法（如基于LLM的方法）在生成数据、优化算法和评估系统中发挥了重要作用，但仍存在数据集偏差和语义差距等挑战。

Conclusion: 模拟方法对推动CRSs研究具有潜力，未来需解决现有挑战并探索新方向。

Abstract: Conversational Recommender Systems (CRSs) have garnered attention as a novel
approach to delivering personalized recommendations through multi-turn
dialogues. This review developed a taxonomy framework to systematically
categorize relevant publications into four groups: dataset construction,
algorithm design, system evaluation, and empirical studies, providing a
comprehensive analysis of simulation methods in CRSs research. Our analysis
reveals that simulation methods play a key role in tackling CRSs' main
challenges. For example, LLM-based simulation methods have been used to create
conversational recommendation data, enhance CRSs algorithms, and evaluate CRSs.
Despite several challenges, such as dataset bias, the limited output
flexibility of LLM-based simulations, and the gap between text semantic space
and behavioral semantics, persist due to the complexity in Human-Computer
Interaction (HCI) of CRSs, simulation methods hold significant potential for
advancing CRS research. This review offers a thorough summary of the current
research landscape in this domain and identifies promising directions for
future inquiry.

</details>
