<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.AI](#cs.AI) [Total: 36]
- [cs.IR](#cs.IR) [Total: 21]
- [cs.LG](#cs.LG) [Total: 38]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.DL](#cs.DL) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Rethinking Graph-Based Document Classification: Learning Data-Driven Structures Beyond Heuristic Approaches](https://arxiv.org/abs/2508.00864)
*Margarita Bugueño,Gerard de Melo*

Main category: cs.CL

TL;DR: 提出了一种数据驱动的图结构学习方法，用于文档分类，优于传统启发式方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有图文档表示依赖启发式或领域知识的问题，实现自动化的图结构学习。

Method: 构建同质加权图，节点为句子，边通过自注意力模型学习，并使用统计过滤保留强相关句子。

Result: 在三个数据集上表现优于启发式方法，准确率和F1分数更高，统计过滤提升了分类鲁棒性。

Conclusion: 自动图生成方法优于传统启发式，为NLP应用提供了新方向。

Abstract: In document classification, graph-based models effectively capture document
structure, overcoming sequence length limitations and enhancing contextual
understanding. However, most existing graph document representations rely on
heuristics, domain-specific rules, or expert knowledge. Unlike previous
approaches, we propose a method to learn data-driven graph structures,
eliminating the need for manual design and reducing domain dependence. Our
approach constructs homogeneous weighted graphs with sentences as nodes, while
edges are learned via a self-attention model that identifies dependencies
between sentence pairs. A statistical filtering strategy aims to retain only
strongly correlated sentences, improving graph quality while reducing the graph
size. Experiments on three document classification datasets demonstrate that
learned graphs consistently outperform heuristic-based graphs, achieving higher
accuracy and $F_1$ score. Furthermore, our study demonstrates the effectiveness
of the statistical filtering in improving classification robustness. These
results highlight the potential of automatic graph generation over traditional
heuristic approaches and open new directions for broader applications in NLP.

</details>


### [2] [FECT: Factuality Evaluation of Interpretive AI-Generated Claims in Contact Center Conversation Transcripts](https://arxiv.org/abs/2508.00889)
*Hagyeong Shin,Binoy Robin Dalal,Iwona Bialynicka-Birula,Navjot Matharu,Ryan Muir,Xingwei Yang,Samuel W. K. Wong*

Main category: cs.CL

TL;DR: 论文提出了一种名为3D（分解、解耦、脱离）的新范式，用于评估大型语言模型（LLM）在联系中心对话分析中的事实性，并引入了FECT基准数据集。


<details>
  <summary>Details</summary>
Motivation: 企业应用中，LLM的幻觉问题可能导致错误的业务决策，尤其是在联系中心对话分析中，缺乏事实性评估的标准。

Method: 提出3D范式（分解、解耦、脱离）作为人类标注指南和LLM评估提示，并创建FECT数据集。

Result: 通过3D范式对齐LLM评估，实现了对联系中心对话分析中AI生成内容的事实性自动评估。

Conclusion: 研究为评估联系中心对话分析中AI生成内容的事实性提供了新方法。

Abstract: Large language models (LLMs) are known to hallucinate, producing natural
language outputs that are not grounded in the input, reference materials, or
real-world knowledge. In enterprise applications where AI features support
business decisions, such hallucinations can be particularly detrimental. LLMs
that analyze and summarize contact center conversations introduce a unique set
of challenges for factuality evaluation, because ground-truth labels often do
not exist for analytical interpretations about sentiments captured in the
conversation and root causes of the business problems. To remedy this, we first
introduce a \textbf{3D} -- \textbf{Decompose, Decouple, Detach} -- paradigm in
the human annotation guideline and the LLM-judges' prompt to ground the
factuality labels in linguistically-informed evaluation criteria. We then
introduce \textbf{FECT}, a novel benchmark dataset for \textbf{F}actuality
\textbf{E}valuation of Interpretive AI-Generated \textbf{C}laims in Contact
Center Conversation \textbf{T}ranscripts, labeled under our 3D paradigm.
Lastly, we report our findings from aligning LLM-judges on the 3D paradigm.
Overall, our findings contribute a new approach for automatically evaluating
the factuality of outputs generated by an AI system for analyzing contact
center conversations.

</details>


### [3] [XAutoLM: Efficient Fine-Tuning of Language Models via Meta-Learning and AutoML](https://arxiv.org/abs/2508.00924)
*Ernesto L. Estevanell-Valladares,Suilan Estevez-Velarde,Yoan Gutiérrez,Andrés Montoyo,Ruslan Mitkov*

Main category: cs.CL

TL;DR: XAutoLM是一个基于元学习的AutoML框架，旨在高效优化语言模型的微调流程，减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有自动化框架未能同时解决模型选择和超参数优化问题，导致语言模型微调的计算成本和环境影响较高。

Method: XAutoLM通过提取任务和系统级元特征，复用历史经验，优化采样策略，避免无效配置。

Result: 在多个文本分类和问答任务中，XAutoLM显著提升了性能，减少了评估时间和错误率。

Conclusion: XAutoLM为资源高效的语言模型微调提供了新方法，推动了绿色AI的发展。

Abstract: Experts in machine learning leverage domain knowledge to navigate decisions
in model selection, hyperparameter optimisation, and resource allocation. This
is particularly critical for fine-tuning language models (LMs), where repeated
trials incur substantial computational overhead and environmental impact.
However, no existing automated framework simultaneously tackles the entire
model selection and HPO task for resource-efficient LM fine-tuning. We
introduce XAutoLM, a meta-learning-augmented AutoML framework that reuses past
experiences to optimise discriminative and generative LM fine-tuning pipelines
efficiently. XAutoLM learns from stored successes and failures by extracting
task- and system-level meta-features to bias its sampling toward fruitful
configurations and away from costly dead ends. On four text classification and
two question-answering benchmarks, XAutoLM surpasses zero-shot optimiser's peak
F1 on five of six tasks, cuts mean evaluation time by up to 4.5x, reduces error
ratios by up to sevenfold, and uncovers up to 50% more pipelines above the
zero-shot Pareto front. In contrast, simpler memory-based baselines suffer
negative transfer. We release XAutoLM and our experience store to catalyse
resource-efficient, Green AI fine-tuning in the NLP community.

</details>


### [4] [MAO-ARAG: Multi-Agent Orchestration for Adaptive Retrieval-Augmented Generation](https://arxiv.org/abs/2508.01005)
*Yiqun Chen,Erhan Zhang,Lingyong Yan,Shuaiqiang Wang,Jizhou Huang,Dawei Yin,Jiaxin Mao*

Main category: cs.CL

TL;DR: 提出了一种自适应RAG框架MAO-ARAG，通过多智能体协调动态规划工作流，以提高问答系统的准确性和成本效率。


<details>
  <summary>Details</summary>
Motivation: 固定RAG管道难以平衡不同查询的性能和成本效率，需自适应解决方案。

Method: MAO-ARAG采用多智能体协调，包括执行器智能体（如查询重构、文档选择和生成）和规划智能体，后者通过强化学习动态选择工作流。

Result: 在多个QA数据集上实验表明，MAO-ARAG能提供高质量答案，同时控制成本和延迟。

Conclusion: MAO-ARAG通过动态规划工作流，显著提升了问答系统的性能和效率。

Abstract: In question-answering (QA) systems, Retrieval-Augmented Generation (RAG) has
become pivotal in enhancing response accuracy and reducing hallucination
issues. The architecture of RAG systems varies significantly, encompassing
single-round RAG, iterative RAG, and reasoning RAG, each tailored to address
different types of queries. Due to the varying complexity of real-world
queries, a fixed RAG pipeline often struggles to balance performance and cost
efficiency across different queries. To address this challenge, we propose an
adaptive RAG framework called MAO-ARAG, which leverages multi-agent
orchestration. Our adaptive RAG is conceived as a multi-turn framework.
Specifically, we define multiple executor agents, representing typical RAG
modules such as query reformulation agents, document selection agent, and
generation agents. A planner agent intelligently selects and integrates the
appropriate agents from these executors into a suitable workflow tailored for
each query, striving for high-quality answers while maintaining reasonable
costs. During each turn, the planner agent is trained using reinforcement
learning, guided by an outcome-based reward (F1 score) and a cost-based
penalty, continuously improving answer quality while keeping costs within a
reasonable range. Experiments conducted on multiple QA datasets demonstrate
that our approach, which dynamically plans workflows for each query, not only
achieves high answer quality but also maintains both cost and latency within
acceptable limits.The code of MAO-ARAG is on
https://github.com/chenyiqun/Agentic-RAG.

</details>


### [5] [UrBLiMP: A Benchmark for Evaluating the Linguistic Competence of Large Language Models in Urdu](https://arxiv.org/abs/2508.01006)
*Farah Adeeba,Brian Dillon,Hassan Sajjad,Rajesh Bhatt*

Main category: cs.CL

TL;DR: 论文介绍了UrBLiMP基准测试，用于评估多语言大语言模型在低资源语言乌尔都语中的语法知识，发现模型表现差异显著。


<details>
  <summary>Details</summary>
Motivation: 评估多语言大语言模型在低资源语言乌尔都语中的语法知识，填补现有研究的空白。

Method: 构建UrBLiMP数据集，包含5,696对最小差异句子，针对十种核心语法现象，并进行人工评估。

Result: LLaMA-3-70B表现最佳（94.73%），但与其他顶级模型（如Gemma-3-27B-PT）无显著差异。

Conclusion: 当前多语言大语言模型在低资源语言中捕捉细粒度语法知识的能力存在潜力与局限性。

Abstract: Multilingual Large Language Models (LLMs) have shown remarkable performance
across various languages; however, they often include significantly less data
for low-resource languages such as Urdu compared to high-resource languages
like English. To assess the linguistic knowledge of LLMs in Urdu, we present
the Urdu Benchmark of Linguistic Minimal Pairs (UrBLiMP) i.e. pairs of
minimally different sentences that contrast in grammatical acceptability.
UrBLiMP comprises 5,696 minimal pairs targeting ten core syntactic phenomena,
carefully curated using the Urdu Treebank and diverse Urdu text corpora. A
human evaluation of UrBLiMP annotations yielded a 96.10% inter-annotator
agreement, confirming the reliability of the dataset. We evaluate twenty
multilingual LLMs on UrBLiMP, revealing significant variation in performance
across linguistic phenomena. While LLaMA-3-70B achieves the highest average
accuracy (94.73%), its performance is statistically comparable to other top
models such as Gemma-3-27B-PT. These findings highlight both the potential and
the limitations of current multilingual LLMs in capturing fine-grained
syntactic knowledge in low-resource languages.

</details>


### [6] [Cross-Domain Web Information Extraction at Pinterest](https://arxiv.org/abs/2508.01096)
*Michael Farag,Patrick Halina,Andrey Zaytsev,Alekhya Munagala,Imtihan Ahmed,Junhao Wang*

Main category: cs.CL

TL;DR: Pinterest提出了一种高效且低成本的结构化数据提取系统，结合网页的结构、视觉和文本信息，使用简单模型（如XGBoost）实现比复杂模型（如GPT）更高的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 互联网上存在大量非结构化信息，将其转换为结构化格式对提升用户体验和内容分发至关重要。

Method: 采用新颖的网页表示方法，结合结构、视觉和文本模态，优化为小型模型学习，捕获HTML节点的文本、样式和布局信息。

Result: 系统处理速度超过每秒1000个URL，成本比最便宜的GPT替代方案低1000倍，且准确性更高。

Conclusion: 该方法展示了在结构化数据提取任务中，简单模型可以超越复杂模型，同时具备高可扩展性和成本效益。

Abstract: The internet offers a massive repository of unstructured information, but
it's a significant challenge to convert this into a structured format. At
Pinterest, the ability to accurately extract structured product data from
e-commerce websites is essential to enhance user experiences and improve
content distribution. In this paper, we present Pinterest's system for
attribute extraction, which achieves remarkable accuracy and scalability at a
manageable cost. Our approach leverages a novel webpage representation that
combines structural, visual, and text modalities into a compact form,
optimizing it for small model learning. This representation captures each
visible HTML node with its text, style and layout information. We show how this
allows simple models such as eXtreme Gradient Boosting (XGBoost) to extract
attributes more accurately than much more complex Large Language Models (LLMs)
such as Generative Pre-trained Transformer (GPT). Our results demonstrate a
system that is highly scalable, processing over 1,000 URLs per second, while
being 1000 times more cost-effective than the cheapest GPT alternatives.

</details>


### [7] [Asking the Right Questions: Benchmarking Large Language Models in the Development of Clinical Consultation Templates](https://arxiv.org/abs/2508.01159)
*Liam G. McCoy,Fateme Nateghi Haredasht,Kanav Chopra,David Wu,David JH Wu,Abass Conteh,Sarita Khemani,Saloni Kumar Maharaj,Vishnu Ravi,Arth Pahwa,Yingjie Weng,Leah Rosengaus,Lena Giang,Kelvin Zhenghao Li,Olivia Jee,Daniel Shirvani,Ethan Goh,Jonathan H. Chen*

Main category: cs.CL

TL;DR: 评估大型语言模型（LLMs）生成结构化临床咨询模板的能力，发现模型在全面性上表现良好，但模板过长且优先级排序不佳。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在电子咨询中生成临床模板的潜力，以提升医生间信息交换效率。

Method: 使用145个专家模板，通过多代理流程（提示优化、语义自动评分和优先级分析）评估多个前沿模型。

Result: 模型如o3全面性高达92.2%，但模板过长且优先级排序不准确，性能因专科而异。

Conclusion: LLMs可提升临床信息交换，但需更稳健的评估方法以优化优先级排序。

Abstract: This study evaluates the capacity of large language models (LLMs) to generate
structured clinical consultation templates for electronic consultation. Using
145 expert-crafted templates developed and routinely used by Stanford's
eConsult team, we assess frontier models -- including o3, GPT-4o, Kimi K2,
Claude 4 Sonnet, Llama 3 70B, and Gemini 2.5 Pro -- for their ability to
produce clinically coherent, concise, and prioritized clinical question
schemas. Through a multi-agent pipeline combining prompt optimization, semantic
autograding, and prioritization analysis, we show that while models like o3
achieve high comprehensiveness (up to 92.2\%), they consistently generate
excessively long templates and fail to correctly prioritize the most clinically
important questions under length constraints. Performance varies across
specialties, with significant degradation in narrative-driven fields such as
psychiatry and pain medicine. Our findings demonstrate that LLMs can enhance
structured clinical information exchange between physicians, while highlighting
the need for more robust evaluation methods that capture a model's ability to
prioritize clinically salient information within the time constraints of
real-world physician communication.

</details>


### [8] [CSIRO-LT at SemEval-2025 Task 11: Adapting LLMs for Emotion Recognition for Multiple Languages](https://arxiv.org/abs/2508.01161)
*Jiyu Chen,Necva Bölücü,Sarvnaz Karimi,Diego Mollá,Cécile L. Paris*

Main category: cs.CL

TL;DR: 论文研究了跨语言情感检测的挑战，提出了一种基于多语言预训练LLM和LoRA微调的方法，效果最佳。


<details>
  <summary>Details</summary>
Motivation: 解决不同语言和文化背景下情感表达的多样性问题，提升跨语言情感识别的准确性。

Method: 使用预训练的多语言LLM，并针对每种语言单独进行LoRA微调。

Result: 实验表明，该方法在情感识别任务中表现最优。

Conclusion: 通过语言特定的微调策略，可以有效提升跨语言情感识别的性能。

Abstract: Detecting emotions across different languages is challenging due to the
varied and culturally nuanced ways of emotional expressions. The
\textit{Semeval 2025 Task 11: Bridging the Gap in Text-Based emotion} shared
task was organised to investigate emotion recognition across different
languages. The goal of the task is to implement an emotion recogniser that can
identify the basic emotional states that general third-party observers would
attribute to an author based on their written text snippet, along with the
intensity of those emotions. We report our investigation of various
task-adaptation strategies for LLMs in emotion recognition. We show that the
most effective method for this task is to fine-tune a pre-trained multilingual
LLM with LoRA setting separately for each language.

</details>


### [9] [Adaptive Content Restriction for Large Language Models via Suffix Optimization](https://arxiv.org/abs/2508.01198)
*Yige Li,Peihai Jiang,Jun Sun,Peng Shu,Tianming Liu,Zhen Xiang*

Main category: cs.CL

TL;DR: 论文提出了一种轻量级方法（Suffix Optimization, SOP）来动态限制大语言模型生成特定受限内容，无需微调模型，并在多个模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型生成内容的广泛性，针对不同用户群体和快速变化的需求进行内容限制具有挑战性，传统微调方法成本高昂且不灵活。

Method: 提出Adaptive Content Restriction (AdaCoRe)任务，采用Suffix Optimization (SOP)方法，通过在提示后添加优化后缀实现内容限制。

Result: SOP在CoReBench基准测试中表现优于基线方法，平均限制率提升6%-17%，并在实际平台POE上验证了实用性。

Conclusion: SOP是一种高效、轻量级的内容限制方法，适用于动态需求，具有实际应用潜力。

Abstract: Large Language Models (LLMs) have demonstrated significant success across
diverse applications. However, enforcing content restrictions remains a
significant challenge due to their expansive output space. One aspect of
content restriction is preventing LLMs from generating harmful content via
model alignment approaches such as supervised fine-tuning (SFT). Yet, the need
for content restriction may vary significantly across user groups, change
rapidly over time, and not always align with general definitions of
harmfulness. Applying SFT to each of these specific use cases is impractical
due to the high computational, data, and storage demands. Motivated by this
need, we propose a new task called \textit{Adaptive Content Restriction}
(AdaCoRe), which focuses on lightweight strategies -- methods without model
fine-tuning -- to prevent deployed LLMs from generating restricted terms for
specific use cases. We propose the first method for AdaCoRe, named
\textit{Suffix Optimization (SOP)}, which appends a short, optimized suffix to
any prompt to a) prevent a target LLM from generating a set of restricted
terms, while b) preserving the output quality. To evaluate AdaCoRe approaches,
including our SOP, we create a new \textit{Content Restriction Benchmark}
(CoReBench), which contains 400 prompts for 80 restricted terms across 8
carefully selected categories. We demonstrate the effectiveness of SOP on
CoReBench, which outperforms the system-level baselines such as system suffix
by 15\%, 17\%, 10\%, 9\%, and 6\% on average restriction rates for Gemma2-2B,
Mistral-7B, Vicuna-7B, Llama3-8B, and Llama3.1-8B, respectively. We also
demonstrate that SOP is effective on POE, an online platform hosting various
commercial LLMs, highlighting its practicality in real-world scenarios.

</details>


### [10] [Show or Tell? Modeling the evolution of request-making in Human-LLM conversations](https://arxiv.org/abs/2508.01213)
*Shengqi Zhu,Jeffrey M. Rzeszotarski,David Mimno*

Main category: cs.CL

TL;DR: 论文提出了一种新任务，将聊天查询分割为请求内容、角色、查询特定上下文和附加表达，并分析了用户行为模式与模型能力的关系。


<details>
  <summary>Details</summary>
Motivation: 研究用户在与LLM交互时的行为模式，揭示其与人类间互动的差异，并探索模型能力对用户行为的影响。

Method: 提出分割聊天查询的任务，并通过数据资源进行历时分析，比较早期与后期查询模式的变化。

Result: 发现用户查询模式从强调请求逐渐收敛，且模型能力的引入在社区层面可追踪用户行为变化。

Conclusion: 研究为理解LLM用户行为提供了新视角，并展示了模型能力对用户行为的显著影响。

Abstract: Chat logs provide a rich source of information about LLM users, but patterns
of user behavior are often masked by the variability of queries. We present a
new task, segmenting chat queries into contents of requests, roles,
query-specific context, and additional expressions. We find that, despite the
familiarity of chat-based interaction, request-making in LLM queries remains
significantly different from comparable human-human interactions. With the data
resource, we introduce an important perspective of diachronic analyses with
user expressions. We find that query patterns vary between early ones
emphasizing requests, and individual users explore patterns but tend to
converge with experience. Finally, we show that model capabilities affect user
behavior, particularly with the introduction of new models, which are traceable
at the community level.

</details>


### [11] [WebDS: An End-to-End Benchmark for Web-based Data Science](https://arxiv.org/abs/2508.01222)
*Ethan Hsu,Hong Meng Yam,Ines Bouissou,Aaron Murali John,Raj Thota,Josh Koe,Vivek Sarath Putta,G K Dharesan,Alexander Spangher,Shikhar Murty,Tenghao Huang,Christopher D. Manning*

Main category: cs.CL

TL;DR: WebDS是一个端到端的基于网络的数据科学基准测试，包含870个任务，覆盖29个网站，旨在评估复杂、多步骤的数据科学工作流。现有SOTA LLM代理在WebDS任务中表现不佳，揭示了新的失败模式。


<details>
  <summary>Details</summary>
Motivation: 现有网络基准测试和数据科学基准测试未能全面评估复杂的数据科学任务，尤其是涉及多步骤操作和异构数据格式的情况。WebDS填补了这一空白。

Method: WebDS包含870个任务，覆盖29个多样化网站，要求代理执行复杂操作，使用工具处理异构数据。

Result: 当前SOTA LLM代理在WebDS任务中表现较差，例如Browser Use仅完成15%的任务，失败原因包括信息基础不足、重复行为和走捷径。

Conclusion: WebDS为开发实用的基于LLM的数据科学工具提供了更真实和强大的测试平台。

Abstract: A large portion of real-world data science tasks are complex and require
multi-hop web-based interactions: finding appropriate data available on the
internet, synthesizing real-time data of various modalities from different
locations, and producing summarized analyses. Existing web benchmarks often
focus on simplistic interactions, such as form submissions or e-commerce
transactions, and often do not require diverse tool-using capabilities required
for web based data science. Conversely, traditional data science benchmarks
typically concentrate on static, often textually bound datasets and do not
assess end-to-end workflows that encompass data acquisition, cleaning,
analysis, and insight generation. In response, we introduce WebDS, the first
end-to-end web-based data science benchmark. It comprises 870 web-based data
science tasks across 29 diverse websites from structured government data
portals to unstructured news media, challenging agents to perform complex,
multi-step operations requiring the use of tools and heterogeneous data formats
that better reflect the realities of modern data analytics. Evaluations of
current SOTA LLM agents indicate significant performance gaps in accomplishing
these tasks. For instance, Browser Use, which accomplishes 80% of tasks on Web
Voyager, successfully completes only 15% of tasks in WebDS, which our analysis
suggests is due to new failure modes like poor information grounding,
repetitive behavior and shortcut-taking that agents performing WebDS' tasks
display. By providing a more robust and realistic testing ground, WebDS sets
the stage for significant advances in the development of practically useful
LLM-based data science.

</details>


### [12] [WarriorMath: Enhancing the Mathematical Ability of Large Language Models with a Defect-aware Framework](https://arxiv.org/abs/2508.01245)
*Yue Chen,Minghua He,Fangkai Yang,Pu Zhao,Lu Wang,Yu Kang,Yifei Dong,Yuefeng Zhan,Hao Sun,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.CL

TL;DR: WarriorMath提出了一种缺陷感知的数学问题解决框架，通过针对性数据合成和渐进式训练提升LLMs的数学能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视LLMs的具体失败模式，导致合成问题对性能提升有限。

Method: WarriorMath结合多专家LLMs协作生成、批评和改进问题，并通过渐进式学习框架逐步微调模型。

Result: 在六个数学基准测试中，WarriorMath平均性能提升12.57%，达到新SOTA。

Conclusion: 缺陷感知的多专家框架能有效提升LLMs的数学能力。

Abstract: Large Language Models (LLMs) excel in solving mathematical problems, yet
their performance is often limited by the availability of high-quality, diverse
training data. Existing methods focus on augmenting datasets through rephrasing
or difficulty progression but overlook the specific failure modes of LLMs. This
results in synthetic questions that the model can already solve, providing
minimal performance gains. To address this, we propose WarriorMath, a
defect-aware framework for mathematical problem solving that integrates both
targeted data synthesis and progressive training. In the synthesis stage, we
employ multiple expert LLMs in a collaborative process to generate, critique,
and refine problems. Questions that base LLMs fail to solve are identified and
iteratively improved through expert-level feedback, producing high-quality,
defect-aware training data. In the training stage, we introduce a progressive
learning framework that iteratively fine-tunes the model using increasingly
challenging data tailored to its weaknesses. Experiments on six mathematical
benchmarks show that WarriorMath outperforms strong baselines by 12.57% on
average, setting a new state-of-the-art. Our results demonstrate the
effectiveness of a defect-aware, multi-expert framework for improving
mathematical ability.

</details>


### [13] [Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025](https://arxiv.org/abs/2508.01263)
*Long S. T. Nguyen,Khang H. N. Vo,Thu H. A. Nguyen,Tuan C. Bui,Duc Q. Nguyen,Thanh-Tung Tran,Anh D. Nguyen,Minh L. Nguyen,Fabien Baldacci,Thang H. Bui,Emanuel Di Nardo,Angelo Ciaramella,Son H. Le,Ihsan Ullah,Lorenzo Di Rocco,Tho T. Quan*

Main category: cs.CL

TL;DR: 论文分析了2025年XAI挑战赛，探讨了在教育中结合轻量级LLM和符号推理以实现可解释AI的方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI在教育中的普及，透明性和可解释性需求增加，但现有hackathon很少直接解决教育场景中的XAI问题。

Method: 通过hackathon形式，要求参与者构建基于轻量级LLM或混合系统的问答系统，生成逻辑清晰的解释。

Result: 挑战赛提供了高质量数据集和评估协议，展示了LLM与符号推理结合在XAI中的潜力。

Conclusion: 该研究为未来教育中的XAI系统和竞赛提供了实用见解，推动了可解释AI的发展。

Abstract: The growing integration of Artificial Intelligence (AI) into education has
intensified the need for transparency and interpretability. While hackathons
have long served as agile environments for rapid AI prototyping, few have
directly addressed eXplainable AI (XAI) in real-world educational contexts.
This paper presents a comprehensive analysis of the XAI Challenge 2025, a
hackathon-style competition jointly organized by Ho Chi Minh City University of
Technology (HCMUT) and the International Workshop on Trustworthiness and
Reliability in Neurosymbolic AI (TRNS-AI), held as part of the International
Joint Conference on Neural Networks (IJCNN 2025). The challenge tasked
participants with building Question-Answering (QA) systems capable of answering
student queries about university policies while generating clear, logic-based
natural language explanations. To promote transparency and trustworthiness,
solutions were required to use lightweight Large Language Models (LLMs) or
hybrid LLM-symbolic systems. A high-quality dataset was provided, constructed
via logic-based templates with Z3 validation and refined through expert student
review to ensure alignment with real-world academic scenarios. We describe the
challenge's motivation, structure, dataset construction, and evaluation
protocol. Situating the competition within the broader evolution of AI
hackathons, we argue that it represents a novel effort to bridge LLMs and
symbolic reasoning in service of explainability. Our findings offer actionable
insights for future XAI-centered educational systems and competitive research
initiatives.

</details>


### [14] [Prompting Large Language Models with Partial Knowledge for Answering Questions with Unseen Entities](https://arxiv.org/abs/2508.01290)
*Zhichao Yan,Jiapu Wang,Jiaoyan Chen,Yanyan Wang,Hongye Tan,Jiye Liang,Xiaoli Li,Ru Li,Jeff Z. Pan*

Main category: cs.CL

TL;DR: 论文提出了一种新视角：通过部分相关知识唤醒LLMs的能力，解决了RAG系统中部分相关知识利用的挑战，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统中部分相关知识利用的难题，尤其是在知识库不完整的情况下。

Method: 通过构建部分相关知识（移除包含答案的路径），并理论分析和实验验证LLMs的唤醒效应。

Result: 在知识图谱问答数据集上验证了方法的有效性，并在新任务Unseen Entity KGQA中表现优于传统方法。

Conclusion: 部分相关知识可以唤醒LLMs的能力，为实际应用提供了更有效的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) shows impressive performance by
supplementing and substituting parametric knowledge in Large Language Models
(LLMs). Retrieved knowledge can be divided into three types: explicit answer
evidence, implicit answer clue, and insufficient answer context which can be
further categorized into totally irrelevant and partially relevant information.
Effectively utilizing partially relevant knowledge remains a key challenge for
RAG systems, especially in incomplete knowledge base retrieval. Contrary to the
conventional view, we propose a new perspective: LLMs can be awakened via
partially relevant knowledge already embedded in LLMs. To comprehensively
investigate this phenomenon, the triplets located in the gold reasoning path
and their variants are used to construct partially relevant knowledge by
removing the path that contains the answer. We provide theoretical analysis of
the awakening effect in LLMs and support our hypothesis with experiments on two
Knowledge Graphs (KGs) Question Answering (QA) datasets. Furthermore, we
present a new task, Unseen Entity KGQA, simulating real-world challenges where
entity linking fails due to KG incompleteness. Our awakening-based approach
demonstrates greater efficacy in practical applications, outperforms
traditional methods that rely on embedding-based similarity which are prone to
returning noisy information.

</details>


### [15] [KEDAS: Knowledge Editing Alignment with Diverse Augmentation and Self-adaptive Inference](https://arxiv.org/abs/2508.01302)
*Chenming Tang,Yutong Yang,Yunfang Wu*

Main category: cs.CL

TL;DR: KEDAS提出了一种知识编辑对齐方法，通过多样增强和自适应推理提升大型语言模型的知识编辑能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有知识编辑方法在参数编辑和检索式方法上的不足，提升模型对编辑知识的应用能力。

Method: 采用低秩适应学习上下文编辑知识，设计多样编辑增强技术和自适应推理机制。

Result: 在36个案例中的35个表现最佳，编辑成功率和通用任务性能均显著提升。

Conclusion: KEDAS是一种高效、鲁棒的知识编辑对齐范式。

Abstract: Knowledge editing aims to modify outdated knowledge in large language models
(LLMs) efficiently while retaining their powerful capabilities. Most existing
methods rely on either parameter-level editing or retrieval-based approaches.
In this work, we propose Knowledge Editing alignment with Diverse Augmentation
and Self-adaptive inference (KEDAS) to better align LLMs with knowledge
editing. In the alignment phase, LLMs learn to apply in-context edited
knowledge via low-rank adaptation. During editing, we design a diverse edit
augmentation technique to improve the recall of edits. After that, a
self-adaptive post-alignment inference mechanism is proposed, in which a
filter-based smart retriever is employed to perform a dynamic selection of
inference routing. Specifically, irrelevant queries will go through the
original pre-alignment model directly, while relevant ones, together with their
related edits, go through the model with aligned adapters activated. In
experiments, KEDAS secures the highest overall performance scores in 35 out of
36 cases across four datasets with three LLMs on three settings, surpassing its
strong knowledge editing alignment counterpart by about 19.8 harmonic mean
scores of edit success, locality and portability and outperforming both
parameter editing and retrieval-based baselines significantly. Analysis of
computational cost and performance on general tasks further validates the
robustness and efficiency of KEDAS, indicating that it presents an ideal
paradigm of knowledge editing alignment.

</details>


### [16] [D-SCoRE: Document-Centric Segmentation and CoT Reasoning with Structured Export for QA-CoT Data Generation](https://arxiv.org/abs/2508.01309)
*Weibo Zhou,Lingbo Li,Shangsong Liang*

Main category: cs.CL

TL;DR: D-SCoRE是一种无需训练的流程，利用LLM和提示工程从任意文本生成高质量QA数据集，支持领域特定LLM的监督微调。


<details>
  <summary>Details</summary>
Motivation: 解决高质量QA数据集稀缺且成本高的问题，支持领域特定LLM的监督微调。

Method: 结合文档处理、分段、CoT推理和结构化导出，生成QA-CoT数据集，并通过多维控制机制增强多样性和相关性。

Result: 在SQuADShifts和Covid-QA测试集上，D-SCoRE生成的QA数据集表现优于人工标注数据集。

Conclusion: D-SCoRE简单、可扩展，能高效生成QA数据并支持跨领域高性能微调。

Abstract: The scarcity and high cost of high-quality question-answering (QA) datasets
hinder supervised fine-tuning (SFT) for domain-specific large language models
(LLMs). To address this, we introduce D-SCoRE, a training-free pipeline that
utilizes LLMs and prompt engineering to produce diverse, high-quality QA
datasets from arbitrary textual sources. D-SCoRE integrates
$\textbf{D}$ocument-centric processing, $\textbf{S}$egmentation, $\textbf{Co}$T
$\textbf{R}$easoning, and structured $\textbf{E}$xport to generate QA-COT
datasets tailored for domain-aware SFT. Multi-dimensional control mechanisms,
such as semantic role transformation, question type balancing, and
counterfactual materials, enhance diversity and relevance, overcoming
limitations of existing QA generation. LLMs fine-tuned on D-SCoRE-generated QA
datasets, and human-annotated QA datasets (SQuAD, Covid-QA) are evaluated on
SQuADShifts and Covid-QA test sets, with D-SCoRE outperforming across most
domains. D-SCoRE generates six QA-CoT pairs with four-option counterfactual
materials per 100-200-word text in 90 seconds using an 8B LLM on consumer-grade
hardware. Its simplicity and scalability enable efficient QA generation and
high-performance fine-tuning across domains.

</details>


### [17] [LinkQA: Synthesizing Diverse QA from Multiple Seeds Strongly Linked by Knowledge Points](https://arxiv.org/abs/2508.01317)
*Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: LinkSyn是一种基于知识图谱的合成框架，用于生成高质量、多样化的训练数据，提升大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型训练数据稀缺且多样性不足的问题。

Method: 通过知识图谱构建、路径采样概率调整和扩散合成技术，生成多学科、多难度的QA数据。

Result: 合成的LinkQA数据集（50B tokens）显著提升了Llama-3 8B在MMLU和CMMLU上的性能（平均提升11.51%）。

Conclusion: LinkSyn和LinkQA为提升大语言模型性能提供了有效的数据增强方法。

Abstract: The advancement of large language models (LLMs) struggles with the scarcity
of high-quality, diverse training data. To address this limitation, we propose
LinkSyn, a novel knowledge point (KP) graph-based synthesis framework that
enables flexible control over discipline and difficulty distributions while
balancing KP coverage and popularity. LinkSyn extracts KPs from
question-answering (QA) seed data and constructs a KP graph to synthesize
diverse QA data from multiple seeds strongly linked by KPs and sampled from
graph walks. Specifically, LinkSyn incorporates (1) a knowledge distribution
value function to guide the adjustment of path sampling probability and balance
KP coverage and popularity during graph walks; (2) diffusion-based synthesis
via DeepSeek-R1 by leveraging multiple seeds with dense logical associations
along each path; and (3) high-difficulty QA enhancement within given
disciplines by flexible difficulty adjustments. By executing LinkSyn, we
synthesize LinkQA, a diverse multi-disciplinary QA dataset with 50B tokens.
Extensive experiments on Llama-3 8B demonstrate that continual pre-training
with LinkQA yields an average improvement of $\mathbf{11.51\%}$ on MMLU and
CMMLU, establishing new SOTA results. LinkQA consistently enhances performance
across model size and initial FLOPs scales.

</details>


### [18] [Large-Scale Diverse Synthesis for Mid-Training](https://arxiv.org/abs/2508.01326)
*Xuemiao Zhang,Chengying Tu,Can Ren,Rongxiang Weng,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: 提出了一种名为BoostQA的新型多样化QA数据集合成方法，解决了传统数据集的局限性和模型在STEM领域及高难度数据上的不足，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 高质量、知识密集的训练数据稀缺，传统语料库信息有限，且现有QA数据在可扩展性和知识多样性方面存在挑战，尤其是在跨领域和高难度数据上。

Method: 通过多源种子数据收集、STEM多级合成和高难度合成框架，结合DeepSeek模型优化答案质量，构建了100B-token的BoostQA数据集，并用于中训练阶段。

Result: Llama-3 8B模型在40B-token数据集上中训练后，MMLU和CMMLU平均提升12.74%，并在12个基准测试中达到SOTA性能。

Conclusion: BoostQA方法显著提升了模型性能，并展示了良好的可扩展性，适用于不同规模和计算资源的模型。

Abstract: The scarcity of high-quality, knowledge-intensive training data hinders the
development of large language models (LLMs), as traditional corpora provide
limited information. Previous studies have synthesized and integrated
corpora-dependent question-answering (QA) data to improve model performance but
face challenges in QA data scalability and knowledge diversity, particularly in
cross-domain contexts. Furthermore, leveraging our designed discipline and
difficulty annotation system, we probe model deficiencies in STEM disciplines
and high-difficulty data. To overcome these limitations, we propose a novel
diversified pipeline to synthesize BoostQA, a 100B-token large-scale QA
dataset. Our synthesis framework: (1) curates seed data from heterogeneous
sources; (2) utilizes DeepSeek-R1 to implement STEM-focused multi-grade
synthesis to boost data diversity and high-difficulty synthesis to mitigate
difficulty degradation; (3) refines answers via DeepSeek-V3 to improve output
quality. We utilize BoostQA in mid-training, a mid-stage between pre-training
and post-training, to optimize domain-specific knowledge acquisition and
enhance data quality. Our method enables Llama-3 8B, mid-trained on a 40B-token
dataset, to achieve an average improvement of $\mathbf{12.74\%}$ on MMLU and
CMMLU and establish SOTA average performance across 12 benchmarks. BoostQA also
demonstrates robust scalability, with performance consistently improving as
model size, data volume, and initial FLOPs scale.

</details>


### [19] [MaRGen: Multi-Agent LLM Approach for Self-Directed Market Research and Analysis](https://arxiv.org/abs/2508.01370)
*Roman Koshkin,Pengyu Dai,Nozomi Fujikawa,Masahito Togami,Marco Visentini-Scarzanella*

Main category: cs.CL

TL;DR: 提出了一种基于大型语言模型的自动化框架，用于端到端商业分析和市场报告生成，通过多代理协作和迭代改进机制提升报告质量。


<details>
  <summary>Details</summary>
Motivation: 旨在通过自动化框架降低市场分析成本，同时复制专业咨询师的分析方法，提供高效且经济的市场洞察。

Method: 系统采用研究者、审阅者、撰写者和检索者四种代理，通过多步骤流程（数据查询、分析、可视化、报告生成）和LLM评估系统优化报告质量。

Result: 实验显示，框架在7分钟内生成6页详细报告，成本约1美元，并通过自动审阅和顾问知识提升报告质量。

Conclusion: 该框架为自动化生成经济实惠的市场洞察提供了重要一步。

Abstract: We present an autonomous framework that leverages Large Language Models
(LLMs) to automate end-to-end business analysis and market report generation.
At its core, the system employs specialized agents - Researcher, Reviewer,
Writer, and Retriever - that collaborate to analyze data and produce
comprehensive reports. These agents learn from real professional consultants'
presentation materials at Amazon through in-context learning to replicate
professional analytical methodologies. The framework executes a multi-step
process: querying databases, analyzing data, generating insights, creating
visualizations, and composing market reports. We also introduce a novel
LLM-based evaluation system for assessing report quality, which shows alignment
with expert human evaluations. Building on these evaluations, we implement an
iterative improvement mechanism that optimizes report quality through automated
review cycles. Experimental results show that report quality can be improved by
both automated review cycles and consultants' unstructured knowledge. In
experimental validation, our framework generates detailed 6-page reports in 7
minutes at a cost of approximately \$1. Our work could be an important step to
automatically create affordable market insights.

</details>


### [20] [MedSynth: Realistic, Synthetic Medical Dialogue-Note Pairs](https://arxiv.org/abs/2508.01401)
*Ahmad Rezaie Mianroodi,Amirali Rezaie,Niko Grisel Todorov,Cyril Rakovski,Frank Rudzicz*

Main category: cs.CL

TL;DR: MedSynth是一个合成医疗对话和笔记数据集，旨在提升Dial-2-Note和Note-2-Dial任务性能，包含10,000多对对话-笔记数据，覆盖2000多种ICD-10代码。


<details>
  <summary>Details</summary>
Motivation: 减轻医生临床记录负担，减少职业倦怠，推动医疗文档自动化工具发展。

Method: 通过分析疾病分布，创建包含多样化对话-笔记对的合成数据集MedSynth。

Result: 数据集显著提升了模型在医疗笔记生成和对话生成任务中的表现。

Conclusion: MedSynth为医疗领域提供了开源、隐私合规且多样化的训练数据资源。

Abstract: Physicians spend significant time documenting clinical encounters, a burden
that contributes to professional burnout. To address this, robust automation
tools for medical documentation are crucial. We introduce MedSynth -- a novel
dataset of synthetic medical dialogues and notes designed to advance the
Dialogue-to-Note (Dial-2-Note) and Note-to-Dialogue (Note-2-Dial) tasks.
Informed by an extensive analysis of disease distributions, this dataset
includes over 10,000 dialogue-note pairs covering over 2000 ICD-10 codes. We
demonstrate that our dataset markedly enhances the performance of models in
generating medical notes from dialogues, and dialogues from medical notes. The
dataset provides a valuable resource in a field where open-access,
privacy-compliant, and diverse training data are scarce. Code is available at
https://github.com/ahmadrezarm/MedSynth/tree/main and the dataset is available
at https://huggingface.co/datasets/Ahmad0067/MedSynth.

</details>


### [21] [ArzEn-MultiGenre: An aligned parallel dataset of Egyptian Arabic song lyrics, novels, and subtitles, with English translations](https://arxiv.org/abs/2508.01411)
*Rania Al-Sabbagh*

Main category: cs.CL

TL;DR: ArzEn-MultiGenre是一个埃及阿拉伯语与英语平行数据集，包含歌曲歌词、小说和电视剧字幕，可用于机器翻译模型评估、微调大语言模型及翻译研究。


<details>
  <summary>Details</summary>
Motivation: 填补现有埃及阿拉伯语和英语平行数据集中缺乏的文本类型，并为机器翻译、翻译研究和教学提供高质量资源。

Method: 数据集包含25,557个手动翻译和对齐的文本片段，涵盖多种文体。

Result: 数据集为机器翻译、跨语言分析和翻译教学提供了黄金标准资源。

Conclusion: ArzEn-MultiGenre填补了现有数据集的空白，并为多领域研究提供了高质量数据。

Abstract: ArzEn-MultiGenre is a parallel dataset of Egyptian Arabic song lyrics,
novels, and TV show subtitles that are manually translated and aligned with
their English counterparts. The dataset contains 25,557 segment pairs that can
be used to benchmark new machine translation models, fine-tune large language
models in few-shot settings, and adapt commercial machine translation
applications such as Google Translate. Additionally, the dataset is a valuable
resource for research in various disciplines, including translation studies,
cross-linguistic analysis, and lexical semantics. The dataset can also serve
pedagogical purposes by training translation students and aid professional
translators as a translation memory. The contributions are twofold: first, the
dataset features textual genres not found in existing parallel Egyptian Arabic
and English datasets, and second, it is a gold-standard dataset that has been
translated and aligned by human experts.

</details>


### [22] [Discovering Bias Associations through Open-Ended LLM Generations](https://arxiv.org/abs/2508.01412)
*Jinhao Pan,Chahat Raj,Ziwei Zhu*

Main category: cs.CL

TL;DR: BADF框架用于发现LLM中已知和未知的社会偏见关联，通过开放生成内容分析偏见。


<details>
  <summary>Details</summary>
Motivation: 现有偏见评估方法依赖预定义关联，无法捕捉新偏见形式，BADF旨在填补这一空白。

Method: BADF系统性地从LLM开放生成内容中提取身份与概念的关联，支持多模型和多样化场景实验。

Result: BADF能全面映射和分析偏见关联，为LLM偏见研究提供新工具和数据支持。

Conclusion: BADF提升了开放生成中偏见的理解，并为识别和分析偏见提供了可扩展工具。

Abstract: Social biases embedded in Large Language Models (LLMs) raise critical
concerns, resulting in representational harms -- unfair or distorted portrayals
of demographic groups -- that may be expressed in subtle ways through generated
language. Existing evaluation methods often depend on predefined
identity-concept associations, limiting their ability to surface new or
unexpected forms of bias. In this work, we present the Bias Association
Discovery Framework (BADF), a systematic approach for extracting both known and
previously unrecognized associations between demographic identities and
descriptive concepts from open-ended LLM outputs. Through comprehensive
experiments spanning multiple models and diverse real-world contexts, BADF
enables robust mapping and analysis of the varied concepts that characterize
demographic identities. Our findings advance the understanding of biases in
open-ended generation and provide a scalable tool for identifying and analyzing
bias associations in LLMs. Data, code, and results are available at
https://github.com/JP-25/Discover-Open-Ended-Generation

</details>


### [23] [From Query to Logic: Ontology-Driven Multi-Hop Reasoning in LLMs](https://arxiv.org/abs/2508.01424)
*Haonan Bian,Yutao Qi,Rui Yang,Yuanxi Che,Jiaqian Wang,Heming Xia,Ranran Zhen*

Main category: cs.CL

TL;DR: ORACLE框架结合LLMs与知识图谱，通过动态构建知识本体、转化为逻辑推理链和分解问题，提升多跳问答性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在复杂多跳问答任务中表现不足，因无法捕捉实体间深层关系。

Method: ORACLE分三阶段：动态构建问题知识本体、转化为一阶逻辑推理链、分解原问题为子问题。

Result: 在多个MQA基准测试中表现优异，媲美DeepSeek-R1，推理链更逻辑且可解释。

Conclusion: ORACLE有效提升LLMs在多跳问答中的性能，生成更合理的推理链。

Abstract: Large Language Models (LLMs), despite their success in question answering,
exhibit limitations in complex multi-hop question answering (MQA) tasks that
necessitate non-linear, structured reasoning. This limitation stems from their
inability to adequately capture deep conceptual relationships between entities.
To overcome this challenge, we present **ORACLE** (**O**ntology-driven
**R**easoning **A**nd **C**hain for **L**ogical **E**ucidation), a
training-free framework that combines LLMs' generative capabilities with the
structural benefits of knowledge graphs. Our approach operates through three
stages: (1) dynamic construction of question-specific knowledge ontologies
using LLMs, (2) transformation of these ontologies into First-Order Logic
reasoning chains, and (3) systematic decomposition of the original query into
logically coherent sub-questions. Experimental results on several standard MQA
benchmarks show that our framework achieves highly competitive performance,
rivaling current state-of-the-art models like DeepSeek-R1. Detailed analyses
further confirm the effectiveness of each component, while demonstrating that
our method generates more logical and interpretable reasoning chains than
existing approaches.

</details>


### [24] [Towards Efficient Medical Reasoning with Minimal Fine-Tuning Data](https://arxiv.org/abs/2508.01450)
*Xinlin Zhuang,Feilong Tang,Haolin Yang,Ming Hu,Huifa Li,Haochen Xue,Yichen Li,Junjun He,Zongyuan Ge,Ying Qian,Imran Razzak*

Main category: cs.CL

TL;DR: 论文提出了一种名为DIQ的数据选择策略，通过结合样本难度和梯度影响，优化医学推理任务的微调效果。


<details>
  <summary>Details</summary>
Motivation: 现有监督微调（SFT）方法依赖未过滤数据集，导致计算成本高且性能不佳。传统方法仅基于样本难度或梯度影响选择数据，未能平衡复杂推理与优化效果。

Method: 提出Difficulty-Influence Quadrant（DIQ）策略，优先选择高难度高梯度影响的样本，以平衡临床推理和优化效果。

Result: 实验表明，DIQ仅需1%数据即可匹配全数据集性能，10%数据时优于基线。人类和LLM评估显示其生成结果更符合专家实践。

Conclusion: DIQ通过有原则的数据选择，显著提升了医学推理任务的效率和性能，优于传统方法。

Abstract: Supervised Fine-Tuning (SFT) plays a pivotal role in adapting Large Language
Models (LLMs) to specialized domains such as medical reasoning. However,
existing SFT practices often rely on unfiltered datasets that contain redundant
and low-quality samples, leading to substantial computational costs and
suboptimal performance. Although existing methods attempt to alleviate this
problem by selecting data based on sample difficulty, defined by knowledge and
reasoning complexity, they overlook each sample's optimization utility
reflected in its gradient. Interestingly, we find that gradient-based influence
alone favors easy-to-optimize samples that cause large parameter shifts but
lack deep reasoning chains, while difficulty alone selects noisy or overly
complex cases that fail to guide stable optimization. Based on this
observation, we propose a data selection strategy, Difficulty-Influence
Quadrant (DIQ), which prioritizes samples in the high-difficulty-high-influence
quadrant to balance complex clinical reasoning with substantial gradient
influence, enabling efficient medical reasoning with minimal fine-tuning data.
Furthermore, Human and LLM-as-a-judge evaluations show that DIQ-selected
subsets demonstrate higher data quality and generate clinical reasoning that is
more aligned with expert practices in differential diagnosis, safety check, and
evidence citation, as DIQ emphasizes samples that foster expert-like reasoning
patterns. Extensive experiments on medical reasoning benchmarks demonstrate
that DIQ enables models fine-tuned on only 1% of selected data to match
full-dataset performance, while using 10% consistently outperforms the
baseline, highlighting the superiority of principled data selection over
brute-force scaling. The code and data are available at
https://github.com/mihara-bot/DIQ.

</details>


### [25] [TreeDiff: AST-Guided Code Generation with Diffusion LLMs](https://arxiv.org/abs/2508.01473)
*Yiming Zeng,Jinghan Cao,Zexin Li,Yiming Chen,Tao Ren,Dawei Xiang,Xidong Wu,Shangqian Gao,Tingting Yu*

Main category: cs.CL

TL;DR: 提出了一种基于语法感知的扩散框架，通过结合抽象语法树（AST）的结构先验，改进代码生成任务中的扩散模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型在结构化领域（如源代码）中的应用面临挑战，因为编程语言具有严格的语法和语义规则，标准标记级噪声处理可能忽略这些结构。

Method: 提出语法感知扩散框架，通过选择性破坏AST子树中的语法有意义代码片段，而非随机标记，以尊重语法边界并捕捉长程依赖。

Result: 实验表明，语法感知噪声处理显著提高了语法正确性、重构准确性和对未见代码模式的泛化能力。

Conclusion: 结合结构信息的扩散训练具有潜力，语法引导的去噪是改进代码生成任务中扩散模型的有前景方向。

Abstract: Recent advances in diffusion-based language models have opened new
possibilities for controllable and bidirectional sequence generation. These
models provide an alternative to traditional autoregressive approaches by
framing text generation as an iterative denoising process. However, applying
diffusion models to structured domains such as source code remains a
significant challenge. Programming languages differ from natural language in
that they follow strict syntactic and semantic rules, with hierarchical
organization that must be preserved for correctness. Standard token-level
corruption techniques used during training often ignore this structure, which
may hinder the model's ability to learn meaningful representations of code. To
address this limitation, we propose a syntax-aware diffusion framework that
incorporates structural priors from Abstract Syntax Trees (ASTs) into the
denoising process. Instead of masking individual tokens at random, we
selectively corrupt syntactically meaningful code spans derived from AST
subtrees. This enables the model to reconstruct programs in a way that respects
grammatical boundaries and captures long-range dependencies. Experimental
results demonstrate that syntax-aware corruption significantly improves
syntactic correctness, reconstruction accuracy, and generalization to unseen
code patterns. These findings highlight the potential of incorporating
structural information into diffusion-based training and suggest that
syntax-guided denoising is a promising direction for advancing diffusion-based
language models in code generation tasks.

</details>


### [26] [Harnessing Collective Intelligence of LLMs for Robust Biomedical QA: A Multi-Model Approach](https://arxiv.org/abs/2508.01480)
*Dimitra Panou,Alexandros C. Dimopoulos,Manolis Koubarakis,Martin Reczko*

Main category: cs.CL

TL;DR: 论文介绍了在BioASQ挑战中使用开源大语言模型（LLMs）进行生物医学问答的方法，通过多数投票和答案联合策略优化结果，并在2025年挑战中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 生物医学文本挖掘和问答任务需求高，但文献增长迅速，需要高效方法。

Method: 使用开源LLMs作为检索增强生成器，结合多数投票和答案联合策略处理不同类型问题。

Result: 在BioASQ挑战中取得多项优异成绩，包括理想答案第一名和精确答案第二名。

Conclusion: 研究为特定问题类型的最优LLM组合提供了实用见解。

Abstract: Biomedical text mining and question-answering are essential yet highly
demanding tasks, particularly in the face of the exponential growth of
biomedical literature. In this work, we present our participation in the 13th
edition of the BioASQ challenge, which involves biomedical semantic
question-answering for Task 13b and biomedical question-answering for
developing topics for the Synergy task. We deploy a selection of open-source
large language models (LLMs) as retrieval-augmented generators to answer
biomedical questions. Various models are used to process the questions. A
majority voting system combines their output to determine the final answer for
Yes/No questions, while for list and factoid type questions, the union of their
answers in used. We evaluated 13 state-of-the-art open source LLMs, exploring
all possible model combinations to contribute to the final answer, resulting in
tailored LLM pipelines for each question type. Our findings provide valuable
insight into which combinations of LLMs consistently produce superior results
for specific question types. In the four rounds of the 2025 BioASQ challenge,
our system achieved notable results: in the Synergy task, we secured 1st place
for ideal answers and 2nd place for exact answers in round 2, as well as two
shared 1st places for exact answers in round 3 and 4.

</details>


### [27] [TeSent: A Benchmark Dataset for Fairness-aware Explainable Sentiment Classification in Telugu](https://arxiv.org/abs/2508.01486)
*Vallabhaneni Raj Kumar,Ashwin S,Supriya Manna,Niladri Sett,Cheedella V S N M S Hema Harshitha,Kurakula Harshitha,Anand Kumar Sharma,Basina Deepakraj,Tanuj Sarkar,Bondada Navaneeth Krishna,Samanthapudi Shakeer*

Main category: cs.CL

TL;DR: 论文介绍了TeSent，一个用于泰卢固语情感分类的基准数据集，并探讨了其可解释性和公平性。


<details>
  <summary>Details</summary>
Motivation: 泰卢固语在NLP领域资源匮乏，缺乏高质量标注数据，TeSent旨在填补这一空白。

Method: 通过爬取多领域文本，构建26,150句数据集，开发标注平台和协议，并微调预训练模型。

Result: 实验表明，使用标注理由训练模型可提高准确性、减少偏见，并使解释更符合人类推理。

Conclusion: TeSent为泰卢固语NLP任务提供了资源，并展示了可解释性和公平性的重要性。

Abstract: In the Indian subcontinent, Telugu, one of India's six classical languages,
is the most widely spoken Dravidian Language. Despite its 96 million speaker
base worldwide, Telugu remains underrepresented in the global NLP and Machine
Learning landscape, mainly due to lack of high-quality annotated resources.
This work introduces TeSent, a comprehensive benchmark dataset for sentiment
classification, a key text classification problem, in Telugu. TeSent not only
provides ground truth labels for the sentences, but also supplements with
provisions for evaluating explainability and fairness, two critical
requirements in modern-day machine learning tasks. We scraped Telugu texts
covering multiple domains from various social media platforms, news websites
and web-blogs to preprocess and generate 26,150 sentences, and developed a
custom-built annotation platform and a carefully crafted annotation protocol
for collecting the ground truth labels along with their human-annotated
rationales. We then fine-tuned several SOTA pre-trained models in two ways:
with rationales, and without rationales. Further, we provide a detailed
plausibility and faithfulness evaluation suite, which exploits the rationales,
for six widely used post-hoc explainers applied on the trained models. Lastly,
we curate TeEEC, Equity Evaluation Corpus in Telugu, a corpus to evaluate
fairness of Telugu sentiment and emotion related NLP tasks, and provide a
fairness evaluation suite for the trained classifier models. Our experimental
results suggest that training with rationales may improve model accuracy,
reduce bias in models, and make the explainers' output more aligned to human
reasoning.

</details>


### [28] [The Homogenizing Effect of Large Language Models on Human Expression and Thought](https://arxiv.org/abs/2508.01491)
*Zhivar Sourati,Alireza S. Ziabari,Morteza Dehghani*

Main category: cs.CL

TL;DR: LLMs可能标准化语言和推理，导致认知多样性减少，影响集体智慧和创造力。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs如何反映和强化主流语言和推理模式，同时边缘化其他声音和策略。

Method: 综合语言学、认知科学和计算机科学的证据，分析LLMs的设计和广泛使用。

Result: LLMs通过训练数据和广泛使用加剧语言和推理的趋同，可能导致认知同质化。

Conclusion: 需警惕LLMs对认知多样性的潜在负面影响，以保护集体智慧和适应能力。

Abstract: Cognitive diversity, reflected in variations of language, perspective, and
reasoning, is essential to creativity and collective intelligence. This
diversity is rich and grounded in culture, history, and individual experience.
Yet as large language models (LLMs) become deeply embedded in people's lives,
they risk standardizing language and reasoning. This Review synthesizes
evidence across linguistics, cognitive, and computer science to show how LLMs
reflect and reinforce dominant styles while marginalizing alternative voices
and reasoning strategies. We examine how their design and widespread use
contribute to this effect by mirroring patterns in their training data and
amplifying convergence as all people increasingly rely on the same models
across contexts. Unchecked, this homogenization risks flattening the cognitive
landscapes that drive collective intelligence and adaptability.

</details>


### [29] [A Theory of Adaptive Scaffolding for LLM-Based Pedagogical Agents](https://arxiv.org/abs/2508.01503)
*Clayton Cohn,Surya Rayala,Namrata Srivastava,Joyce Horn Fonteles,Shruti Jain,Xinying Luo,Divya Mereddy,Naveeduddin Mohammed,Gautam Biswas*

Main category: cs.CL

TL;DR: 论文提出了一种结合证据中心设计与社会认知理论的框架，用于基于LLM的教育代理，以支持STEM+C学习。


<details>
  <summary>Details</summary>
Motivation: 当前LLM系统（如ChatGPT）在教育中的应用缺乏理论基础，需要结合学习理论提升其教学效果。

Method: 提出一个结合Evidence-Centered Design与Social Cognitive Theory的框架，并以Inquizzitor为例展示其应用。

Result: Inquizzitor能提供高质量的评估和互动，符合核心学习理论，受到师生认可。

Conclusion: 研究表明理论驱动的LLM在教育中具有潜力，能提供自适应和原则性的教学支持。

Abstract: Large language models (LLMs) present new opportunities for creating
pedagogical agents that engage in meaningful dialogue to support student
learning. However, the current use of LLM systems like ChatGPT in classrooms
often lacks the solid theoretical foundation found in earlier intelligent
tutoring systems. To bridge this gap, we propose a framework that combines
Evidence-Centered Design with Social Cognitive Theory for adaptive scaffolding
in LLM-based agents focused on STEM+C learning. We illustrate this framework
with Inquizzitor, an LLM-based formative assessment agent that integrates
human-AI hybrid intelligence and provides feedback grounded in cognitive
science principles. Our findings show that Inquizzitor delivers high-quality
assessment and interaction aligned with core learning theories, offering
teachers effective guidance that students value. This research underscores the
potential for theory-driven LLM integration in education, highlighting the
ability of these systems to provide adaptive and principled instruction.

</details>


### [30] [MOPrompt: Multi-objective Semantic Evolution for Prompt Optimization](https://arxiv.org/abs/2508.01541)
*Sara Câmara,Eduardo Luz,Valéria Carvalho,Ivan Meneghini,Gladston Moreira*

Main category: cs.CL

TL;DR: MOPrompt是一种多目标进化优化框架，用于同时优化提示的准确性和上下文大小，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 手动设计提示复杂且耗时，现有自动方法多关注单一目标（如性能），忽略了效率与效果的权衡。

Method: 提出MOPrompt框架，通过多目标进化优化映射Pareto前沿，平衡上下文大小与性能。

Result: 在葡萄牙语情感分析任务中，MOPrompt在保持峰值准确率（0.97）的同时，将标记长度减少31%。

Conclusion: MOPrompt为实际应用中LLM的部署提供了关键工具，展示了效率与性能的权衡。

Abstract: Prompt engineering is crucial for unlocking the potential of Large Language
Models (LLMs). Still, since manual prompt design is often complex,
non-intuitive, and time-consuming, automatic prompt optimization has emerged as
a research area. However, a significant challenge in prompt optimization is
managing the inherent trade-off between task performance, such as accuracy, and
context size. Most existing automated methods focus on a single objective,
typically performance, thereby failing to explore the critical spectrum of
efficiency and effectiveness. This paper introduces the MOPrompt, a novel
Multi-objective Evolutionary Optimization (EMO) framework designed to optimize
prompts for both accuracy and context size (measured in tokens) simultaneously.
Our framework maps the Pareto front of prompt solutions, presenting
practitioners with a set of trade-offs between context size and performance, a
crucial tool for deploying Large Language Models (LLMs) in real-world
applications. We evaluate MOPrompt on a sentiment analysis task in Portuguese,
using Gemma-2B and Sabiazinho-3 as evaluation models. Our findings show that
MOPrompt substantially outperforms the baseline framework. For the Sabiazinho
model, MOPrompt identifies a prompt that achieves the same peak accuracy (0.97)
as the best baseline solution, but with a 31% reduction in token length.

</details>


### [31] [Are All Prompt Components Value-Neutral? Understanding the Heterogeneous Adversarial Robustness of Dissected Prompt in Large Language Models](https://arxiv.org/abs/2508.01554)
*Yujia Zheng,Tianhao Li,Haotian Huang,Tianyu Zeng,Jingyu Lu,Chuangxin Chu,Yuekai Huang,Ziyou Jiang,Qian Xiong,Yuyao Ge,Mingyang Li*

Main category: cs.CL

TL;DR: 论文提出PromptAnatomy框架，通过分解提示的功能组件并选择性扰动（ComPerturb）生成对抗样本，结合PPL过滤提升攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法忽视提示的结构异质性，导致评估不全面。

Method: 提出PromptAnatomy框架，分解提示为功能组件，使用ComPerturb选择性扰动，并引入PPL过滤。

Result: 在多个数据集和LLM上，ComPerturb达到最高攻击成功率。

Conclusion: 提示结构感知和可控扰动对LLM对抗鲁棒性评估至关重要。

Abstract: Prompt-based adversarial attacks have become an effective means to assess the
robustness of large language models (LLMs). However, existing approaches often
treat prompts as monolithic text, overlooking their structural
heterogeneity-different prompt components contribute unequally to adversarial
robustness. Prior works like PromptRobust assume prompts are value-neutral, but
our analysis reveals that complex, domain-specific prompts with rich structures
have components with differing vulnerabilities. To address this gap, we
introduce PromptAnatomy, an automated framework that dissects prompts into
functional components and generates diverse, interpretable adversarial examples
by selectively perturbing each component using our proposed method, ComPerturb.
To ensure linguistic plausibility and mitigate distribution shifts, we further
incorporate a perplexity (PPL)-based filtering mechanism. As a complementary
resource, we annotate four public instruction-tuning datasets using the
PromptAnatomy framework, verified through human review. Extensive experiments
across these datasets and five advanced LLMs demonstrate that ComPerturb
achieves state-of-the-art attack success rates. Ablation studies validate the
complementary benefits of prompt dissection and PPL filtering. Our results
underscore the importance of prompt structure awareness and controlled
perturbation for reliable adversarial robustness evaluation in LLMs. Code and
data are available at https://github.com/Yujiaaaaa/PACP.

</details>


### [32] [OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets](https://arxiv.org/abs/2508.01630)
*Maziyar Panahi*

Main category: cs.CL

TL;DR: OpenMed NER 是一种开源、领域适应的转换器模型，通过轻量级领域自适应预训练（DAPT）和参数高效的低秩适应（LoRA）技术，在生物医学命名实体识别（NER）任务中实现了高性能和计算效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学领域命名实体识别任务中，如何在保持计算效率的同时实现高性能的挑战。

Method: 结合轻量级领域自适应预训练（DAPT）和低秩适应（LoRA）技术，使用 DeBERTa-v3、PubMedBERT 和 BioELECTRA 作为基础模型，在 350k 条公开可用的研究文献和临床笔记上进行训练。

Result: 在 12 个生物医学 NER 基准测试中，OpenMed NER 在 10 个数据集上实现了新的最高性能（micro-F1 分数），特别是在疾病和化学实体识别上表现突出。

Conclusion: OpenMed NER 展示了开源模型在生物医学 NER 任务中的潜力，同时具备高效、低碳排放和合规性优势。

Abstract: Named-entity recognition (NER) is fundamental to extracting structured
information from the >80% of healthcare data that resides in unstructured
clinical notes and biomedical literature. Despite recent advances with large
language models, achieving state-of-the-art performance across diverse entity
types while maintaining computational efficiency remains a significant
challenge. We introduce OpenMed NER, a suite of open-source, domain-adapted
transformer models that combine lightweight domain-adaptive pre-training (DAPT)
with parameter-efficient Low-Rank Adaptation (LoRA). Our approach performs
cost-effective DAPT on a 350k-passage corpus compiled from ethically sourced,
publicly available research repositories and de-identified clinical notes
(PubMed, arXiv, and MIMIC-III) using DeBERTa-v3, PubMedBERT, and BioELECTRA
backbones. This is followed by task-specific fine-tuning with LoRA, which
updates less than 1.5% of model parameters. We evaluate our models on 12
established biomedical NER benchmarks spanning chemicals, diseases, genes, and
species. OpenMed NER achieves new state-of-the-art micro-F1 scores on 10 of
these 12 datasets, with substantial gains across diverse entity types. Our
models advance the state-of-the-art on foundational disease and chemical
benchmarks (e.g., BC5CDR-Disease, +2.70 pp), while delivering even larger
improvements of over 5.3 and 9.7 percentage points on more specialized gene and
clinical cell line corpora. This work demonstrates that strategically adapted
open-source models can surpass closed-source solutions. This performance is
achieved with remarkable efficiency: training completes in under 12 hours on a
single GPU with a low carbon footprint (< 1.2 kg CO2e), producing permissively
licensed, open-source checkpoints designed to help practitioners facilitate
compliance with emerging data protection and AI regulations, such as the EU AI
Act.

</details>


### [33] [Authorship Attribution in Multilingual Machine-Generated Texts](https://arxiv.org/abs/2508.01656)
*Lucio La Cava,Dominik Macko,Róbert Móro,Ivan Srba,Andrea Tagarelli*

Main category: cs.CL

TL;DR: 论文探讨了多语言作者归属问题，研究了如何将文本归属到人类或多种LLM生成器，并分析了单语言方法在多语言环境中的适用性和局限性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM生成文本与人类写作越来越难以区分，传统的二元分类方法已不足，需要更细粒度的作者归属方法。当前研究局限于单语言（主要是英语），忽视了LLM的多语言特性。

Method: 研究覆盖18种语言和8种生成器（7种LLM和人类），评估单语言AA方法在多语言环境中的适用性、跨语言迁移能力及生成器对归属性能的影响。

Result: 研究发现某些单语言AA方法可适应多语言环境，但在跨语言家族迁移时存在显著局限，凸显了多语言AA的复杂性。

Conclusion: 多语言作者归属面临重大挑战，需开发更鲁棒的方法以适应现实场景。

Abstract: As Large Language Models (LLMs) have reached human-like fluency and
coherence, distinguishing machine-generated text (MGT) from human-written
content becomes increasingly difficult. While early efforts in MGT detection
have focused on binary classification, the growing landscape and diversity of
LLMs require a more fine-grained yet challenging authorship attribution (AA),
i.e., being able to identify the precise generator (LLM or human) behind a
text. However, AA remains nowadays confined to a monolingual setting, with
English being the most investigated one, overlooking the multilingual nature
and usage of modern LLMs. In this work, we introduce the problem of
Multilingual Authorship Attribution, which involves attributing texts to human
or multiple LLM generators across diverse languages. Focusing on 18 languages
-- covering multiple families and writing scripts -- and 8 generators (7 LLMs
and the human-authored class), we investigate the multilingual suitability of
monolingual AA methods, their cross-lingual transferability, and the impact of
generators on attribution performance. Our results reveal that while certain
monolingual AA methods can be adapted to multilingual settings, significant
limitations and challenges remain, particularly in transferring across diverse
language families, underscoring the complexity of multilingual AA and the need
for more robust approaches to better match real-world scenarios.

</details>


### [34] [CUPID: Evaluating Personalized and Contextualized Alignment of LLMs from Interactions](https://arxiv.org/abs/2508.01674)
*Tae Soo Kim,Yoonjoo Lee,Yoonah Park,Jiho Kim,Young-Ho Kim,Juho Kim*

Main category: cs.CL

TL;DR: CUPID是一个评估LLMs是否能从多轮交互中推断用户动态偏好的基准测试，结果显示当前先进模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 人类偏好是动态且上下文相关的，而现有LLMs假设偏好是静态的，需要改进以实现个性化交互。

Method: 引入CUPID基准，包含756个人工标注的交互会话历史，评估LLMs在新请求中推断和应用偏好的能力。

Result: 评估10个LLMs，发现其推断偏好和识别相关上下文的能力不足（精确度<50%，召回率<65%）。

Conclusion: LLMs需提升上下文个性化能力，CUPID可作为推动改进的资源。

Abstract: Personalization of Large Language Models (LLMs) often assumes users hold
static preferences that reflect globally in all tasks. In reality, humans hold
dynamic preferences that change depending on the context. As users interact
with an LLM in various contexts, they naturally reveal their contextual
preferences, which a model must infer and apply in future contexts to ensure
alignment. To assess this, we introduce CUPID, a benchmark of 756 human-curated
interaction session histories between users and LLM-based chat assistants. In
each interaction session, the user provides a request in a specific context and
expresses their preference through multi-turn feedback. Given a new user
request and prior interaction sessions, our benchmark assesses whether LLMs can
infer the preference relevant to this request and generate a response that
satisfies this preference. With CUPID, we evaluated 10 open and proprietary
LLMs, revealing that state-of-the-art LLMs struggle to infer preferences from
multi-turn interactions and fail to discern what previous context is relevant
to a new request -- under 50% precision and 65% recall. Our work highlights the
need to advance LLM capabilities for more contextually personalized
interactions and proposes CUPID as a resource to drive these improvements.

</details>


### [35] [The Bidirectional Process Reward Model](https://arxiv.org/abs/2508.01682)
*Lingyin Zhang,Jun Gao,Xiaoxue Ren,Ziqiang Cao*

Main category: cs.CL

TL;DR: 提出了一种双向评估范式BiPRM，通过结合从左到右和从右到左的评估流，提升过程奖励模型的推理质量。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型（PRMs）采用单向评估范式，无法利用全局上下文验证推理步骤的一致性。

Method: 提出BiPRM，通过反向推理轨迹实现双向评估，无需额外参数或延迟。

Result: 在两个数学推理基准测试中，BiPRM显著优于单向基线，最高提升31.9%。

Conclusion: BiPRM高效、兼容性强，为过程奖励建模提供了新方向。

Abstract: Process Reward Models (PRMs) have emerged as a promising approach to enhance
the reasoning quality of Large Language Models (LLMs) by assigning fine-grained
scores to intermediate reasoning steps within a solution trajectory. However,
existing PRMs predominantly adopt a unidirectional left-to-right (L2R)
evaluation paradigm, which limits their ability to leverage global context,
making it challenging to verify the consistency of earlier steps based on later
ones. In light of these challenges, we propose a novel bidirectional evaluation
paradigm, named Bidirectional Process Reward Model (BiPRM). BiPRM seamlessly
incorporates a parallel right-to-left (R2L) evaluation stream alongside the
conventional L2R flow, enabling later reasoning steps to help assess earlier
ones in real time. Notably, the built-in R2L evaluation is implemented solely
through prompt modifications that reverse the original reasoning trajectory,
without any additional parameters or inference latency introduced. This ensures
BiPRM remains both efficient and broadly compatible with existing PRM studies.
We conduct extensive experiments on two mathematical reasoning benchmarks using
samples generated by three different policy models. Our method, BiPRM, is
evaluated across three backbones and three distinct PRM objectives. Across all
settings, BiPRM consistently outperforms unidirectional baselines, achieving up
to a 31.9% improvement in stepwise reward evaluation. Generally, our results
highlight BiPRM's effectiveness, robustness, and general applicability,
offering a promising new direction for process-based reward modeling.

</details>


### [36] [Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge Synergy](https://arxiv.org/abs/2508.01696)
*Yi Jiang,Sendong Zhao,Jianbo Li,Haochun Wang,Lizhe Zhang,Yan Liu,Bin Qin*

Main category: cs.CL

TL;DR: 论文提出了一种名为Collaborative Chain-of-Agents（CoCoA）的框架，通过多智能体协同增强检索增强生成（RAG）中参数化知识与检索知识的融合，显著提升了开放领域和多跳问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法在生成过程中未能充分利用知识，参数化知识与检索知识之间的协同作用有限，甚至检索内容可能误导生成。

Method: 提出CoCoA-zero（多智能体RAG框架）和CoCoA（长链训练策略），通过条件知识归纳和推理增强知识融合。

Result: 实验表明，CoCoA-zero和CoCoA在开放领域和多跳问答任务中表现优异。

Conclusion: CoCoA框架有效提升了知识融合能力，为RAG方法提供了新的优化方向。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising framework for
enhancing the capabilities of Large Language Models (LLMs), especially in
knowledge-intensive tasks. Despite its advantages, current RAG methods often
struggle to *fully exploit knowledge during generation*. In particular, the
synergy between the model's internal parametric knowledge and external
retrieved knowledge remains limited. Retrieved contents may sometimes mislead
generation, while certain generated content can guide the model toward more
accurate outputs. In this work, we propose Collaborative Chain-of-Agents, a
framework designed to enhance explicitly synergy over both parametric and
retrieved knowledge. Specifically, we first introduce CoCoA-zero, a multi-agent
RAG framework that first performs conditional knowledge induction and then
reasons answers. Building on this, we develop CoCoA, a long-chain training
strategy that synthesizes extended multi-agent reasoning trajectories from
CoCoA-zero to fine-tune the LLM. This strategy enhances the model's capability
to explicitly integrate and jointly leverage parametric and retrieved
knowledge. Experiments results show that CoCoA-zero and CoCoA achieve superior
performance on open-domain and multi-hop QA tasks.

</details>


### [37] [Am I Blue or Is My Hobby Counting Teardrops? Expression Leakage in Large Language Models as a Symptom of Irrelevancy Disruption](https://arxiv.org/abs/2508.01708)
*Berkay Köprü,Mehrzad Mashal,Yigit Gurses,Akos Kadar,Maximilian Schmitt,Ditty Mathew,Felix Burkhardt,Florian Eyben,Björn W. Schuller*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLM）中的表达泄漏现象，即模型生成与输入上下文语义无关的情感化表达。通过构建数据集和自动评估流程，发现模型规模扩大能减少表达泄漏，但需在模型构建过程中专门处理，提示无法缓解。负向情感提示会导致更高的表达泄漏率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在自然语言处理（NLP）中表现出色，但容易引入无关信息。此前研究关注语义泄漏，本文提出表达泄漏现象，即模型生成与上下文无关的情感化表达，需进一步研究其影响和缓解方法。

Method: 构建了一个基准数据集，并提出自动生成数据集的方案。设计了一个与人类判断高度相关的自动评估流程，加速模型分析。实验分析了模型规模、提示方式对表达泄漏的影响。

Result: 模型规模扩大时，同一家族内的表达泄漏减少；表达泄漏无法通过提示缓解，需在模型构建过程中专门处理；负向情感提示比正向情感提示导致更高的表达泄漏率。

Conclusion: 表达泄漏是LLM中需专门处理的问题，模型规模扩大有助于缓解，但需在构建过程中优化。负向情感对生成的干扰更强，提示无法有效缓解表达泄漏。

Abstract: Large language models (LLMs) have advanced natural language processing (NLP)
skills such as through next-token prediction and self-attention, but their
ability to integrate broad context also makes them prone to incorporating
irrelevant information. Prior work has focused on semantic leakage, bias
introduced by semantically irrelevant context. In this paper, we introduce
expression leakage, a novel phenomenon where LLMs systematically generate
sentimentally charged expressions that are semantically unrelated to the input
context. To analyse the expression leakage, we collect a benchmark dataset
along with a scheme to automatically generate a dataset from free-form text
from common-crawl. In addition, we propose an automatic evaluation pipeline
that correlates well with human judgment, which accelerates the benchmarking by
decoupling from the need of annotation for each analysed model. Our experiments
show that, as the model scales in the parameter space, the expression leakage
reduces within the same LLM family. On the other hand, we demonstrate that
expression leakage mitigation requires specific care during the model building
process, and cannot be mitigated by prompting. In addition, our experiments
indicate that, when negative sentiment is injected in the prompt, it disrupts
the generation process more than the positive sentiment, causing a higher
expression leakage rate.

</details>


### [38] [CultureGuard: Towards Culturally-Aware Dataset and Guard Model for Multilingual Safety Applications](https://arxiv.org/abs/2508.01710)
*Raviraj Joshi,Rakesh Paul,Kanishk Singla,Anusha Kamath,Michael Evans,Katherine Luna,Shaona Ghosh,Utkarsh Vaidya,Eileen Long,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: CultureGuard提出了一种多语言文化对齐的安全数据集生成方法，通过合成数据生成和过滤流程，扩展了英语安全数据集到8种语言，并训练了一个多语言安全模型，填补了非英语语言的安全空白。


<details>
  <summary>Details</summary>
Motivation: 非英语语言缺乏文化对齐的安全数据集，导致多语言LLM在安全方面表现不佳。

Method: 采用四阶段合成数据生成和过滤流程：文化数据隔离、文化数据适应、机器翻译和质量过滤。

Result: 生成了包含386,661样本的9语言数据集，训练出的模型在多语言安全基准测试中表现最佳。

Conclusion: 该工作填补了多语言LLM的安全空白，推动了文化感知安全模型的发展。

Abstract: The increasing use of Large Language Models (LLMs) in agentic applications
highlights the need for robust safety guard models. While content safety in
English is well-studied, non-English languages lack similar advancements due to
the high cost of collecting culturally aligned labeled datasets. We present
CultureGuard, a novel solution for curating culturally aligned, high-quality
safety datasets across multiple languages. Our approach introduces a four-stage
synthetic data generation and filtering pipeline: cultural data segregation,
cultural data adaptation, machine translation, and quality filtering. This
pipeline enables the conversion and expansion of the
Nemotron-Content-Safety-Dataset-V2 English safety dataset into eight distinct
languages: Arabic, German, Spanish, French, Hindi, Japanese, Thai, and Chinese.
The resulting dataset, Nemotron-Content-Safety-Dataset-Multilingual-v1,
comprises 386,661 samples in 9 languages and facilitates the training of
Llama-3.1-Nemotron-Safety-Guard-Multilingual-8B-v1 via LoRA-based fine-tuning.
The final model achieves state-of-the-art performance on several multilingual
content safety benchmarks. We also benchmark the latest open LLMs on
multilingual safety and observe that these LLMs are more prone to give unsafe
responses when prompted in non-English languages. This work represents a
significant step toward closing the safety gap in multilingual LLMs by enabling
the development of culturally aware safety guard models.

</details>


### [39] [Enhancing the Preference Extractor in Multi-turn Dialogues: From Annotating Disasters to Accurate Preference Extraction](https://arxiv.org/abs/2508.01739)
*Cheng Wang,ziru Liu,Pengcheng Tang,Mingyu Zhang,Quanyu Dai,Yue Zhu*

Main category: cs.CL

TL;DR: 论文提出了一种名为IterChat的对话数据生成框架，通过分解多轮偏好提取为单轮迭代过程，提高了标注效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前多轮对话数据标注存在困难（标注灾难），且模型训练易受错误传播影响。研究旨在解决这些问题。

Method: 构建新数据格式，将对话分为历史偏好和单轮对话，利用GPT4预定义偏好槽并随机采样生成数据集。

Result: 实验表明，新数据格式在微调或少样本提示下性能优于原始多轮对话，标注效率提高28.4%。

Conclusion: IterChat框架有效解决了多轮偏好提取的标注和训练难题，提升了效率和性能。

Abstract: Identifying user preferences in dialogue systems is a pivotal aspect of
providing satisfying services. Current research shows that using large language
models (LLMs) to fine-tune a task-specific preference extractor yields
excellent results in terms of accuracy and generalization. However, the primary
challenge stems from the inherent difficulty in obtaining high-quality labeled
multi-turn dialogue data. Accurately tracking user preference transitions
across turns not only demands intensive domain expertise and contextual
consistency maintenance for annotators (termed \textbf{``Annotating
Disaster''}) but also complicates model training due to error propagation in
sequential dependency learning. Inspired by the observation that multi-turn
preference extraction can be decomposed into iterative executions of one-turn
extraction processes. We propose a novel dialogue data generation framework
named \textbf{IterChat}. First, we construct a new data format that categorizes
the dialogue data into attributed historical preferences and one-turn
dialogues. This reduces the probability of annotation errors and improves
annotation efficiency. Then, to generate a high-quality and diverse dialogue
dataset, we adopt GPT4 to pre-define the preference slots in the target
preference extractor task and then randomly sample the subset of the slots and
their corresponding schema values to create the dialogue datasets. Experimental
results indicate that fine-tuning or only few-shot prompting with the new
dialogue format yields superior performance compared to the original multi-turn
dialogues. Additionally, the new data format improves annotator efficiency with
a win rate of 28.4\% higher than the original multi-turn dialogues.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [40] [Exploring Agentic Artificial Intelligence Systems: Towards a Typological Framework](https://arxiv.org/abs/2508.00844)
*Christopher Wissuchek,Patrick Zschech*

Main category: cs.AI

TL;DR: 本文提出了一种分类自主AI系统的框架，定义了八个维度以评估其认知和环境代理能力。


<details>
  <summary>Details</summary>
Motivation: AI系统正从被动工具发展为自主代理，但缺乏分类和比较这些系统的结构化框架。

Method: 采用多阶段方法论构建并精炼了一个分类法，通过人机混合方法评估，并进一步提炼为构造类型。

Result: 该框架为研究人员和从业者提供了分析AI系统不同代理能力的方法。

Conclusion: 该分类法为评估当前AI系统和预测未来自主AI发展提供了基础。

Abstract: Artificial intelligence (AI) systems are evolving beyond passive tools into
autonomous agents capable of reasoning, adapting, and acting with minimal human
intervention. Despite their growing presence, a structured framework is lacking
to classify and compare these systems. This paper develops a typology of
agentic AI systems, introducing eight dimensions that define their cognitive
and environmental agency in an ordinal structure. Using a multi-phase
methodological approach, we construct and refine this typology, which is then
evaluated through a human-AI hybrid approach and further distilled into
constructed types. The framework enables researchers and practitioners to
analyze varying levels of agency in AI systems. By offering a structured
perspective on the progression of AI capabilities, the typology provides a
foundation for assessing current systems and anticipating future developments
in agentic AI.

</details>


### [41] [A Formal Framework for the Definition of 'State': Hierarchical Representation and Meta-Universe Interpretation](https://arxiv.org/abs/2508.00853)
*Kei Itoh*

Main category: cs.AI

TL;DR: 该研究通过引入数学上严谨的'状态'概念统一形式结构，强化了包括智能公理化定义在内的多样化系统的理论基础。


<details>
  <summary>Details</summary>
Motivation: 解决'状态'概念长期缺乏共识和形式化清晰定义的问题，为跨领域的理论研究提供统一框架。

Method: 提出'分层状态网格'和'中间元宇宙（IMU）'，构建元理论基础，扩展跨宇宙理论至语言翻译和智能体集成。

Result: 建立了基于'定义=状态'原则的元形式逻辑框架，适用于智能定义、形式逻辑和科学理论。

Conclusion: 该研究为智能定义和跨领域理论提供了数学上严谨的基础，具有广泛的应用潜力。

Abstract: This study aims to reinforce the theoretical foundation for diverse
systems--including the axiomatic definition of intelligence--by introducing a
mathematically rigorous and unified formal structure for the concept of
'state,' which has long been used without consensus or formal clarity. First, a
'hierarchical state grid' composed of two axes--state depth and mapping
hierarchy--is proposed to provide a unified notational system applicable across
mathematical, physical, and linguistic domains. Next, the 'Intermediate
Meta-Universe (IMU)' is introduced to enable explicit descriptions of definers
(ourselves) and the languages we use, thereby allowing conscious meta-level
operations while avoiding self-reference and logical inconsistency. Building on
this meta-theoretical foundation, this study expands inter-universal theory
beyond mathematics to include linguistic translation and agent integration,
introducing the conceptual division between macrocosm-inter-universal and
microcosm-inter-universal operations for broader expressivity. Through these
contributions, this paper presents a meta-formal logical framework--grounded in
the principle of definition = state--that spans time, language, agents, and
operations, providing a mathematically robust foundation applicable to the
definition of intelligence, formal logic, and scientific theory at large.

</details>


### [42] [AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks](https://arxiv.org/abs/2508.00890)
*Fali Wang,Hui Liu,Zhenwei Dai,Jingying Zeng,Zhiwei Zhang,Zongyu Wu,Chen Luo,Zhen Li,Xianfeng Tang,Qi He,Suhang Wang*

Main category: cs.AI

TL;DR: 论文研究了多阶段复杂任务中的测试时计算最优扩展问题，提出了基于LLM的AgentTTS框架，显著提升了搜索效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单阶段任务的测试时扩展，而现实中的多阶段复杂任务需要针对不同子任务分配计算资源，因此研究多阶段任务的优化分配具有重要意义。

Method: 通过大量实验得出三个经验性见解，并基于此提出AgentTTS框架，利用LLM代理通过迭代反馈自主搜索最优分配方案。

Result: 实验表明，AgentTTS在搜索效率和性能上优于传统方法和其他基于LLM的基线，且对训练集规模变化更具鲁棒性。

Conclusion: AgentTTS为解决多阶段复杂任务中的计算资源分配问题提供了高效且可解释的解决方案。

Abstract: Test-time scaling (TTS) enhances the performance of large language models
(LLMs) by allocating additional compute resources during inference. However,
existing research primarily investigates TTS in single-stage tasks; while many
real-world problems are multi-stage complex tasks, composed of a sequence of
heterogeneous subtasks with each subtask requires LLM of specific capability.
Therefore, we study a novel problem: the test-time compute-optimal scaling in
multi-stage complex tasks, aiming to select suitable models and allocate
budgets per subtask to maximize overall performance. TTS in multi-stage tasks
introduces two fundamental challenges: (i) The combinatorial search space of
model and budget allocations, combined with the high cost of inference, makes
brute-force search impractical. (ii) The optimal model and budget allocations
across subtasks are interdependent, increasing the complexity of the
compute-optimal search. To address this gap, we conduct extensive pilot
experiments on four tasks across six datasets, deriving three empirical
insights characterizing the behavior of LLMs in multi-stage complex tasks.
Informed by these insights, we propose AgentTTS, an LLM-agent-based framework
that autonomously searches for compute-optimal allocations through iterative
feedback-driven interactions with the execution environment. Experimental
results demonstrate that AgentTTS significantly outperforms traditional and
other LLM-based baselines in search efficiency, and shows improved robustness
to varying training set sizes and enhanced interpretability.

</details>


### [43] [ff4ERA: A new Fuzzy Framework for Ethical Risk Assessment in AI](https://arxiv.org/abs/2508.00899)
*Abeer Dyoub,Ivan Letteri,Francesca A. Lisi*

Main category: cs.AI

TL;DR: 论文提出了一种模糊框架ff4ERA，用于量化伦理风险，支持AI系统在人类价值观和可接受风险水平下的决策。


<details>
  <summary>Details</summary>
Motivation: 随着共生AI的发展，伦理风险评估（ERA）面临不确定性、模糊性和信息不完整等挑战，需要一种灵活、透明且稳健的框架。

Method: 结合模糊逻辑、模糊层次分析法（FAHP）和确定性因子（CF），通过伦理风险评分（ERS）量化风险。

Result: 案例研究表明，ff4ERA能生成上下文敏感的伦理风险评分，且对无关输入保持稳健。

Conclusion: ff4ERA框架能够提供可解释、可追踪且风险感知的伦理评估，支持假设分析和设计优化。

Abstract: The emergence of Symbiotic AI (SAI) introduces new challenges to ethical
decision-making as it deepens human-AI collaboration. As symbiosis grows, AI
systems pose greater ethical risks, including harm to human rights and trust.
Ethical Risk Assessment (ERA) thus becomes crucial for guiding decisions that
minimize such risks. However, ERA is hindered by uncertainty, vagueness, and
incomplete information, and morality itself is context-dependent and imprecise.
This motivates the need for a flexible, transparent, yet robust framework for
ERA. Our work supports ethical decision-making by quantitatively assessing and
prioritizing multiple ethical risks so that artificial agents can select
actions aligned with human values and acceptable risk levels. We introduce
ff4ERA, a fuzzy framework that integrates Fuzzy Logic, the Fuzzy Analytic
Hierarchy Process (FAHP), and Certainty Factors (CF) to quantify ethical risks
via an Ethical Risk Score (ERS) for each risk type. The final ERS combines the
FAHP-derived weight, propagated CF, and risk level. The framework offers a
robust mathematical approach for collaborative ERA modeling and systematic,
step-by-step analysis. A case study confirms that ff4ERA yields
context-sensitive, ethically meaningful risk scores reflecting both expert
input and sensor-based evidence. Risk scores vary consistently with relevant
factors while remaining robust to unrelated inputs. Local sensitivity analysis
shows predictable, mostly monotonic behavior across perturbations, and global
Sobol analysis highlights the dominant influence of expert-defined weights and
certainty factors, validating the model design. Overall, the results
demonstrate ff4ERA ability to produce interpretable, traceable, and risk-aware
ethical assessments, enabling what-if analyses and guiding designers in
calibrating membership functions and expert judgments for reliable ethical
decision support.

</details>


### [44] [An analysis of AI Decision under Risk: Prospect theory emerges in Large Language Models](https://arxiv.org/abs/2508.00902)
*Kenneth Payne*

Main category: cs.AI

TL;DR: 论文测试了Kahneman和Tversky的'前景理论'在大型语言模型中的应用，发现模型与人类在风险决策中表现相似，且情境（如军事与民用）对风险偏好的影响显著。


<details>
  <summary>Details</summary>
Motivation: 验证大型语言模型是否像人类一样在风险决策中表现出前景理论描述的偏差，并探讨情境对风险偏好的影响。

Method: 通过实验测试大型语言模型在不同情境（如军事与民用）下的风险决策行为，分析其与前景理论的契合度。

Result: 模型在风险决策中表现出与人类相似的前景理论偏差，且军事情境下的'框架效应'更显著。

Conclusion: 语言模型捕捉了人类的启发式与偏见，但这些偏见具有情境依赖性，支持Wittgenstein的'语言游戏'概念。

Abstract: Judgment of risk is key to decision-making under uncertainty. As Daniel
Kahneman and Amos Tversky famously discovered, humans do so in a distinctive
way that departs from mathematical rationalism. Specifically, they demonstrated
experimentally that humans accept more risk when they feel themselves at risk
of losing something than when they might gain. I report the first tests of
Kahneman and Tversky's landmark 'prospect theory' with Large Language Models,
including today's state of the art chain-of-thought 'reasoners'.
  In common with humans, I find that prospect theory often anticipates how
these models approach risky decisions across a range of scenarios. I also
demonstrate that context is key to explaining much of the variance in risk
appetite. The 'frame' through which risk is apprehended appears to be embedded
within the language of the scenarios tackled by the models. Specifically, I
find that military scenarios generate far larger 'framing effects' than do
civilian settings, ceteris paribus. My research suggests, therefore, that
language models the world, capturing our human heuristics and biases. But also
that these biases are uneven - the idea of a 'frame' is richer than simple
gains and losses. Wittgenstein's notion of 'language games' explains the
contingent, localised biases activated by these scenarios. Finally, I use my
findings to reframe the ongoing debate about reasoning and memorisation in
LLMs.

</details>


### [45] [Knowledge Editing for Multi-Hop Question Answering Using Semantic Analysis](https://arxiv.org/abs/2508.00914)
*Dominic Simon,Rickard Ewetz*

Main category: cs.AI

TL;DR: CHECK是一种基于语义分析的知识编辑框架，用于改进大型语言模型在多跳问答任务中的表现，通过逻辑优化和重新提示提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法在处理需要组合推理的任务（如多跳问答）时表现不佳，导致推理过程不逻辑。

Method: CHECK通过类比编译器和LLM推理，先对推理链进行语义分析，修正语义错误，再通过逻辑优化和高温重新提示执行。

Result: 在四个数据集上，CHECK比五种最先进框架平均提高了22.8%的多跳问答准确率。

Conclusion: CHECK通过语义分析和逻辑优化显著提升了多跳问答任务的性能。

Abstract: Large Language Models (LLMs) require lightweight avenues of updating stored
information that has fallen out of date. Knowledge Editing (KE) approaches have
been successful in updating model knowledge for simple factual queries but
struggle with handling tasks that require compositional reasoning such as
multi-hop question answering (MQA). We observe that existing knowledge editors
leverage decompositional techniques that result in illogical reasoning
processes. In this paper, we propose a knowledge editor for MQA based on
semantic analysis called CHECK. Our framework is based on insights from an
analogy between compilers and reasoning using LLMs. Similar to how source code
is first compiled before being executed, we propose to semantically analyze
reasoning chains before executing the chains to answer questions. Reasoning
chains with semantic errors are revised to ensure consistency through logic
optimization and re-prompting the LLM model at a higher temperature. We
evaluate the effectiveness of CHECK against five state-of-the-art frameworks on
four datasets and achieve an average 22.8% improved MQA accuracy.

</details>


### [46] [Cooperative Perception: A Resource-Efficient Framework for Multi-Drone 3D Scene Reconstruction Using Federated Diffusion and NeRF](https://arxiv.org/abs/2508.00967)
*Massoud Pourmandi*

Main category: cs.AI

TL;DR: 提出了一种创新的无人机群感知系统，通过联邦学习、轻量级语义提取和局部NeRF更新，解决计算限制、低带宽通信和实时场景重建问题。


<details>
  <summary>Details</summary>
Motivation: 解决无人机群在计算能力有限、通信带宽低以及实时场景重建中的挑战。

Method: 结合联邦学习的共享扩散模型、YOLOv12轻量级语义提取和局部NeRF更新，设计生成扩散模型用于联合场景重建，并引入语义感知压缩协议。

Result: 系统在模拟和实际无人机测试中验证了其高效性和可扩展性。

Conclusion: 该框架为多智能体AI在自主系统中的发展提供了突破性进展。

Abstract: The proposal introduces an innovative drone swarm perception system that aims
to solve problems related to computational limitations and low-bandwidth
communication, and real-time scene reconstruction. The framework enables
efficient multi-agent 3D/4D scene synthesis through federated learning of
shared diffusion model and YOLOv12 lightweight semantic extraction and local
NeRF updates while maintaining privacy and scalability. The framework redesigns
generative diffusion models for joint scene reconstruction, and improves
cooperative scene understanding, while adding semantic-aware compression
protocols. The approach can be validated through simulations and potential
real-world deployment on drone testbeds, positioning it as a disruptive
advancement in multi-agent AI for autonomous systems.

</details>


### [47] [AutoEDA: Enabling EDA Flow Automation through Microservice-Based LLM Agents](https://arxiv.org/abs/2508.01012)
*Yiyi Lu,Hoi Ian Au,Junyao Zhang,Jingyu Pan,Yiting Wang,Ang Li,Jianyi Zhang,Yiran Chen*

Main category: cs.AI

TL;DR: AutoEDA是一个基于MCP协议的EDA自动化框架，通过结构化提示工程减少微调需求，提升RTL-to-GDSII流程的效率和脚本质量。


<details>
  <summary>Details</summary>
Motivation: 传统EDA工作流依赖手动脚本和工具交互，效率低且难以扩展，现有LLM解决方案需昂贵微调且缺乏标准化框架。

Method: 利用MCP协议实现并行学习，结构化提示工程减少微调，智能参数提取与任务分解，扩展CodeBLEU评估脚本质量。

Result: 在五个基准测试中，AutoEDA在自动化准确性、效率和脚本质量上优于现有方法。

Conclusion: AutoEDA开源发布，支持EDA社区的可重复性和标准化自动化。

Abstract: Modern Electronic Design Automation (EDA) workflows, especially the
RTL-to-GDSII flow, require heavily manual scripting and demonstrate a multitude
of tool-specific interactions which limits scalability and efficiency. While
LLMs introduces strides for automation, existing LLM solutions require
expensive fine-tuning and do not contain standardized frameworks for
integration and evaluation. We introduce AutoEDA, a framework for EDA
automation that leverages paralleled learning through the Model Context
Protocol (MCP) specific for standardized and scalable natural language
experience across the entire RTL-to-GDSII flow. AutoEDA limits fine-tuning
through structured prompt engineering, implements intelligent parameter
extraction and task decomposition, and provides an extended CodeBLEU metric to
evaluate the quality of TCL scripts. Results from experiments over five
previously curated benchmarks show improvements in automation accuracy and
efficiency, as well as script quality when compared to existing methods.
AutoEDA is released open-sourced to support reproducibility and the EDA
community. Available at: https://github.com/AndyLu666/MCP-EDA-Server

</details>


### [48] [CADDesigner: Conceptual Design of CAD Models Based on General-Purpose Agent](https://arxiv.org/abs/2508.01031)
*Jingzhe Ni,Xiaolong Yin,Xintong Li,Xingyu Lu,Ji Wei,Ruofeng Tong,Min Tang,Peng Du*

Main category: cs.AI

TL;DR: 提出了一种基于大型语言模型（LLM）的CAD概念设计代理，通过文本和草图输入，结合交互式对话和视觉反馈，生成高质量CAD建模代码。


<details>
  <summary>Details</summary>
Motivation: 降低CAD设计的门槛，提高设计效率，减少对专业知识的依赖。

Method: 采用Context-Independent Imperative Paradigm（CIP），结合交互式对话和视觉反馈，生成CAD代码，并通过知识库持续优化。

Result: 实验结果表明，该方法在CAD代码生成方面达到最先进水平。

Conclusion: 该代理通过交互式设计和持续学习，显著提升了CAD设计的效率和可访问性。

Abstract: Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing
but typically requires a high level of expertise from designers. To lower the
entry barrier and improve design efficiency, we present an agent for CAD
conceptual design powered by large language models (LLMs). The agent accepts
both abstract textual descriptions and freehand sketches as input, engaging in
interactive dialogue with users to refine and clarify design requirements
through comprehensive requirement analysis. Built upon a novel
Context-Independent Imperative Paradigm (CIP), the agent generates high-quality
CAD modeling code. During the generation process, the agent incorporates
iterative visual feedback to improve model quality. Generated design cases are
stored in a structured knowledge base, enabling continuous improvement of the
agent's code generation capabilities. Experimental results demonstrate that our
method achieves state-of-the-art performance in CAD code generation.

</details>


### [49] [REACT: A Real-Time Edge-AI Based V2X Framework for Accident Avoidance in Autonomous Driving System](https://arxiv.org/abs/2508.01057)
*Fengze Yang,Bo Yu,Yang Zhou,Xuewen Luo,Zhengzhong Tu,Chenxi Liu*

Main category: cs.AI

TL;DR: REACT是一个基于轻量级VLM的实时V2X轨迹优化框架，显著减少碰撞率并提升自动驾驶安全性。


<details>
  <summary>Details</summary>
Motivation: 人为错误导致的多车碰撞频发，需通过V2X通信提升自动驾驶系统的协同感知能力，但现有方法存在泛化性差、推理浅层和单模态输入依赖等问题。

Method: REACT结合轻量级VLM和多模态输入处理模块，通过边缘适配策略优化实时性能。

Result: 在DeepAccident基准测试中，REACT减少77%碰撞率，VPQ达48.2%，推理延迟0.57秒。

Conclusion: 轻量级VLM在实时边缘协同规划中可行，语言引导的上下文推理能提升自动驾驶的安全性和响应速度。

Abstract: Collisions caused by human error are the most common type of multi-vehicle
crash, highlighting the critical need for autonomous driving (AD) systems to
leverage cooperative perception through Vehicle-to-Everything (V2X)
communication. This capability extends situational awareness beyond the
limitations of onboard sensors. However, current transformer-based V2X
frameworks suffer from limited generalization, shallow contextual reasoning,
and reliance on mono-modal inputs. Vision-Language Models (VLMs) offer enhanced
reasoning and multimodal integration but typically fall short of real-time
performance requirements in safety-critical applications. This paper presents
REACT, a real-time, V2X-integrated trajectory optimization framework built upon
a fine-tuned lightweight VLM. REACT integrates a set of specialized modules
that process multimodal inputs into optimized, risk-aware trajectories. To
ensure real-time performance on edge devices, REACT incorporates edge
adaptation strategies that reduce model complexity and accelerate inference.
Evaluated on the DeepAccident benchmark, REACT achieves state-of-the-art
performance, a 77% collision rate reduction, a 48.2% Video Panoptic Quality
(VPQ), and a 0.57-second inference latency on the Jetson AGX Orin. Ablation
studies validate the contribution of each input, module, and edge adaptation
strategy. These results demonstrate the feasibility of lightweight VLMs for
real-time edge-based cooperative planning and showcase the potential of
language-guided contextual reasoning to improve safety and responsiveness in
autonomous driving.

</details>


### [50] [gpuRDF2vec -- Scalable GPU-based RDF2vec](https://arxiv.org/abs/2508.01073)
*Martin Böckling,Heiko Paulheim*

Main category: cs.AI

TL;DR: gpuRDF2vec是一个开源库，利用GPU和多节点执行加速RDF2vec流程，显著提升知识图谱嵌入生成速度。


<details>
  <summary>Details</summary>
Motivation: 解决大规模知识图谱嵌入生成效率低下的问题。

Method: 利用现代GPU和多节点执行优化RDF2vec流程，包括随机游走和嵌入训练。

Result: 在合成图和真实基准测试中，gpuRDF2vec显著快于现有最快方案jRDF2vec，且能处理大规模/密集图。

Conclusion: gpuRDF2vec为研究者和实践者提供了高效训练大规模知识图谱嵌入的工具。

Abstract: Generating Knowledge Graph (KG) embeddings at web scale remains challenging.
Among existing techniques, RDF2vec combines effectiveness with strong
scalability. We present gpuRDF2vec, an open source library that harnesses
modern GPUs and supports multi-node execution to accelerate every stage of the
RDF2vec pipeline. Extensive experiments on both synthetically generated graphs
and real-world benchmarks show that gpuRDF2vec achieves up to a substantial
speedup over the currently fastest alternative, i.e., jRDF2vec. In a
single-node setup, our walk-extraction phase alone outperforms pyRDF2vec,
SparkKGML, and jRDF2vec by a substantial margin using random walks on large/
dense graphs, and scales very well to longer walks, which typically lead to
better quality embeddings. Our implementation of gpuRDF2vec enables
practitioners and researchers to train high-quality KG embeddings on
large-scale graphs within practical time budgets and builds on top of Pytorch
Lightning for the scalable word2vec implementation.

</details>


### [51] [Multispin Physics of AI Tipping Points and Hallucinations](https://arxiv.org/abs/2508.01097)
*Neil F. Johnson,Frank Yingjie Huo*

Main category: cs.AI

TL;DR: 生成式AI（如ChatGPT）的输出可能重复且有偏见，更令人担忧的是其输出可能在用户未察觉时从正确突变为错误。2024年因此造成670亿美元损失和数人死亡。通过将AI映射到多自旋热系统，揭示了其基本注意力头的隐藏突变点，并推导出公式量化用户提示和训练偏见的影响。研究还展示了多层架构如何放大这种突变，为提升AI透明度和量化风险提供了路径。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的输出突变可能导致严重后果，如经济损失和生命危险，因此需要揭示其机制并量化风险。

Method: 将AI映射到多自旋热系统，推导出突变点的精确公式，并分析多层架构对突变放大的影响。

Result: 揭示了AI输出突变的隐藏机制，提出了量化用户提示和训练偏见影响的公式，并展示了多层架构的放大效应。

Conclusion: 研究为提升AI透明度、解释性和性能提供了理论支持，并为量化用户风险和法律责任开辟了路径。

Abstract: Output from generative AI such as ChatGPT, can be repetitive and biased. But
more worrying is that this output can mysteriously tip mid-response from good
(correct) to bad (misleading or wrong) without the user noticing. In 2024
alone, this reportedly caused $67 billion in losses and several deaths.
Establishing a mathematical mapping to a multispin thermal system, we reveal a
hidden tipping instability at the scale of the AI's 'atom' (basic Attention
head). We derive a simple but essentially exact formula for this tipping point
which shows directly the impact of a user's prompt choice and the AI's training
bias. We then show how the output tipping can get amplified by the AI's
multilayer architecture. As well as helping improve AI transparency,
explainability and performance, our results open a path to quantifying users'
AI risk and legal liabilities.

</details>


### [52] [Platonic Representations for Poverty Mapping: Unified Vision-Language Codes or Agent-Induced Novelty?](https://arxiv.org/abs/2508.01109)
*Satiyabooshan Murugaboopathy,Connor T. Jerzak,Adel Daoud*

Main category: cs.AI

TL;DR: 研究通过卫星图像和网络文本预测家庭财富，多模态框架融合视觉和语言信号，表现优于单一方法，并发现部分表征收敛现象。


<details>
  <summary>Details</summary>
Motivation: 探索社会经济指标（如家庭财富）是否能在卫星图像和网络文本中留下可恢复的痕迹，以提供新的数据来源和分析方法。

Method: 使用非洲社区的DHS数据，结合Landsat图像和LLM生成的文本描述，开发了五种预测管道，包括视觉模型、LLM文本、AI代理检索文本、联合编码器和集成信号。

Result: 多模态框架在财富预测中表现优于单一方法（R-squared 0.77 vs. 0.63），LLM内部知识比代理检索文本更有效，部分表征收敛现象被发现。

Conclusion: 融合视觉和语言信号能提高财富预测的准确性和鲁棒性，同时揭示了社会经济指标的潜在共享表征，并发布了大规模多模态数据集。

Abstract: We investigate whether socio-economic indicators like household wealth leave
recoverable imprints in satellite imagery (capturing physical features) and
Internet-sourced text (reflecting historical/economic narratives). Using
Demographic and Health Survey (DHS) data from African neighborhoods, we pair
Landsat images with LLM-generated textual descriptions conditioned on
location/year and text retrieved by an AI search agent from web sources. We
develop a multimodal framework predicting household wealth (International
Wealth Index) through five pipelines: (i) vision model on satellite images,
(ii) LLM using only location/year, (iii) AI agent searching/synthesizing web
text, (iv) joint image-text encoder, (v) ensemble of all signals. Our framework
yields three contributions. First, fusing vision and agent/LLM text outperforms
vision-only baselines in wealth prediction (e.g., R-squared of 0.77 vs. 0.63 on
out-of-sample splits), with LLM-internal knowledge proving more effective than
agent-retrieved text, improving robustness to out-of-country and out-of-time
generalization. Second, we find partial representational convergence: fused
embeddings from vision/language modalities correlate moderately (median cosine
similarity of 0.60 after alignment), suggesting a shared latent code of
material well-being while retaining complementary details, consistent with the
Platonic Representation Hypothesis. Although LLM-only text outperforms
agent-retrieved data, challenging our Agent-Induced Novelty Hypothesis, modest
gains from combining agent data in some splits weakly support the notion that
agent-gathered information introduces unique representational structures not
fully captured by static LLM knowledge. Third, we release a large-scale
multimodal dataset comprising more than 60,000 DHS clusters linked to satellite
images, LLM-generated descriptions, and agent-retrieved texts.

</details>


### [53] [H2C: Hippocampal Circuit-inspired Continual Learning for Lifelong Trajectory Prediction in Autonomous Driving](https://arxiv.org/abs/2508.01158)
*Yunlong Lin,Zirui Li,Guodong Du,Xiaocong Zhao,Cheng Gong,Xinwei Wang,Chao Lu,Jianwei Gong*

Main category: cs.AI

TL;DR: 论文提出了一种受海马体启发的持续学习方法（H2C），用于解决深度学习在轨迹预测中的灾难性遗忘问题，通过选择性记忆回放保留先验知识。


<details>
  <summary>Details</summary>
Motivation: 深度学习在轨迹预测中表现优异，但存在灾难性遗忘问题，限制了其在动态分布场景中的应用。受神经科学启发，海马体在记忆回放中的作用为解决方案提供了思路。

Method: H2C通过两种互补策略选择代表性样本，最大化样本多样性和等概率采样，并通过记忆回放损失函数更新模型。

Result: 在INTERACTION数据集上的实验表明，H2C平均减少了22.71%的灾难性遗忘，且无需手动标注分布变化。

Conclusion: H2C有效解决了深度学习在轨迹预测中的灾难性遗忘问题，为自动驾驶系统在动态场景中的应用提供了可行方案。

Abstract: Deep learning (DL) has shown state-of-the-art performance in trajectory
prediction, which is critical to safe navigation in autonomous driving (AD).
However, most DL-based methods suffer from catastrophic forgetting, where
adapting to a new distribution may cause significant performance degradation in
previously learned ones. Such inability to retain learned knowledge limits
their applicability in the real world, where AD systems need to operate across
varying scenarios with dynamic distributions. As revealed by neuroscience, the
hippocampal circuit plays a crucial role in memory replay, effectively
reconstructing learned knowledge based on limited resources. Inspired by this,
we propose a hippocampal circuit-inspired continual learning method (H2C) for
trajectory prediction across varying scenarios. H2C retains prior knowledge by
selectively recalling a small subset of learned samples. First, two
complementary strategies are developed to select the subset to represent
learned knowledge. Specifically, one strategy maximizes inter-sample diversity
to represent the distinctive knowledge, and the other estimates the overall
knowledge by equiprobable sampling. Then, H2C updates via a memory replay loss
function calculated by these selected samples to retain knowledge while
learning new data. Experiments based on various scenarios from the INTERACTION
dataset are designed to evaluate H2C. Experimental results show that H2C
reduces catastrophic forgetting of DL baselines by 22.71% on average in a
task-free manner, without relying on manually informed distributional shifts.
The implementation is available at https://github.com/BIT-Jack/H2C-lifelong.

</details>


### [54] [Benchmarking and Bridging Emotion Conflicts for Multimodal Emotion Reasoning](https://arxiv.org/abs/2508.01181)
*Zhiyuan Han,Beier Zhu,Yanlong Xu,Peipei Song,Xun Yang*

Main category: cs.AI

TL;DR: 论文提出了CA-MER基准测试和MoSEAR框架，用于解决多模态情感推理中的情感冲突问题，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在多模态情感推理中忽视情感冲突场景，导致对音频信号的过度依赖。

Method: 提出MoSEAR框架，包括MoSE模块（减少模态偏见的微调头）和AR模块（重新平衡模态贡献的注意力机制）。

Result: MoSEAR在多个基准测试中表现优异，尤其在模态冲突条件下。

Conclusion: MoSEAR有效解决了情感冲突问题，提升了多模态情感推理的性能。

Abstract: Despite their strong performance in multimodal emotion reasoning, existing
Multimodal Large Language Models (MLLMs) often overlook the scenarios involving
emotion conflicts, where emotional cues from different modalities are
inconsistent. To fill this gap, we first introduce CA-MER, a new benchmark
designed to examine MLLMs under realistic emotion conflicts. It consists of
three subsets: video-aligned, audio-aligned, and consistent, where only one or
all modalities reflect the true emotion. However, evaluations on our CA-MER
reveal that current state-of-the-art emotion MLLMs systematically over-rely on
audio signal during emotion conflicts, neglecting critical cues from visual
modality. To mitigate this bias, we propose MoSEAR, a parameter-efficient
framework that promotes balanced modality integration. MoSEAR consists of two
modules: (1)MoSE, modality-specific experts with a regularized gating mechanism
that reduces modality bias in the fine-tuning heads; and (2)AR, an attention
reallocation mechanism that rebalances modality contributions in frozen
backbones during inference. Our framework offers two key advantages: it
mitigates emotion conflicts and improves performance on consistent
samples-without incurring a trade-off between audio and visual modalities.
Experiments on multiple benchmarks-including MER2023, EMER, DFEW, and our
CA-MER-demonstrate that MoSEAR achieves state-of-the-art performance,
particularly under modality conflict conditions.

</details>


### [55] [A Survey on Agent Workflow -- Status and Future](https://arxiv.org/abs/2508.01186)
*Chaojia Yu,Zihan Cheng,Hanwen Cui,Yishuo Gao,Zexu Luo,Yijin Wang,Hangbin Zheng,Yong Zhao*

Main category: cs.AI

TL;DR: 本文综述了大型语言模型时代下自主代理工作流系统的功能与架构，比较了20多个代表性系统，并探讨了优化、安全及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着自主代理系统复杂度的增加，工作流框架成为实现可扩展、可控和安全AI行为的关键。本文旨在全面回顾代理工作流系统。

Method: 通过分类现有系统（功能能力和架构特征），比较20多个代表性系统，分析共同模式、技术挑战和趋势。

Result: 总结了代理工作流系统的功能与架构特征，提出了优化策略、安全问题及开放性问题。

Conclusion: 未来研究应关注标准化和多模态集成，以推动代理设计、工作流基础设施和安全自动化的交叉领域发展。

Abstract: In the age of large language models (LLMs), autonomous agents have emerged as
a powerful paradigm for achieving general intelligence. These agents
dynamically leverage tools, memory, and reasoning capabilities to accomplish
user-defined goals. As agent systems grow in complexity, agent
workflows-structured orchestration frameworks-have become central to enabling
scalable, controllable, and secure AI behaviors. This survey provides a
comprehensive review of agent workflow systems, spanning academic frameworks
and industrial implementations. We classify existing systems along two key
dimensions: functional capabilities (e.g., planning, multi-agent collaboration,
external API integration) and architectural features (e.g., agent roles,
orchestration flows, specification languages). By comparing over 20
representative systems, we highlight common patterns, potential technical
challenges, and emerging trends. We further address concerns related to
workflow optimization strategies and security. Finally, we outline open
problems such as standardization and multimodal integration, offering insights
for future research at the intersection of agent design, workflow
infrastructure, and safe automation.

</details>


### [56] [Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens](https://arxiv.org/abs/2508.01191)
*Chengshuai Zhao,Zhen Tan,Pingchuan Ma,Dawei Li,Bohan Jiang,Yancheng Wang,Yingzhen Yang,Huan Liu*

Main category: cs.AI

TL;DR: 研究发现，CoT推理在超出训练数据分布时会失效，表明其泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: 探索CoT推理是否真正反映模型的推理能力，还是仅依赖训练数据的分布。

Method: 通过任务、长度和格式三个维度分析CoT推理，并使用DataAlchemy环境进行实验。

Result: CoT推理在超出训练分布时表现脆弱，无法泛化。

Conclusion: CoT推理的泛化能力受限，强调了实现真正通用推理的挑战。

Abstract: Chain-of-Thought (CoT) prompting has been shown to improve Large Language
Model (LLM) performance on various tasks. With this approach, LLMs appear to
produce human-like reasoning steps before providing answers (a.k.a., CoT
reasoning), which often leads to the perception that they engage in deliberate
inferential processes. However, some initial findings suggest that CoT
reasoning may be more superficial than it appears, motivating us to explore
further. In this paper, we study CoT reasoning via a data distribution lens and
investigate if CoT reasoning reflects a structured inductive bias learned from
in-distribution data, allowing the model to conditionally generate reasoning
paths that approximate those seen during training. Thus, its effectiveness is
fundamentally bounded by the degree of distribution discrepancy between the
training data and the test queries. With this lens, we dissect CoT reasoning
via three dimensions: task, length, and format. To investigate each dimension,
we design DataAlchemy, an isolated and controlled environment to train LLMs
from scratch and systematically probe them under various distribution
conditions. Our results reveal that CoT reasoning is a brittle mirage that
vanishes when it is pushed beyond training distributions. This work offers a
deeper understanding of why and when CoT reasoning fails, emphasizing the
ongoing challenge of achieving genuine and generalizable reasoning.

</details>


### [57] [Importance Sampling is All You Need: Predict LLM's performance on new benchmark by reusing existing benchmark](https://arxiv.org/abs/2508.01203)
*Junjie Shi,Wei Ma,Shi Ying,Lingxiao Jiang,Yang liu,Bo Du*

Main category: cs.AI

TL;DR: 提出BIS框架，通过分析提示分布预测LLM在代码生成任务中的性能，无需真实数据，显著降低评估成本。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成基准面临高成本构建和数据集污染问题，需一种无需真实数据的性能预测方法。

Method: 基于重要性采样理论和重要性加权自编码器，重新加权现有基准样本以预测新基准性能，引入权重截断策略稳定估计。

Result: 在4个CodeLlama模型和9个基准上测试，预测代码正确性得分平均误差1.1%，最佳和最差误差分别为0.3%和1.9%。

Conclusion: BIS可靠且广泛适用，显著降低代码相关任务中LLM基准测试的成本和努力。

Abstract: With the rapid advancement of large language models , code generation has
become a key benchmark for evaluating LLM capabilities. However, existing
benchmarks face two major challenges: (1) the escalating cost of constructing
high-quality test suites and reference solutions, and (2) the increasing risk
of data contamination, which undermines the reliability of benchmark-based
evaluations. In this paper, we propose BIS, a prompt-centric evaluation
framework that enables ground-truth-free prediction of LLM performance on code
generation tasks. Rather than executing generated code, BIS estimates
performance metrics by analyzing the prompt distribution alone. Built on
importance sampling theory and implemented using Importance Weighted
Autoencoders, our method reweights samples from existing annotated benchmarks
to estimate performance on new, unseen benchmarks. To stabilize the estimation,
we introduce weight truncation strategies and compute marginal expectations
across the fitted distributions. BIS serves as a complementary tool that
supports benchmark development and validation under constrained resources,
offering actionable and quick feedback for prompt selection and contamination
assessment. We conduct extensive experiments involving 8,000 evaluation points
across 4 CodeLlama models and 9 diverse benchmarks. Our framework achieves an
average absolute prediction error of 1.1% for code correctness scores, with
best- and worst-case errors of 0.3% and 1.9%, respectively. It also generalizes
well to other metrics, attaining average absolute errors of 2.15% for pass@1.
These results demonstrate the reliability and broad applicability of BIS, which
can significantly reduce the cost and effort of benchmarking LLMs in
code-related tasks.

</details>


### [58] [Calibrated Prediction Set in Fault Detection with Risk Guarantees via Significance Tests](https://arxiv.org/abs/2508.01208)
*Mingchen Mei,Yi Li,YiYao Qian,Zijun Jia*

Main category: cs.AI

TL;DR: 提出了一种结合显著性检验和共形预测框架的新型故障检测方法，提供严格的风险保证。


<details>
  <summary>Details</summary>
Motivation: 现有诊断模型在复杂场景（如分布偏移）下缺乏严格的风险控制和可靠的不确定性量化。

Method: 将故障检测转化为假设检验任务，基于模型残差定义非一致性度量，利用校准数据集计算新样本的p值，构建数学保证的预测集。

Result: 实验验证了方法的理论性质，覆盖率始终达到或超过名义水平，且在高风险容忍度下预测集更小。

Conclusion: 该方法为故障检测提供了理论框架，实现了明确的风险控制，提升了诊断系统的可信度。

Abstract: Fault detection is crucial for ensuring the safety and reliability of modern
industrial systems. However, a significant scientific challenge is the lack of
rigorous risk control and reliable uncertainty quantification in existing
diagnostic models, particularly when facing complex scenarios such as
distributional shifts. To address this issue, this paper proposes a novel fault
detection method that integrates significance testing with the conformal
prediction framework to provide formal risk guarantees. The method transforms
fault detection into a hypothesis testing task by defining a nonconformity
measure based on model residuals. It then leverages a calibration dataset to
compute p-values for new samples, which are used to construct prediction sets
mathematically guaranteed to contain the true label with a user-specified
probability, $1-\alpha$. Fault classification is subsequently performed by
analyzing the intersection of the constructed prediction set with predefined
normal and fault label sets. Experimental results on cross-domain fault
diagnosis tasks validate the theoretical properties of our approach. The
proposed method consistently achieves an empirical coverage rate at or above
the nominal level ($1-\alpha$), demonstrating robustness even when the
underlying point-prediction models perform poorly. Furthermore, the results
reveal a controllable trade-off between the user-defined risk level ($\alpha$)
and efficiency, where higher risk tolerance leads to smaller average prediction
set sizes. This research contributes a theoretically grounded framework for
fault detection that enables explicit risk control, enhancing the
trustworthiness of diagnostic systems in safety-critical applications and
advancing the field from simple point predictions to informative,
uncertainty-aware outputs.

</details>


### [59] [SketchAgent: Generating Structured Diagrams from Hand-Drawn Sketches](https://arxiv.org/abs/2508.01237)
*Cheng Tan,Qi Chen,Jingxuan Wei,Gaowei Wu,Zhangyang Gao,Siyuan Li,Bihui Yu,Ruifeng Guo,Stan Z. Li*

Main category: cs.AI

TL;DR: SketchAgent是一个多智能体系统，旨在将手绘草图自动转换为结构化图表，减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 手绘草图虽然直观高效，但缺乏结构约束和语义精确性，难以自动转换为机器可读的图表。

Method: SketchAgent结合草图识别、符号推理和迭代验证，生成语义连贯且结构准确的图表。

Result: 提出了Sketch2Diagram Benchmark数据集，包含6,000多个高质量示例，验证了方法的有效性。

Conclusion: SketchAgent在设计、教育和工程领域具有广泛应用潜力，填补了草图与机器可读图表之间的鸿沟。

Abstract: Hand-drawn sketches are a natural and efficient medium for capturing and
conveying ideas. Despite significant advancements in controllable natural image
generation, translating freehand sketches into structured, machine-readable
diagrams remains a labor-intensive and predominantly manual task. The primary
challenge stems from the inherent ambiguity of sketches, which lack the
structural constraints and semantic precision required for automated diagram
generation. To address this challenge, we introduce SketchAgent, a multi-agent
system designed to automate the transformation of hand-drawn sketches into
structured diagrams. SketchAgent integrates sketch recognition, symbolic
reasoning, and iterative validation to produce semantically coherent and
structurally accurate diagrams, significantly reducing the need for manual
effort. To evaluate the effectiveness of our approach, we propose the
Sketch2Diagram Benchmark, a comprehensive dataset and evaluation framework
encompassing eight diverse diagram categories, such as flowcharts, directed
graphs, and model architectures. The dataset comprises over 6,000 high-quality
examples with token-level annotations, standardized preprocessing, and rigorous
quality control. By streamlining the diagram generation process, SketchAgent
holds great promise for applications in design, education, and engineering,
while offering a significant step toward bridging the gap between intuitive
sketching and machine-readable diagram generation. The benchmark is released at
https://huggingface.co/datasets/DiagramAgent/Sketch2Diagram-Benchmark.

</details>


### [60] [Unifying Mixture of Experts and Multi-Head Latent Attention for Efficient Language Models](https://arxiv.org/abs/2508.01261)
*Sushant Mehta,Raj Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.AI

TL;DR: MoE-MLA-RoPE结合了Mixture of Experts、Multi-head Latent Attention和Rotary Position Embeddings，通过细粒度专家路由、共享专家隔离和无梯度冲突负载平衡，实现了高效语言建模，显著减少内存和加速推理。


<details>
  <summary>Details</summary>
Motivation: 解决模型容量与计算效率之间的权衡问题，提升语言模型的效率。

Method: 1. 细粒度专家路由（64微专家和top-k选择）；2. 共享专家隔离（2个常用专家和62个专用专家）；3. 无梯度冲突负载平衡。

Result: 68% KV缓存内存减少，3.2倍推理加速，验证损失降低6.9%，生成质量提升（GPT-4评分更高）。

Conclusion: 架构创新而非参数扩展定义了资源受限语言模型的效率前沿。

Abstract: We present MoE-MLA-RoPE, a novel architecture combination that combines
Mixture of Experts (MoE) with Multi-head Latent Attention (MLA) and Rotary
Position Embeddings (RoPE) for efficient language modeling. Our approach
addresses the fundamental trade-off between model capacity and computational
efficiency through three key innovations: (1) fine-grained expert routing with
64 micro-experts and top-$k$ selection, enabling flexible specialization
through 3.6 * 10^7 possible expert combinations; (2) shared expert isolation
that dedicates 2 always active experts for common patterns while routing to 6
of 62 specialized experts; and (3) gradient-conflict-free load balancing that
maintains expert utilization without interfering with primary loss
optimization.
  Extensive experiments on models ranging from 17M to 202M parameters
demonstrate that MoE-MLA-RoPE with compression ratio r=d/2 achieves 68% KV
cache memory reduction and 3.2x inference speedup while maintaining competitive
perplexity (0.8% degradation). Compared to the parameters with 53.9M
parameters, MoE-MLA-RoPE improves the validation loss by 6.9% over the vanilla
transformers while using 42% fewer active parameters per forward pass.
FLOP-matched experiments reveal even larger gains: 11.1% improvement with 3.2x
inference acceleration. Automated evaluation using GPT-4 as a judge confirms
quality improvements in generation, with higher scores on coherence (8.1/10),
creativity (7.9/10) and grammatical correctness (8.2/10). Our results establish
that architectural novelty, not parameter scaling, defines the efficiency
frontier for resource-constrained language model deployment.

</details>


### [61] [Win-k: Improved Membership Inference Attacks on Small Language Models](https://arxiv.org/abs/2508.01268)
*Roya Arkhmammadova,Hosein Madadi Tamar,M. Emre Gursoy*

Main category: cs.AI

TL;DR: 本文研究了针对小型语言模型（SLMs）的成员推理攻击（MIAs），提出了一种名为win-k的新攻击方法，并在实验中验证了其优于现有攻击方法。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型因其高效性和可部署性在资源受限环境中受到重视，但成员推理攻击对其隐私和知识产权构成威胁。现有攻击方法在小型模型上效果不佳，因此需要改进。

Method: 提出了一种基于现有最先进攻击方法（min-k）的新攻击方法win-k，并在三个数据集和八个SLMs上进行了实验评估。

Result: 实验结果表明，win-k在AUROC、TPR @ 1% FPR和FPR @ 99% TPR等指标上优于现有攻击方法，尤其是在更小的模型上表现更佳。

Conclusion: win-k是一种有效的针对小型语言模型的成员推理攻击方法，尤其在小型模型上表现突出。

Abstract: Small language models (SLMs) are increasingly valued for their efficiency and
deployability in resource-constrained environments, making them useful for
on-device, privacy-sensitive, and edge computing applications. On the other
hand, membership inference attacks (MIAs), which aim to determine whether a
given sample was used in a model's training, are an important threat with
serious privacy and intellectual property implications. In this paper, we study
MIAs on SLMs. Although MIAs were shown to be effective on large language models
(LLMs), they are relatively less studied on emerging SLMs, and furthermore,
their effectiveness decreases as models get smaller. Motivated by this finding,
we propose a new MIA called win-k, which builds on top of a state-of-the-art
attack (min-k). We experimentally evaluate win-k by comparing it with five
existing MIAs using three datasets and eight SLMs. Results show that win-k
outperforms existing MIAs in terms of AUROC, TPR @ 1% FPR, and FPR @ 99% TPR
metrics, especially on smaller models.

</details>


### [62] [KCR: Resolving Long-Context Knowledge Conflicts via Reasoning in LLMs](https://arxiv.org/abs/2508.01273)
*Xianda Zheng,Zijian Huang,Meng-Fen Chiang,Michael J. Witbrock,Kaiqi Zhao*

Main category: cs.AI

TL;DR: 提出了知识冲突推理（KCR）框架，通过强化学习训练LLMs在长文本冲突中选择逻辑一致的上下文，提升其解决知识冲突的能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理多源知识冲突时容易混淆，尤其是在长文本冲突中，需要提升其解决冲突的能力。

Method: 提取冲突长文本中的推理路径（文本或局部知识图谱），通过强化学习训练模型选择逻辑一致的推理路径。

Result: 实验表明，KCR显著提升了多种骨干模型在长文本场景中解决知识冲突的能力。

Conclusion: KCR框架有效增强了LLMs解决知识冲突的能力，尤其在长文本冲突中表现优异。

Abstract: Knowledge conflicts commonly arise across diverse sources, and their
prevalence has increased with the advent of LLMs. When dealing with conflicts
between multiple contexts, also known as \emph{inter-context knowledge
conflicts}, LLMs are often confused by lengthy and conflicting contexts. To
address this challenge, we propose the Knowledge Conflict Reasoning (KCR)
framework, which enhances the ability of LLMs to resolve conflicting knowledge.
The key idea of KCR is to train backbone LLMs to establish a correct reasoning
process by rewarding them for selecting and adhering to the context with
stronger logical consistency when presented with conflicting contexts.
Specifically, we first extract reasoning paths, represented by either text or
local knowledge graphs, from the conflicting long contexts. Subsequently, we
employ Reinforcement Learning to encourage the model to learn the paradigm of
reasoning process that follows correct reasoning paths rather than the
incorrect counterparts. This enables the backbone models to genuinely acquire
the capability to resolve inter-context knowledge conflicts within long
contexts. Experimental results demonstrate that our framework significantly
improves the ability of various backbone models to resolve knowledge conflicts
in long-context scenarios, yielding substantial performance gains.

</details>


### [63] [Multi-TW: Benchmarking Multimodal Models on Traditional Chinese Question Answering in Taiwan](https://arxiv.org/abs/2508.01274)
*Jui-Ming Yao,Bing-Cheng Xie,Sheng-Wei Peng,Hao-Yuan Chen,He-Rong Zheng,Bing-Jia Tan,Peter Shaojui Wang,Shun-Feng Su*

Main category: cs.AI

TL;DR: Multi-TW是首个针对传统中文的多模态基准测试，评估模型性能和延迟，填补了现有基准的空白。


<details>
  <summary>Details</summary>
Motivation: 现有基准常忽略传统中文的三模态评估和推理延迟，Multi-TW旨在解决这一问题。

Method: Multi-TW包含900道多选题（图文、音频文本对），评估了多种多模态模型和视觉语言模型。

Result: 闭源模型在多模态任务中表现更优，开源模型在音频任务中表现良好；端到端多模态管道延迟更低。

Conclusion: Multi-TW揭示了传统中文微调和高效多模态架构的需求。

Abstract: Multimodal Large Language Models (MLLMs) process visual, acoustic, and
textual inputs, addressing the limitations of single-modality LLMs. However,
existing benchmarks often overlook tri-modal evaluation in Traditional Chinese
and do not consider inference latency. To address this, we introduce Multi-TW,
the first Traditional Chinese benchmark for evaluating the performance and
latency of any-to-any multimodal models. Multi-TW includes 900 multiple-choice
questions (image and text, audio and text pairs) sourced from official
proficiency tests developed with the Steering Committee for the Test of
Proficiency-Huayu (SC-TOP). We evaluated various any-to-any models and
vision-language models (VLMs) with audio transcription. Our results show that
closed-source models generally outperform open-source ones across modalities,
although open-source models can perform well in audio tasks. End-to-end
any-to-any pipelines offer clear latency advantages compared to VLMs using
separate audio transcription. Multi-TW presents a comprehensive view of model
capabilities and highlights the need for Traditional Chinese fine-tuning and
efficient multimodal architectures.

</details>


### [64] [BioDisco: Multi-agent hypothesis generation with dual-mode evidence, iterative feedback and temporal evaluation](https://arxiv.org/abs/2508.01285)
*Yujing Ke,Kevin George,Kathan Pandya,David Blumenthal,Maximilian Sprang,Gerrit Großmann,Sebastian Vollmer,David Antony Selby*

Main category: cs.AI

TL;DR: BioDisco是一个多智能体框架，结合语言模型推理和双模式证据系统，用于生成新颖且基于证据的科学假设，并通过迭代优化和时间评估验证性能。


<details>
  <summary>Details</summary>
Motivation: 科学假设的生成常因信息量大和复杂性高而受限，现有自动化方法在生成新颖且基于证据的假设方面表现不足。

Method: BioDisco结合语言模型推理和双模式证据系统（生物医学知识图谱和文献检索），集成内部评分和反馈循环进行迭代优化，并通过时间评估和Bradley-Terry配对比较模型验证性能。

Result: 评估显示BioDisco在生成新颖性和显著性方面优于现有方法，且具有灵活性和模块化设计。

Conclusion: BioDisco是一个实用工具，有望推动新科学假设的发现。

Abstract: Identifying novel hypotheses is essential to scientific research, yet this
process risks being overwhelmed by the sheer volume and complexity of available
information. Existing automated methods often struggle to generate novel and
evidence-grounded hypotheses, lack robust iterative refinement and rarely
undergo rigorous temporal evaluation for future discovery potential. To address
this, we propose BioDisco, a multi-agent framework that draws upon language
model-based reasoning and a dual-mode evidence system (biomedical knowledge
graphs and automated literature retrieval) for grounded novelty, integrates an
internal scoring and feedback loop for iterative refinement, and validates
performance through pioneering temporal and human evaluations and a
Bradley-Terry paired comparison model to provide statistically-grounded
assessment. Our evaluations demonstrate superior novelty and significance over
ablated configurations representative of existing agentic architectures.
Designed for flexibility and modularity, BioDisco allows seamless integration
of custom language models or knowledge graphs, and can be run with just a few
lines of code. We anticipate researchers using this practical tool as a
catalyst for the discovery of new hypotheses.

</details>


### [65] [How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective](https://arxiv.org/abs/2508.01300)
*Ma'ayan Armony,Albert Meroño-Peñuela,Gerard Canal*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLM）在规划任务中的能力，提出了一种基于自然语言处理（NLP）的恢复流程，以提高生成计划的质量和成功率。


<details>
  <summary>Details</summary>
Motivation: LLM在规划任务中常生成错误或虚构的动作，现有评估方法主要关注成功率，缺乏对无效计划的全面分析。

Method: 提出了一种包含NLP评估和三阶段恢复流程的管道，最终通过符号规划器完成计划。

Result: 研究发现LLM在计划生成中缺乏明确推理，恢复流程将成功率从21.9%提升至27.5%，但质量仍不及传统规划器。

Conclusion: LLM在规划任务中的可靠性有限，需进一步研究以提高其推理和规划能力。

Abstract: The reasoning and planning abilities of Large Language Models (LLMs) have
been a frequent topic of discussion in recent years. Their ability to take
unstructured planning problems as input has made LLMs' integration into AI
planning an area of interest. Nevertheless, LLMs are still not reliable as
planners, with the generated plans often containing mistaken or hallucinated
actions. Existing benchmarking and evaluation methods investigate planning with
LLMs, focusing primarily on success rate as a quality indicator in various
planning tasks, such as validating plans or planning in relaxed conditions. In
this paper, we approach planning with LLMs as a natural language processing
(NLP) task, given that LLMs are NLP models themselves. We propose a recovery
pipeline consisting of an NLP-based evaluation of the generated plans, along
with three stages to recover the plans through NLP manipulation of the
LLM-generated plans, and eventually complete the plan using a symbolic planner.
This pipeline provides a holistic analysis of LLM capabilities in the context
of AI task planning, enabling a broader understanding of the quality of invalid
plans. Our findings reveal no clear evidence of underlying reasoning during
plan generation, and that a pipeline comprising an NLP-based analysis of the
plans, followed by a recovery mechanism, still falls short of the quality and
reliability of classical planners. On average, only the first 2.65 actions of
the plan are executable, with the average length of symbolically generated
plans being 8.4 actions. The pipeline still improves action quality and
increases the overall success rate from 21.9% to 27.5%.

</details>


### [66] [PUZZLED: Jailbreaking LLMs through Word-Based Puzzles](https://arxiv.org/abs/2508.01306)
*Yelim Ahn,Jaejin Lee*

Main category: cs.AI

TL;DR: PUZZLED是一种新型的越狱攻击方法，通过将有害指令的关键词隐藏为字谜，利用大语言模型的推理能力绕过安全检测。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）在各领域的广泛应用，确保其安全性成为关键问题。现有方法依赖迭代提示工程或语义转换，效果有限。

Method: PUZZLED设计了三种字谜类型（单词搜索、变位词、填字游戏），将有害指令的关键词隐藏其中，模型需解谜后生成响应。

Result: 在五种先进LLMs上测试，平均攻击成功率（ASR）达88.8%，其中GPT-4.1为96.5%，Claude 3.7 Sonnet为92.3%。

Conclusion: PUZZLED通过利用LLMs的推理能力，将简单字谜转化为高效的越狱策略，展示了现有安全措施的脆弱性。

Abstract: As large language models (LLMs) are increasingly deployed across diverse
domains, ensuring their safety has become a critical concern. In response,
studies on jailbreak attacks have been actively growing. Existing approaches
typically rely on iterative prompt engineering or semantic transformations of
harmful instructions to evade detection. In this work, we introduce PUZZLED, a
novel jailbreak method that leverages the LLM's reasoning capabilities. It
masks keywords in a harmful instruction and presents them as word puzzles for
the LLM to solve. We design three puzzle types-word search, anagram, and
crossword-that are familiar to humans but cognitively demanding for LLMs. The
model must solve the puzzle to uncover the masked words and then proceed to
generate responses to the reconstructed harmful instruction. We evaluate
PUZZLED on five state-of-the-art LLMs and observe a high average attack success
rate (ASR) of 88.8%, specifically 96.5% on GPT-4.1 and 92.3% on Claude 3.7
Sonnet. PUZZLED is a simple yet powerful attack that transforms familiar
puzzles into an effective jailbreak strategy by harnessing LLMs' reasoning
capabilities.

</details>


### [67] [Idempotent Equilibrium Analysis of Hybrid Workflow Allocation: A Mathematical Schema for Future Work](https://arxiv.org/abs/2508.01323)
*Faruk Alpay,Bugra Kilictas,Taylan Alpay,Hamdi Alakkad*

Main category: cs.AI

TL;DR: 论文通过形式化任务分配过程，证明在广泛假设下存在稳定均衡，长期自动化份额为x*=α/(α+β)，并预测到2045年自动化将占工作的65%，人类将专注于监督AI模块。


<details>
  <summary>Details</summary>
Motivation: 研究大规模AI系统如何改变人与机器的任务分配，探索其均衡状态及对未来的影响。

Method: 使用格论固定点工具（Tarski和Banach）证明均衡存在性和唯一性，并通过连续模型和动态基准验证。

Result: 存在稳定均衡，自动化份额为x*=α/(α+β)，模拟预测2045年自动化占65%，人类转向监督角色。

Conclusion: 人类将专注于AI模块的监督与整合，政策应促进人机协作以实现福利最大化。

Abstract: The rapid advance of large-scale AI systems is reshaping how work is divided
between people and machines. We formalise this reallocation as an iterated
task-delegation map and show that--under broad, empirically grounded
assumptions--the process converges to a stable idempotent equilibrium in which
every task is performed by the agent (human or machine) with enduring
comparative advantage. Leveraging lattice-theoretic fixed-point tools (Tarski
and Banach), we (i) prove existence of at least one such equilibrium and (ii)
derive mild monotonicity conditions that guarantee uniqueness. In a stylised
continuous model the long-run automated share takes the closed form $x^* =
\alpha / (\alpha + \beta)$, where $\alpha$ captures the pace of automation and
$\beta$ the rate at which new, human-centric tasks appear; hence full
automation is precluded whenever $\beta > 0$. We embed this analytic result in
three complementary dynamical benchmarks--a discrete linear update, an
evolutionary replicator dynamic, and a continuous Beta-distributed task
spectrum--each of which converges to the same mixed equilibrium and is
reproducible from the provided code-free formulas. A 2025-to-2045 simulation
calibrated to current adoption rates projects automation rising from
approximately 10% of work to approximately 65%, leaving a persistent one-third
of tasks to humans. We interpret that residual as a new profession of workflow
conductor: humans specialise in assigning, supervising and integrating AI
modules rather than competing with them. Finally, we discuss implications for
skill development, benchmark design and AI governance, arguing that policies
which promote "centaur" human-AI teaming can steer the economy toward the
welfare-maximising fixed point.

</details>


### [68] [Towards Evaluation for Real-World LLM Unlearning](https://arxiv.org/abs/2508.01324)
*Ke Miao,Yuke Hu,Xiaochen Li,Wenjie Bao,Zhihao Liu,Zhan Qin,Kui Ren*

Main category: cs.AI

TL;DR: 提出新指标DCUE，解决现有LLM遗忘评估指标的局限性，并通过实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘评估指标在实用性、准确性和鲁棒性方面存在不足，需改进以适应实际场景。

Method: 提出DCUE指标，通过验证集修正核心令牌的置信度分布偏差，并用Kolmogorov-Smirnov检验量化结果。

Result: 实验表明DCUE克服了现有指标的局限性，为未来遗忘算法设计提供指导。

Conclusion: DCUE是一种更实用、可靠的遗忘评估指标，推动相关算法发展。

Abstract: This paper analyzes the limitations of existing unlearning evaluation metrics
in terms of practicality, exactness, and robustness in real-world LLM
unlearning scenarios. To overcome these limitations, we propose a new metric
called Distribution Correction-based Unlearning Evaluation (DCUE). It
identifies core tokens and corrects distributional biases in their confidence
scores using a validation set. The evaluation results are quantified using the
Kolmogorov-Smirnov test. Experimental results demonstrate that DCUE overcomes
the limitations of existing metrics, which also guides the design of more
practical and reliable unlearning algorithms in the future.

</details>


### [69] [NatureGAIA: Pushing the Frontiers of GUI Agents with a Challenging Benchmark and High-Quality Trajectory Dataset](https://arxiv.org/abs/2508.01330)
*Zihan Zheng,Tianle Cui,Chuwen Xie,Jiahui Zhang,Jiahui Pan,Lewei He,Qianglong Chen*

Main category: cs.AI

TL;DR: 论文提出了一个基于因果路径原则的新基准\Benchmark，用于解决现有评估基准在准确性、可重复性和可扩展性上的不足，并开发了分层代理架构\Agent以优化长任务。通过强化微调（RFT）提升模型性能，但发现较小模型在复杂任务中存在能力上限。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLM）驱动的GUI代理评估基准在准确性、可重复性和可扩展性方面存在显著不足，亟需改进。

Method: 提出\Benchmark基准，基于因果路径原则设计任务；开发分层代理架构\Agent生成高质量轨迹数据集；使用RFT对Qwen2.5-VL-7B模型进行微调。

Result: \Benchmark对当前最先进LLM构成挑战（Claude-sonnet-4的WPSR仅为34.6%）；RFT显著提升小模型性能（WPSR从3.3%升至10.8%），但在复杂场景下性能急剧下降。

Conclusion: 研究为GUI代理领域提供了严格的评估标准和高质数据集，揭示了小模型在综合任务中的能力上限，为未来开发提供指导。

Abstract: The rapid advancement of Large Language Model (LLM)-driven Graphical User
Interface (GUI) agents is significantly hampered by the profound limitations of
existing evaluation benchmarks in terms of accuracy, reproducibility, and
scalability. To address this critical gap, we introduce \Benchmark, a novel
benchmark engineered on the principle of Causal Pathways. This design paradigm
structures complex tasks into a series of programmatically verifiable atomic
steps, ensuring a rigorous, fully automated, and reproducible standard for
assessment. Concurrently, to mitigate the inherent capability deficits of
agents, we developed \Agent, a hierarchical agent architecture specifically
optimized for long-horizon tasks. We leveraged this agent to generate a
high-quality, human-verified trajectory dataset that uniquely captures diverse
and even self-correcting interaction patterns of LLMs. We then utilized this
dataset to perform Reinforcement Fine-Tuning (RFT) on the Qwen2.5-VL-7B model.
Our experiments reveal that \Benchmark~presents a formidable challenge to
current state-of-the-art LLMs; even the top-performing Claude-sonnet-4 achieved
a Weighted Pathway Success Rate (WPSR) of only 34.6\%. Moreover, while RFT
substantially improved the smaller model's GUI execution capabilities (WPSR
increased from 3.3\% to 10.8\%), its performance degraded sharply when handling
complex scenarios. This outcome highlights the inherent capability ceiling of
smaller models when faced with comprehensive tasks that integrate perception,
decision-making, and execution. This research contributes a rigorous evaluation
standard and a high-quality dataset to the community, aiming to guide the
future development of GUI agents.

</details>


### [70] [Relation-Aware LNN-Transformer for Intersection-Centric Next-Step Prediction](https://arxiv.org/abs/2508.01368)
*Zhehong Ren,Tianluo Zhang,Yiheng Lu,Yushen Liang,Promethee Spathis*

Main category: cs.AI

TL;DR: 论文提出了一种基于道路节点的框架，用于预测用户的下一个位置，克服了传统封闭世界假设的局限性，并在城市规模轨迹数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法假设封闭世界，限制了预测的灵活性，无法捕捉探索性行为或城市道路网络的拓扑约束。

Method: 采用道路节点中心框架，结合方向性POI聚合和结构图嵌入，使用关系感知的LNN-Transformer进行序列建模。

Result: 模型在多个指标上优于现有基线，且在噪声环境下表现稳健。

Conclusion: 该框架为城市规模的下一个位置预测提供了更灵活和准确的解决方案。

Abstract: Next-step location prediction plays a pivotal role in modeling human
mobility, underpinning applications from personalized navigation to strategic
urban planning. However, approaches that assume a closed world - restricting
choices to a predefined set of points of interest (POIs) - often fail to
capture exploratory or target-agnostic behavior and the topological constraints
of urban road networks. Hence, we introduce a road-node-centric framework that
represents road-user trajectories on the city's road-intersection graph,
thereby relaxing the closed-world constraint and supporting next-step
forecasting beyond fixed POI sets. To encode environmental context, we
introduce a sector-wise directional POI aggregation that produces compact
features capturing distance, bearing, density and presence cues. By combining
these cues with structural graph embeddings, we obtain semantically grounded
node representations. For sequence modeling, we integrate a Relation-Aware
LNN-Transformer - a hybrid of a Continuous-time Forgetting Cell CfC-LNN and a
bearing-biased self-attention module - to capture both fine-grained temporal
dynamics and long-range spatial dependencies. Evaluated on city-scale road-user
trajectories, our model outperforms six state-of-the-art baselines by up to 17
percentage points in accuracy at one hop and 10 percentage points in MRR, and
maintains high resilience under noise, losing only 2.4 percentage points in
accuracy at one under 50 meter GPS perturbation and 8.9 percentage points in
accuracy at one hop under 25 percent POI noise.

</details>


### [71] [TripTailor: A Real-World Benchmark for Personalized Travel Planning](https://arxiv.org/abs/2508.01432)
*Yuanzhe Shen,Kaimin Wang,Changze Lv,Xiaoqing Zheng,Xuanjing Huang*

Main category: cs.AI

TL;DR: TripTailor是一个针对真实场景个性化旅行规划的基准测试，包含大量真实POI和旅行行程数据，实验显示当前LLM生成的行程中仅有不到10%达到人类水平。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试依赖模拟数据，无法反映LLM生成行程与真实行程的差异，且评估指标不全面。

Method: 引入TripTailor基准测试，包含50万+真实POI和近4000条多样化行程数据。

Result: 实验表明，最新LLM生成的行程中仅有不到10%达到人类水平，且存在可行性、合理性和个性化定制等挑战。

Conclusion: TripTailor有望推动旅行规划代理的发展，生成更符合用户需求的实用行程。

Abstract: The continuous evolution and enhanced reasoning capabilities of large
language models (LLMs) have elevated their role in complex tasks, notably in
travel planning, where demand for personalized, high-quality itineraries is
rising. However, current benchmarks often rely on unrealistic simulated data,
failing to reflect the differences between LLM-generated and real-world
itineraries. Existing evaluation metrics, which primarily emphasize
constraints, fall short of providing a comprehensive assessment of the overall
quality of travel plans. To address these limitations, we introduce TripTailor,
a benchmark designed specifically for personalized travel planning in
real-world scenarios. This dataset features an extensive collection of over
500,000 real-world points of interest (POIs) and nearly 4,000 diverse travel
itineraries, complete with detailed information, providing a more authentic
evaluation framework. Experiments show that fewer than 10\% of the itineraries
generated by the latest state-of-the-art LLMs achieve human-level performance.
Moreover, we identify several critical challenges in travel planning, including
the feasibility, rationality, and personalized customization of the proposed
solutions. We hope that TripTailor will drive the development of travel
planning agents capable of understanding and meeting user needs while
generating practical itineraries. Our code and dataset are available at
https://github.com/swxkfm/TripTailor

</details>


### [72] [$R^2$-CoD: Understanding Text-Graph Complementarity in Relational Reasoning via Knowledge Co-Distillation](https://arxiv.org/abs/2508.01475)
*Zhen Wu,Ritam Dutt,Luke M. Breitfeller,Armineh Nourbakhsh,Siddharth Parekh,Carolyn Rosé*

Main category: cs.AI

TL;DR: 本文通过统一架构研究文本与图表示的互补性，探索五种关系推理任务，揭示训练中双表示的演化模式。


<details>
  <summary>Details</summary>
Motivation: 研究文本与图结构在关系推理任务中的互补性及其对混合模型的影响。

Method: 采用知识共蒸馏（CoD）的统一架构，分析五种任务中文本与图的表示演化。

Result: 揭示了训练过程中双表示的校准与分歧模式，明确了整合的适用条件与原因。

Conclusion: 文本与图表示的整合在特定条件下能显著提升关系推理任务的性能。

Abstract: Relational reasoning lies at the core of many NLP tasks, drawing on
complementary signals from text and graphs. While prior research has
investigated how to leverage this dual complementarity, a detailed and
systematic understanding of text-graph interplay and its effect on hybrid
models remains underexplored. We take an analysis-driven approach to
investigate text-graph representation complementarity via a unified
architecture that supports knowledge co-distillation (CoD). We explore five
tasks involving relational reasoning that differ in how text and graph
structures encode the information needed to solve that task. By tracking how
these dual representations evolve during training, we uncover interpretable
patterns of alignment and divergence, and provide insights into when and why
their integration is beneficial.

</details>


### [73] [CARGO: A Co-Optimization Framework for EV Charging and Routing in Goods Delivery Logistics](https://arxiv.org/abs/2508.01476)
*Arindam Khanda,Anurag Satpathy,Amit Jha,Sajal K. Das*

Main category: cs.AI

TL;DR: CARGO框架优化电动车辆配送路线和充电计划，显著降低充电成本。


<details>
  <summary>Details</summary>
Motivation: 电动车辆配送因电池容量有限需优化充电计划，但现有方法未充分考虑充电点可用性、成本等因素。

Method: 提出混合整数线性规划（MILP）精确解和高效启发式方法，解决配送路线和充电联合优化问题。

Result: 相比基准策略，充电成本降低39%（EDF）和22%（NDF），同时完成类似配送量。

Conclusion: CARGO框架有效解决电动车辆配送中的充电和路线规划问题，具有实际应用潜力。

Abstract: With growing interest in sustainable logistics, electric vehicle (EV)-based
deliveries offer a promising alternative for urban distribution. However, EVs
face challenges due to their limited battery capacity, requiring careful
planning for recharging. This depends on factors such as the charging point
(CP) availability, cost, proximity, and vehicles' state of charge (SoC). We
propose CARGO, a framework addressing the EV-based delivery route planning
problem (EDRP), which jointly optimizes route planning and charging for
deliveries within time windows. After proving the problem's NP-hardness, we
propose a mixed integer linear programming (MILP)-based exact solution and a
computationally efficient heuristic method. Using real-world datasets, we
evaluate our methods by comparing the heuristic to the MILP solution, and
benchmarking it against baseline strategies, Earliest Deadline First (EDF) and
Nearest Delivery First (NDF). The results show up to 39% and 22% reductions in
the charging cost over EDF and NDF, respectively, while completing comparable
deliveries.

</details>


### [74] [WinkTPG: An Execution Framework for Multi-Agent Path Finding Using Temporal Reasoning](https://arxiv.org/abs/2508.01495)
*Jingtian Yan,Stephen F. Smith,Jiaoyang Li*

Main category: cs.AI

TL;DR: 论文提出了一种名为kTPG的多智能体速度优化算法，以及其扩展框架WinkTPG，用于将MAPF计划优化为动力学可行的路径，并动态减少不确定性。实验表明，WinkTPG能在1秒内为1000个智能体生成速度曲线，且解决方案质量提升高达51.7%。


<details>
  <summary>Details</summary>
Motivation: 现有MAPF算法依赖简化的动力学模型，导致智能体无法直接执行生成的路径计划，需要一种方法将MAPF计划优化为动力学可行的路径。

Method: 提出kTPG算法，将MAPF计划优化为动力学可行的路径；进一步提出WinkTPG框架，通过窗口机制动态优化MAPF计划。

Result: WinkTPG能在1秒内为1000个智能体生成速度曲线，解决方案质量提升高达51.7%。

Conclusion: kTPG和WinkTPG有效解决了MAPF计划动力学可行性的问题，显著提升了执行效率和解决方案质量。

Abstract: Planning collision-free paths for a large group of agents is a challenging
problem with numerous real-world applications. While recent advances in
Multi-Agent Path Finding (MAPF) have shown promising progress, standard MAPF
algorithms rely on simplified kinodynamic models, preventing agents from
directly following the generated MAPF plan. To bridge this gap, we propose
kinodynamic Temporal Plan Graph Planning (kTPG), a multi-agent speed
optimization algorithm that efficiently refines a MAPF plan into a
kinodynamically feasible plan while accounting for uncertainties and preserving
collision-freeness. Building on kTPG, we propose Windowed kTPG (WinkTPG), a
MAPF execution framework that incrementally refines MAPF plans using a
window-based mechanism, dynamically incorporating agent information during
execution to reduce uncertainty. Experiments show that WinkTPG can generate
speed profiles for up to 1,000 agents in 1 second and improves solution quality
by up to 51.7% over existing MAPF execution methods.

</details>


### [75] [Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning](https://arxiv.org/abs/2508.01543)
*Derin Cayir,Renjie Tao,Rashi Rungta,Kai Sun,Sean Chen,Haidar Khan,Minseok Kim,Julia Reinspach,Yue Liu*

Main category: cs.AI

TL;DR: Refine-n-Judge是一种自动迭代方法，利用单一LLM作为数据精炼器和评估器，提升数据集质量，无需额外人工标注或奖励模型。


<details>
  <summary>Details</summary>
Motivation: 人类反馈成本高且难以扩展，现有迭代方法需要额外资源，Refine-n-Judge旨在通过自动化解决这些问题。

Method: LLM同时生成精炼结果并评估改进，迭代直至无进一步优化，生成高质量偏好标记数据。

Result: 在多个数据集上表现优异，模型偏好率超74%，性能提升显著（AlpacaEval +5%，MT-Bench +19%）。

Conclusion: Refine-n-Judge能高效生成高质量数据集，显著提升模型性能，具有可扩展性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress through
preference-based fine-tuning, which critically depends on the quality of the
underlying training data. While human feedback is essential for improving data
quality, it is costly and does not scale well. In this paper, we introduce
Refine-n-Judge, an automated iterative approach that leverages a single LLM as
both a refiner and a judge to enhance dataset quality. Unlike existing
iterative refinement methods, Refine-n-Judge employs an LLM to both generate
refinements and explicitly evaluate each improvement, ensuring that every
iteration meaningfully enhances the dataset without requiring additional human
annotation or a separate reward model. At each step, the LLM refines a response
and judges whether the refinement is an improvement over the previous answer.
This process continues until the LLM prefers the initial answer over the
refinement, indicating no further improvements. This produces sequences of
increasing quality, preference-labeled responses ideal for fine-tuning.
  We demonstrate the effectiveness of Refine-n-Judge across a range of public
datasets spanning five corpora, targeting tasks such as coding, math, and
conversation. Models (Llama 3.1-8B and Llama 3.3-70B) fine-tuned on
Refine-n-Judge-enhanced datasets were preferred by LLM judges in over 74% of
comparisons against models tuned on the original dataset by GPT-4.
Additionally, we report performance gains: +5% on AlpacaEval and AlpacaEval
2.0, and +19% on MT-Bench. Our results indicate that Refine-n-Judge produces
high-quality datasets and scalable model improvements.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [76] [Addressing Cold Start For next-article Recommendation](https://arxiv.org/abs/2508.01036)
*Omar Elgohary,Nathan Jorgenson,Trenton Marple*

Main category: cs.IR

TL;DR: 本研究将ALMM模型从歌曲推荐调整到新闻推荐，改进冷启动场景下的推荐性能，使用BERT和TF-IDF提取新闻特征，并验证了模型的改进效果。


<details>
  <summary>Details</summary>
Motivation: 解决冷启动场景下新闻推荐性能不足的问题，通过调整ALMM模型以适应新闻推荐任务。

Method: 修改ALMM模型，使用BERT和TF-IDF提取新闻标题和摘要的特征，并结合用户阅读行为构建三元组。

Result: 改进后的ALMM模型在冷启动场景下表现优于Forbes和Oord基线模型。

Conclusion: ALMM模型在未大幅修改的情况下不适用于新闻推荐任务。

Abstract: This replication study modifies ALMM, the Adaptive Linear Mapping Model
constructed for the next song recommendation, to the news recommendation
problem on the MIND dataset. The original version of ALMM computes latent
representations for users, last-time items, and current items in a tensor
factorization structure and learns a linear mapping from content features to
latent item vectors. Our replication aims to improve recommendation performance
in cold-start scenarios by restructuring this model to sequential news click
behavior, viewing consecutively read articles as (last news, next news) tuples.
Instead of the original audio features, we apply BERT and a TF-IDF (Term
Frequency-Inverse Document Frequency) to news titles and abstracts to extract
token contextualized representations and align them with triplet-based user
reading patterns. We also propose a reproducibly thorough pre-processing
pipeline combining news filtering and feature integrity validation. Our
implementation of ALMM with TF-IDF shows relatively improved recommendation
accuracy and robustness over Forbes and Oord baseline models in the cold-start
scenario. We demonstrate that ALMM in a minimally modified state is not
suitable for next news recommendation.

</details>


### [77] [Towards Bridging Review Sparsity in Recommendation with Textual Edge Graph Representation](https://arxiv.org/abs/2508.01128)
*Leyao Wang,Xutao Mao,Xuhui Zhan,Yuying Zhao,Bo Ni,Ryan A. Rossi,Nesreen K. Ahmed,Tyler Derr*

Main category: cs.IR

TL;DR: TWISTER是一个通过联合建模语义和结构信号来填补缺失评论的统一框架，显著提升了推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中用户很少留下评论，导致数据稀疏性严重，现有模型效果受限。传统填补方法要么丢失语义，要么忽略结构依赖。

Method: 提出TWISTER框架，将用户-物品交互表示为文本边图（TEG），利用大语言模型作为图感知聚合器生成缺失评论。

Result: 在Amazon和Goodreads数据集上，TWISTER优于传统数值、基于图和LLM的基线方法，生成更高质量的评论并提升推荐性能。

Conclusion: TWISTER生成的评论更有帮助、真实且具体，同时优化结构信号以改进推荐效果。

Abstract: Textual reviews enrich recommender systems with fine-grained preference
signals and enhanced explainability. However, in real-world scenarios, users
rarely leave reviews, resulting in severe sparsity that undermines the
effectiveness of existing models. A natural solution is to impute or generate
missing reviews to enrich the data. However, conventional imputation techniques
-- such as matrix completion and LLM-based augmentation -- either lose
contextualized semantics by embedding texts into vectors, or overlook
structural dependencies among user-item interactions. To address these
shortcomings, we propose TWISTER (ToWards Imputation on Sparsity with Textual
Edge Graph Representation), a unified framework that imputes missing reviews by
jointly modeling semantic and structural signals. Specifically, we represent
user-item interactions as a Textual-Edge Graph (TEG), treating reviews as edge
attributes. To capture relational context, we construct line-graph views and
employ a large language model as a graph-aware aggregator. For each interaction
lacking a textual review, our model aggregates the neighborhood's
natural-language representations to generate a coherent and personalized
review. Experiments on the Amazon and Goodreads datasets show that TWISTER
consistently outperforms traditional numeric, graph-based, and LLM baselines,
delivering higher-quality imputed reviews and, more importantly, enhanced
recommendation performance. In summary, TWISTER generates reviews that are more
helpful, authentic, and specific, while smoothing structural signals for
improved recommendations.

</details>


### [78] [CM$^3$: Calibrating Multimodal Recommendation](https://arxiv.org/abs/2508.01226)
*Xin Zhou,Yongjie Wang,Zhiqi Shen*

Main category: cs.IR

TL;DR: 该研究重新审视了多模态推荐系统中的对齐和均匀性属性，提出了一种基于多模态相似性的校准均匀性损失方法，并通过球形Bézier方法融合多模态特征，实验表明其性能优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有模型在多模态推荐系统中倾向于过度强调均匀性而忽视对齐性，研究旨在通过校准均匀性损失和更好的多模态特征融合方法改进这一问题。

Method: 利用多模态数据的相似性校准均匀性分布，引入球形Bézier方法融合多模态特征。

Result: 在五个真实数据集上的实验表明，该方法性能优于基线，NDCG@20性能提升达5.4%。

Conclusion: 校准均匀性损失和改进的多模态特征融合方法能有效提升多模态推荐系统的性能。

Abstract: Alignment and uniformity are fundamental principles within the domain of
contrastive learning. In recommender systems, prior work has established that
optimizing the Bayesian Personalized Ranking (BPR) loss contributes to the
objectives of alignment and uniformity. Specifically, alignment aims to draw
together the representations of interacting users and items, while uniformity
mandates a uniform distribution of user and item embeddings across a unit
hypersphere. This study revisits the alignment and uniformity properties within
the context of multimodal recommender systems, revealing a proclivity among
extant models to prioritize uniformity to the detriment of alignment. Our
hypothesis challenges the conventional assumption of equitable item treatment
through a uniformity loss, proposing a more nuanced approach wherein items with
similar multimodal attributes converge toward proximal representations within
the hyperspheric manifold. Specifically, we leverage the inherent similarity
between items' multimodal data to calibrate their uniformity distribution,
thereby inducing a more pronounced repulsive force between dissimilar entities
within the embedding space. A theoretical analysis elucidates the relationship
between this calibrated uniformity loss and the conventional uniformity
function. Moreover, to enhance the fusion of multimodal features, we introduce
a Spherical B\'ezier method designed to integrate an arbitrary number of
modalities while ensuring that the resulting fused features are constrained to
the same hyperspherical manifold. Empirical evaluations conducted on five
real-world datasets substantiate the superiority of our approach over competing
baselines. We also shown that the proposed methods can achieve up to a 5.4%
increase in NDCG@20 performance via the integration of MLLM-extracted features.
Source code is available at: https://github.com/enoche/CM3.

</details>


### [79] [A Study on Enhancing User Engagement by Employing Gamified Recommender Systems](https://arxiv.org/abs/2508.01265)
*Ali Fallahi,Azam Bastanfard,Amineh Amini,Hadi Saboohi*

Main category: cs.IR

TL;DR: 本文综述了游戏化推荐系统如何提升用户参与度，并比较了不同构建方法，分析了其局限性、评估指标及未来方向。


<details>
  <summary>Details</summary>
Motivation: 现代商业中，个性化推荐系统对提升用户体验至关重要。游戏化规则的应用能解决冷启动和数据不足问题，同时提高用户参与度。

Method: 通过全面综述游戏化推荐系统，比较不同构建方法，并深入分析其方法、局限性、评估指标、数据集及推荐技术。

Result: 研究发现游戏化推荐系统能有效提升用户参与度，并揭示了该领域的流行趋势、研究空白和未探索方向。

Conclusion: 本文为研究者提供了游戏化推荐系统的详细分析，并提出了未来研究方向，以促进用户满意度和参与度的提升。

Abstract: Providing customized products and services in the modern business world is
one of the most efficient solutions to improve users' experience and their
engagements with the industries. To aim, recommender systems, by producing
personalized recommendations, have a crucial role in the digital age. As a
consequence of modern improvements in the internet and online-based
technologies, using gamification rules also increased in various fields. Recent
studies showed that considering gamification concepts in implementing
recommendation systems not only can become helpful to overcome the cold start
and lack of sufficient data, moreover, can effectively improve user engagement.
Gamification can motivate individuals to have more activities on the system;
these interactions are valuable resources of data for recommender engines.
Unlike the past related works about using gamified recommendation systems in
different environments or studies that particularly surveyed gamification
strategies or recommenders separately, this work provides a comprehensive
review of how gamified recommender systems can enhance user engagement in
various domain applications. Furthermore, comparing different approaches for
building recommender systems is followed by in-depth surveying about
investigating the gamified recommender systems, including their approaches,
limitations, evaluation metrics, proposed achievements, datasets, domain areas,
and their recommendation techniques. This exhaustive analysis provides a
detailed picture of the topic's popularity, gaps, and unexplored regions. It is
envisaged that the proposed research and introduced possible future directions
would serve as a stepping stone for researchers interested in using gamified
recommender systems for user satisfaction and engagement.

</details>


### [80] [SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation](https://arxiv.org/abs/2508.01375)
*Yining Yao,Ziwei Li,Shuwen Xiao,Boya Du,Jialin Zhu,Junjun Zheng,Xiangheng Kong,Yuning Jiang*

Main category: cs.IR

TL;DR: 提出了一种轻量级的语义-行为对齐框架，用于冷启动推荐，通过多模态表示和行为空间对齐提升CTR预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决冷启动和长尾物品推荐中多模态特征与行为空间对齐的高计算成本问题。

Method: 利用领域知识训练多模态编码器生成行为感知语义表示，并通过残差量化语义ID动态对齐多模态表示与排序模型。

Result: 在淘宝平台上，离线AUC提升0.83%，在线A/B测试点击量增加13.21%，订单量增加13.44%。

Conclusion: 该方法有效提升了冷启动推荐性能，验证了语义-行为对齐的轻量级实现可行性。

Abstract: In recommendation systems, predicting Click-Through Rate (CTR) is crucial for
accurately matching users with items. To improve recommendation performance for
cold-start and long-tail items, recent studies focus on leveraging item
multimodal features to model users' interests. However, obtaining multimodal
representations for items relies on complex pre-trained encoders, which incurs
unacceptable computation cost to train jointly with downstream ranking models.
Therefore, it is important to maintain alignment between semantic and behavior
space in a lightweight way.
  To address these challenges, we propose a Semantic-Behavior Alignment for
Cold-start Recommendation framework, which mainly focuses on utilizing
multimodal representations that align with the user behavior space to predict
CTR. First, we leverage domain-specific knowledge to train a multimodal encoder
to generate behavior-aware semantic representations. Second, we use residual
quantized semantic ID to dynamically bridge the gap between multimodal
representations and the ranking model, facilitating the continuous
semantic-behavior alignment. We conduct our offline and online experiments on
the Taobao, one of the world's largest e-commerce platforms, and have achieved
an increase of 0.83% in offline AUC, 13.21% clicks increase and 13.44% orders
increase in the online A/B test, emphasizing the efficacy of our method.

</details>


### [81] [Req-Rec: Enhancing Requirements Elicitation for Increasing Stakeholder's Satisfaction Using a Collaborative Filtering Based Recommender System](https://arxiv.org/abs/2508.01502)
*Ali Fallahi,Amineh Amini,Azam Bastanfard,Hadi Saboohi*

Main category: cs.IR

TL;DR: 论文提出了一种名为Req-Rec的混合推荐系统，结合协同过滤和repertory grid技术，用于需求获取阶段，以提高利益相关者满意度并克服传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 项目成功与否与识别正确的利益相关者及其需求密切相关，但传统需求获取技术存在效率低、时间限制和地域限制等问题。

Method: 提出Req-Rec方法，结合协同过滤和repertory grid技术，构建混合推荐系统。

Result: Req-Rec有效克服了传统需求获取技术的弱点，如时间限制、地域限制和需求获取过程中的偏见。

Conclusion: Req-Rec通过推荐相关需求，帮助利益相关者更全面地了解项目，提高了需求获取的效率和满意度。

Abstract: The success or failure of a project is highly related to recognizing the
right stakeholders and accurately finding and discovering their requirements.
However, choosing the proper elicitation technique was always a considerable
challenge for efficient requirement engineering. As a consequence of the swift
improvement of digital technologies since the past decade, recommender systems
have become an efficient channel for making a deeply personalized interactive
communication with stakeholders. In this research, a new method, called the
Req-Rec (Requirements Recommender), is proposed. It is a hybrid recommender
system based on the collaborative filtering approach and the repertory grid
technique as the core component. The primary goal of Req-Rec is to increase
stakeholder satisfaction by assisting them in the requirement elicitation
phase. Based on the results, the method efficiently could overcome weaknesses
of common requirement elicitation techniques, such as time limitation,
location-based restrictions, and bias in requirements' elicitation process.
Therefore, recommending related requirements assists stakeholders in becoming
more aware of different aspects of the project.

</details>


### [82] [End-to-End Personalization: Unifying Recommender Systems with Large Language Models](https://arxiv.org/abs/2508.01514)
*Danial Ebrat,Tina Aminian,Sepideh Ahmadian,Luis Rueda*

Main category: cs.IR

TL;DR: 提出了一种结合图注意力网络（GAT）和大语言模型（LLM）的混合推荐框架，以提高个性化和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决在有限用户反馈或异构项目属性场景下，推荐系统的个性化和可解释性问题。

Method: 使用LLM生成用户和项目的语义丰富表示，结合GAT进行协同过滤，并引入混合损失函数优化排名。

Result: 在MovieLens数据集上表现优于基线模型，LLM嵌入和余弦相似度项显著提升性能。

Conclusion: LLM的集成能显著提高推荐系统的准确性和可解释性。

Abstract: Recommender systems are essential for guiding users through the vast and
diverse landscape of digital content by delivering personalized and relevant
suggestions. However, improving both personalization and interpretability
remains a challenge, particularly in scenarios involving limited user feedback
or heterogeneous item attributes. In this article, we propose a novel hybrid
recommendation framework that combines Graph Attention Networks (GATs) with
Large Language Models (LLMs) to address these limitations. LLMs are first used
to enrich user and item representations by generating semantically meaningful
profiles based on metadata such as titles, genres, and overviews. These
enriched embeddings serve as initial node features in a user and movie
bipartite graph, which is processed using a GAT based collaborative filtering
model. To enhance ranking accuracy, we introduce a hybrid loss function that
combines Bayesian Personalized Ranking (BPR), cosine similarity, and robust
negative sampling. Post-processing involves reranking the GAT-generated
recommendations using the LLM, which also generates natural-language
justifications to improve transparency. We evaluated our model on benchmark
datasets, including MovieLens 100k and 1M, where it consistently outperforms
strong baselines. Ablation studies confirm that LLM-based embeddings and the
cosine similarity term significantly contribute to performance gains. This work
demonstrates the potential of integrating LLMs to improve both the accuracy and
interpretability of recommender systems.

</details>


### [83] [ChEmbed: Enhancing Chemical Literature Search Through Domain-Specific Text Embeddings](https://arxiv.org/abs/2508.01643)
*Ali Shiraee Kasmaee,Mohammad Khodadad,Mehdi Astaraki,Mohammad Arshi Saloot,Nicholas Sherck,Hamidreza Mahyar,Soheila Samiee*

Main category: cs.IR

TL;DR: ChEmbed是一种针对化学文献检索优化的文本嵌入模型，通过领域适配和化学专用令牌改进检索质量，显著优于通用嵌入模型。


<details>
  <summary>Details</summary>
Motivation: 通用文本嵌入模型在化学术语表示上表现不佳，导致检索质量低下，缺乏专门针对化学文献的嵌入模型。

Method: 开发了ChEmbed模型，基于化学特定文本数据集（PubChem、Semantic Scholar、ChemRxiv）进行微调，利用大语言模型生成合成查询，并扩展了900个化学专用令牌。

Result: 在ChemRxiv Retrieval基准测试中，ChEmbed将nDCG@10从0.82提升至0.91（+9个百分点）。

Conclusion: ChEmbed是一种轻量级、可复现的嵌入解决方案，显著提升了化学文献检索的效率。

Abstract: Retrieval-Augmented Generation (RAG) systems in chemistry heavily depend on
accurate and relevant retrieval of chemical literature. However,
general-purpose text embedding models frequently fail to adequately represent
complex chemical terminologies, resulting in suboptimal retrieval quality.
Specialized embedding models tailored to chemical literature retrieval have not
yet been developed, leaving a substantial performance gap. To address this
challenge, we introduce ChEmbed, a domain-adapted family of text embedding
models fine-tuned on a dataset comprising chemistry-specific text from the
PubChem, Semantic Scholar, and ChemRxiv corpora. To create effective training
data, we employ large language models to synthetically generate queries,
resulting in approximately 1.7 million high-quality query-passage pairs.
Additionally, we augment the tokenizer by adding 900 chemically specialized
tokens to previously unused slots, which significantly reduces the
fragmentation of chemical entities, such as IUPAC names. ChEmbed also maintains
a 8192-token context length, enabling the efficient retrieval of longer
passages compared to many other open-source embedding models, which typically
have a context length of 512 or 2048 tokens. Evaluated on our newly introduced
ChemRxiv Retrieval benchmark, ChEmbed outperforms state-of-the-art general
embedding models, raising nDCG@10 from 0.82 to 0.91 (+9 pp). ChEmbed represents
a practical, lightweight, and reproducible embedding solution that effectively
improves retrieval for chemical literature search.

</details>


### [84] [Counterfactual Reciprocal Recommender Systems for User-to-User Matching](https://arxiv.org/abs/2508.01867)
*Kazuki Kawamura,Takuma Udagawa,Kei Tateno*

Main category: cs.IR

TL;DR: 论文提出了一种名为CFRR的因果框架，用于解决互惠推荐系统中的偏见问题，通过逆倾向评分和自归一化目标，显著提升了推荐效果和公平性。


<details>
  <summary>Details</summary>
Motivation: 互惠推荐系统（如约会、游戏和人才平台）中的历史数据偏向热门用户，导致反馈循环加剧偏见，影响学习和公平性。

Method: 提出Counterfactual Reciprocal Recommender Systems (CFRR)，采用逆倾向评分和自归一化目标来减少偏见。

Result: 实验显示，CFRR在NDCG@10上提升3.5%，长尾用户覆盖率增加51%，基尼曝光不平等性降低24%。

Conclusion: CFRR为更准确和公平的用户匹配提供了有效解决方案。

Abstract: Reciprocal recommender systems (RRS) in dating, gaming, and talent platforms
require mutual acceptance for a match. Logged data, however, over-represents
popular profiles due to past exposure policies, creating feedback loops that
skew learning and fairness. We introduce Counterfactual Reciprocal Recommender
Systems (CFRR), a causal framework to mitigate this bias. CFRR uses inverse
propensity scored, self-normalized objectives. Experiments show CFRR improves
NDCG@10 by up to 3.5% (e.g., from 0.459 to 0.475 on DBLP, from 0.299 to 0.307
on Synthetic), increases long-tail user coverage by up to 51% (from 0.504 to
0.763 on Synthetic), and reduces Gini exposure inequality by up to 24% (from
0.708 to 0.535 on Synthetic). CFRR offers a promising approach for more
accurate and fair user-to-user matching.

</details>


### [85] [Evaluating Position Bias in Large Language Model Recommendations](https://arxiv.org/abs/2508.02020)
*Ethan Bito,Yongli Ren,Estrid He*

Main category: cs.IR

TL;DR: LLM-based recommendation models exhibit position bias, where input order affects recommendations. A new prompting strategy, RISE, is introduced to mitigate this bias, showing improved stability without fine-tuning.


<details>
  <summary>Details</summary>
Motivation: To address the position bias in LLM-based recommendation models, which can disproportionately influence recommendations based on input order.

Method: Analyze position bias in LLM-based recommendations on real-world datasets and introduce the RISE prompting strategy to mitigate bias.

Result: RISE reduces sensitivity to input ordering and improves stability, outperforming baselines without requiring fine-tuning.

Conclusion: The RISE method effectively mitigates position bias in LLM-based recommendations, enhancing their reliability for practical use.

Abstract: Large Language Models (LLMs) are being increasingly explored as
general-purpose tools for recommendation tasks, enabling zero-shot and
instruction-following capabilities without the need for task-specific training.
While the research community is enthusiastically embracing LLMs, there are
important caveats to directly adapting them for recommendation tasks. In this
paper, we show that LLM-based recommendation models suffer from position bias,
where the order of candidate items in a prompt can disproportionately influence
the recommendations produced by LLMs. First, we analyse the position bias of
LLM-based recommendations on real-world datasets, where results uncover
systemic biases of LLMs with high sensitivity to input orders. Furthermore, we
introduce a new prompting strategy to mitigate the position bias of LLM
recommendation models called Ranking via Iterative SElection (RISE). We compare
our proposed method against various baselines on key benchmark datasets.
Experiment results show that our method reduces sensitivity to input ordering
and improves stability without requiring model fine-tuning or post-processing.

</details>


### [86] [Why Generate When You Can Transform? Unleashing Generative Attention for Dynamic Recommendation](https://arxiv.org/abs/2508.02050)
*Yuli Liu,Wenjun Kong,Cheng Luo,Weizhi Ma*

Main category: cs.IR

TL;DR: 论文提出生成式注意力机制替代传统确定性注意力，提升序列推荐的灵活性和表现力。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制因线性确定性限制，难以捕捉用户偏好的动态非线性特征。

Method: 提出基于变分自编码器（VAE）和扩散模型（DMs）的两种生成式注意力模型。

Result: 实验证明模型在准确性和多样性上显著优于现有方法。

Conclusion: 生成式注意力机制为序列推荐提供了更灵活和表达力强的解决方案。

Abstract: Sequential Recommendation (SR) focuses on personalizing user experiences by
predicting future preferences based on historical interactions. Transformer
models, with their attention mechanisms, have become the dominant architecture
in SR tasks due to their ability to capture dependencies in user behavior
sequences. However, traditional attention mechanisms, where attention weights
are computed through query-key transformations, are inherently linear and
deterministic. This fixed approach limits their ability to account for the
dynamic and non-linear nature of user preferences, leading to challenges in
capturing evolving interests and subtle behavioral patterns. Given that
generative models excel at capturing non-linearity and probabilistic
variability, we argue that generating attention distributions offers a more
flexible and expressive alternative compared to traditional attention
mechanisms. To support this claim, we present a theoretical proof demonstrating
that generative attention mechanisms offer greater expressiveness and
stochasticity than traditional deterministic approaches. Building upon this
theoretical foundation, we introduce two generative attention models for SR,
each grounded in the principles of Variational Autoencoders (VAE) and Diffusion
Models (DMs), respectively. These models are designed specifically to generate
adaptive attention distributions that better align with variable user
preferences. Extensive experiments on real-world datasets show our models
significantly outperform state-of-the-art in both accuracy and diversity.

</details>


### [87] [Evaluating User Experience in Conversational Recommender Systems: A Systematic Review Across Classical and LLM-Powered Approaches](https://arxiv.org/abs/2508.02096)
*Raj Mahmud,Yufeng Wu,Abdullah Bin Sawad,Shlomo Berkovsky,Mukesh Prasad,A. Baki Kocaballi*

Main category: cs.IR

TL;DR: 本文系统综述了2017-2025年间23项实证研究，揭示了对话推荐系统(CRS)用户体验(UX)评估的局限性，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 填补对话推荐系统(CRS)用户体验(UX)评估的空白，特别是在自适应和基于大型语言模型(LLM)的系统中。

Method: 遵循PRISMA指南进行系统综述，分析23项实证研究。

Result: 发现UX评估的局限性，如事后调查主导、情感UX构造评估不足、自适应行为与UX结果关联少，LLM引入的新问题未充分评估。

Conclusion: 提出了UX评估的结构化框架和改进方向，支持更透明、以用户为中心的CRS评估实践。

Abstract: Conversational Recommender Systems (CRSs) are receiving growing research
attention across domains, yet their user experience (UX) evaluation remains
limited. Existing reviews largely overlook empirical UX studies, particularly
in adaptive and large language model (LLM)-based CRSs. To address this gap, we
conducted a systematic review following PRISMA guidelines, synthesising 23
empirical studies published between 2017 and 2025. We analysed how UX has been
conceptualised, measured, and shaped by domain, adaptivity, and LLM.
  Our findings reveal persistent limitations: post hoc surveys dominate,
turn-level affective UX constructs are rarely assessed, and adaptive behaviours
are seldom linked to UX outcomes. LLM-based CRSs introduce further challenges,
including epistemic opacity and verbosity, yet evaluations infrequently address
these issues. We contribute a structured synthesis of UX metrics, a comparative
analysis of adaptive and nonadaptive systems, and a forward-looking agenda for
LLM-aware UX evaluation. These findings support the development of more
transparent, engaging, and user-centred CRS evaluation practices.

</details>


### [88] [FinCPRG: A Bidirectional Generation Pipeline for Hierarchical Queries and Rich Relevance in Financial Chinese Passage Retrieval](https://arxiv.org/abs/2508.02222)
*Xuan Xu,Beilin Chu,Qinhong Lin,Yixiao Zhong,Fufang Wen,Jiaqi Liu,Binjie Fei,Yu Li,Zhongliang Yang,Linna Zhou*

Main category: cs.IR

TL;DR: 本文提出了一种双向生成管道，用于构建层次化查询和丰富相关性标签的金融段落检索数据集（FinCPRG）。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在跨文档查询需求表达和标注质量控制方面的局限性。

Method: 采用双向生成管道，包括自下而上（从单文档生成查询）和自上而下（从多文档标题生成查询）的方法，并结合直接映射标注和间接正例挖掘。

Result: 构建了包含层次化查询和丰富相关性标签的FinCPRG数据集，并通过实验验证了其有效性。

Conclusion: FinCPRG在段落检索的训练和基准测试中表现出色，解决了现有方法的不足。

Abstract: In recent years, large language models (LLMs) have demonstrated significant
potential in constructing passage retrieval datasets. However, existing methods
still face limitations in expressing cross-doc query needs and controlling
annotation quality. To address these issues, this paper proposes a
bidirectional generation pipeline, which aims to generate 3-level hierarchical
queries for both intra-doc and cross-doc scenarios and mine additional
relevance labels on top of direct mapping annotation. The pipeline introduces
two query generation methods: bottom-up from single-doc text and top-down from
multi-doc titles. The bottom-up method uses LLMs to disassemble and generate
structured queries at both sentence-level and passage-level simultaneously from
intra-doc passages. The top-down approach incorporates three key financial
elements--industry, topic, and time--to divide report titles into clusters and
prompts LLMs to generate topic-level queries from each cluster. For relevance
annotation, our pipeline not only relies on direct mapping annotation from the
generation relationship but also implements an indirect positives mining method
to enrich the relevant query-passage pairs. Using this pipeline, we constructed
a Financial Passage Retrieval Generated dataset (FinCPRG) from almost 1.3k
Chinese financial research reports, which includes hierarchical queries and
rich relevance labels. Through evaluations of mined relevance labels,
benchmarking and training experiments, we assessed the quality of FinCPRG and
validated its effectiveness as a passage retrieval dataset for both training
and benchmarking.

</details>


### [89] [From Generation to Consumption: Personalized List Value Estimation for Re-ranking](https://arxiv.org/abs/2508.02242)
*Kaike Zhang,Xiaobei Wang,Xiaoyu Liu,Shuchang Liu,Hailan Yang,Xiang Li,Fei Sun,Qi Cao*

Main category: cs.IR

TL;DR: CAVE提出了一种个性化消费感知的列表价值评估框架，通过建模用户退出行为来更准确地估计推荐列表的实际消费价值。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了用户可能在消费完整列表前退出的情况，导致估计值与实际消费值不匹配。

Method: CAVE将列表价值建模为子列表价值的期望，加权用户在每个位置的退出概率，并分解退出概率为兴趣驱动和随机因素（如疲劳）。

Result: 在多个数据集和在线A/B测试中，CAVE表现优于基线方法。

Conclusion: 显式建模用户退出行为能显著提升重排序效果。

Abstract: Re-ranking is critical in recommender systems for optimizing the order of
recommendation lists, thus improving user satisfaction and platform revenue.
Most existing methods follow a generator-evaluator paradigm, where the
evaluator estimates the overall value of each candidate list. However, they
often ignore the fact that users may exit before consuming the full list,
leading to a mismatch between estimated generation value and actual consumption
value. To bridge this gap, we propose CAVE, a personalized Consumption-Aware
list Value Estimation framework. CAVE formulates the list value as the
expectation over sub-list values, weighted by user-specific exit probabilities
at each position. The exit probability is decomposed into an interest-driven
component and a stochastic component, the latter modeled via a Weibull
distribution to capture random external factors such as fatigue. By jointly
modeling sub-list values and user exit behavior, CAVE yields a more faithful
estimate of actual list consumption value. We further contribute three
large-scale real-world list-wise benchmarks from the Kuaishou platform, varying
in size and user activity patterns. Extensive experiments on these benchmarks,
two Amazon datasets, and online A/B testing on Kuaishou show that CAVE
consistently outperforms strong baselines, highlighting the benefit of
explicitly modeling user exits in re-ranking.

</details>


### [90] [Voronoi Diagram Encoded Hashing](https://arxiv.org/abs/2508.02266)
*Yang Xu,Kai Ming Ting*

Main category: cs.IR

TL;DR: 论文提出了一种基于Voronoi图的无学习哈希方法VDeH，其性能优于现有方法且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 现有学习哈希方法（L2H）存在局限性，如性能与无学习方法相当且仅支持三种哈希函数类型，因此探索Voronoi图在哈希中的潜力。

Method: 利用Voronoi图的特性，提出VDeH方法，通过数据依赖的相似性度量构建哈希函数，并生成独立的二进制位。

Result: 在多个基准数据集上，VDeH在相同比特长度下表现出更优的性能和更低的计算成本。

Conclusion: VDeH展示了Voronoi图在哈希中的潜力，为无学习哈希提供了高效且性能优越的解决方案。

Abstract: The goal of learning to hash (L2H) is to derive data-dependent hash functions
from a given data distribution in order to map data from the input space to a
binary coding space. Despite the success of L2H, two observations have cast
doubt on the source of the power of L2H, i.e., learning. First, a recent study
shows that even using a version of locality sensitive hashing functions without
learning achieves binary representations that have comparable accuracy as those
of L2H, but with less time cost. Second, existing L2H methods are constrained
to three types of hash functions: thresholding, hyperspheres, and hyperplanes
only. In this paper, we unveil the potential of Voronoi diagrams in hashing.
Voronoi diagram is a suitable candidate because of its three properties. This
discovery has led us to propose a simple and efficient no-learning binary
hashing method, called Voronoi Diagram Encoded Hashing (VDeH), which constructs
a set of hash functions through a data-dependent similarity measure and
produces independent binary bits through encoded hashing. We demonstrate
through experiments on several benchmark datasets that VDeH achieves superior
performance and lower computational cost compared to existing state-of-the-art
methods under the same bit length.

</details>


### [91] [Research Knowledge Graphs in NFDI4DataScience: Key Activities, Achievements, and Future Directions](https://arxiv.org/abs/2508.02300)
*Kanishka Silva,Marcel R. Ackermann,Heike Fliegl,Genet-Asefa Gesese,Fidan Limani,Philipp Mayr,Peter Mutschke,Allard Oelen,Muhammad Asif Suryani,Sharmila Upadhyaya,Benjamin Zapilko,Harald Sack,Stefan Dietze*

Main category: cs.IR

TL;DR: 论文介绍了NFDI4DataScience联盟如何通过研究知识图谱（RKGs）解决AI和数据科学研究中的透明性、可重复性和可发现性问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI和数据科学研究的复杂性和体量增长，确保研究的透明性、可重复性和可发现性变得困难。

Method: 利用标准化本体、共享词汇和自动化信息提取技术构建语义丰富的研究知识图谱。

Result: 开发了NFDI4DS本体、元数据标准、工具和服务，支持FAIR原则，并实现了多个社区项目和RKG实例。

Conclusion: 这些努力旨在捕捉和连接数据集、模型、软件和科学出版物之间的复杂关系。

Abstract: As research in Artificial Intelligence and Data Science continues to grow in
volume and complexity, it becomes increasingly difficult to ensure
transparency, reproducibility, and discoverability. To address these
challenges, as research artifacts should be understandable and usable by
machines, the NFDI4DataScience consortium is developing and providing Research
Knowledge Graphs (RKGs). Building upon earlier works, this paper presents
recent progress in creating semantically rich RKGs using standardized
ontologies, shared vocabularies, and automated Information Extraction
techniques. Key achievements include the development of the NFDI4DS ontology,
metadata standards, tools, and services designed to support the FAIR
principles, as well as community-led projects and various implementations of
RKGs. Together, these efforts aim to capture and connect the complex
relationships between datasets, models, software, and scientific publications.

</details>


### [92] [Agentic Personalized Fashion Recommendation in the Age of Generative AI: Challenges, Opportunities, and Evaluation](https://arxiv.org/abs/2508.02342)
*Yashar Deldjoo,Nima Rafiee,Mahdyar Ravanbakhsh*

Main category: cs.IR

TL;DR: 本文探讨了时尚推荐系统（FaRS）面临的独特挑战，并提出了一种混合模态细化（AMMR）管道，以解决动态趋势和用户需求。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统难以捕捉时尚领域的动态变化和复杂关系，导致用户满意度下降。本文旨在解决这一问题。

Method: 提出了一种混合模态细化（AMMR）管道，结合多模态编码器、代理LLM规划器和动态检索。

Result: AMMR能够更好地满足用户和品牌的需求，适应快速变化的时尚库存。

Conclusion: 未来的时尚推荐系统需要向自适应、生成式和利益相关者感知的方向发展。

Abstract: Fashion recommender systems (FaRS) face distinct challenges due to rapid
trend shifts, nuanced user preferences, intricate item-item compatibility, and
the complex interplay among consumers, brands, and influencers. Traditional
recommendation approaches, largely static and retrieval-focused, struggle to
effectively capture these dynamic elements, leading to decreased user
satisfaction and elevated return rates. This paper synthesizes both academic
and industrial viewpoints to map the distinctive output space and stakeholder
ecosystem of modern FaRS, identifying the complex interplay among users,
brands, platforms, and influencers, and highlighting the unique data and
modeling challenges that arise.
  We outline a research agenda for industrial FaRS, centered on five
representative scenarios spanning static queries, outfit composition, and
multi-turn dialogue, and argue that mixed-modality refinement-the ability to
combine image-based references (anchors) with nuanced textual constraints-is a
particularly critical task for real-world deployment. To this end, we propose
an Agentic Mixed-Modality Refinement (AMMR) pipeline, which fuses multimodal
encoders with agentic LLM planners and dynamic retrieval, bridging the gap
between expressive user intent and fast-changing fashion inventories. Our work
shows that moving beyond static retrieval toward adaptive, generative, and
stakeholder-aware systems is essential to satisfy the evolving expectations of
fashion consumers and brands.

</details>


### [93] [Beyond Chunks and Graphs: Retrieval-Augmented Generation through Triplet-Driven Thinking](https://arxiv.org/abs/2508.02435)
*Shengbo Gong,Xianfeng Tang,Carl Yang,Wei jin*

Main category: cs.IR

TL;DR: T$^2$RAG是一种新型检索增强生成框架，通过基于原子三元组的简单知识库，显著提升性能并降低成本。


<details>
  <summary>Details</summary>
Motivation: 解决多轮RAG和Graph RAG在性能与效率之间的权衡问题。

Method: 利用LLM将问题分解为可搜索的三元组，并通过迭代检索三元组数据库中的证据来解决问题。

Result: 在六个数据集上平均性能提升11%，检索成本降低45%。

Conclusion: T$^2$RAG在性能和效率上优于现有方法，具有实际应用潜力。

Abstract: Retrieval-augmented generation (RAG) is critical for reducing hallucinations
and incorporating external knowledge into Large Language Models (LLMs).
However, advanced RAG systems face a trade-off between performance and
efficiency. Multi-round RAG approaches achieve strong reasoning but incur
excessive LLM calls and token costs, while Graph RAG methods suffer from
computationally expensive, error-prone graph construction and retrieval
redundancy. To address these challenges, we propose T$^2$RAG, a novel framework
that operates on a simple, graph-free knowledge base of atomic triplets.
T$^2$RAG leverages an LLM to decompose questions into searchable triplets with
placeholders, which it then iteratively resolves by retrieving evidence from
the triplet database. Empirical results show that T$^2$RAG significantly
outperforms state-of-the-art multi-round and Graph RAG methods, achieving an
average performance gain of up to 11\% across six datasets while reducing
retrieval costs by up to 45\%. Our code is available at
https://github.com/rockcor/T2RAG

</details>


### [94] [Dynamic Forgetting and Spatio-Temporal Periodic Interest Modeling for Local-Life Service Recommendation](https://arxiv.org/abs/2508.02451)
*Zhaoyu Hu,Hao Guo,Yuan Tian,Erpeng Xue,Jianyang Wang,Xianyang Qi,Hongxiang Lin,Lei Wang,Sheng Chen*

Main category: cs.IR

TL;DR: 论文提出了一种基于遗忘曲线的时空周期性兴趣建模方法（STIM），用于解决本地生活服务平台中用户行为序列建模的稀疏性和时空依赖性问题，显著提升了交易量。


<details>
  <summary>Details</summary>
Motivation: 在数字经济的背景下，推荐系统面临用户行为序列稀疏性和强时空依赖性的挑战，通过模拟人类记忆的遗忘过程来改进推荐效果。

Method: STIM方法包括基于遗忘曲线的动态掩码模块、查询混合专家（MoE）方法和分层多兴趣网络单元，用于提取时空特征和建模用户兴趣。

Result: 在线A/B测试显示，STIM方法使总交易量（GTV）提升了1.54%，离线实验也验证了其有效性。

Conclusion: STIM方法成功应用于大规模本地生活服务推荐系统，显著提升了推荐效果。

Abstract: In the context of the booming digital economy, recommendation systems, as a
key link connecting users and numerous services, face challenges in modeling
user behavior sequences on local-life service platforms, including the sparsity
of long sequences and strong spatio-temporal dependence. Such challenges can be
addressed by drawing an analogy to the forgetting process in human memory. This
is because users' responses to recommended content follow the recency effect
and the cyclicality of memory. By exploring this, this paper introduces the
forgetting curve and proposes Spatio-Temporal periodic Interest Modeling (STIM)
with long sequences for local-life service recommendation. STIM integrates
three key components: a dynamic masking module based on the forgetting curve,
which is used to extract both recent spatiotemporal features and periodic
spatiotemporal features; a query-based mixture of experts (MoE) approach that
can adaptively activate expert networks under different dynamic masks, enabling
the collaborative modeling of time, location, and items; and a hierarchical
multi-interest network unit, which captures multi-interest representations by
modeling the hierarchical interactions between the shallow and deep semantics
of users' recent behaviors. By introducing the STIM method, we conducted online
A/B tests and achieved a 1.54\% improvement in gross transaction volume (GTV).
In addition, extended offline experiments also showed improvements. STIM has
been deployed in a large-scale local-life service recommendation system,
serving hundreds of millions of daily active users in core application
scenarios.

</details>


### [95] [Decomposed Reasoning with Reinforcement Learning for Relevance Assessment in UGC Platforms](https://arxiv.org/abs/2508.02506)
*Xiaowei Yuan,Lei Jin,Haoxin Zhang,Yan Gao,Yi Wu,Yao Hu,Ziyang Huang,Jun Zhao,Kang Liu*

Main category: cs.IR

TL;DR: 论文提出了一种名为R3A的模型，通过分解推理框架和强化学习，解决了UGC平台中查询-文档对相关性评估的挑战。


<details>
  <summary>Details</summary>
Motivation: UGC平台中，用户意图模糊和内容噪声大，导致检索增强生成（RAG）的相关性评估效果不佳。

Method: R3A采用分解推理框架，利用高排名文档推断查询意图，并通过片段提取减少噪声影响，结合强化学习优化模型。

Result: 实验表明，R3A在离线和在线实验中均显著优于现有基线方法。

Conclusion: R3A有效提升了UGC平台中相关性评估的准确性。

Abstract: Retrieval-augmented generation (RAG) plays a critical role in user-generated
content (UGC) platforms, but its effectiveness depends heavily on accurate
relevance assessment of query-document pairs. Despite recent advances in
applying large language models (LLMs) to relevance modeling, UGC platforms
present unique challenges: 1) ambiguous user intent due to sparse user feedback
in RAG scenarios, and 2) substantial noise introduced by informal and
unstructured language. To address these issues, we propose the Reinforced
Reasoning Model for Relevance Assessment (R3A), which introduces a decomposed
reasoning framework over queries and candidate documents before scoring. R3A
first leverages auxiliary high-ranked documents within the platform to infer
latent query intent. It then performs verbatim fragment extraction to justify
relevance decisions, thereby reducing errors caused by noisy UGC. Based on a
reinforcement learning framework, R3A is optimized to mitigate distortions
arising from ambiguous queries and unstructured content. Experimental results
show that R3A significantly outperforms existing baseline methods in terms of
relevance accuracy, across both offline benchmarks and online experiments.

</details>


### [96] [Hubness Reduction with Dual Bank Sinkhorn Normalization for Cross-Modal Retrieval](https://arxiv.org/abs/2508.02538)
*Zhengxin Pan,Haishuai Wang,Fangyu Wu,Peng Zhang,Jiajun Bu*

Main category: cs.IR

TL;DR: 论文提出了一种概率平衡框架（DBSN）来解决跨模态检索中的hubness问题，通过平衡查询和目标概率，显著提升了检索精度。


<details>
  <summary>Details</summary>
Motivation: 尽管跨模态检索取得了进展，但hubness问题仍影响相似性测量的准确性。现有方法机制不明确，需要更有效的解决方案。

Method: 分析了Inverted Softmax方法，提出概率平衡框架，并引入Sinkhorn Normalization（SN）和Dual Bank Sinkhorn Normalization（DBSN）来平衡查询和目标概率。

Result: 在多种跨模态检索任务中（如图文、视频-文本、音频-文本检索），SN和DBSN均表现出性能提升。

Conclusion: DBSN通过平衡查询和目标概率，有效解决了hubness问题，提升了跨模态检索的精度。

Abstract: The past decade has witnessed rapid advancements in cross-modal retrieval,
with significant progress made in accurately measuring the similarity between
cross-modal pairs. However, the persistent hubness problem, a phenomenon where
a small number of targets frequently appear as nearest neighbors to numerous
queries, continues to hinder the precision of similarity measurements. Despite
several proposed methods to reduce hubness, their underlying mechanisms remain
poorly understood. To bridge this gap, we analyze the widely-adopted Inverted
Softmax approach and demonstrate its effectiveness in balancing target
probabilities during retrieval. Building on these insights, we propose a
probability-balancing framework for more effective hubness reduction. We
contend that balancing target probabilities alone is inadequate and, therefore,
extend the framework to balance both query and target probabilities by
introducing Sinkhorn Normalization (SN). Notably, we extend SN to scenarios
where the true query distribution is unknown, showing that current methods,
which rely solely on a query bank to estimate target hubness, produce
suboptimal results due to a significant distributional gap between the query
bank and targets. To mitigate this issue, we introduce Dual Bank Sinkhorn
Normalization (DBSN), incorporating a corresponding target bank alongside the
query bank to narrow this distributional gap. Our comprehensive evaluation
across various cross-modal retrieval tasks, including image-text retrieval,
video-text retrieval, and audio-text retrieval, demonstrates consistent
performance improvements, validating the effectiveness of both SN and DBSN. All
codes are publicly available at https://github.com/ppanzx/DBSN.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [97] [PCS Workflow for Veridical Data Science in the Age of AI](https://arxiv.org/abs/2508.00835)
*Zachary T. Rewolinski,Bin Yu*

Main category: cs.LG

TL;DR: 本文介绍了PCS框架，旨在解决数据科学生命周期中的不确定性，并通过案例研究展示了数据清理阶段的决策对预测的影响。


<details>
  <summary>Details</summary>
Motivation: 数据科学在AI中至关重要，但其结果难以复现，主要原因是数据科学生命周期中的不确定性。传统统计方法未能有效解决这一问题。

Method: 提出更新的PCS框架，结合生成式AI，提供原则性方法以应对数据科学生命周期中的不确定性。

Result: 通过案例研究展示了数据清理阶段的决策如何影响下游预测的不确定性。

Conclusion: PCS框架为数据科学提供了一种可验证的方法，帮助减少不确定性并提高结果的可复现性。

Abstract: Data science is a pillar of artificial intelligence (AI), which is
transforming nearly every domain of human activity, from the social and
physical sciences to engineering and medicine. While data-driven findings in AI
offer unprecedented power to extract insights and guide decision-making, many
are difficult or impossible to replicate. A key reason for this challenge is
the uncertainty introduced by the many choices made throughout the data science
life cycle (DSLC). Traditional statistical frameworks often fail to account for
this uncertainty. The Predictability-Computability-Stability (PCS) framework
for veridical (truthful) data science offers a principled approach to
addressing this challenge throughout the DSLC. This paper presents an updated
and streamlined PCS workflow, tailored for practitioners and enhanced with
guided use of generative AI. We include a running example to display the PCS
framework in action, and conduct a related case study which showcases the
uncertainty in downstream predictions caused by judgment calls in the data
cleaning stage.

</details>


### [98] [A Residual Guided strategy with Generative Adversarial Networks in training Physics-Informed Transformer Networks](https://arxiv.org/abs/2508.00855)
*Ziyang Zhang,Feifan Zhang,Weidong Tang,Lei Shi,Tailai Chen*

Main category: cs.LG

TL;DR: 提出了一种基于GAN的残差引导训练策略，通过Transformer和GAN结合解决PINNs在时空区域残差未解析和时序因果性违反的问题。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在复杂物理系统建模中存在残差未解析和时序因果性违反的局限性。

Method: 采用解码器Transformer捕捉时序相关性，结合残差感知GAN动态识别高残差区域，并引入因果惩罚项和自适应采样机制。

Result: 在Allen-Cahn、Klein-Gordon和Navier-Stokes方程上实验，相对MSE降低达三个数量级。

Conclusion: 该方法填补了深度学习与物理驱动建模的鸿沟，为多尺度和时间依赖PDE系统提供了鲁棒解决方案。

Abstract: Nonlinear partial differential equations (PDEs) are pivotal in modeling
complex physical systems, yet traditional Physics-Informed Neural Networks
(PINNs) often struggle with unresolved residuals in critical spatiotemporal
regions and violations of temporal causality. To address these limitations, we
propose a novel Residual Guided Training strategy for Physics-Informed
Transformer via Generative Adversarial Networks (GAN). Our framework integrates
a decoder-only Transformer to inherently capture temporal correlations through
autoregressive processing, coupled with a residual-aware GAN that dynamically
identifies and prioritizes high-residual regions. By introducing a causal
penalty term and an adaptive sampling mechanism, the method enforces temporal
causality while refining accuracy in problematic domains. Extensive numerical
experiments on the Allen-Cahn, Klein-Gordon, and Navier-Stokes equations
demonstrate significant improvements, achieving relative MSE reductions of up
to three orders of magnitude compared to baseline methods. This work bridges
the gap between deep learning and physics-driven modeling, offering a robust
solution for multiscale and time-dependent PDE systems.

</details>


### [99] [Deploying Geospatial Foundation Models in the Real World: Lessons from WorldCereal](https://arxiv.org/abs/2508.00858)
*Christina Butsko,Kristof Van Tricht,Gabriel Tseng,Giorgia Milli,David Rolnick,Ruben Cartuyvels,Inbal Becker Reshef,Zoltan Szantoi,Hannah Kerner*

Main category: cs.LG

TL;DR: 本文提出了一种结构化方法，将地理空间基础模型整合到实际应用中，通过案例研究展示了其性能提升和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 地理空间基础模型在遥感应用中有潜力，但实际部署面临挑战，标准化评估未能捕捉真实世界的复杂性。

Method: 提出三步协议：定义应用需求、适应领域数据、严格实证测试，并以Presto模型在作物制图中的案例为例。

Result: 微调预训练模型显著优于传统监督方法，展示了强大的时空泛化能力。

Conclusion: 该协议为实践者提供了可复制的蓝图，并为未来研究奠定了基础，展示了框架的可扩展性。

Abstract: The increasing availability of geospatial foundation models has the potential
to transform remote sensing applications such as land cover classification,
environmental monitoring, and change detection. Despite promising benchmark
results, the deployment of these models in operational settings is challenging
and rare. Standardized evaluation tasks often fail to capture real-world
complexities relevant for end-user adoption such as data heterogeneity,
resource constraints, and application-specific requirements. This paper
presents a structured approach to integrate geospatial foundation models into
operational mapping systems. Our protocol has three key steps: defining
application requirements, adapting the model to domain-specific data and
conducting rigorous empirical testing. Using the Presto model in a case study
for crop mapping, we demonstrate that fine-tuning a pre-trained model
significantly improves performance over conventional supervised methods. Our
results highlight the model's strong spatial and temporal generalization
capabilities. Our protocol provides a replicable blueprint for practitioners
and lays the groundwork for future research to operationalize foundation models
in diverse remote sensing applications. Application of the protocol to the
WorldCereal global crop-mapping system showcases the framework's scalability.

</details>


### [100] [Discrete approach to machine learning](https://arxiv.org/abs/2508.00869)
*Dmitriy Kashitsyn,Dmitriy Shabanov*

Main category: cs.LG

TL;DR: 论文提出了一种基于稀疏位向量和固定长度线性向量的编码与结构信息处理方法，探讨了多维代码的降维和离散嵌入的几何方法，并研究了三种模态下的代码空间结构与性质。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索多维代码的降维和离散嵌入方法，以反映不同模态的内部结构，并尝试与哺乳动物新皮质的组织结构进行类比。

Method: 采用稀疏位向量和固定长度线性向量进行编码，提出离散的随机降维方法和几何离散嵌入方法，并以语言形态学和免疫组化标记为例进行分析。

Result: 研究发现代码空间的布局与新皮质的“风车”结构存在相似性，推测模型中的过程可能与新皮质的组织方式类似。

Conclusion: 论文展示了代码空间结构与新皮质组织的潜在相似性，为未来研究提供了新的视角。

Abstract: The article explores an encoding and structural information processing
approach using sparse bit vectors and fixed-length linear vectors. The
following are presented: a discrete method of speculative stochastic
dimensionality reduction of multidimensional code and linear spaces with linear
asymptotic complexity; a geometric method for obtaining discrete embeddings of
an organised code space that reflect the internal structure of a given
modality. The structure and properties of a code space are investigated using
three modalities as examples: morphology of Russian and English languages, and
immunohistochemical markers. Parallels are drawn between the resulting map of
the code space layout and so-called pinwheels appearing on the mammalian
neocortex. A cautious assumption is made about similarities between neocortex
organisation and processes happening in our models.

</details>


### [101] [A Data-Driven Machine Learning Approach for Predicting Axial Load Capacity in Steel Storage Rack Columns](https://arxiv.org/abs/2508.00876)
*Bakhtiyar Mammadli,Casim Yazici,Muhammed Gürbüz,İrfan Kocaman,F. Javier Dominguez-Gutierrez,Fatih Mehmet Özkal*

Main category: cs.LG

TL;DR: 提出了一种基于机器学习的框架，用于预测冷弯型钢构件的轴向承载能力，通过梯度提升回归和SHAP解释性分析，实现了高精度预测和模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统分析方法难以捕捉冷弯型钢构件在屈曲行为中的非线性和几何复杂性，因此需要一种更准确且可解释的预测方法。

Method: 采用多种回归算法（从线性模型到核回归和集成树方法）进行模型选择，最终选择梯度提升回归，并使用SHAP进行特征重要性分析。

Result: 梯度提升回归在多个指标（如R2、RMSE、MAE）上表现最佳，并通过交互式Web工具实现了实际应用。

Conclusion: 该框架为结构工程师提供了一种高效、准确的预测工具，提升了设计安全性和决策效率。

Abstract: In this study, we present a machine learning (ML) framework to predict the
axial load-bearing capacity, (kN), of cold-formed steel structural members. The
methodology emphasizes robust model selection and interpretability, addressing
the limitations of traditional analytical approaches in capturing the
nonlinearities and geometrical complexities inherent to buckling behavior. The
dataset, comprising key geometric and mechanical parameters of steel columns,
was curated with appropriate pre-processing steps including removal of
non-informative identifiers and imputation of missing values. A comprehensive
suite of regression algorithms, ranging from linear models to kernel-based
regressors and ensemble tree methods was evaluated. Among these, Gradient
Boosting Regression exhibited superior predictive performance across multiple
metrics, including the coefficient of determination (R2), root mean squared
error (RMSE), and mean absolute error (MAE), and was consequently selected as
the final model. Model interpretability was addressed using SHapley Additive
exPlanations (SHAP), enabling insight into the relative importance and
interaction of input features influencing the predicted axial capacity. To
facilitate practical deployment, the model was integrated into an interactive,
Python-based web interface via Streamlit. This tool allows end-users-such as
structural engineers and designers, to input design parameters manually or
through CSV upload, and to obtain real-time predictions of axial load capacity
without the need for programming expertise. Applied to the context of steel
storage rack columns, the framework demonstrates how data-driven tools can
enhance design safety, streamline validation workflows, and inform
decision-making in structural applications where buckling is a critical failure
mode

</details>


### [102] [Satellite Connectivity Prediction for Fast-Moving Platforms](https://arxiv.org/abs/2508.00877)
*Chao Yan,Babak Mafakheri*

Main category: cs.LG

TL;DR: 论文探讨了利用机器学习预测卫星信号质量，以提升移动物体（如飞机）的卫星连接可靠性，测试F1分数达0.97。


<details>
  <summary>Details</summary>
Motivation: 随着对无缝互联网接入需求的增长，卫星连接在移动物体（如飞机）中的重要性日益凸显，但频繁切换卫星信号带来挑战。

Method: 通过分析GEO卫星与飞机通信的真实数据集，利用机器学习预测信号质量，并实现主动网络切换。

Result: 预测模型在测试数据上F1分数达0.97，验证了机器学习在信号质量预测中的准确性。

Conclusion: 该模型可提升卫星通信效率，并适用于其他移动物体，如车辆和火车，具有广泛适用性。

Abstract: Satellite connectivity is gaining increased attention as the demand for
seamless internet access, especially in transportation and remote areas,
continues to grow. For fast-moving objects such as aircraft, vehicles, or
trains, satellite connectivity is critical due to their mobility and frequent
presence in areas without terrestrial coverage. Maintaining reliable
connectivity in these cases requires frequent switching between satellite
beams, constellations, or orbits. To enhance user experience and address
challenges like long switching times, Machine Learning (ML) algorithms can
analyze historical connectivity data and predict network quality at specific
locations. This allows for proactive measures, such as network switching before
connectivity issues arise. In this paper, we analyze a real dataset of
communication between a Geostationary Orbit (GEO) satellite and aircraft over
multiple flights, using ML to predict signal quality. Our prediction model
achieved an F1 score of 0.97 on the test data, demonstrating the accuracy of
machine learning in predicting signal quality during flight. By enabling
seamless broadband service, including roaming between different satellite
constellations and providers, our model addresses the need for real-time
predictions of signal quality. This approach can further be adapted to automate
satellite and beam-switching mechanisms to improve overall communication
efficiency. The model can also be retrained and applied to any moving object
with satellite connectivity, using customized datasets, including connected
vehicles and trains.

</details>


### [103] [GNN-ASE: Graph-Based Anomaly Detection and Severity Estimation in Three-Phase Induction Machines](https://arxiv.org/abs/2508.00879)
*Moutaz Bellah Bentrad,Adel Ghoggal,Tahar Bahi,Abderaouf Bahi*

Main category: cs.LG

TL;DR: 论文提出了一种基于图神经网络（GNN）的无模型方法，用于感应电机的故障诊断，避免了传统模型方法的复杂性和计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的诊断方法复杂且计算成本高，需要开发动态模型，难以实现。

Method: 使用GNN-ASE模型直接从原始电流和振动信号中自动学习特征，无需预处理或手动特征提取。

Result: 模型在偏心缺陷、轴承故障和断条检测中分别达到92.5%、91.2%和93.1%的准确率。

Conclusion: GNN框架提供了一种轻量且强大的解决方案，简化了实现并保持了高诊断性能，是传统方法的替代选择。

Abstract: The diagnosis of induction machines has traditionally relied on model-based
methods that require the development of complex dynamic models, making them
difficult to implement and computationally expensive. To overcome these
limitations, this paper proposes a model-free approach using Graph Neural
Networks (GNNs) for fault diagnosis in induction machines. The focus is on
detecting multiple fault types -- including eccentricity, bearing defects, and
broken rotor bars -- under varying severity levels and load conditions. Unlike
traditional approaches, raw current and vibration signals are used as direct
inputs, eliminating the need for signal preprocessing or manual feature
extraction. The proposed GNN-ASE model automatically learns and extracts
relevant features from raw inputs, leveraging the graph structure to capture
complex relationships between signal types and fault patterns. It is evaluated
for both individual fault detection and multi-class classification of combined
fault conditions. Experimental results demonstrate the effectiveness of the
proposed model, achieving 92.5\% accuracy for eccentricity defects, 91.2\% for
bearing faults, and 93.1\% for broken rotor bar detection. These findings
highlight the model's robustness and generalization capability across different
operational scenarios. The proposed GNN-based framework offers a lightweight
yet powerful solution that simplifies implementation while maintaining high
diagnostic performance. It stands as a promising alternative to conventional
model-based diagnostic techniques for real-world induction machine monitoring
and predictive maintenance.

</details>


### [104] [Reproducibility of Machine Learning-Based Fault Detection and Diagnosis for HVAC Systems in Buildings: An Empirical Study](https://arxiv.org/abs/2508.00880)
*Adil Mukhtar,Michael Hadwiger,Franz Wotawa,Gerald Schweiger*

Main category: cs.LG

TL;DR: 论文分析了机器学习在建筑能源系统中的透明度和可重复性标准，发现几乎所有文章因关键信息不足而不可重复，呼吁采取针对性措施。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于机器学习领域对透明度和可靠性的关注，尤其是在应用学科中可重复性问题的表现尚不明确。

Method: 通过分析建筑能源系统中机器学习应用的透明度与可重复性标准，评估关键维度的信息披露情况。

Result: 结果显示，几乎所有文章因信息披露不足而不可重复，72%未明确数据集来源，仅两篇提供代码链接（其中一条失效）。

Conclusion: 结论强调需要制定可重复性指南、研究人员培训及期刊会议政策以提升透明度和可重复性。

Abstract: Reproducibility is a cornerstone of scientific research, enabling independent
verification and validation of empirical findings. The topic gained prominence
in fields such as psychology and medicine, where concerns about non -
replicable results sparked ongoing discussions about research practices. In
recent years, the fast-growing field of Machine Learning (ML) has become part
of this discourse, as it faces similar concerns about transparency and
reliability. Some reproducibility issues in ML research are shared with other
fields, such as limited access to data and missing methodological details. In
addition, ML introduces specific challenges, including inherent nondeterminism
and computational constraints. While reproducibility issues are increasingly
recognized by the ML community and its major conferences, less is known about
how these challenges manifest in applied disciplines. This paper contributes to
closing this gap by analyzing the transparency and reproducibility standards of
ML applications in building energy systems. The results indicate that nearly
all articles are not reproducible due to insufficient disclosure across key
dimensions of reproducibility. 72% of the articles do not specify whether the
dataset used is public, proprietary, or commercially available. Only two papers
share a link to their code - one of which was broken. Two-thirds of the
publications were authored exclusively by academic researchers, yet no
significant differences in reproducibility were observed compared to
publications with industry-affiliated authors. These findings highlight the
need for targeted interventions, including reproducibility guidelines, training
for researchers, and policies by journals and conferences that promote
transparency and reproducibility.

</details>


### [105] [Hallucination Detection and Mitigation with Diffusion in Multi-Variate Time-Series Foundation Models](https://arxiv.org/abs/2508.00881)
*Vijja Wichitwechkarn,Charles Fox,Ruchi Choudhary*

Main category: cs.LG

TL;DR: 该论文提出了多变量时间序列（MVTS）基础模型中幻觉的新定义、检测和缓解方法，并通过扩散模型估计幻觉水平。实验表明，预训练的MVTS填补模型平均幻觉水平高达59.5%，而提出的缓解方法可降低47.7%。


<details>
  <summary>Details</summary>
Motivation: 目前自然语言处理领域对幻觉有明确定义和解决方法，但MVTS基础模型缺乏类似的定义和方法，阻碍了其安全应用。

Method: 提出MVTS幻觉的新定义，使用扩散模型估计幻觉水平，并通过关系数据集进行基准测试。提出缓解方法以减少幻觉。

Result: 预训练的MVTS填补模型平均幻觉水平达59.5%，缓解方法可降低47.7%。

Conclusion: 该研究为MVTS基础模型的幻觉问题提供了定义和解决方法，有助于其更安全和广泛的应用。

Abstract: Foundation models for natural language processing have many coherent
definitions of hallucination and methods for its detection and mitigation.
However, analogous definitions and methods do not exist for multi-variate
time-series (MVTS) foundation models. We propose new definitions for MVTS
hallucination, along with new detection and mitigation methods using a
diffusion model to estimate hallucination levels. We derive relational datasets
from popular time-series datasets to benchmark these relational hallucination
levels. Using these definitions and models, we find that open-source
pre-trained MVTS imputation foundation models relationally hallucinate on
average up to 59.5% as much as a weak baseline. The proposed mitigation method
reduces this by up to 47.7% for these models. The definition and methods may
improve adoption and safe usage of MVTS foundation models.

</details>


### [106] [Multi-Grained Temporal-Spatial Graph Learning for Stable Traffic Flow Forecasting](https://arxiv.org/abs/2508.00884)
*Zhenan Lin,Yuni Lai,Wai Lun Lo,Richard Tai-Chiu Hsung,Harris Sik-Ho Tsang,Xiaoyu Xue,Kai Zhou,Yulin Zhu*

Main category: cs.LG

TL;DR: 提出了一种多粒度时空图学习框架，通过图变换编码器和门控融合单元增强全局和局部时空模式，提升交通流预测的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 动态交通流预测具有高度非线性和复杂的时空依赖性，现有方法难以捕捉全局时空模式且易过拟合。

Method: 使用图变换编码器提取全局时空模式，结合图卷积的局部模式，通过门控融合单元和残差连接技术平衡两者重要性。

Result: 实验表明，该方法在多个真实交通网络上优于其他基线模型。

Conclusion: 所提框架能有效挖掘隐藏的全局时空关系，提升交通流预测性能。

Abstract: Time-evolving traffic flow forecasting are playing a vital role in
intelligent transportation systems and smart cities. However, the dynamic
traffic flow forecasting is a highly nonlinear problem with complex
temporal-spatial dependencies. Although the existing methods has provided great
contributions to mine the temporal-spatial patterns in the complex traffic
networks, they fail to encode the globally temporal-spatial patterns and are
prone to overfit on the pre-defined geographical correlations, and thus hinder
the model's robustness on the complex traffic environment. To tackle this
issue, in this work, we proposed a multi-grained temporal-spatial graph
learning framework to adaptively augment the globally temporal-spatial patterns
obtained from a crafted graph transformer encoder with the local patterns from
the graph convolution by a crafted gated fusion unit with residual connection
techniques. Under these circumstances, our proposed model can mine the hidden
global temporal-spatial relations between each monitor stations and balance the
relative importance of local and global temporal-spatial patterns. Experiment
results demonstrate the strong representation capability of our proposed method
and our model consistently outperforms other strong baselines on various
real-world traffic networks.

</details>


### [107] [Stochastic Optimal Control via Measure Relaxations](https://arxiv.org/abs/2508.00886)
*Etienne Buehrle,Christoph Stiller*

Main category: cs.LG

TL;DR: 将随机系统的最优控制问题转化为基于占用测度的凸优化问题，通过Christoffel多项式从数据中学习成本函数。


<details>
  <summary>Details</summary>
Motivation: 解决随机系统最优控制问题中传统方法（如鲁棒或基于场景的优化）难以扩展到长优化时间的问题。

Method: 将最优控制问题转化为占用测度的凸优化问题，并利用Christoffel多项式从数据中学习成本函数。

Result: 在合成和实际场景中验证了方法的有效性，实验代码已开源。

Conclusion: 该方法为随机系统的最优控制提供了一种可扩展的解决方案。

Abstract: The optimal control problem of stochastic systems is commonly solved via
robust or scenario-based optimization methods, which are both challenging to
scale to long optimization horizons. We cast the optimal control problem of a
stochastic system as a convex optimization problem over occupation measures. We
demonstrate our method on a set of synthetic and real-world scenarios, learning
cost functions from data via Christoffel polynomials. The code for our
experiments is available at https://github.com/ebuehrle/dpoc.

</details>


### [108] [FRAM: Frobenius-Regularized Assignment Matching with Mixed-Precision Computing](https://arxiv.org/abs/2508.00887)
*Binrui Shen,Yuan Liang,Shengxin Zhu*

Main category: cs.LG

TL;DR: 论文提出了一种新的图匹配松弛框架FRA，通过Frobenius正则化线性分配问题减少误差，并设计了SDSN算法和混合精度架构，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有投影松弛方法在解决NP难的QAP问题时，会引入数值尺度敏感性和几何不对齐误差，需要一种更有效的方法来减少这些误差。

Method: 提出FRA框架，将投影步骤重新表述为Frobenius正则化线性分配问题，并设计SDSN算法和混合精度架构以高效求解。

Result: FRAM在CPU基准测试中优于所有基线方法，结合GPU混合精度架构时，速度提升高达370倍，且精度损失可忽略。

Conclusion: FRA框架和SDSN算法有效减少了松弛误差，混合精度架构显著提升了计算效率，为图匹配问题提供了高效解决方案。

Abstract: Graph matching, typically formulated as a Quadratic Assignment Problem (QAP),
seeks to establish node correspondences between two graphs. To address the
NP-hardness of QAP, some existing methods adopt projection-based relaxations
that embed the problem into the convex hull of the discrete domain. However,
these relaxations inevitably enlarge the feasible set, introducing two sources
of error: numerical scale sensitivity and geometric misalignment between the
relaxed and original domains. To alleviate these errors, we propose a novel
relaxation framework by reformulating the projection step as a
Frobenius-regularized Linear Assignment (FRA) problem, where a tunable
regularization term mitigates feasible region inflation. This formulation
enables normalization-based operations to preserve numerical scale invariance
without compromising accuracy. To efficiently solve FRA, we propose the Scaling
Doubly Stochastic Normalization (SDSN) algorithm. Building on its favorable
computational properties, we develop a theoretically grounded mixed-precision
architecture to achieve substantial acceleration. Comprehensive CPU-based
benchmarks demonstrate that FRAM consistently outperforms all baseline methods
under identical precision settings. When combined with a GPU-based
mixed-precision architecture, FRAM achieves up to 370X speedup over its
CPU-FP64 counterpart, with negligible loss in solution accuracy.

</details>


### [109] [A Dynamic, Context-Aware Framework for Risky Driving Prediction Using Naturalistic Data](https://arxiv.org/abs/2508.00888)
*Amir Hossein Kalantari,Eleonora Papadimitriou,Amir Pooyan Afghari*

Main category: cs.LG

TL;DR: 该研究提出了一种动态个性化框架，用于识别风险驾驶行为，利用滚动时间窗口和双层优化动态校准风险阈值和模型超参数，评估了三种数据驱动模型，其中DNN在高召回任务中表现突出，XGBoost表现最平衡，随机森林对动态调整敏感。


<details>
  <summary>Details</summary>
Motivation: 现有框架依赖固定时间窗口和静态阈值，难以应对真实驾驶的随机性，因此需要动态个性化方法。

Method: 使用比利时自然驾驶数据，采用滚动时间窗口和双层优化动态校准风险阈值和模型超参数，评估了三种模型（随机森林、XGBoost、DNN）和两种安全指标（速度加权车距和激烈驾驶事件）。

Result: DNN在高召回任务中表现突出，XGBoost表现最平衡，随机森林对动态调整敏感；速度加权车距比激烈驾驶事件更稳定。

Conclusion: 自适应个性化风险检测方法对实时安全反馈和智能交通系统中的驾驶员支持具有重要价值。

Abstract: Naturalistic driving studies offer a powerful means for observing and
quantifying real-world driving behaviour. One of their prominent applications
in traffic safety is the continuous monitoring and classification of risky
driving behaviour. However, many existing frameworks rely on fixed time windows
and static thresholds for distinguishing between safe and risky behaviour -
limiting their ability to respond to the stochastic nature of real-world
driving. This study proposes a dynamic and individualised framework for
identifying risky driving behaviour using Belgian naturalistic driving data.
The approach leverages a rolling time window and bi-level optimisation to
dynamically calibrate both risk thresholds and model hyperparameters, capturing
subtle behavioural shifts. Two safety indicators, speed-weighted headway and
harsh driving events, were evaluated using three data-driven models: Random
Forest, XGBoost, and Deep Neural Network (DNN). The DNN demonstrated strong
capability in capturing subtle changes in driving behaviour, particularly
excelling in high-recall tasks, making it promising for early-stage risk
detection. XGBoost provided the most balanced and stable performance across
different thresholds and evaluation metrics. While random forest showed more
variability, it responded sensitively to dynamic threshold adjustments, which
may be advantageous during model adaptation or tuning. Speed-weighted headway
emerged as a more stable and context-sensitive risk indicator than harsh
driving events, likely due to its robustness to label sparsity and contextual
variation. Overall, the findings support the value of adaptive, personalised
risk detection approaches for enhancing real-time safety feedback and tailoring
driver support in intelligent transport systems.

</details>


### [110] [Maximize margins for robust splicing detection](https://arxiv.org/abs/2508.00897)
*Julien Simon de Kergunic,Rony Abecidan,Patrick Bas,Vincent Itier*

Main category: cs.LG

TL;DR: 论文探讨了深度学习检测器对训练条件的高敏感性，提出通过最大化潜在边距选择模型以提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习检测器对评估图像的轻微后处理敏感，影响实际部署的可靠性。

Method: 训练同一模型的不同变体，选择潜在边距最大的模型。

Result: 实验显示潜在边距分布与检测器泛化能力强相关。

Conclusion: 通过优化潜在边距可构建更鲁棒的检测器。

Abstract: Despite recent progress in splicing detection, deep learning-based forensic
tools remain difficult to deploy in practice due to their high sensitivity to
training conditions. Even mild post-processing applied to evaluation images can
significantly degrade detector performance, raising concerns about their
reliability in operational contexts. In this work, we show that the same deep
architecture can react very differently to unseen post-processing depending on
the learned weights, despite achieving similar accuracy on in-distribution test
data. This variability stems from differences in the latent spaces induced by
training, which affect how samples are separated internally. Our experiments
reveal a strong correlation between the distribution of latent margins and a
detector's ability to generalize to post-processed images. Based on this
observation, we propose a practical strategy for building more robust
detectors: train several variants of the same model under different conditions,
and select the one that maximizes latent margins.

</details>


### [111] [Filtering with Self-Attention and Storing with MLP: One-Layer Transformers Can Provably Acquire and Extract Knowledge](https://arxiv.org/abs/2508.00901)
*Ruichen Xu,Kexin Chen*

Main category: cs.LG

TL;DR: 论文探讨了Transformer模型在预训练中获取知识及在微调中提取知识的机制，提出了一种结合自注意力和MLP的单层框架，并证明了其收敛性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有理论对Transformer如何获取和提取知识的研究局限于单层注意力架构，且标准训练目标可能无法有效获取事实知识。

Method: 引入结合自注意力和MLP的单层Transformer框架，分析其梯度动态，验证收敛性和泛化能力。

Result: 证明Transformer在预训练中能有效获取知识，在特定条件下微调后可成功提取知识，否则会出现幻觉。

Conclusion: 研究为Transformer的知识获取和提取提供了理论支持，并通过实验验证了其有效性。

Abstract: Modern large language models excel in knowledge-intensive tasks, yet how
transformers acquire (store) knowledge during pre-training and extract
(retrieve) it during post-fine-tuning inference remains theoretically opaque.
While prior theoretical work has begun to investigate these questions through
the analysis of training dynamics, such studies are limited to single-layer,
attention-only architectures. However, most existing studies suggest that MLPs
are the most contributing components for storing knowledge in transformer-based
language models. Meanwhile, our empirical investigations reveal that such
simplified models, when trained using standard next-token prediction
objectives, may be incapable of acquiring or extracting factual knowledge. To
overcome this limitation, we introduce a tractable one-layer transformer
framework that crucially incorporates both self-attention and MLP modules. By
tracking its gradient dynamics, we establish convergence and generalization
guarantees that illuminate the ability of knowledge acquisition and extraction.
We prove that 1) Transformers can achieve near-optimal training loss during
pre-training, signifying effective knowledge acquisition; 2) With a large
fine-tuning dataset and specific data multiplicity conditions met, transformers
can achieve low generalization error when tested on factual knowledge learned
during pre-training but not reinforced during the fine-tuning, indicating
successful knowledge extraction; 3) When the conditions are not satisfied,
transformers exhibit high generalization loss, resulting in hallucinations. Our
analysis includes both full fine-tuning and low-rank fine-tuning. Furthermore,
our analysis offers theoretical insights into several pertinent empirical
phenomena, such as the role of learning rate schedules. Experiments on
synthetic and real-world PopQA datasets with GPT-2 and Llama-3.2-1B validate
our results.

</details>


### [112] [Universal Neurons in GPT-2: Emergence, Persistence, and Functional Impact](https://arxiv.org/abs/2508.00903)
*Advey Nandan,Cheng-Ting Chou,Amrit Kurakula,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.LG

TL;DR: 研究GPT-2 Small模型中神经元普遍性现象，发现训练中普遍神经元（跨模型激活相关）的演化及其对预测的功能影响。


<details>
  <summary>Details</summary>
Motivation: 探讨独立训练的GPT-2模型中普遍神经元的出现及其稳定性，揭示神经网络训练中的普遍表征结构。

Method: 分析五个GPT-2模型在三个训练阶段（100k、200k、300k步），通过激活相关性识别普遍神经元，并进行消融实验评估其功能影响。

Result: 普遍神经元对模型预测有显著功能影响，且在深层网络中表现出高度稳定性。

Conclusion: 神经网络训练中会形成稳定且普遍的神经元表征结构。

Abstract: We investigate the phenomenon of neuron universality in independently trained
GPT-2 Small models, examining how these universal neurons-neurons with
consistently correlated activations across models-emerge and evolve throughout
training. By analyzing five GPT-2 models at three checkpoints (100k, 200k, 300k
steps), we identify universal neurons through pairwise correlation analysis of
activations over a dataset of 5 million tokens. Ablation experiments reveal
significant functional impacts of universal neurons on model predictions,
measured via loss and KL divergence. Additionally, we quantify neuron
persistence, demonstrating high stability of universal neurons across training
checkpoints, particularly in deeper layers. These findings suggest stable and
universal representational structures emerge during neural network training.

</details>


### [113] [NeuCoReClass AD: Redefining Self-Supervised Time Series Anomaly Detection](https://arxiv.org/abs/2508.00909)
*Aitor Sánchez-Ferrera,Usue Mori,Borja Calvo,Jose A. Lozano*

Main category: cs.LG

TL;DR: NeuCoReClass AD是一种自监督多任务时间序列异常检测框架，结合对比、重建和分类代理任务，无需领域特定知识即可生成多样化且信息丰富的增强视图。


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法多依赖单一代理任务和领域特定转换，限制了其在多样化问题中的泛化能力。

Method: 采用神经转换学习生成多样化增强视图，结合对比、重建和分类任务。

Result: 在多个基准测试中表现优于经典方法和多数深度学习替代方案，并能无监督地识别异常特征。

Conclusion: NeuCoReClass AD通过多任务自监督学习有效提升了时间序列异常检测的泛化能力和性能。

Abstract: Time series anomaly detection plays a critical role in a wide range of
real-world applications. Among unsupervised approaches, self-supervised
learning has gained traction for modeling normal behavior without the need of
labeled data. However, many existing methods rely on a single proxy task,
limiting their ability to capture meaningful patterns in normal data. Moreover,
they often depend on handcrafted transformations tailored specific domains,
hindering their generalization accross diverse problems. To address these
limitations, we introduce NeuCoReClass AD, a self-supervised multi-task time
series anomaly detection framework that combines contrastive, reconstruction,
and classification proxy tasks. Our method employs neural transformation
learning to generate augmented views that are informative, diverse, and
coherent, without requiring domain-specific knowledge. We evaluate NeuCoReClass
AD across a wide range of benchmarks, demonstrating that it consistently
outperforms both classical baselines and most deep-learning alternatives.
Furthermore, it enables the characterization of distinct anomaly profiles in a
fully unsupervised manner.

</details>


### [114] [Predictive Auditing of Hidden Tokens in LLM APIs via Reasoning Length Estimation](https://arxiv.org/abs/2508.00912)
*Ziyao Wang,Guoheng Sun,Yexiao He,Zheyu Shen,Bowei Tian,Ang Li*

Main category: cs.LG

TL;DR: PALACE是一个用户端框架，通过预测隐藏的推理令牌数量，解决商业LLM服务中令牌膨胀和潜在超额计费的问题。


<details>
  <summary>Details</summary>
Motivation: 商业LLM服务隐藏内部推理痕迹，可能导致令牌膨胀和超额计费，亟需可靠的令牌审计方法。

Method: PALACE通过GRPO增强的适配模块和轻量级领域路由器，动态校准不同推理任务的令牌使用模式。

Result: 实验表明，PALACE在数学、编码、医学和通用推理任务中实现了低相对误差和高预测准确性。

Conclusion: PALACE为标准化预测审计迈出了重要一步，提升了透明度和用户信任。

Abstract: Commercial LLM services often conceal internal reasoning traces while still
charging users for every generated token, including those from hidden
intermediate steps, raising concerns of token inflation and potential
overbilling. This gap underscores the urgent need for reliable token auditing,
yet achieving it is far from straightforward: cryptographic verification (e.g.,
hash-based signature) offers little assurance when providers control the entire
execution pipeline, while user-side prediction struggles with the inherent
variance of reasoning LLMs, where token usage fluctuates across domains and
prompt styles. To bridge this gap, we present PALACE (Predictive Auditing of
LLM APIs via Reasoning Token Count Estimation), a user-side framework that
estimates hidden reasoning token counts from prompt-answer pairs without access
to internal traces. PALACE introduces a GRPO-augmented adaptation module with a
lightweight domain router, enabling dynamic calibration across diverse
reasoning tasks and mitigating variance in token usage patterns. Experiments on
math, coding, medical, and general reasoning benchmarks show that PALACE
achieves low relative error and strong prediction accuracy, supporting both
fine-grained cost auditing and inflation detection. Taken together, PALACE
represents an important first step toward standardized predictive auditing,
offering a practical path to greater transparency, accountability, and user
trust.

</details>


### [115] [SmartDate: AI-Driven Precision Sorting and Quality Control in Date Fruits](https://arxiv.org/abs/2508.00921)
*Khaled Eskaf*

Main category: cs.LG

TL;DR: SmartDate是一个AI驱动的系统，用于自动化分拣和质量控制椰枣。它结合深度学习、遗传算法和强化学习，通过高分辨率成像和VisNIR光谱传感器评估关键特征，实现了94.5%的准确率和0.96的AUC-ROC。


<details>
  <summary>Details</summary>
Motivation: 提高椰枣分类准确性并预测保质期，减少浪费，确保市场仅接收高质量产品。

Method: 结合深度学习、遗传算法和强化学习，利用高分辨率成像和VisNIR光谱传感器评估水分、糖含量和质地等特征。

Result: 系统达到94.5%的准确率、93.1%的F1分数和0.96的AUC-ROC。

Conclusion: SmartDate为智能农业设立了新标准，显著减少浪费并提升产品质量。

Abstract: SmartDate is an AI-powered system for automated sorting and quality control
of date fruits. It combines deep learning, genetic algorithms, and
reinforcement learning to improve classification accuracy and predict shelf
life. The system uses high-resolution imaging and Visible-Near-Infrared
(VisNIR) spectral sensors to evaluate key features such as moisture, sugar
content, and texture. Reinforcement learning enables real-time adaptation to
production conditions, while genetic algorithms optimize model parameters.
SmartDate achieved 94.5 percent accuracy, 93.1 percent F1-score, and an AUC-ROC
of 0.96. The system reduces waste and ensures that only high-quality dates
reach the market, setting a new benchmark in smart agriculture.

</details>


### [116] [CaliMatch: Adaptive Calibration for Improving Safe Semi-supervised Learning](https://arxiv.org/abs/2508.00922)
*Jinsoo Bae,Seoung Bum Kim,Hyungrok Do*

Main category: cs.LG

TL;DR: CaliMatch提出了一种新的半监督学习方法，通过校准分类器和OOD检测器来解决标签分布不匹配问题，避免了现有方法因过度自信导致的错误。


<details>
  <summary>Details</summary>
Motivation: 解决半监督学习中标签分布不匹配问题，避免因深度神经网络过度自信导致的伪标签或OOD检测错误。

Method: 提出CaliMatch方法，结合自适应标签平滑和温度缩放，无需手动调整平滑度，实现分类器和OOD检测器的校准。

Result: 在多个数据集（如CIFAR-10、ImageNet等）上验证，CaliMatch优于现有方法。

Conclusion: CaliMatch通过校准分类器和OOD检测器，显著提升了安全半监督学习的性能。

Abstract: Semi-supervised learning (SSL) uses unlabeled data to improve the performance
of machine learning models when labeled data is scarce. However, its real-world
applications often face the label distribution mismatch problem, in which the
unlabeled dataset includes instances whose ground-truth labels are absent from
the labeled training dataset. Recent studies, referred to as safe SSL, have
addressed this issue by using both classification and out-of-distribution (OOD)
detection. However, the existing methods may suffer from overconfidence in deep
neural networks, leading to increased SSL errors because of high confidence in
incorrect pseudo-labels or OOD detection. To address this, we propose a novel
method, CaliMatch, which calibrates both the classifier and the OOD detector to
foster safe SSL. CaliMatch presents adaptive label smoothing and temperature
scaling, which eliminates the need to manually tune the smoothing degree for
effective calibration. We give a theoretical justification for why improving
the calibration of both the classifier and the OOD detector is crucial in safe
SSL. Extensive evaluations on CIFAR-10, CIFAR-100, SVHN, TinyImageNet, and
ImageNet demonstrate that CaliMatch outperforms the existing methods in safe
SSL tasks.

</details>


### [117] [From Generator to Embedder: Harnessing Innate Abilities of Multimodal LLMs via Building Zero-Shot Discriminative Embedding Model](https://arxiv.org/abs/2508.00955)
*Yeong-Joon Ju,Seong-Whan Lee*

Main category: cs.LG

TL;DR: 提出了一种高效的多模态嵌入框架，通过分层提示模板和自感知硬负采样，解决了生成式MLLM在判别式表示学习中的挑战，无需对比预训练即可达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决MLLM在判别式表示学习中的低效问题，避免大规模对比预训练的高计算成本和未充分利用MLLM指令跟随能力的问题。

Method: 1. 分层嵌入提示模板：通过两级指令架构生成判别式表示；2. 自感知硬负采样：利用模型自身理解高效挖掘困难负样本并过滤假负样本。

Result: 分层提示在零样本任务中表现与对比训练基线相当，微调性能提升4.8点；自感知硬负采样进一步实现SOTA性能。

Conclusion: 该框架为MLLM在通用嵌入任务中的应用提供了高效路径，显著减少训练时间。

Abstract: Multimodal Large Language Models (MLLMs) have emerged as a promising solution
for universal embedding tasks, yet adapting their generative nature for
discriminative representation learning remains a significant challenge. The
dominant paradigm of large-scale contrastive pre-training suffers from critical
inefficiencies, including prohibitive computational costs and a failure to
leverage the intrinsic, instruction-following capabilities of MLLMs. To
overcome these limitations, we propose an efficient framework for universal
multimodal embeddings, which bridges this gap by centering on two synergistic
components. First, our hierarchical embedding prompt template employs a
two-level instruction architecture that forces the model to produce
discriminative representations. Building on this strong foundation, our second
component, self-aware hard negative sampling, redefines the fine-tuning process
by leveraging the model's own understanding to efficiently mine challenging
negatives while actively filtering out potential false negatives. Our
comprehensive experiments show that our hierarchical prompt achieves zero-shot
performance competitive with contrastively trained baselines and enhances the
fine-tuning process by lifting a simple in-batch negative baseline by 4.8
points on the MMEB benchmark. We further boost the performance via our
self-aware hard negative sampling, achieving the state-of-the-art performance
without the contrative pre-training. Our work presents an effective and
efficient pathway to adapt MLLMs for universal embedding tasks, significantly
reducing training time.

</details>


### [118] [Beyond Benchmarks: Dynamic, Automatic And Systematic Red-Teaming Agents For Trustworthy Medical Language Models](https://arxiv.org/abs/2508.00923)
*Jiazhen Pan,Bailiang Jian,Paul Hager,Yundi Zhang,Che Liu,Friedrike Jungmann,Hongwei Bran Li,Chenyu You,Junde Wu,Jiayuan Zhu,Fenglin Liu,Yuyuan Liu,Niklas Bubeck,Christian Wachinger,Chen,Chen,Zhenyu Gong,Cheng Ouyang,Georgios Kaissis,Benedikt Wiestler,Daniel Rueckert*

Main category: cs.LG

TL;DR: 论文提出了一种动态、自动、系统的红队测试框架（DAS），用于持续检测大型语言模型（LLMs）在临床实践中的安全性问题，揭示了静态基准测试无法捕捉的严重漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在医疗领域的快速应用，静态安全测试已无法满足需求，亟需动态方法实时发现模型弱点，确保患者安全和AI可信度。

Method: 采用DAS框架，通过对抗代理自动生成和演化测试用例，实时评估LLMs在鲁棒性、隐私、偏见/公平性和幻觉四个关键领域的安全性。

Result: 测试15个LLMs发现，静态基准表现与实际漏洞存在巨大差距：94%的正确回答在动态测试中失败，隐私泄露率86%，偏见影响81%，幻觉率超66%。

Conclusion: DAS框架为医疗AI提供了可扩展的动态安全监测工具，弥补了静态测试的不足，是未来临床应用中不可或缺的安全保障。

Abstract: Ensuring the safety and reliability of large language models (LLMs) in
clinical practice is critical to prevent patient harm and promote trustworthy
healthcare applications of AI. However, LLMs are advancing so rapidly that
static safety benchmarks often become obsolete upon publication, yielding only
an incomplete and sometimes misleading picture of model trustworthiness. We
demonstrate that a Dynamic, Automatic, and Systematic (DAS) red-teaming
framework that continuously stress-tests LLMs can reveal significant weaknesses
of current LLMs across four safety-critical domains: robustness, privacy,
bias/fairness, and hallucination. A suite of adversarial agents is applied to
autonomously mutate test cases, identify/evolve unsafe-triggering strategies,
and evaluate responses, uncovering vulnerabilities in real time without human
intervention. Applying DAS to 15 proprietary and open-source LLMs revealed a
stark contrast between static benchmark performance and vulnerability under
adversarial pressure. Despite a median MedQA accuracy exceeding 80\%, 94\% of
previously correct answers failed our dynamic robustness tests. We observed
similarly high failure rates across other domains: privacy leaks were elicited
in 86\% of scenarios, cognitive-bias priming altered clinical recommendations
in 81\% of fairness tests, and we identified hallucination rates exceeding 66\%
in widely used models. Such profound residual risks are incompatible with
routine clinical practice. By converting red-teaming from a static checklist
into a dynamic stress-test audit, DAS red-teaming offers the surveillance that
hospitals/regulators/technology vendors require as LLMs become embedded in
patient chatbots, decision-support dashboards, and broader healthcare
workflows. Our framework delivers an evolvable, scalable, and reliable
safeguard for the next generation of medical AI.

</details>


### [119] [Learning Unified User Quantized Tokenizers for User Representation](https://arxiv.org/abs/2508.00956)
*Chuan He,Yang Chen,Wuliang Huang,Tianyi Zheng,Jianhu Chen,Bin Dou,Yice Luo,Yun Zhu,Baokun Wang,Yongchao Liu,Xing Fu,Yu Cheng,Chuntao Hong,Weiqiang Wang,Xin-Wei Yao*

Main category: cs.LG

TL;DR: 论文提出U^2QT框架，通过早期融合异构数据和统一表征学习，解决了多源用户表征学习中的存储、扩展性和跨任务泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在异构数据融合中存在统一表征框架缺失、存储与扩展性问题以及跨任务泛化能力不足的挑战。

Method: U^2QT采用两阶段架构：1）因果Q-Former将域特定特征映射到共享因果表征空间；2）多视图RQ-VAE将表征离散化为紧凑令牌，支持高效存储。

Result: 实验表明，U^2QT在行为预测和推荐任务中优于基线，同时在存储和计算效率上表现优异。

Conclusion: U^2QT的统一令牌化框架支持与语言模型的无缝集成，适用于工业级应用。

Abstract: Multi-source user representation learning plays a critical role in enabling
personalized services on web platforms (e.g., Alipay). While prior works have
adopted late-fusion strategies to combine heterogeneous data sources, they
suffer from three key limitations: lack of unified representation frameworks,
scalability and storage issues in data compression, and inflexible cross-task
generalization. To address these challenges, we propose U^2QT (Unified User
Quantized Tokenizers), a novel framework that integrates cross-domain knowledge
transfer with early fusion of heterogeneous domains. Our framework employs a
two-stage architecture: first, a causal Q-Former projects domain-specific
features into a shared causal representation space to preserve inter-modality
dependencies; second, a multi-view RQ-VAE discretizes causal embeddings into
compact tokens through shared and source-specific codebooks, enabling efficient
storage while maintaining semantic coherence. Experimental results showcase
U^2QT's advantages across diverse downstream tasks, outperforming task-specific
baselines in future behavior prediction and recommendation tasks while
achieving efficiency gains in storage and computation. The unified tokenization
framework enables seamless integration with language models and supports
industrial-scale applications.

</details>


### [120] [Hybrid Hypergraph Networks for Multimodal Sequence Data Classification](https://arxiv.org/abs/2508.00926)
*Feng Xu,Hui Wang,Yuting Huang,Danwei Zhang,Zizhu Fan*

Main category: cs.LG

TL;DR: 提出了一种混合超图网络（HHN）框架，通过分段优先、图结构后续的策略建模时序多模态数据，解决了现有方法忽略时序依赖和模态间复杂关系的问题。


<details>
  <summary>Details</summary>
Motivation: 时序多模态数据（如视听数据）的分类任务面临长程时序依赖和跨模态交互的挑战，现有方法多模态独立处理且融合策略浅层，限制了模型对复杂结构的表达能力。

Method: HHN将序列分割为时间戳段作为异构图节点，通过最大熵差异准则捕获模态内结构，再通过超图卷积提取高阶依赖，并通过时序对齐和图注意力建立模态间链接。

Result: 在四个多模态数据集上实现了SOTA结果，验证了其在复杂分类任务中的有效性。

Conclusion: HHN通过分段和图结构策略有效建模时序多模态数据，显著提升了分类性能。

Abstract: Modeling temporal multimodal data poses significant challenges in
classification tasks, particularly in capturing long-range temporal
dependencies and intricate cross-modal interactions. Audiovisual data, as a
representative example, is inherently characterized by strict temporal order
and diverse modalities. Effectively leveraging the temporal structure is
essential for understanding both intra-modal dynamics and inter-modal
correlations. However, most existing approaches treat each modality
independently and rely on shallow fusion strategies, which overlook temporal
dependencies and hinder the model's ability to represent complex structural
relationships. To address the limitation, we propose the hybrid hypergraph
network (HHN), a novel framework that models temporal multimodal data via a
segmentation-first, graph-later strategy. HHN splits sequences into timestamped
segments as nodes in a heterogeneous graph. Intra-modal structures are captured
via hyperedges guided by a maximum entropy difference criterion, enhancing node
heterogeneity and structural discrimination, followed by hypergraph convolution
to extract high-order dependencies. Inter-modal links are established through
temporal alignment and graph attention for semantic fusion. HHN achieves
state-of-the-art (SOTA) results on four multimodal datasets, demonstrating its
effectiveness in complex classification tasks.

</details>


### [121] [Cooperative effects in feature importance of individual patterns: application to air pollutants and Alzheimer disease](https://arxiv.org/abs/2508.00930)
*M. Ontivero-Ortega,A. Fania,A. Lacalamita,R. Bellotti,A. Monaco,S. Stramaglia*

Main category: cs.LG

TL;DR: 本文提出了一种自适应版本的LOCO方法（Hi-Fi），用于量化特征重要性中的协同效应，并通过三个分数（唯一、冗余和协同）描述每个特征。与标准方法不同，该方法在回归问题中揭示了高阶效应，并以一个健康应用为例展示了其潜力。


<details>
  <summary>Details</summary>
Motivation: 传统特征重要性工具仅通过单一分数衡量特征相关性，无法捕捉高阶效应。本文旨在通过Hi-Fi方法，量化特征的协同和冗余效应，从而更全面地理解特征间的关系。

Method: 提出自适应LOCO方法（Hi-Fi），为每个特征分配三个分数（唯一、冗余和协同），并与Shapley效应进行比较。应用于空气污染物与阿尔茨海默病死亡率的关系分析。

Result: 发现O3和NO2与死亡率之间存在协同效应，尤其在Bergamo和Brescia地区。城市绿地密度也与污染物协同影响死亡率预测。

Conclusion: Hi-Fi作为一种广泛适用的工具，为XAI和复杂系统的高阶关系分析提供了新视角。

Abstract: Leveraging recent advances in the analysis of synergy and redundancy in
systems of random variables, an adaptive version of the widely used metric
Leave One Covariate Out (LOCO) has been recently proposed to quantify
cooperative effects in feature importance (Hi-Fi), a key technique in
explainable artificial intelligence (XAI), so as to disentangle high-order
effects involving a particular input feature in regression problems.
Differently from standard feature importance tools, where a single score
measures the relevance of each feature, each feature is here characterized by
three scores, a two-body (unique) score and higher-order scores (redundant and
synergistic). This paper presents a framework to assign those three scores
(unique, redundant, and synergistic) to each individual pattern of the data
set, while comparing it with the well-known measure of feature importance named
{\it Shapley effect}. To illustrate the potential of the proposed framework, we
focus on a One-Health application: the relation between air pollutants and
Alzheimer's disease mortality rate. Our main result is the synergistic
association between features related to $O_3$ and $NO_2$ with mortality,
especially in the provinces of Bergamo e Brescia; notably also the density of
urban green areas displays synergistic influence with pollutants for the
prediction of AD mortality. Our results place local Hi-Fi as a promising tool
of wide applicability, which opens new perspectives for XAI as well as to
analyze high-order relationships in complex systems.

</details>


### [122] [OKG-LLM: Aligning Ocean Knowledge Graph with Observation Data via LLMs for Global Sea Surface Temperature Prediction](https://arxiv.org/abs/2508.00933)
*Hanchen Yang,Jiaqi Wang,Jiannong Cao,Wengen Li,Jialun Zheng,Yangning Li,Chunyu Miao,Jihong Guan,Shuigeng Zhou,Philip S. Yu*

Main category: cs.LG

TL;DR: 论文提出了一种结合海洋知识图谱与大语言模型（OKG-LLM）的新框架，用于提升海表温度（SST）预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法在SST预测中忽视了领域知识，限制了预测精度的进一步提升。

Method: 构建海洋知识图谱（OKG），开发图嵌入网络学习语义和结构知识，并与数值数据结合，利用预训练大语言模型进行预测。

Result: 实验表明OKG-LLM在真实数据集上优于现有方法。

Conclusion: OKG-LLM展示了提升SST预测的潜力，代码已开源。

Abstract: Sea surface temperature (SST) prediction is a critical task in ocean science,
supporting various applications, such as weather forecasting, fisheries
management, and storm tracking. While existing data-driven methods have
demonstrated significant success, they often neglect to leverage the rich
domain knowledge accumulated over the past decades, limiting further
advancements in prediction accuracy. The recent emergence of large language
models (LLMs) has highlighted the potential of integrating domain knowledge for
downstream tasks. However, the application of LLMs to SST prediction remains
underexplored, primarily due to the challenge of integrating ocean domain
knowledge and numerical data. To address this issue, we propose Ocean Knowledge
Graph-enhanced LLM (OKG-LLM), a novel framework for global SST prediction. To
the best of our knowledge, this work presents the first systematic effort to
construct an Ocean Knowledge Graph (OKG) specifically designed to represent
diverse ocean knowledge for SST prediction. We then develop a graph embedding
network to learn the comprehensive semantic and structural knowledge within the
OKG, capturing both the unique characteristics of individual sea regions and
the complex correlations between them. Finally, we align and fuse the learned
knowledge with fine-grained numerical SST data and leverage a pre-trained LLM
to model SST patterns for accurate prediction. Extensive experiments on the
real-world dataset demonstrate that OKG-LLM consistently outperforms
state-of-the-art methods, showcasing its effectiveness, robustness, and
potential to advance SST prediction. The codes are available in the online
repository.

</details>


### [123] [FeatureCuts: Feature Selection for Large Data by Optimizing the Cutoff](https://arxiv.org/abs/2508.00954)
*Andy Hu,Devika Prasad,Luiz Pizzato,Nicholas Foord,Arman Abrahamyan,Anna Leontjeva,Cooper Doyle,Dan Jermyn*

Main category: cs.LG

TL;DR: FeatureCuts是一种新型特征选择算法，通过自适应选择最优特征截断点，显著减少特征数量和计算时间，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 在机器学习中，特征选择的目标是找到能够高效训练模型的特征子集，现有方法在特征减少和计算效率上仍有改进空间。

Method: FeatureCuts通过自适应选择最优特征截断点，结合过滤排名方法，显著提升特征选择效率。

Result: 在14个公开数据集和1个行业数据集上，FeatureCuts平均减少15%的特征和99.6%的计算时间，同时保持模型性能。与PSO结合时，进一步减少25%的特征和66%的计算时间。

Conclusion: FeatureCuts是一种高效、可扩展的特征选择算法，适用于企业级大规模数据集。

Abstract: In machine learning, the process of feature selection involves finding a
reduced subset of features that captures most of the information required to
train an accurate and efficient model. This work presents FeatureCuts, a novel
feature selection algorithm that adaptively selects the optimal feature cutoff
after performing filter ranking. Evaluated on 14 publicly available datasets
and one industry dataset, FeatureCuts achieved, on average, 15 percentage
points more feature reduction and up to 99.6% less computation time while
maintaining model performance, compared to existing state-of-the-art methods.
When the selected features are used in a wrapper method such as Particle Swarm
Optimization (PSO), it enables 25 percentage points more feature reduction,
requires 66% less computation time, and maintains model performance when
compared to PSO alone. The minimal overhead of FeatureCuts makes it scalable
for large datasets typically seen in enterprise applications.

</details>


### [124] [Controllable and Stealthy Shilling Attacks via Dispersive Latent Diffusion](https://arxiv.org/abs/2508.01987)
*Shutong Qiao,Wei Yuan,Junliang Yu,Tong Chen,Quoc Viet Hung Nguyen,Hongzhi Yin*

Main category: cs.LG

TL;DR: 论文提出了一种基于扩散的攻击框架DLDA，能够生成高效且难以检测的虚假用户，揭示了推荐系统在对抗攻击中的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有攻击模型难以同时实现目标项目的强对抗推广和避免检测的真实行为，导致对推荐系统真实威胁的低估。

Method: DLDA在预对齐的协作嵌入空间中，通过条件潜在扩散过程迭代生成虚假用户配置文件，并引入分散正则化机制提高行为模式的真实性和可变性。

Result: 在三个真实数据集和五种流行推荐模型上的实验表明，DLDA相比现有攻击方法，能更有效地推广目标项目且更难被检测。

Conclusion: 现代推荐系统比以往认为的更脆弱，亟需更强大的防御机制。

Abstract: Recommender systems (RSs) are now fundamental to various online platforms,
but their dependence on user-contributed data leaves them vulnerable to
shilling attacks that can manipulate item rankings by injecting fake users.
Although widely studied, most existing attack models fail to meet two critical
objectives simultaneously: achieving strong adversarial promotion of target
items while maintaining realistic behavior to evade detection. As a result, the
true severity of shilling threats that manage to reconcile the two objectives
remains underappreciated. To expose this overlooked vulnerability, we present
DLDA, a diffusion-based attack framework that can generate highly effective yet
indistinguishable fake users by enabling fine-grained control over target
promotion. Specifically, DLDA operates in a pre-aligned collaborative embedding
space, where it employs a conditional latent diffusion process to iteratively
synthesize fake user profiles with precise target item control. To evade
detection, DLDA introduces a dispersive regularization mechanism that promotes
variability and realism in generated behavioral patterns. Extensive experiments
on three real-world datasets and five popular RS models demonstrate that,
compared to prior attacks, DLDA consistently achieves stronger item promotion
while remaining harder to detect. These results highlight that modern RSs are
more vulnerable than previously recognized, underscoring the urgent need for
more robust defenses.

</details>


### [125] [Small sample-based adaptive text classification through iterative and contrastive description refinement](https://arxiv.org/abs/2508.00957)
*Amrit Rajeev,Udayaadithya Avadhanam,Harshula Tulapurkar,SaiBarath Sundar*

Main category: cs.LG

TL;DR: 提出了一种结合迭代主题细化、对比提示和主动学习的零样本文本分类框架，适用于动态环境，并在AGNews和DBpedia上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决零样本分类在动态知识领域（如票务系统）中的困难，尤其是大语言模型在泛化和数据多样性不足时的问题。

Method: 通过迭代对比提示和主动学习，结合人工干预，动态优化分类边界并引入新类别。

Result: 在AGNews和DBpedia上分别达到91%和84%的准确率，引入新类别后性能稳定。

Conclusion: 基于提示的语义推理在有限监督下能有效实现细粒度分类。

Abstract: Zero-shot text classification remains a difficult task in domains with
evolving knowledge and ambiguous category boundaries, such as ticketing
systems. Large language models (LLMs) often struggle to generalize in these
scenarios due to limited topic separability, while few-shot methods are
constrained by insufficient data diversity. We propose a classification
framework that combines iterative topic refinement, contrastive prompting, and
active learning. Starting with a small set of labeled samples, the model
generates initial topic labels. Misclassified or ambiguous samples are then
used in an iterative contrastive prompting process to refine category
distinctions by explicitly teaching the model to differentiate between closely
related classes. The framework features a human-in-the-loop component, allowing
users to introduce or revise category definitions in natural language. This
enables seamless integration of new, unseen categories without retraining,
making the system well-suited for real-world, dynamic environments. The
evaluations on AGNews and DBpedia demonstrate strong performance: 91% accuracy
on AGNews (3 seen, 1 unseen class) and 84% on DBpedia (8 seen, 1 unseen), with
minimal accuracy shift after introducing unseen classes (82% and 87%,
respectively). The results highlight the effectiveness of prompt-based semantic
reasoning for fine-grained classification with limited supervision.

</details>


### [126] [Enhancing material behavior discovery using embedding-oriented Physically-Guided Neural Networks with Internal Variables](https://arxiv.org/abs/2508.00959)
*Rubén Muñoz-Sierra,Manuel Doblaré,Jacobo Ayensa-Jiménez*

Main category: cs.LG

TL;DR: 论文提出了一种改进的PGNNIV框架，通过降阶建模技术解决高维数据扩展性问题，并引入多种替代解码器结构，提高了计算效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: PGNNIV模型在处理高维数据（如空间场或时变系统）时面临扩展性挑战，需要改进以提升其适用性和效率。

Method: 采用降阶建模技术，引入基于谱分解、POD和预训练自编码器的替代解码器，并结合迁移学习和微调策略。

Result: 改进后的PGNNIV框架成功识别了本构状态方程，提高了预测精度、噪声鲁棒性，并减少了计算需求。

Conclusion: 提出的方法可根据不同场景定制，有效解决了PGNNIV的扩展性问题，适用于多种建模目标。

Abstract: Physically Guided Neural Networks with Internal Variables are SciML tools
that use only observable data for training and and have the capacity to unravel
internal state relations. They incorporate physical knowledge both by
prescribing the model architecture and using loss regularization, thus endowing
certain specific neurons with a physical meaning as internal state variables.
Despite their potential, these models face challenges in scalability when
applied to high-dimensional data such as fine-grid spatial fields or
time-evolving systems. In this work, we propose some enhancements to the PGNNIV
framework that address these scalability limitations through reduced-order
modeling techniques. Specifically, we introduce alternatives to the original
decoder structure using spectral decomposition, POD, and pretrained
autoencoder-based mappings. These surrogate decoders offer varying trade-offs
between computational efficiency, accuracy, noise tolerance, and
generalization, while improving drastically the scalability. Additionally, we
integrate model reuse via transfer learning and fine-tuning strategies to
exploit previously acquired knowledge, supporting efficient adaptation to novel
materials or configurations, and significantly reducing training time while
maintaining or improving model performance. To illustrate these various
techniques, we use a representative case governed by the nonlinear diffusion
equation, using only observable data. Results demonstrate that the enhanced
PGNNIV framework successfully identifies the underlying constitutive state
equations while maintaining high predictive accuracy. It also improves
robustness to noise, mitigates overfitting, and reduces computational demands.
The proposed techniques can be tailored to various scenarios depending on data
availability, resources, and specific modeling objectives, overcoming
scalability challenges in all the scenarios.

</details>


### [127] [Compression-Induced Communication-Efficient Large Model Training and Inferencing](https://arxiv.org/abs/2508.00960)
*Sudip K. Seal,Maksudul Alam,Jorge Ramirez,Sajal Dash,Hao Lu*

Main category: cs.LG

TL;DR: 论文提出了一种名为“phantom parallelism”的新策略，旨在减少大型神经网络训练中的能耗，特别是传统张量并行方法的低效问题。


<details>
  <summary>Details</summary>
Motivation: 大型神经网络训练和推理的能源效率是可持续大规模机器学习的关键挑战，传统张量并行方法能耗高。

Method: 提出了phantom parallelism方法，包括新的前向和反向传播算子，并在端到端训练流程中实现，与传统方法对比。

Result: 实验显示，phantom parallelism能减少约50%的能耗，并在较少GPU上训练较小模型达到相同效果。

Conclusion: phantom parallelism是一种高效节能的替代方案，有望显著降低大型神经网络训练的能源消耗。

Abstract: Energy efficiency of training and inferencing with large neural network
models is a critical challenge facing the future of sustainable large-scale
machine learning workloads. This paper introduces an alternative strategy,
called phantom parallelism, to minimize the net energy consumption of
traditional tensor (model) parallelism, the most energy-inefficient component
of large neural network training. The approach is presented in the context of
feed-forward network architectures as a preliminary, but comprehensive,
proof-of-principle study of the proposed methodology. We derive new forward and
backward propagation operators for phantom parallelism, implement them as
custom autograd operations within an end-to-end phantom parallel training
pipeline and compare its parallel performance and energy-efficiency against
those of conventional tensor parallel training pipelines. Formal analyses that
predict lower bandwidth and FLOP counts are presented with supporting empirical
results on up to 256 GPUs that corroborate these gains. Experiments are shown
to deliver ~50% reduction in the energy consumed to train FFNs using the
proposed phantom parallel approach when compared with conventional tensor
parallel methods. Additionally, the proposed approach is shown to train smaller
phantom models to the same model loss on smaller GPU counts as larger tensor
parallel models on larger GPU counts offering the possibility for even greater
energy savings.

</details>


### [128] [FinKario: Event-Enhanced Automated Construction of Financial Knowledge Graph](https://arxiv.org/abs/2508.00961)
*Xiang Li,Penglei Sun,Wanyun Zhou,Zikai Wei,Yongqi Zhang,Xiaowen Chu*

Main category: cs.LG

TL;DR: 论文提出FinKario和FinKario-RAG方法，通过实时整合市场事件和结构化金融知识，提升LLMs在金融分析中的表现，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 个体投资者在金融市场中处于劣势，缺乏专业分析能力。现有金融研究报告更新慢且非结构化，限制了LLMs的决策支持效果。

Method: 提出FinKario数据集（包含大量实体和关系）和FinKario-RAG检索策略，实时整合市场事件和结构化金融知识。

Result: FinKario与FinKario-RAG在股票趋势预测中表现优异，分别超越金融LLMs和机构策略18.81%和17.85%。

Conclusion: FinKario和FinKario-RAG有效解决了金融知识更新慢和非结构化问题，显著提升了LLMs的金融分析能力。

Abstract: Individual investors are significantly outnumbered and disadvantaged in
financial markets, overwhelmed by abundant information and lacking professional
analysis. Equity research reports stand out as crucial resources, offering
valuable insights. By leveraging these reports, large language models (LLMs)
can enhance investors' decision-making capabilities and strengthen financial
analysis. However, two key challenges limit their effectiveness: (1) the rapid
evolution of market events often outpaces the slow update cycles of existing
knowledge bases, (2) the long-form and unstructured nature of financial reports
further hinders timely and context-aware integration by LLMs. To address these
challenges, we tackle both data and methodological aspects. First, we introduce
the Event-Enhanced Automated Construction of Financial Knowledge Graph
(FinKario), a dataset comprising over 305,360 entities, 9,625 relational
triples, and 19 distinct relation types. FinKario automatically integrates
real-time company fundamentals and market events through prompt-driven
extraction guided by professional institutional templates, providing structured
and accessible financial insights for LLMs. Additionally, we propose a
Two-Stage, Graph-Based retrieval strategy (FinKario-RAG), optimizing the
retrieval of evolving, large-scale financial knowledge to ensure efficient and
precise data access. Extensive experiments show that FinKario with FinKario-RAG
achieves superior stock trend prediction accuracy, outperforming financial LLMs
by 18.81% and institutional strategies by 17.85% on average in backtesting.

</details>


### [129] [Rethinking Multimodality: Optimizing Multimodal Deep Learning for Biomedical Signal Classification](https://arxiv.org/abs/2508.00963)
*Timothy Oladunni,Alex Wong*

Main category: cs.LG

TL;DR: 研究提出了一种新的多模态深度学习方法，分析互补特征域对生物医学信号分类的影响，发现并非所有模态融合都有益。


<details>
  <summary>Details</summary>
Motivation: 探讨多模态融合在生物医学信号分类中的实际效果，验证互补特征域的重要性。

Method: 设计了五种深度学习模型（三种单模态和两种多模态），通过ECG分类任务验证性能。

Result: Hybrid 1（融合时间和时频域）表现最佳，而Hybrid 2（额外加入频域）未带来改进，甚至略有下降。

Conclusion: 多模态设计的核心在于特征域的互补性而非数量，提出了量化互补性的理论框架。

Abstract: This study proposes a novel perspective on multimodal deep learning for
biomedical signal classification, systematically analyzing how complementary
feature domains impact model performance. While fusing multiple domains often
presumes enhanced accuracy, this work demonstrates that adding modalities can
yield diminishing returns, as not all fusions are inherently advantageous. To
validate this, five deep learning models were designed, developed, and
rigorously evaluated: three unimodal (1D-CNN for time, 2D-CNN for
time-frequency, and 1D-CNN-Transformer for frequency) and two multimodal
(Hybrid 1, which fuses 1D-CNN and 2D-CNN; Hybrid 2, which combines 1D-CNN,
2D-CNN, and a Transformer). For ECG classification, bootstrapping and Bayesian
inference revealed that Hybrid 1 consistently outperformed the 2D-CNN baseline
across all metrics (p-values < 0.05, Bayesian probabilities > 0.90), confirming
the synergistic complementarity of the time and time-frequency domains.
Conversely, Hybrid 2's inclusion of the frequency domain offered no further
improvement and sometimes a marginal decline, indicating representational
redundancy; a phenomenon further substantiated by a targeted ablation study.
This research redefines a fundamental principle of multimodal design in
biomedical signal analysis. We demonstrate that optimal domain fusion isn't
about the number of modalities, but the quality of their inherent
complementarity. This paradigm-shifting concept moves beyond purely heuristic
feature selection. Our novel theoretical contribution, "Complementary Feature
Domains in Multimodal ECG Deep Learning," presents a mathematically
quantifiable framework for identifying ideal domain combinations, demonstrating
that optimal multimodal performance arises from the intrinsic
information-theoretic complementarity among fused domains.

</details>


### [130] [Graph Embedding in the Graph Fractional Fourier Transform Domain](https://arxiv.org/abs/2508.02383)
*Changjie Sheng,Zhichao Zhang,Wei Yao*

Main category: cs.LG

TL;DR: 论文提出了一种基于图分数傅里叶变换的广义分数滤波嵌入方法（GEFRFE），通过扩展传统谱嵌入方法，提升了嵌入空间的表现力。


<details>
  <summary>Details</summary>
Motivation: 传统谱嵌入方法在捕捉潜在结构特征方面表现有限，无法充分利用变换域的信息。

Method: 利用图分数傅里叶变换扩展GEFFE方法，引入分数域滤波和非线性特征组合，并通过搜索优化和ResNet18自适应学习动态确定分数阶。

Result: 在六个基准数据集上的实验表明，GEFRFE能捕捉更丰富的结构特征，显著提升分类性能，同时保持与GEFFE相当的计算复杂度。

Conclusion: GEFRFE通过分数域扩展显著提升了谱嵌入的表现力，为图表示学习提供了更高效的方法。

Abstract: Spectral graph embedding plays a critical role in graph representation
learning by generating low-dimensional vector representations from graph
spectral information. However, the embedding space of traditional spectral
embedding methods often exhibit limited expressiveness, failing to exhaustively
capture latent structural features across alternative transform domains. To
address this issue, we use the graph fractional Fourier transform to extend the
existing state-of-the-art generalized frequency filtering embedding (GEFFE)
into fractional domains, giving birth to the generalized fractional filtering
embedding (GEFRFE), which enhances embedding informativeness via the graph
fractional domain. The GEFRFE leverages graph fractional domain filtering and a
nonlinear composition of eigenvector components derived from a fractionalized
graph Laplacian. To dynamically determine the fractional order, two parallel
strategies are introduced: search-based optimization and a ResNet18-based
adaptive learning. Extensive experiments on six benchmark datasets demonstrate
that the GEFRFE captures richer structural features and significantly enhance
classification performance. Notably, the proposed method retains computational
complexity comparable to GEFFE approaches.

</details>


### [131] [VAULT: Vigilant Adversarial Updates via LLM-Driven Retrieval-Augmented Generation for NLI](https://arxiv.org/abs/2508.00965)
*Roie Kazoom,Ofir Cohen,Rami Puzis,Asaf Shabtai,Ofer Hadar*

Main category: cs.LG

TL;DR: VAULT是一个全自动对抗性RAG流程，通过检索、对抗生成和迭代训练三个阶段提升NLI模型的鲁棒性，显著提高了多个基准数据集的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决NLI模型在对抗性数据下的弱点，提升其鲁棒性和准确性。

Method: 采用三阶段流程：平衡少样本检索（结合语义和词汇相似性）、LLM生成对抗性假设并通过验证、迭代注入训练集逐步增强模型。

Result: 在SNLI、ANLI和MultiNLI数据集上分别提升4.12%、5.91%和17.32%的准确性，且优于现有对抗性方法。

Conclusion: VAULT通过自动化高质量对抗数据生成，显著提升了NLI任务的鲁棒性，无需人工干预。

Abstract: We introduce VAULT, a fully automated adversarial RAG pipeline that
systematically uncovers and remedies weaknesses in NLI models through three
stages: retrieval, adversarial generation, and iterative retraining. First, we
perform balanced few-shot retrieval by embedding premises with both semantic
(BGE) and lexical (BM25) similarity. Next, we assemble these contexts into LLM
prompts to generate adversarial hypotheses, which are then validated by an LLM
ensemble for label fidelity. Finally, the validated adversarial examples are
injected back into the training set at increasing mixing ratios, progressively
fortifying a zero-shot RoBERTa-base model.On standard benchmarks, VAULT
elevates RoBERTa-base accuracy from 88.48% to 92.60% on SNLI +4.12%, from
75.04% to 80.95% on ANLI +5.91%, and from 54.67% to 71.99% on MultiNLI +17.32%.
It also consistently outperforms prior in-context adversarial methods by up to
2.0% across datasets. By automating high-quality adversarial data curation at
scale, VAULT enables rapid, human-independent robustness improvements in NLI
inference tasks.

</details>


### [132] [Masked Omics Modeling for Multimodal Representation Learning across Histopathology and Molecular Profiles](https://arxiv.org/abs/2508.00969)
*Lucas Robinet,Ahmad Berjaoui,Elizabeth Cohen-Jonathan Moyal*

Main category: cs.LG

TL;DR: MORPHEUS是一个基于Transformer的多模态预训练框架，整合了组织病理学和多组学数据，通过掩码建模学习跨模态关系，并在多种任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 组织病理学数据不足以全面表征分子特征和临床结果，而多组学数据（如转录组、甲基化组或基因组）包含重要信息。因此，需要一种统一框架来整合这些数据。

Method: MORPHEUS通过掩码建模目标随机选择组学部分，学习跨模态关系，并支持从任何子模态推断组学数据。

Result: MORPHEUS在多种模态组合和任务中优于现有方法，展示了其在肿瘤学多模态基础模型中的潜力。

Conclusion: MORPHEUS是一个有前景的多模态框架，适用于肿瘤学研究和临床应用。

Abstract: Self-supervised learning has driven major advances in computational pathology
by enabling models to learn rich representations from hematoxylin and eosin
(H&E)-stained cancer tissue. However, histopathology alone often falls short
for molecular characterization and understanding clinical outcomes, as
important information is contained in high-dimensional omics profiles like
transcriptomics, methylomics, or genomics. In this work, we introduce MORPHEUS,
a unified transformer-based pre-training framework that encodes both
histopathology and multi-omics data into a shared latent space. At its core,
MORPHEUS relies on a masked modeling objective applied to randomly selected
omics portions, encouraging the model to learn biologically meaningful
cross-modal relationships. The same pre-trained network can be applied to
histopathology alone or in combination with any subset of omics modalities,
seamlessly adapting to the available inputs. Additionally, MORPHEUS enables
any-to-any omics generation, enabling one or more omics profiles to be inferred
from any subset of modalities, including H&E alone. Pre-trained on a large
pan-cancer cohort, MORPHEUS consistently outperforms state-of-the-art methods
across diverse modality combinations and tasks, positioning itself as a
promising framework for developing multimodal foundation models in oncology.
The code is available at: https://github.com/Lucas-rbnt/MORPHEUS

</details>


### [133] [Optimal Scheduling Algorithms for LLM Inference: Theory and Practice](https://arxiv.org/abs/2508.01002)
*Agrim Bari,Parikshit Hegde,Gustavo de Veciana*

Main category: cs.LG

TL;DR: 论文提出了一种针对大型语言模型（LLM）推理系统的调度框架，包括理论模型和实际调度器（RAD和SLAI），显著提升了吞吐量和响应时间。


<details>
  <summary>Details</summary>
Motivation: 随着LLM工具的广泛应用，其独特的双阶段计算结构（预填充和解码）需要新的路由和调度策略。

Method: 提出了理论框架，设计了两大原则（最优分块和动态资源分配），并开发了RAD和SLAI调度器。

Result: 在Mistral-7B模型上测试，SLAI将TTFT中位数降低53%，服务容量提升26%，同时满足尾部TBT延迟约束。

Conclusion: 该研究为LLM推理系统的高效调度提供了理论和实践支持，显著优化了性能。

Abstract: With the growing use of Large Language Model (LLM)-based tools like ChatGPT,
Perplexity, and Gemini across industries, there is a rising need for efficient
LLM inference systems. These systems handle requests with a unique two-phase
computation structure: a prefill-phase that processes the full input prompt and
a decode-phase that autoregressively generates tokens one at a time. This
structure calls for new strategies for routing and scheduling requests.
  In this paper, we take a comprehensive approach to this challenge by
developing a theoretical framework that models routing and scheduling in LLM
inference systems. We identify two key design principles-optimal tiling and
dynamic resource allocation-that are essential for achieving high throughput.
Guided by these principles, we propose the Resource-Aware Dynamic (RAD)
scheduler and prove that it achieves throughput optimality under mild
conditions. To address practical Service Level Objectives (SLOs) such as
serving requests with different Time Between Token (TBT) constraints, we design
the SLO-Aware LLM Inference (SLAI) scheduler. SLAI uses real-time measurements
to prioritize decode requests that are close to missing their TBT deadlines and
reorders prefill requests based on known prompt lengths to further reduce the
Time To First Token (TTFT) delays.
  We evaluate SLAI on the Openchat ShareGPT4 dataset using the Mistral-7B model
on an NVIDIA RTX ADA 6000 GPU. Compared to Sarathi-Serve, SLAI reduces the
median TTFT by 53% and increases the maximum serving capacity by 26% such that
median TTFT is below 0.5 seconds, while meeting tail TBT latency constraints.

</details>


### [134] [v-PuNNs: van der Put Neural Networks for Transparent Ultrametric Representation Learning](https://arxiv.org/abs/2508.01010)
*Gnankan Landry Regis N'guessan*

Main category: cs.LG

TL;DR: v-PuNNs是一种新型神经网络架构，利用p-adic数表示层次结构数据，通过TURL原则和VAPO优化方法，在多个基准测试中取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在欧几里得空间中表示层次结构数据效果不佳，需要一种更精确、可解释的模型。

Method: 提出v-PuNNs架构，神经元为p-adic球的特征函数，采用TURL原则和VAPO优化方法。

Result: 在WordNet、GO和NCBI基准测试中取得最高精度，学习到的度量具有完美超度量性质。

Conclusion: v-PuNNs结合数论与深度学习，为层次数据提供了精确、可解释且高效的模型。

Abstract: Conventional deep learning models embed data in Euclidean space
$\mathbb{R}^d$, a poor fit for strictly hierarchical objects such as taxa, word
senses, or file systems. We introduce van der Put Neural Networks (v-PuNNs),
the first architecture whose neurons are characteristic functions of p-adic
balls in $\mathbb{Z}_p$. Under our Transparent Ultrametric Representation
Learning (TURL) principle every weight is itself a p-adic number, giving exact
subtree semantics. A new Finite Hierarchical Approximation Theorem shows that a
depth-K v-PuNN with $\sum_{j=0}^{K-1}p^{\,j}$ neurons universally represents
any K-level tree. Because gradients vanish in this discrete space, we propose
Valuation-Adaptive Perturbation Optimization (VAPO), with a fast deterministic
variant (HiPaN-DS) and a moment-based one (HiPaN / Adam-VAPO). On three
canonical benchmarks our CPU-only implementation sets new state-of-the-art:
WordNet nouns (52,427 leaves) 99.96% leaf accuracy in 16 min; GO
molecular-function 96.9% leaf / 100% root in 50 s; NCBI Mammalia Spearman $\rho
= -0.96$ with true taxonomic distance. The learned metric is perfectly
ultrametric (zero triangle violations), and its fractal and
information-theoretic properties are analyzed. Beyond classification we derive
structural invariants for quantum systems (HiPaQ) and controllable generative
codes for tabular data (Tab-HiPaN). v-PuNNs therefore bridge number theory and
deep learning, offering exact, interpretable, and efficient models for
hierarchical data.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [135] [DBAIOps: A Reasoning LLM-Enhanced Database Operation and Maintenance System using Knowledge Graphs](https://arxiv.org/abs/2508.01136)
*Wei Zhou,Peng Sun,Xuanhe Zhou,Qianglei Zang,Ji Xu,Tieying Zhang,Guoliang Li,Fan Wu*

Main category: cs.DB

TL;DR: DBAIOps是一种结合推理LLM和知识图谱的混合数据库运维系统，显著提升了诊断准确性和用户体验。


<details>
  <summary>Details</summary>
Motivation: 现有自动数据库运维方法无法有效利用专家经验，规则方法仅支持基础任务，LLM方法生成结果不准确或通用。

Method: DBAIOps采用异构图模型表示诊断经验，构建半自动图谱，开发800+异常模型，并利用两阶段图演化机制和推理LLM进行诊断。

Result: 在四种主流数据库系统中，DBAIOps在根因和人工评估准确性上分别比基线高34.85%和47.22%。

Conclusion: DBAIOps通过结合推理LLM和知识图谱，显著提升了数据库运维的自动化和准确性。

Abstract: The operation and maintenance (O&M) of database systems is critical to
ensuring system availability and performance, typically requiring expert
experience (e.g., identifying metric-to-anomaly relations) for effective
diagnosis and recovery. However, existing automatic database O&M methods,
including commercial products, cannot effectively utilize expert experience. On
the one hand, rule-based methods only support basic O&M tasks (e.g.,
metric-based anomaly detection), which are mostly numerical equations and
cannot effectively incorporate literal O&M experience (e.g., troubleshooting
guidance in manuals). On the other hand, LLM-based methods, which retrieve
fragmented information (e.g., standard documents + RAG), often generate
inaccurate or generic results. To address these limitations, we present
DBAIOps, a novel hybrid database O&M system that combines reasoning LLMs with
knowledge graphs to achieve DBA-style diagnosis. First, DBAIOps introduces a
heterogeneous graph model for representing the diagnosis experience, and
proposes a semi-automatic graph construction algorithm to build that graph from
thousands of documents. Second, DBAIOps develops a collection of (800+)
reusable anomaly models that identify both directly alerted metrics and
implicitly correlated experience and metrics. Third, for each anomaly, DBAIOps
proposes a two-stage graph evolution mechanism to explore relevant diagnosis
paths and identify missing relations automatically. It then leverages a
reasoning LLM (e.g., DeepSeek-R1) to infer root causes and generate clear
diagnosis reports for both DBAs and common users. Our evaluation over four
mainstream database systems (Oracle, MySQL, PostgreSQL, and DM8) demonstrates
that DBAIOps outperforms state-of-the-art baselines, 34.85% and 47.22% higher
in root cause and human evaluation accuracy, respectively.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [136] [Understanding User Preferences for Interaction Styles in Conversational Recommender Systems: The Predictive Role of System Qualities, User Experience, and Traits](https://arxiv.org/abs/2508.02328)
*Raj Mahmud,Shlomo Berkovsky,Mukesh Prasad,A. Baki Kocaballi*

Main category: cs.HC

TL;DR: 研究发现，用户对探索性对话的偏好受享受度、实用性、新颖性和对话质量影响，且年龄、性别和控制偏好显著影响选择。


<details>
  <summary>Details</summary>
Motivation: 探讨影响用户对对话推荐系统（CRS）交互偏好的因素。

Method: 采用被试内设计（N=139），参与者体验两种脚本化CRS对话并评分，通过逻辑回归和聚类分析数据。

Result: 探索性偏好由享受度、实用性、新颖性和对话质量预测；发现五种潜在用户档案；年龄、性别和控制偏好显著影响选择。

Conclusion: 研究为CRS用户建模整合了情感、认知和特质预测因子，并支持动态适应用户需求的对话设计。

Abstract: Conversational Recommender Systems (CRSs) deliver personalised
recommendations through multi-turn natural language dialogue and increasingly
support both task-oriented and exploratory interactions. Yet, the factors
shaping user interaction preferences remain underexplored. In this
within-subjects study (\(N = 139\)), participants experienced two scripted CRS
dialogues, rated their experiences, and indicated the importance of eight
system qualities. Logistic regression revealed that preference for the
exploratory interaction was predicted by enjoyment, usefulness, novelty, and
conversational quality. Unexpectedly, perceived effectiveness was also
associated with exploratory preference. Clustering uncovered five latent user
profiles with distinct dialogue style preferences. Moderation analyses
indicated that age, gender, and control preference significantly influenced
these choices. These findings integrate affective, cognitive, and trait-level
predictors into CRS user modelling and inform autonomy-sensitive,
value-adaptive dialogue design. The proposed predictive and adaptive framework
applies broadly to conversational AI systems seeking to align dynamically with
evolving user needs.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [137] [TreeRanker: Fast and Model-agnostic Ranking System for Code Suggestions in IDEs](https://arxiv.org/abs/2508.02455)
*Daniele Cipollone,Egor Bogomolov,Arie van Deursen,Maliheh Izadi*

Main category: cs.SE

TL;DR: 提出了一种基于语言模型的轻量级、模型无关的代码补全排名方法，通过前缀树和贪婪解码优化补全建议的排名。


<details>
  <summary>Details</summary>
Motivation: 现有代码补全系统依赖手工启发式或轻量级机器学习模型，难以捕捉上下文信息并泛化到不同项目和编码风格。

Method: 将所有有效补全组织为前缀树，通过单次贪婪解码收集令牌级分数，实现无需束搜索、提示工程或模型调整的精确排名。

Result: 方法快速、架构无关，且兼容现有代码补全模型，为IDE工具集成语言模型提供了实用途径。

Conclusion: 该方法为IDE提供了更智能、响应更快的开发者辅助工具，展示了语言模型在现有工具中的实际应用潜力。

Abstract: Token-level code completion is one of the most critical features in modern
Integrated Development Environments (IDEs). It assists developers by suggesting
relevant identifiers and APIs during coding. While completions are typically
derived from static analysis, their usefulness depends heavily on how they are
ranked, as correct predictions buried deep in the list are rarely seen by
users. Most current systems rely on hand-crafted heuristics or lightweight
machine learning models trained on user logs, which can be further improved to
capture context information and generalize across projects and coding styles.
In this work, we propose a new scoring approach to ranking static completions
using language models in a lightweight and model-agnostic way. Our method
organizes all valid completions into a prefix tree and performs a single greedy
decoding pass to collect token-level scores across the tree. This enables a
precise token-aware ranking without needing beam search, prompt engineering, or
model adaptations. The approach is fast, architecture-agnostic, and compatible
with already deployed models for code completion. These findings highlight a
practical and effective pathway for integrating language models into already
existing tools within IDEs, and ultimately providing smarter and more
responsive developer assistance.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [138] [I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking](https://arxiv.org/abs/2508.02243)
*Ziyan Liu,Junwen Li,Kaiwen Li,Tong Ruan,Chao Wang,Xinyan He,Zongyu Wang,Xuezhi Cao,Jingping Liu*

Main category: cs.CV

TL;DR: 提出了一种基于LLM的多模态实体链接框架I2CR，通过文本优先和视觉补充的多轮迭代策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在图像数据冗余和视觉特征一次性提取的问题，影响效果和准确性。

Method: 提出I2CR框架，优先利用文本信息，不足时通过多轮迭代整合视觉线索。

Result: 在三个公开数据集上分别提升3.2%、5.1%和1.6%，优于现有方法。

Conclusion: I2CR框架有效解决了多模态实体链接中的挑战，显著提升了性能。

Abstract: Multimodal entity linking plays a crucial role in a wide range of
applications. Recent advances in large language model-based methods have become
the dominant paradigm for this task, effectively leveraging both textual and
visual modalities to enhance performance. Despite their success, these methods
still face two challenges, including unnecessary incorporation of image data in
certain scenarios and the reliance only on a one-time extraction of visual
features, which can undermine their effectiveness and accuracy. To address
these challenges, we propose a novel LLM-based framework for the multimodal
entity linking task, called Intra- and Inter-modal Collaborative Reflections.
This framework prioritizes leveraging text information to address the task.
When text alone is insufficient to link the correct entity through intra- and
inter-modality evaluations, it employs a multi-round iterative strategy that
integrates key visual clues from various aspects of the image to support
reasoning and enhance matching accuracy. Extensive experiments on three widely
used public datasets demonstrate that our framework consistently outperforms
current state-of-the-art methods in the task, achieving improvements of 3.2%,
5.1%, and 1.6%, respectively. Our code is available at
https://github.com/ziyan-xiaoyu/I2CR/.

</details>


### [139] [Learning Partially-Decorrelated Common Spaces for Ad-hoc Video Search](https://arxiv.org/abs/2508.02340)
*Fan Hu,Zijie Xin,Xirong Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为LPD的方法，通过构建部分解相关的公共空间来解决视频搜索中的视觉多样性问题。


<details>
  <summary>Details</summary>
Motivation: 解决视频搜索中因视觉多样性导致的检索不全面问题。

Method: LPD方法包括特征特定的公共空间构建和解相关损失，以及基于熵的多空间三元组排序损失。

Result: 在TRECVID AVS基准测试中验证了LPD的有效性，并展示了其增强结果多样性的能力。

Conclusion: LPD通过多样化公共空间显著提升了视频搜索的全面性和多样性。

Abstract: Ad-hoc Video Search (AVS) involves using a textual query to search for
multiple relevant videos in a large collection of unlabeled short videos. The
main challenge of AVS is the visual diversity of relevant videos. A simple
query such as "Find shots of a man and a woman dancing together indoors" can
span a multitude of environments, from brightly lit halls and shadowy bars to
dance scenes in black-and-white animations. It is therefore essential to
retrieve relevant videos as comprehensively as possible. Current solutions for
the AVS task primarily fuse multiple features into one or more common spaces,
yet overlook the need for diverse spaces. To fully exploit the expressive
capability of individual features, we propose LPD, short for Learning Partially
Decorrelated common spaces. LPD incorporates two key innovations:
feature-specific common space construction and the de-correlation loss.
Specifically, LPD learns a separate common space for each video and text
feature, and employs de-correlation loss to diversify the ordering of negative
samples across different spaces. To enhance the consistency of multi-space
convergence, we designed an entropy-based fair multi-space triplet ranking
loss. Extensive experiments on the TRECVID AVS benchmarks (2016-2023) justify
the effectiveness of LPD. Moreover, diversity visualizations of LPD's spaces
highlight its ability to enhance result diversity.

</details>


### [140] [Uni-Layout: Integrating Human Feedback in Unified Layout Generation and Evaluation](https://arxiv.org/abs/2508.02374)
*Shuo Lu,Yanyin Chen,Wei Feng,Jiahao Fan,Fengheng Li,Zheng Zhang,Jingjing Lv,Junjie Shen,Ching Law,Jian Liang*

Main category: cs.CV

TL;DR: Uni-Layout是一个统一布局生成与评估的框架，通过自然语言提示处理多种布局任务，并引入大规模人类反馈数据集Layout-HF100k，结合视觉和几何信息进行定性定量评估，动态优化对齐生成与评估。


<details>
  <summary>Details</summary>
Motivation: 当前布局生成方法存在任务特定性强、评估指标与感知不一致的问题，限制了其适用性和有效性。

Method: 提出Uni-Layout框架，包括统一生成器、基于Layout-HF100k的人类模拟评估器，以及动态边际偏好优化（DMPO）对齐两者。

Result: 实验表明Uni-Layout显著优于任务特定和通用方法。

Conclusion: Uni-Layout通过统一生成与评估，结合人类反馈，显著提升了布局生成的适用性和效果。

Abstract: Layout generation plays a crucial role in enhancing both user experience and
design efficiency. However, current approaches suffer from task-specific
generation capabilities and perceptually misaligned evaluation metrics, leading
to limited applicability and ineffective measurement. In this paper, we propose
\textit{Uni-Layout}, a novel framework that achieves unified generation,
human-mimicking evaluation and alignment between the two. For universal
generation, we incorporate various layout tasks into a single taxonomy and
develop a unified generator that handles background or element contents
constrained tasks via natural language prompts. To introduce human feedback for
the effective evaluation of layouts, we build \textit{Layout-HF100k}, the first
large-scale human feedback dataset with 100,000 expertly annotated layouts.
Based on \textit{Layout-HF100k}, we introduce a human-mimicking evaluator that
integrates visual and geometric information, employing a Chain-of-Thought
mechanism to conduct qualitative assessments alongside a confidence estimation
module to yield quantitative measurements. For better alignment between the
generator and the evaluator, we integrate them into a cohesive system by
adopting Dynamic-Margin Preference Optimization (DMPO), which dynamically
adjusts margins based on preference strength to better align with human
judgments. Extensive experiments show that \textit{Uni-Layout} significantly
outperforms both task-specific and general-purpose methods. Our code is
publicly available at https://github.com/JD-GenX/Uni-Layout.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [141] [A Schema.org Mapping for Brazilian Legal Norms: Toward Interoperable Legal Graphs and Open Government Data](https://arxiv.org/abs/2508.00827)
*Hudson de Martim*

Main category: cs.DL

TL;DR: 论文提出了一种将巴西法律数据映射到schema.org/Legislation词汇的方法，以提升法律数据的机器可读性和互操作性。


<details>
  <summary>Details</summary>
Motivation: 解决法律数据机器可读性不足的问题，促进法律科技应用（如法律知识图谱）的发展。

Method: 使用JSON-LD和Linked Data技术，将巴西法律数据统一映射到schema.org/Legislation词汇，涵盖概念实体和数字出版物。

Result: 提出的结构化模式提高了巴西法律数据的质量和互操作性，支持全球开放政府数据生态系统的集成。

Conclusion: 该方法为法律数据的标准化和机器可读性提供了可行方案，有助于推动法律科技的发展。

Abstract: Open Government Data (OGD) initiatives aim to enhance transparency and public
participation by making government data openly accessible. However, structuring
legal norms for machine readability remains a critical challenge for advancing
Legal Tech applications such as Legal Knowledge Graphs (LKGs). Focusing on the
Normas.leg.br portal initiative by the Brazilian National Congress, we propose
a unified mapping of Brazilian legislation to the schema.org/Legislation
vocabulary via JSON-LD and Linked Data. Our approach covers both the conceptual
"Norm" entity (mapped to sdo:Legislation) and its digital publications or
manifestations (mapped to sdo:LegislationObject). We detail key properties for
each type, providing concrete examples and considering URN identifiers (per the
LexML standard), multilingual support, versioning in the Official Journal, and
inter-norm relationships (e.g., citations and references). Our structured
schema improves the quality and interoperability of Brazilian legal data,
fosters integration within the global OGD ecosystem, and facilitates the
creation of a wor

</details>


### [142] [Better Recommendations: Validating AI-generated Subject Terms Through LOC Linked Data Service](https://arxiv.org/abs/2508.00867)
*Kwok Leong Tang,Yi Jiang*

Main category: cs.DL

TL;DR: 探讨AI生成主题词在图书馆编目中的应用，结合LOC关联数据服务验证，提出混合方法提升效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 传统主题编目效率低且积压严重，AI虽有潜力但准确性不足，需结合人工验证改进。

Method: 提出混合方法，结合AI技术与LOC关联数据服务的人工验证。

Result: 混合方法有望提升编目精确性、效率和元数据质量。

Conclusion: AI与人工验证结合是优化图书馆编目的可行方向。

Abstract: This article explores the integration of AI-generated subject terms into
library cataloging, focusing on validation through the Library of Congress
Linked Data Service. It examines the challenges of traditional subject
cataloging under the Library of Congress Subject Headings system, including
inefficiencies and cataloging backlogs. While generative AI shows promise in
expediting cataloging workflows, studies reveal significant limitations in the
accuracy of AI-assigned subject headings. The article proposes a hybrid
approach combining AI technology with human validation through LOC Linked Data
Service, aiming to enhance the precision, efficiency, and overall quality of
metadata creation in library cataloging practices.

</details>
